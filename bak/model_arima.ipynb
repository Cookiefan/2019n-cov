{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.integrate as spi\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['KaiTi'] # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from ncov.reader import get_data,watch_data\n",
    "import statsmodels.tsa.api as smt    \n",
    "from statsmodels.tsa.stattools import adfuller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEIR_cell(torch.nn.Module):\n",
    "    def __init__(self, N, beta_init, gamma_2_init, theta_init):\n",
    "        super(SEIR_cell, self).__init__()\n",
    "        # self.date_len = date_len\n",
    "        self.beta = Parameter(torch.tensor([beta_init], requires_grad=True))\n",
    "        self.N = Parameter(torch.tensor([N], requires_grad=True))\n",
    "        self.gamma_1 = 0.\n",
    "        self.gamma_2 = Parameter(torch.tensor([gamma_2_init], requires_grad=True))\n",
    "        self.alpha = 1.\n",
    "        self.theta = Parameter(torch.tensor([theta_init], requires_grad=True))\n",
    "        # self.E_ratio = Parameter(torch.tensor([3.], requires_grad=True))\n",
    "\n",
    "\n",
    "    def clamp(self, X):\n",
    "        # return torch.clamp(X, min=0, max=self.N)\n",
    "        return X\n",
    "\n",
    "    def forward(self, X):\n",
    "        S, confirm, Exposed, recover, dead = X\n",
    "        # self.beta = beta_old + self.beta_add\n",
    "        # self.gamma_2 = gamma_2_old + self.gamma_2_add\n",
    "        S_rest = self.clamp(S - self.beta*confirm*S/self.N) # dS/dt\n",
    "        E = self.clamp(Exposed + self.beta*confirm*S/self.N - self.alpha*Exposed) # dE/dt\n",
    "\n",
    "        # I = self.clamp(confirm + self.alpha*Exposed - self.gamma_2*confirm - self.theta*confirm) # dI/dt\n",
    "        # R = self.clamp(recover + self.gamma_2*confirm) # dR/dt\n",
    "        # D = self.clamp(dead + self.theta*confirm)\n",
    "        I = self.clamp(confirm + self.alpha*E - self.gamma_2*confirm - self.theta*confirm) # dI/dt\n",
    "        R = self.clamp(recover + self.gamma_2*I) # dR/dt\n",
    "        D = self.clamp(dead + self.theta*I)\n",
    "\n",
    "        return S_rest, I, E, R, D, self.beta, self.gamma_2, self.theta, self.N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SEIR_model(torch.nn.Module):\n",
    "    def __init__(self, date_len, pred_date_len=0, N=2870000., beta_init=0.2586,  gamma_2_init=0.018, theta_init=0.001, E_ratio_init=3., I_init=41, R_init=2., D_init=0.):\n",
    "        super(SEIR_model, self).__init__()\n",
    "        self.date_len = date_len\n",
    "        self.SEIR_cells = torch.nn.ModuleList()\n",
    "        self.SEIR_pred_cells = torch.nn.ModuleList()\n",
    "        self.N = N\n",
    "        self.E_ratio = E_ratio_init\n",
    "        # self.I = (1e-6)*self.N\n",
    "        # self.E = (self.I * self.E_ratio)\n",
    "        # self.R = (1e-6 / 2)*self.N\n",
    "        # self.S = (self.N - self.I - self.E - self.R)\n",
    "        # self.beta = Parameter(torch.tensor([beta_init], requires_grad=True))\n",
    "        # self.gamma_2 = Parameter(torch.tensor([gamma_2_init], requires_grad=True))\n",
    "        self.beta = beta_init\n",
    "        self.gamma_2 = gamma_2_init\n",
    "        self.theta = theta_init\n",
    "        self.I = I_init\n",
    "        self.E = (self.I * self.E_ratio)\n",
    "        self.R = R_init\n",
    "        self.D = D_init\n",
    "        self.S = (self.N - self.I - self.E - self.R - self.D)\n",
    "        self.date_len = date_len-1\n",
    "        self.pred_date_len = pred_date_len\n",
    "        # self.date_total_len = self.date_len + self.pred_date_len\n",
    "        for i in range(self.date_len):\n",
    "            self.SEIR_cells.append(SEIR_cell(self.N,self.beta,self.gamma_2, self.theta))\n",
    "\n",
    "        self.S_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.I_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.E_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.R_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.D_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        inp = self.S, self.I, self.E, self.R, self.D\n",
    "        # param = beta_init, gamma_2_init\n",
    "        S_tensor = torch.zeros((self.date_len+1,))\n",
    "        I_tensor = torch.zeros((self.date_len+1,))\n",
    "        E_tensor = torch.zeros((self.date_len+1,))\n",
    "        R_tensor = torch.zeros((self.date_len+1,))\n",
    "        D_tensor = torch.zeros((self.date_len+1,))\n",
    "        S_tensor[0], I_tensor[0], E_tensor[0], R_tensor[0], D_tensor[0] = inp\n",
    "        for i in range(self.date_len):\n",
    "            S, I, E, R, D, beta_cur, gamma_2_cur, theta_cur, N = self.SEIR_cells[i](inp)\n",
    "            S_tensor[i+1], I_tensor[i+1], E_tensor[i+1], R_tensor[i+1], D_tensor[i+1] = S, I, E, R, D\n",
    "            self.beta = beta_cur\n",
    "            self.gamma_2 = gamma_2_cur\n",
    "            self.theta = theta_cur\n",
    "            self.S_cur = S\n",
    "            self.I_cur = I\n",
    "            self.E_cur = E\n",
    "            self.R_cur = R\n",
    "            self.D_cur = D\n",
    "            self.N_cur = N\n",
    "            inp = [S, I, E, R, D]\n",
    "        self.S_tensor_cur, self.I_tensor_cur, self.E_tensor_cur, self.R_tensor_cur, self.D_tensor_cur = S_tensor, I_tensor, E_tensor, R_tensor, D_tensor\n",
    "        return S_tensor, I_tensor, E_tensor, R_tensor, D_tensor, beta_cur, gamma_2_cur\n",
    "\n",
    "    def pred(self, pred_date_len, N_cur=-1, beta=1e7, gamma_2=1e7, theta=1e7):\n",
    "        if N_cur==-1:\n",
    "            N_cur=self.N_cur\n",
    "        if beta==1e7:\n",
    "            beta=self.beta\n",
    "        if gamma_2==1e7:\n",
    "            gamma_2=self.gamma_2\n",
    "        if theta==1e7:\n",
    "            theta=self.theta\n",
    "\n",
    "        cur_pred_cells_len = len(self.SEIR_pred_cells)\n",
    "        # print(\"cur_pred_cells_len:\", cur_pred_cells_len)\n",
    "        if cur_pred_cells_len!=pred_date_len:\n",
    "            self.SEIR_pred_cells = torch.nn.ModuleList()\n",
    "            for i in range(pred_date_len):\n",
    "                self.SEIR_pred_cells.append(SEIR_cell(N_cur,beta,gamma_2,theta))\n",
    "        S_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        I_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        E_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        R_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        D_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        # pred:\n",
    "        inp = self.S_cur, self.I_cur, self.E_cur, self.R_cur, self.D_cur\n",
    "        for i in range(pred_date_len):\n",
    "            S, I, E, R, D, beta_, gamma_2_, theta_, N_ = self.SEIR_pred_cells[i](inp)\n",
    "            S_pred_tensor[i], I_pred_tensor[i], E_pred_tensor[i], R_pred_tensor[i], D_pred_tensor[i] = S, I, E, R, D\n",
    "            inp = [S, I, E, R, D]\n",
    "        return S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor\n",
    "    \n",
    "    def param_pred(self,beta_list,gamma_2_list,theta_list):\n",
    "        def test_dif(data):\n",
    "            data=pd.DataFrame(data)\n",
    "            dif=0\n",
    "            p_value = adfuller(data)[1]\n",
    "            dif_data=data\n",
    "            while p_value>0.05:\n",
    "                dif=dif+1\n",
    "                dif_data=dif_data.diff(1).dropna()\n",
    "                p_value= adfuller(dif_data)[1]\n",
    "            return dif\n",
    "        datas=[beta_list,gamma_2_list,theta_list]\n",
    "        params=['beta','gamma_2','theta']\n",
    "        param_dict={}\n",
    "        for i in range(len(params)):\n",
    "            param=params[i]\n",
    "            data=datas[i]\n",
    "            if i==0:\n",
    "                if test_dif(data) >2:\n",
    "                    data=data[np.argmax(data):]\n",
    "            data_copy=pd.DataFrame(data,columns=[param])\n",
    "            dif_data=data_copy\n",
    "            dif_data_list=[data_copy.values]\n",
    "            dif=0\n",
    "            p_value = adfuller(data_copy[param])[1]\n",
    "            while p_value>0.05:\n",
    "                dif=dif+1\n",
    "                dif_data=dif_data.diff(1).dropna()\n",
    "    #             print(dif_data)\n",
    "                dif_data_list.append(dif_data.values)\n",
    "                p_value= adfuller(dif_data[param])[1]\n",
    "            print(u'差分序列次数为：',dif)\n",
    "    #         print(u'差分序列的白噪声检验结果为：', acorr_ljungbox(dif_data,lags=1))     \n",
    "            pmax = int(len(data)/10) \n",
    "            qmax = int(len(data)/10)\n",
    "            if dif>1:\n",
    "                d=0\n",
    "                data=dif_data\n",
    "            else:\n",
    "                d=dif\n",
    "            bic_matrix = [] #bic矩阵\n",
    "            for p in range(pmax+1):\n",
    "                tmp = []\n",
    "                for q in range(qmax+1):\n",
    "#                     print(p,q)\n",
    "                    try: #存在部分报错，所以用try来跳过报错。\n",
    "                        tmp.append(smt.ARIMA(data, (p,d,q)).fit().bic)\n",
    "                    except:\n",
    "                        tmp.append(None)\n",
    "                bic_matrix.append(tmp)\n",
    "            bic_matrix = pd.DataFrame(bic_matrix) #从中可以找出最小值\n",
    "            p,q = bic_matrix.stack().astype('float64').idxmin() #先用stack展平，然后用idxmin找出最小值位置。\n",
    "#             print(u'BIC最小的p值和q值为：%s、%s' %(p,q))\n",
    "            \n",
    "            model = smt.ARIMA(data, (p,d,q)).fit() #建立ARIMA(0, 1, 1)模型\n",
    "            model.summary2() #给出一份模型报告\n",
    "            param_dict[param]=model.forecast(1)[0][0]\n",
    "#             print(param_dict[param])\n",
    "            if dif>1:\n",
    "                dif_data_list[-1]=np.append(dif_data_list[-1],param_dict[param])\n",
    "    #             print( dif_data_list[-1])\n",
    "                for i in range(1,dif+1,1):\n",
    "                    dif_data_list[-i-1]=np.append(dif_data_list[-i-1],dif_data_list[-i][-1]+ dif_data_list[-i-1][-1])\n",
    "    #                 print(dif_data_list[-i-1])\n",
    "                param_dict[param]=dif_data_list[0][-1]\n",
    "        return param_dict\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "def plot_daily_acc(data, accumulated_confirmed, accumulated_pred_confirmed, xlen=10, city=u'武汉', pred_date_len=0):\n",
    "    T_name = 'time'\n",
    "    plt.figure(figsize=(xlen, 6))\n",
    "    time_val = data[T_name].values\n",
    "\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1, pred_date_len + 1):\n",
    "        pred_time.append(max_time_val + np.timedelta64(i, 'D'))\n",
    "    if pred_time == []:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time), axis=0)\n",
    "    plt.plot(time_val, accumulated_confirmed, color='red', label='累计确诊人数', marker='x')\n",
    "    plt.plot(merge_time, accumulated_pred_confirmed, color='blue', label='预测的累计确诊人数', marker='x')\n",
    "    for a, b in zip(merge_time, accumulated_pred_confirmed):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 5), textcoords='offset points', color='blue')\n",
    "    for a, b in zip(time_val, accumulated_confirmed):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 20), textcoords='offset points', color='red')\n",
    "    city_title = u'疫情状况-' + city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')\n",
    "    plt.ylabel(u'人数')\n",
    "    plt.savefig(city+u'累计预测')\n",
    "    plt.show()\n",
    "    return\n",
    "def plot_daily_new(data, new_confirm, pred_new_confirm, xlen=10, city=u'武汉', pred_date_len=0):\n",
    "    plt.figure(figsize=(xlen, 6))\n",
    "    T_name = 'time'\n",
    "    time_val = data[T_name].values\n",
    "    time_val = time_val[1:]\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1,pred_date_len+1):\n",
    "        pred_time.append(max_time_val+np.timedelta64(i,'D'))\n",
    "    if pred_time==[]:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time),axis=0)\n",
    "    plt.plot(time_val, new_confirm, color = 'red', label = '新增确诊人数',marker = 'x')\n",
    "    plt.plot(merge_time, pred_new_confirm, color = 'blue',label = '新增累计确诊人数',marker = 'x')\n",
    "    for a,b in zip(merge_time, pred_new_confirm):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,5), textcoords='offset points',color='blue')\n",
    "    for a,b in zip(time_val, new_confirm):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,20), textcoords='offset points',color='red')\n",
    "    city_title = u'疫情状况-'+city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel('日期')\n",
    "    plt.ylabel('人数')\n",
    "    plt.savefig(city+u'新增预测')\n",
    "    plt.show()\n",
    "    return\n",
    "def cal_acc_confirm(I,R,D):\n",
    "    return I+R+D\n",
    "def cal_new_confirm(I,R,D):\n",
    "    acc_confirm = cal_acc_confirm(I,R,D)\n",
    "    new_confirm = np.zeros((len(acc_confirm)-1))\n",
    "    for i in range(len(acc_confirm)-1):\n",
    "        new_confirm[i] = acc_confirm[i+1]-acc_confirm[i]\n",
    "    return new_confirm\n",
    "def get_data_acc_confirm(data,c='confirmed'):\n",
    "    return np.array(data[c])\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "def make_dir(city, date):\n",
    "    save_root_path = 'models/'\n",
    "    model_city_path = os.path.join(save_root_path, city)\n",
    "\n",
    "    model_city_date_path = os.path.join(model_city_path, date)\n",
    "\n",
    "    if not os.path.exists(model_city_date_path):\n",
    "        print(model_city_date_path)\n",
    "        os.makedirs(model_city_date_path)\n",
    "    return model_city_date_path\n",
    "\n",
    "\n",
    "def train(data, model_city_date_path, N=1e7, I_init=1e-6, R_init=1e-6 / 2., D_init=1e-6 / 6.,\n",
    "          features=['accumulated_confirmed', 'accumulated_recovered', 'accumulated_death'], max_epoches=400):\n",
    "    model_pt = os.path.join(model_city_date_path, 'model.pt')\n",
    "    data_feat = data[features]\n",
    "    Input = np.array(data_feat, dtype=np.float)\n",
    "    print(Input.shape)\n",
    "    date_len = len(Input)\n",
    "    print(date_len)\n",
    "    model = SEIR_model(date_len, pred_date_len=10, N=N, I_init=I_init, R_init=R_init, D_init=D_init)\n",
    "\n",
    "    lr = 0.01\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    loss_min = 1e8\n",
    "    for step in range(max_epoches):\n",
    "        print(\"Training step: \", step)\n",
    "        Input = torch.tensor(Input)\n",
    "        model_inp = Input[:-1]\n",
    "        S, I, E, R, D, beta, gamma_2 = model(model_inp.float())\n",
    "        # print(output)\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        pred_confirmed = I\n",
    "        pred_recovered = R\n",
    "        pred_dead = D\n",
    "        # print(pred_confirmed)\n",
    "\n",
    "        confirmed_gt_tensor = Input[:, 0]\n",
    "        recovered_gt_tensor = Input[:, 1]\n",
    "        dead_gt_tensor = Input[:, 2]\n",
    "        # print(recovered_gt_tensor)\n",
    "        # print(pred_confirmed.shape)\n",
    "        # loss = loss_fn(pred_confirmed,confirmed_gt_tensor)\n",
    "        loss = loss_fn(pred_confirmed, confirmed_gt_tensor) + loss_fn(pred_recovered, recovered_gt_tensor) + loss_fn(\n",
    "            pred_dead, dead_gt_tensor)\n",
    "        print(\"Loss: {}\".format(loss))\n",
    "        if loss < loss_min:\n",
    "            loss_min = loss\n",
    "            torch.save(model, model_pt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss_min:\", loss_min)\n",
    "    return S, I, E, R, D\n",
    "def load_model_predict(model_city_date_path, data, N_cur=-1,beta=1e7,gamma_2=1e7,theta=1e7, city_name='深圳',c='confirmed', features=['I','cured','dead'], pred_date_len=5):\n",
    "    I_name,recover_name,dead_name = features\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    I = model.I_tensor_cur\n",
    "    R = model.R_tensor_cur\n",
    "    D = model.D_tensor_cur\n",
    "    I_pred_old = (I.detach().numpy()).astype(np.int)\n",
    "    R_pred_old = (R.detach().numpy()).astype(np.int)\n",
    "    D_pred_old = (D.detach().numpy()).astype(np.int)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    print(confirm_origin)\n",
    "#     plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name)\n",
    "    new_confirm = cal_new_confirm(np.array(data[I_name]),np.array(data[recover_name]),np.array(data[dead_name]))\n",
    "    cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    new_confirm_pred = cal_new_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "\n",
    "    beta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "    gamma_2 = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "    theta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "    if city_name=='深圳':\n",
    "        theta=get_recent_curve(theta)\n",
    "    print(len(theta))\n",
    "    param = model.param_pred(beta,gamma_2,theta)\n",
    "\n",
    "    print(param)\n",
    "    S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(beta=param['beta'],gamma_2=param['gamma_2'],theta=param['theta'], pred_date_len = pred_date_len)\n",
    "    I_pred_new = (I_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    R_pred_new = (R_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    D_pred_new = (D_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    I_pred_total = np.concatenate((I_pred_old,I_pred_new),axis=0)\n",
    "    R_pred_total = np.concatenate((R_pred_old,R_pred_new),axis=0)\n",
    "    D_pred_total = np.concatenate((D_pred_old,D_pred_new),axis=0)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name, pred_date_len=pred_date_len)\n",
    "\n",
    "    new_confirm_pred_total = cal_new_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    new_confirm_pred_total\n",
    "    plot_daily_new(data, new_confirm, new_confirm_pred_total, city=city_name, pred_date_len=pred_date_len)\n",
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data['I'] = data['confirmed']-data['dead']-data['cured']\n",
    "    if 'nation' in path:    #全国有个E\n",
    "        data['E']=data['suspected']+data['close_contact']+data['under_medical_observation']\n",
    "    data['time']= pd.to_datetime(data['time'])\n",
    "    return data\n",
    "def train_with_city_data(data, N, date, cityname='深圳',max_epoches=2000):\n",
    "    city_pinyin = {'深圳':'shenzhen', '湖北':'hubei', '武汉':'wuhan', '全国':'china'}\n",
    "    pinyin = city_pinyin[cityname]\n",
    "    model_city_date_path = make_dir(pinyin,date)\n",
    "    features=['I', 'cured','dead']\n",
    "    I_init = float(data['I'].iloc[0])\n",
    "    R_init = float(data['cured'].iloc[0])\n",
    "    D_init = float(data['dead'].iloc[0])\n",
    "    N = N\n",
    "    #train里面会保存模型\n",
    "    S,I,E,R,D = train(data, model_city_date_path, N=N, I_init=I_init, R_init=R_init, D_init=D_init, features=features, max_epoches=max_epoches)\n",
    "    return model_city_date_path\n",
    "#read data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3)\n",
      "15\n",
      "Training step:  0\n",
      "Loss: 14933.243517727318\n",
      "Training step:  1\n",
      "Loss: 5765.4618840347875\n",
      "Training step:  2\n",
      "Loss: 5757.817207723621\n",
      "Training step:  3\n",
      "Loss: 6019.973681905188\n",
      "Training step:  4\n",
      "Loss: 5443.304327550675\n",
      "Training step:  5\n",
      "Loss: 4708.770600577024\n",
      "Training step:  6\n",
      "Loss: 4333.876125140409\n",
      "Training step:  7\n",
      "Loss: 4143.34768297394\n",
      "Training step:  8\n",
      "Loss: 3864.521298208378\n",
      "Training step:  9\n",
      "Loss: 3587.69783784463\n",
      "Training step:  10\n",
      "Loss: 3361.115383745678\n",
      "Training step:  11\n",
      "Loss: 3139.6730191619336\n",
      "Training step:  12\n",
      "Loss: 2923.4880141890953\n",
      "Training step:  13\n",
      "Loss: 2723.520314327383\n",
      "Training step:  14\n",
      "Loss: 2534.029236329779\n",
      "Training step:  15\n",
      "Loss: 2353.93449395042\n",
      "Training step:  16\n",
      "Loss: 2184.9203400346223\n",
      "Training step:  17\n",
      "Loss: 2026.078274745615\n",
      "Training step:  18\n",
      "Loss: 1877.3053914969419\n",
      "Training step:  19\n",
      "Loss: 1738.6800414881275\n",
      "Training step:  20\n",
      "Loss: 1609.8818230341026\n",
      "Training step:  21\n",
      "Loss: 1490.721333975655\n",
      "Training step:  22\n",
      "Loss: 1380.9156654547132\n",
      "Training step:  23\n",
      "Loss: 1280.081553824605\n",
      "Training step:  24\n",
      "Loss: 1187.792605682183\n",
      "Training step:  25\n",
      "Loss: 1103.5527923012974\n",
      "Training step:  26\n",
      "Loss: 1026.829910767321\n",
      "Training step:  27\n",
      "Loss: 957.0669897431785\n",
      "Training step:  28\n",
      "Loss: 893.694471379671\n",
      "Training step:  29\n",
      "Loss: 836.1466279913531\n",
      "Training step:  30\n",
      "Loss: 783.8725752328064\n",
      "Training step:  31\n",
      "Loss: 736.3467866443052\n",
      "Training step:  32\n",
      "Loss: 693.075876172745\n",
      "Training step:  33\n",
      "Loss: 653.6032501475354\n",
      "Training step:  34\n",
      "Loss: 617.5117738195604\n",
      "Training step:  35\n",
      "Loss: 584.4245532052914\n",
      "Training step:  36\n",
      "Loss: 554.0042956473462\n",
      "Training step:  37\n",
      "Loss: 525.9515426669129\n",
      "Training step:  38\n",
      "Loss: 500.00220093288726\n",
      "Training step:  39\n",
      "Loss: 475.9246209556661\n",
      "Training step:  40\n",
      "Loss: 453.5164618400445\n",
      "Training step:  41\n",
      "Loss: 432.601520666684\n",
      "Training step:  42\n",
      "Loss: 413.0266624475344\n",
      "Training step:  43\n",
      "Loss: 394.65893733446467\n",
      "Training step:  44\n",
      "Loss: 377.3829359013581\n",
      "Training step:  45\n",
      "Loss: 361.0984078115795\n",
      "Training step:  46\n",
      "Loss: 345.71814878563555\n",
      "Training step:  47\n",
      "Loss: 331.1661468917392\n",
      "Training step:  48\n",
      "Loss: 317.3759706724893\n",
      "Training step:  49\n",
      "Loss: 304.2893773330228\n",
      "Training step:  50\n",
      "Loss: 291.85511725793936\n",
      "Training step:  51\n",
      "Loss: 280.02791115688615\n",
      "Training step:  52\n",
      "Loss: 268.76757747251554\n",
      "Training step:  53\n",
      "Loss: 258.0382896549916\n",
      "Training step:  54\n",
      "Loss: 247.80794506398348\n",
      "Training step:  55\n",
      "Loss: 238.04762947146094\n",
      "Training step:  56\n",
      "Loss: 228.73116326104486\n",
      "Training step:  57\n",
      "Loss: 219.83471733217618\n",
      "Training step:  58\n",
      "Loss: 211.33648839070815\n",
      "Training step:  59\n",
      "Loss: 203.21642476604114\n",
      "Training step:  60\n",
      "Loss: 195.45599515298102\n",
      "Training step:  61\n",
      "Loss: 188.03799375093723\n",
      "Training step:  62\n",
      "Loss: 180.94637619341358\n",
      "Training step:  63\n",
      "Loss: 174.16612145500662\n",
      "Training step:  64\n",
      "Loss: 167.6831156105045\n",
      "Training step:  65\n",
      "Loss: 161.48405391739257\n",
      "Training step:  66\n",
      "Loss: 155.55635821335082\n",
      "Training step:  67\n",
      "Loss: 149.88810707467115\n",
      "Training step:  68\n",
      "Loss: 144.46797657750375\n",
      "Training step:  69\n",
      "Loss: 139.28518984801866\n",
      "Training step:  70\n",
      "Loss: 134.3294738853033\n",
      "Training step:  71\n",
      "Loss: 129.59102239671938\n",
      "Training step:  72\n",
      "Loss: 125.06046360376644\n",
      "Training step:  73\n",
      "Loss: 120.72883216123772\n",
      "Training step:  74\n",
      "Loss: 116.58754448753146\n",
      "Training step:  75\n",
      "Loss: 112.62837693289845\n",
      "Training step:  76\n",
      "Loss: 108.84344631878764\n",
      "Training step:  77\n",
      "Loss: 105.22519246846753\n",
      "Training step:  78\n",
      "Loss: 101.7663624197298\n",
      "Training step:  79\n",
      "Loss: 98.4599960674696\n",
      "Training step:  80\n",
      "Loss: 95.29941302962737\n",
      "Training step:  81\n",
      "Loss: 92.27820056649234\n",
      "Training step:  82\n",
      "Loss: 89.39020241247503\n",
      "Training step:  83\n",
      "Loss: 86.62950840267683\n",
      "Training step:  84\n",
      "Loss: 83.99044479514319\n",
      "Training step:  85\n",
      "Loss: 81.46756520463103\n",
      "Training step:  86\n",
      "Loss: 79.05564207583917\n",
      "Training step:  87\n",
      "Loss: 76.74965863398705\n",
      "Training step:  88\n",
      "Loss: 74.5448012589252\n",
      "Training step:  89\n",
      "Loss: 72.43645223592037\n",
      "Training step:  90\n",
      "Loss: 70.42018284226637\n",
      "Training step:  91\n",
      "Loss: 68.49174673405474\n",
      "Training step:  92\n",
      "Loss: 66.64707360201604\n",
      "Training step:  93\n",
      "Loss: 64.88226306938869\n",
      "Training step:  94\n",
      "Loss: 63.19357880838736\n",
      "Training step:  95\n",
      "Loss: 61.577442855079255\n",
      "Training step:  96\n",
      "Loss: 60.03043010536673\n",
      "Training step:  97\n",
      "Loss: 58.549262977376586\n",
      "Training step:  98\n",
      "Loss: 57.130806227849774\n",
      "Training step:  99\n",
      "Loss: 55.77206191218028\n",
      "Training step:  100\n",
      "Loss: 54.470164479542\n",
      "Training step:  101\n",
      "Loss: 53.22237599611125\n",
      "Training step:  102\n",
      "Loss: 52.02608149074494\n",
      "Training step:  103\n",
      "Loss: 50.878784418626275\n",
      "Training step:  104\n",
      "Loss: 49.77810223936401\n",
      "Training step:  105\n",
      "Loss: 48.721762106828386\n",
      "Training step:  106\n",
      "Loss: 47.707596668667534\n",
      "Training step:  107\n",
      "Loss: 46.73353997395921\n",
      "Training step:  108\n",
      "Loss: 45.7976234878558\n",
      "Training step:  109\n",
      "Loss: 44.897972212373574\n",
      "Training step:  110\n",
      "Loss: 44.03280091267891\n",
      "Training step:  111\n",
      "Loss: 43.20041044835225\n",
      "Training step:  112\n",
      "Loss: 42.39918420917497\n",
      "Training step:  113\n",
      "Loss: 41.62758465498705\n",
      "Training step:  114\n",
      "Loss: 40.884149959133254\n",
      "Training step:  115\n",
      "Loss: 40.16749075494676\n",
      "Training step:  116\n",
      "Loss: 39.476286984622355\n",
      "Training step:  117\n",
      "Loss: 38.80928484971945\n",
      "Training step:  118\n",
      "Loss: 38.16529386241158\n",
      "Training step:  119\n",
      "Loss: 37.54318399646024\n",
      "Training step:  120\n",
      "Loss: 36.941882936761615\n",
      "Training step:  121\n",
      "Loss: 36.36037342617497\n",
      "Training step:  122\n",
      "Loss: 35.797690708211235\n",
      "Training step:  123\n",
      "Loss: 35.25292006403284\n",
      "Training step:  124\n",
      "Loss: 34.725194442104645\n",
      "Training step:  125\n",
      "Loss: 34.21369217871463\n",
      "Training step:  126\n",
      "Loss: 33.71763480749753\n",
      "Training step:  127\n",
      "Loss: 33.23628495599927\n",
      "Training step:  128\n",
      "Loss: 32.76894432724279\n",
      "Training step:  129\n",
      "Loss: 32.31495176419422\n",
      "Training step:  130\n",
      "Loss: 31.87368139496995\n",
      "Training step:  131\n",
      "Loss: 31.444540856580392\n",
      "Training step:  132\n",
      "Loss: 31.02696959497633\n",
      "Training step:  133\n",
      "Loss: 30.620437239133334\n",
      "Training step:  134\n",
      "Loss: 30.224442046900457\n",
      "Training step:  135\n",
      "Loss: 29.838509420327824\n",
      "Training step:  136\n",
      "Loss: 29.462190488193816\n",
      "Training step:  137\n",
      "Loss: 29.09506075345665\n",
      "Training step:  138\n",
      "Loss: 28.736718803374206\n",
      "Training step:  139\n",
      "Loss: 28.386785080055326\n",
      "Training step:  140\n",
      "Loss: 28.044900709233367\n",
      "Training step:  141\n",
      "Loss: 27.710726385084484\n",
      "Training step:  142\n",
      "Loss: 27.383941308948643\n",
      "Training step:  143\n",
      "Loss: 27.064242179851217\n",
      "Training step:  144\n",
      "Loss: 26.751342234765705\n",
      "Training step:  145\n",
      "Loss: 26.44497033660406\n",
      "Training step:  146\n",
      "Loss: 26.144870107969176\n",
      "Training step:  147\n",
      "Loss: 25.850799108751417\n",
      "Training step:  148\n",
      "Loss: 25.562528055706558\n",
      "Training step:  149\n",
      "Loss: 25.279840082201325\n",
      "Training step:  150\n",
      "Loss: 25.002530036366913\n",
      "Training step:  151\n",
      "Loss: 24.730403815956535\n",
      "Training step:  152\n",
      "Loss: 24.463277738253854\n",
      "Training step:  153\n",
      "Loss: 24.2009779434361\n",
      "Training step:  154\n",
      "Loss: 23.943339829848917\n",
      "Training step:  155\n",
      "Loss: 23.690207519703513\n",
      "Training step:  156\n",
      "Loss: 23.4414333537599\n",
      "Training step:  157\n",
      "Loss: 23.196877413613123\n",
      "Training step:  158\n",
      "Loss: 22.956407070251768\n",
      "Training step:  159\n",
      "Loss: 22.719896557607026\n",
      "Training step:  160\n",
      "Loss: 22.487226569864134\n",
      "Training step:  161\n",
      "Loss: 22.25828388135311\n",
      "Training step:  162\n",
      "Loss: 22.032960987888412\n",
      "Training step:  163\n",
      "Loss: 21.81115576846859\n",
      "Training step:  164\n",
      "Loss: 21.592771166297908\n",
      "Training step:  165\n",
      "Loss: 21.37771488813284\n",
      "Training step:  166\n",
      "Loss: 21.165899121001473\n",
      "Training step:  167\n",
      "Loss: 20.957240265383383\n",
      "Training step:  168\n",
      "Loss: 20.751658683982924\n",
      "Training step:  169\n",
      "Loss: 20.549078465261946\n",
      "Training step:  170\n",
      "Loss: 20.349427200941182\n",
      "Training step:  171\n",
      "Loss: 20.15263577671339\n",
      "Training step:  172\n",
      "Loss: 19.958638175448815\n",
      "Training step:  173\n",
      "Loss: 19.767371292205034\n",
      "Training step:  174\n",
      "Loss: 19.578774760389592\n",
      "Training step:  175\n",
      "Loss: 19.392790788452782\n",
      "Training step:  176\n",
      "Loss: 19.209364006519202\n",
      "Training step:  177\n",
      "Loss: 19.028441322396784\n",
      "Training step:  178\n",
      "Loss: 18.849971786430054\n",
      "Training step:  179\n",
      "Loss: 18.673906464688727\n",
      "Training step:  180\n",
      "Loss: 18.500198320013833\n",
      "Training step:  181\n",
      "Loss: 18.328802100462067\n",
      "Training step:  182\n",
      "Loss: 18.159674234717755\n",
      "Training step:  183\n",
      "Loss: 17.992772734063177\n",
      "Training step:  184\n",
      "Loss: 17.82805710051644\n",
      "Training step:  185\n",
      "Loss: 17.665488240772813\n",
      "Training step:  186\n",
      "Loss: 17.50502838559932\n",
      "Training step:  187\n",
      "Loss: 17.34664101435515\n",
      "Training step:  188\n",
      "Loss: 17.190290784326386\n",
      "Training step:  189\n",
      "Loss: 17.03594346458211\n",
      "Training step:  190\n",
      "Loss: 16.883565874073586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  191\n",
      "Loss: 16.733125823715053\n",
      "Training step:  192\n",
      "Loss: 16.58459206219989\n",
      "Training step:  193\n",
      "Loss: 16.43793422531712\n",
      "Training step:  194\n",
      "Loss: 16.29312278855084\n",
      "Training step:  195\n",
      "Loss: 16.150129022753763\n",
      "Training step:  196\n",
      "Loss: 16.008924952701108\n",
      "Training step:  197\n",
      "Loss: 15.86948331834003\n",
      "Training step:  198\n",
      "Loss: 15.73177753856297\n",
      "Training step:  199\n",
      "Loss: 15.595781677341897\n",
      "Training step:  200\n",
      "Loss: 15.461470412069945\n",
      "Training step:  201\n",
      "Loss: 15.328819003968244\n",
      "Training step:  202\n",
      "Loss: 15.19780327042152\n",
      "Training step:  203\n",
      "Loss: 15.068399559116743\n",
      "Training step:  204\n",
      "Loss: 14.940584723865072\n",
      "Training step:  205\n",
      "Loss: 14.814336101996386\n",
      "Training step:  206\n",
      "Loss: 14.689631493220876\n",
      "Training step:  207\n",
      "Loss: 14.566449139859676\n",
      "Training step:  208\n",
      "Loss: 14.444767708353131\n",
      "Training step:  209\n",
      "Loss: 14.32456627196003\n",
      "Training step:  210\n",
      "Loss: 14.205824294566764\n",
      "Training step:  211\n",
      "Loss: 14.08852161553217\n",
      "Training step:  212\n",
      "Loss: 13.972638435495575\n",
      "Training step:  213\n",
      "Loss: 13.858155303084267\n",
      "Training step:  214\n",
      "Loss: 13.74505310245545\n",
      "Training step:  215\n",
      "Loss: 13.633313041619573\n",
      "Training step:  216\n",
      "Loss: 13.522916641484645\n",
      "Training step:  217\n",
      "Loss: 13.4138457255802\n",
      "Training step:  218\n",
      "Loss: 13.306082410400789\n",
      "Training step:  219\n",
      "Loss: 13.199609096344762\n",
      "Training step:  220\n",
      "Loss: 13.094408459178563\n",
      "Training step:  221\n",
      "Loss: 12.990463442031158\n",
      "Training step:  222\n",
      "Loss: 12.887757247818405\n",
      "Training step:  223\n",
      "Loss: 12.786273332163757\n",
      "Training step:  224\n",
      "Loss: 12.685995396630519\n",
      "Training step:  225\n",
      "Loss: 12.586907382477017\n",
      "Training step:  226\n",
      "Loss: 12.488993464530898\n",
      "Training step:  227\n",
      "Loss: 12.392238045754215\n",
      "Training step:  228\n",
      "Loss: 12.296625751527445\n",
      "Training step:  229\n",
      "Loss: 12.202141425152124\n",
      "Training step:  230\n",
      "Loss: 12.108770122101436\n",
      "Training step:  231\n",
      "Loss: 12.016497106987938\n",
      "Training step:  232\n",
      "Loss: 11.925307846740125\n",
      "Training step:  233\n",
      "Loss: 11.835188010721774\n",
      "Training step:  234\n",
      "Loss: 11.746123460213491\n",
      "Training step:  235\n",
      "Loss: 11.658100257179031\n",
      "Training step:  236\n",
      "Loss: 11.571104644240561\n",
      "Training step:  237\n",
      "Loss: 11.485123083396681\n",
      "Training step:  238\n",
      "Loss: 11.40014222544156\n",
      "Training step:  239\n",
      "Loss: 11.316149093413559\n",
      "Training step:  240\n",
      "Loss: 11.233131201730599\n",
      "Training step:  241\n",
      "Loss: 11.151077765605425\n",
      "Training step:  242\n",
      "Loss: 11.069982201298048\n",
      "Training step:  243\n",
      "Loss: 10.989852870220194\n",
      "Training step:  244\n",
      "Loss: 10.91074422373282\n",
      "Training step:  245\n",
      "Loss: 10.832869398498003\n",
      "Training step:  246\n",
      "Loss: 10.756965961954274\n",
      "Training step:  247\n",
      "Loss: 10.685581618845607\n",
      "Training step:  248\n",
      "Loss: 10.62742112826826\n",
      "Training step:  249\n",
      "Loss: 10.612930083094033\n",
      "Training step:  250\n",
      "Loss: 10.74710927345207\n",
      "Training step:  251\n",
      "Loss: 11.410647412051267\n",
      "Training step:  252\n",
      "Loss: 13.899916813374634\n",
      "Training step:  253\n",
      "Loss: 23.28456542562884\n",
      "Training step:  254\n",
      "Loss: 55.14614295120313\n",
      "Training step:  255\n",
      "Loss: 183.1593600292103\n",
      "Training step:  256\n",
      "Loss: 529.9783143382901\n",
      "Training step:  257\n",
      "Loss: 2088.902506328456\n",
      "Training step:  258\n",
      "Loss: 1996.4148368115586\n",
      "Training step:  259\n",
      "Loss: 5282.036888001939\n",
      "Training step:  260\n",
      "Loss: 29.99835161661332\n",
      "Training step:  261\n",
      "Loss: 1775.1097920510083\n",
      "Training step:  262\n",
      "Loss: 5362.2597011442795\n",
      "Training step:  263\n",
      "Loss: 119.54847464112645\n",
      "Training step:  264\n",
      "Loss: 3918.1015800749615\n",
      "Training step:  265\n",
      "Loss: 8173.091957528702\n",
      "Training step:  266\n",
      "Loss: 3167.7697800344417\n",
      "Training step:  267\n",
      "Loss: 4798.744485891757\n",
      "Training step:  268\n",
      "Loss: 4246.262677571925\n",
      "Training step:  269\n",
      "Loss: 1712.890723722127\n",
      "Training step:  270\n",
      "Loss: 2032.5000074878492\n",
      "Training step:  271\n",
      "Loss: 662.2450812035968\n",
      "Training step:  272\n",
      "Loss: 214.57024700787983\n",
      "Training step:  273\n",
      "Loss: 397.7448051389758\n",
      "Training step:  274\n",
      "Loss: 79.93051795240746\n",
      "Training step:  275\n",
      "Loss: 42.16100700792692\n",
      "Training step:  276\n",
      "Loss: 61.38293138705451\n",
      "Training step:  277\n",
      "Loss: 14.199482816474987\n",
      "Training step:  278\n",
      "Loss: 16.33643379908411\n",
      "Training step:  279\n",
      "Loss: 15.556287930040885\n",
      "Training step:  280\n",
      "Loss: 10.130350791345258\n",
      "Training step:  281\n",
      "Loss: 11.06569575241363\n",
      "Training step:  282\n",
      "Loss: 10.409928204753001\n",
      "Training step:  283\n",
      "Loss: 9.84675762605735\n",
      "Training step:  284\n",
      "Loss: 9.933697998219522\n",
      "Training step:  285\n",
      "Loss: 9.744023041303752\n",
      "Training step:  286\n",
      "Loss: 9.648646603441714\n",
      "Training step:  287\n",
      "Loss: 9.606368828389828\n",
      "Training step:  288\n",
      "Loss: 9.530615511854474\n",
      "Training step:  289\n",
      "Loss: 9.475414582190751\n",
      "Training step:  290\n",
      "Loss: 9.424181150176171\n",
      "Training step:  291\n",
      "Loss: 9.370808563624282\n",
      "Training step:  292\n",
      "Loss: 9.321695496015641\n",
      "Training step:  293\n",
      "Loss: 9.273720123171554\n",
      "Training step:  294\n",
      "Loss: 9.226626906240506\n",
      "Training step:  295\n",
      "Loss: 9.181026168097178\n",
      "Training step:  296\n",
      "Loss: 9.136400003667429\n",
      "Training step:  297\n",
      "Loss: 9.092719148727088\n",
      "Training step:  298\n",
      "Loss: 9.049987847812057\n",
      "Training step:  299\n",
      "Loss: 9.008089678295159\n",
      "Training step:  300\n",
      "Loss: 8.96698212537759\n",
      "Training step:  301\n",
      "Loss: 8.926622882811284\n",
      "Training step:  302\n",
      "Loss: 8.88696005298538\n",
      "Training step:  303\n",
      "Loss: 8.84795446773125\n",
      "Training step:  304\n",
      "Loss: 8.809569101182532\n",
      "Training step:  305\n",
      "Loss: 8.771768466468576\n",
      "Training step:  306\n",
      "Loss: 8.734520977630595\n",
      "Training step:  307\n",
      "Loss: 8.697797376628218\n",
      "Training step:  308\n",
      "Loss: 8.66157053502985\n",
      "Training step:  309\n",
      "Loss: 8.625815568181645\n",
      "Training step:  310\n",
      "Loss: 8.590509494679049\n",
      "Training step:  311\n",
      "Loss: 8.555631077170927\n",
      "Training step:  312\n",
      "Loss: 8.521160712385633\n",
      "Training step:  313\n",
      "Loss: 8.487080278634693\n",
      "Training step:  314\n",
      "Loss: 8.453373012320826\n",
      "Training step:  315\n",
      "Loss: 8.420023400255964\n",
      "Training step:  316\n",
      "Loss: 8.387017075560316\n",
      "Training step:  317\n",
      "Loss: 8.35434072328493\n",
      "Training step:  318\n",
      "Loss: 8.321981994941716\n",
      "Training step:  319\n",
      "Loss: 8.289929429814562\n",
      "Training step:  320\n",
      "Loss: 8.258172382624165\n",
      "Training step:  321\n",
      "Loss: 8.226700957451374\n",
      "Training step:  322\n",
      "Loss: 8.195505947210286\n",
      "Training step:  323\n",
      "Loss: 8.16457877800794\n",
      "Training step:  324\n",
      "Loss: 8.133911458188074\n",
      "Training step:  325\n",
      "Loss: 8.103496531629379\n",
      "Training step:  326\n",
      "Loss: 8.073327034849946\n",
      "Training step:  327\n",
      "Loss: 8.043396457680455\n",
      "Training step:  328\n",
      "Loss: 8.013698707192688\n",
      "Training step:  329\n",
      "Loss: 7.984228074579635\n",
      "Training step:  330\n",
      "Loss: 7.954979204771706\n",
      "Training step:  331\n",
      "Loss: 7.925947068552366\n",
      "Training step:  332\n",
      "Loss: 7.8971269369561945\n",
      "Training step:  333\n",
      "Loss: 7.86851435777036\n",
      "Training step:  334\n",
      "Loss: 7.840105133960515\n",
      "Training step:  335\n",
      "Loss: 7.8118953038590195\n",
      "Training step:  336\n",
      "Loss: 7.783881122973443\n",
      "Training step:  337\n",
      "Loss: 7.75605904727875\n",
      "Training step:  338\n",
      "Loss: 7.7284257178700155\n",
      "Training step:  339\n",
      "Loss: 7.70097794686496\n",
      "Training step:  340\n",
      "Loss: 7.673712704451102\n",
      "Training step:  341\n",
      "Loss: 7.646627106984198\n",
      "Training step:  342\n",
      "Loss: 7.6197184060506835\n",
      "Training step:  343\n",
      "Loss: 7.592983978415147\n",
      "Training step:  344\n",
      "Loss: 7.566421316779117\n",
      "Training step:  345\n",
      "Loss: 7.540028021285382\n",
      "Training step:  346\n",
      "Loss: 7.513801791705939\n",
      "Training step:  347\n",
      "Loss: 7.487740420257426\n",
      "Training step:  348\n",
      "Loss: 7.461841784992893\n",
      "Training step:  349\n",
      "Loss: 7.436103843722285\n",
      "Training step:  350\n",
      "Loss: 7.410524628418659\n",
      "Training step:  351\n",
      "Loss: 7.385102240070128\n",
      "Training step:  352\n",
      "Loss: 7.359834843941199\n",
      "Training step:  353\n",
      "Loss: 7.334720665209896\n",
      "Training step:  354\n",
      "Loss: 7.309757984950588\n",
      "Training step:  355\n",
      "Loss: 7.28494513643344\n",
      "Training step:  356\n",
      "Loss: 7.2602805017155285\n",
      "Training step:  357\n",
      "Loss: 7.23576250849942\n",
      "Training step:  358\n",
      "Loss: 7.211389627237596\n",
      "Training step:  359\n",
      "Loss: 7.187160368462803\n",
      "Training step:  360\n",
      "Loss: 7.163073280326239\n",
      "Training step:  361\n",
      "Loss: 7.139126946326124\n",
      "Training step:  362\n",
      "Loss: 7.115319983211872\n",
      "Training step:  363\n",
      "Loss: 7.091651039049676\n",
      "Training step:  364\n",
      "Loss: 7.068118791435737\n",
      "Training step:  365\n",
      "Loss: 7.044721945846379\n",
      "Training step:  366\n",
      "Loss: 7.021459234112904\n",
      "Training step:  367\n",
      "Loss: 6.998329413012192\n",
      "Training step:  368\n",
      "Loss: 6.975331262962919\n",
      "Training step:  369\n",
      "Loss: 6.9524635868194355\n",
      "Training step:  370\n",
      "Loss: 6.9297252087553805\n",
      "Training step:  371\n",
      "Loss: 6.907114973229747\n",
      "Training step:  372\n",
      "Loss: 6.88463174402903\n",
      "Training step:  373\n",
      "Loss: 6.862274403379128\n",
      "Training step:  374\n",
      "Loss: 6.840041851121906\n",
      "Training step:  375\n",
      "Loss: 6.817933003950707\n",
      "Training step:  376\n",
      "Loss: 6.795946794700585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  377\n",
      "Loss: 6.774082171689013\n",
      "Training step:  378\n",
      "Loss: 6.75233809810255\n",
      "Training step:  379\n",
      "Loss: 6.730713551426276\n",
      "Training step:  380\n",
      "Loss: 6.709207522912934\n",
      "Training step:  381\n",
      "Loss: 6.687819017087669\n",
      "Training step:  382\n",
      "Loss: 6.666547051286732\n",
      "Training step:  383\n",
      "Loss: 6.645390655226962\n",
      "Training step:  384\n",
      "Loss: 6.624348870603181\n",
      "Training step:  385\n",
      "Loss: 6.603420750712556\n",
      "Training step:  386\n",
      "Loss: 6.582605360102614\n",
      "Training step:  387\n",
      "Loss: 6.561901774241959\n",
      "Training step:  388\n",
      "Loss: 6.541309079211384\n",
      "Training step:  389\n",
      "Loss: 6.5208263714141435\n",
      "Training step:  390\n",
      "Loss: 6.500452757303851\n",
      "Training step:  391\n",
      "Loss: 6.480187353128766\n",
      "Training step:  392\n",
      "Loss: 6.460029284690716\n",
      "Training step:  393\n",
      "Loss: 6.439977687118536\n",
      "Training step:  394\n",
      "Loss: 6.420031704653915\n",
      "Training step:  395\n",
      "Loss: 6.400190490449309\n",
      "Training step:  396\n",
      "Loss: 6.380453206377023\n",
      "Training step:  397\n",
      "Loss: 6.3608190228482755\n",
      "Training step:  398\n",
      "Loss: 6.341287118641967\n",
      "Training step:  399\n",
      "Loss: 6.321856680742092\n",
      "Training step:  400\n",
      "Loss: 6.302526904183298\n",
      "Training step:  401\n",
      "Loss: 6.283296991904054\n",
      "Training step:  402\n",
      "Loss: 6.2641661546069045\n",
      "Training step:  403\n",
      "Loss: 6.2451336106251265\n",
      "Training step:  404\n",
      "Loss: 6.226198585795416\n",
      "Training step:  405\n",
      "Loss: 6.207360313336472\n",
      "Training step:  406\n",
      "Loss: 6.188618033732441\n",
      "Training step:  407\n",
      "Loss: 6.169970994621611\n",
      "Training step:  408\n",
      "Loss: 6.151418450689474\n",
      "Training step:  409\n",
      "Loss: 6.132959663565921\n",
      "Training step:  410\n",
      "Loss: 6.114593901726833\n",
      "Training step:  411\n",
      "Loss: 6.096320440398748\n",
      "Training step:  412\n",
      "Loss: 6.078138561467515\n",
      "Training step:  413\n",
      "Loss: 6.0600475533899125\n",
      "Training step:  414\n",
      "Loss: 6.042046711108395\n",
      "Training step:  415\n",
      "Loss: 6.024135335968593\n",
      "Training step:  416\n",
      "Loss: 6.00631273563949\n",
      "Training step:  417\n",
      "Loss: 5.988578224036125\n",
      "Training step:  418\n",
      "Loss: 5.9709311212446705\n",
      "Training step:  419\n",
      "Loss: 5.953370753449533\n",
      "Training step:  420\n",
      "Loss: 5.935896452862761\n",
      "Training step:  421\n",
      "Loss: 5.918507557655191\n",
      "Training step:  422\n",
      "Loss: 5.901203411889513\n",
      "Training step:  423\n",
      "Loss: 5.883983365455143\n",
      "Training step:  424\n",
      "Loss: 5.866846774004563\n",
      "Training step:  425\n",
      "Loss: 5.849792998891345\n",
      "Training step:  426\n",
      "Loss: 5.832821407109543\n",
      "Training step:  427\n",
      "Loss: 5.815931371234521\n",
      "Training step:  428\n",
      "Loss: 5.7991222693651405\n",
      "Training step:  429\n",
      "Loss: 5.782393485066984\n",
      "Training step:  430\n",
      "Loss: 5.765744407317003\n",
      "Training step:  431\n",
      "Loss: 5.749174430449202\n",
      "Training step:  432\n",
      "Loss: 5.732682954101326\n",
      "Training step:  433\n",
      "Loss: 5.716269383162634\n",
      "Training step:  434\n",
      "Loss: 5.69993312772262\n",
      "Training step:  435\n",
      "Loss: 5.683673603020665\n",
      "Training step:  436\n",
      "Loss: 5.667490229396609\n",
      "Training step:  437\n",
      "Loss: 5.6513824322421184\n",
      "Training step:  438\n",
      "Loss: 5.635349641952874\n",
      "Training step:  439\n",
      "Loss: 5.619391293881552\n",
      "Training step:  440\n",
      "Loss: 5.603506828291627\n",
      "Training step:  441\n",
      "Loss: 5.58769569031158\n",
      "Training step:  442\n",
      "Loss: 5.571957329890388\n",
      "Training step:  443\n",
      "Loss: 5.556291201752954\n",
      "Training step:  444\n",
      "Loss: 5.540696765356766\n",
      "Training step:  445\n",
      "Loss: 5.525173484848891\n",
      "Training step:  446\n",
      "Loss: 5.509720829023631\n",
      "Training step:  447\n",
      "Loss: 5.494338271280588\n",
      "Training step:  448\n",
      "Loss: 5.479025289583706\n",
      "Training step:  449\n",
      "Loss: 5.463781366420252\n",
      "Training step:  450\n",
      "Loss: 5.448605988760995\n",
      "Training step:  451\n",
      "Loss: 5.433498648020191\n",
      "Training step:  452\n",
      "Loss: 5.418458840016576\n",
      "Training step:  453\n",
      "Loss: 5.403486064934677\n",
      "Training step:  454\n",
      "Loss: 5.388579827286523\n",
      "Training step:  455\n",
      "Loss: 5.373739635873686\n",
      "Training step:  456\n",
      "Loss: 5.358965003750196\n",
      "Training step:  457\n",
      "Loss: 5.3442554481853115\n",
      "Training step:  458\n",
      "Loss: 5.3296104906271715\n",
      "Training step:  459\n",
      "Loss: 5.315029656666569\n",
      "Training step:  460\n",
      "Loss: 5.300512476001234\n",
      "Training step:  461\n",
      "Loss: 5.2860584824003825\n",
      "Training step:  462\n",
      "Loss: 5.27166721366987\n",
      "Training step:  463\n",
      "Loss: 5.257338211617459\n",
      "Training step:  464\n",
      "Loss: 5.243071022018528\n",
      "Training step:  465\n",
      "Loss: 5.2288651945822355\n",
      "Training step:  466\n",
      "Loss: 5.214720282917815\n",
      "Training step:  467\n",
      "Loss: 5.200635844501421\n",
      "Training step:  468\n",
      "Loss: 5.186611440643146\n",
      "Training step:  469\n",
      "Loss: 5.172646636454388\n",
      "Training step:  470\n",
      "Loss: 5.158741000815662\n",
      "Training step:  471\n",
      "Loss: 5.144894106344417\n",
      "Training step:  472\n",
      "Loss: 5.131105529363539\n",
      "Training step:  473\n",
      "Loss: 5.1173748498698695\n",
      "Training step:  474\n",
      "Loss: 5.103701651503039\n",
      "Training step:  475\n",
      "Loss: 5.0900855215147995\n",
      "Training step:  476\n",
      "Loss: 5.076526050738323\n",
      "Training step:  477\n",
      "Loss: 5.063022833558032\n",
      "Training step:  478\n",
      "Loss: 5.049575467879597\n",
      "Training step:  479\n",
      "Loss: 5.036183555100185\n",
      "Training step:  480\n",
      "Loss: 5.0228467000789765\n",
      "Training step:  481\n",
      "Loss: 5.009564511107978\n",
      "Training step:  482\n",
      "Loss: 4.996336599883089\n",
      "Training step:  483\n",
      "Loss: 4.983162581475381\n",
      "Training step:  484\n",
      "Loss: 4.970042074302577\n",
      "Training step:  485\n",
      "Loss: 4.9569747001009805\n",
      "Training step:  486\n",
      "Loss: 4.943960083897284\n",
      "Training step:  487\n",
      "Loss: 4.930997853981023\n",
      "Training step:  488\n",
      "Loss: 4.9180876418770145\n",
      "Training step:  489\n",
      "Loss: 4.905229082317995\n",
      "Training step:  490\n",
      "Loss: 4.892421813217658\n",
      "Training step:  491\n",
      "Loss: 4.879665475643815\n",
      "Training step:  492\n",
      "Loss: 4.866959713791739\n",
      "Training step:  493\n",
      "Loss: 4.854304174957773\n",
      "Training step:  494\n",
      "Loss: 4.8416985095132725\n",
      "Training step:  495\n",
      "Loss: 4.829142370878456\n",
      "Training step:  496\n",
      "Loss: 4.81663541549682\n",
      "Training step:  497\n",
      "Loss: 4.804177302809473\n",
      "Training step:  498\n",
      "Loss: 4.7917676952298995\n",
      "Training step:  499\n",
      "Loss: 4.779406258118726\n",
      "Training step:  500\n",
      "Loss: 4.767092659758861\n",
      "Training step:  501\n",
      "Loss: 4.754826571330713\n",
      "Training step:  502\n",
      "Loss: 4.742607666887673\n",
      "Training step:  503\n",
      "Loss: 4.730435623331732\n",
      "Training step:  504\n",
      "Loss: 4.718310120389382\n",
      "Training step:  505\n",
      "Loss: 4.706230840587641\n",
      "Training step:  506\n",
      "Loss: 4.694197469230225\n",
      "Training step:  507\n",
      "Loss: 4.682209694373982\n",
      "Training step:  508\n",
      "Loss: 4.670267206805553\n",
      "Training step:  509\n",
      "Loss: 4.658369700018064\n",
      "Training step:  510\n",
      "Loss: 4.6465168701881225\n",
      "Training step:  511\n",
      "Loss: 4.634708416152956\n",
      "Training step:  512\n",
      "Loss: 4.622944039387751\n",
      "Training step:  513\n",
      "Loss: 4.611223443983065\n",
      "Training step:  514\n",
      "Loss: 4.5995463366226\n",
      "Training step:  515\n",
      "Loss: 4.587912426560996\n",
      "Training step:  516\n",
      "Loss: 4.576321425601803\n",
      "Training step:  517\n",
      "Loss: 4.564773048075714\n",
      "Training step:  518\n",
      "Loss: 4.553267010818912\n",
      "Training step:  519\n",
      "Loss: 4.541803033151573\n",
      "Training step:  520\n",
      "Loss: 4.530380836856555\n",
      "Training step:  521\n",
      "Loss: 4.51900014615824\n",
      "Training step:  522\n",
      "Loss: 4.5076606877015175\n",
      "Training step:  523\n",
      "Loss: 4.496362190531018\n",
      "Training step:  524\n",
      "Loss: 4.485104386070422\n",
      "Training step:  525\n",
      "Loss: 4.473887008101889\n",
      "Training step:  526\n",
      "Loss: 4.462709792745792\n",
      "Training step:  527\n",
      "Loss: 4.451572478440475\n",
      "Training step:  528\n",
      "Loss: 4.4404748059221895\n",
      "Training step:  529\n",
      "Loss: 4.429416518205353\n",
      "Training step:  530\n",
      "Loss: 4.418397360562523\n",
      "Training step:  531\n",
      "Loss: 4.407417080505129\n",
      "Training step:  532\n",
      "Loss: 4.396475427763869\n",
      "Training step:  533\n",
      "Loss: 4.385572154269461\n",
      "Training step:  534\n",
      "Loss: 4.374707014133495\n",
      "Training step:  535\n",
      "Loss: 4.363879763629478\n",
      "Training step:  536\n",
      "Loss: 4.353090161173992\n",
      "Training step:  537\n",
      "Loss: 4.342337967307973\n",
      "Training step:  538\n",
      "Loss: 4.33162294467812\n",
      "Training step:  539\n",
      "Loss: 4.3209448580186\n",
      "Training step:  540\n",
      "Loss: 4.310303474132682\n",
      "Training step:  541\n",
      "Loss: 4.299698561874647\n",
      "Training step:  542\n",
      "Loss: 4.289129892131808\n",
      "Training step:  543\n",
      "Loss: 4.2785972378066335\n",
      "Training step:  544\n",
      "Loss: 4.268100373799062\n",
      "Training step:  545\n",
      "Loss: 4.257639076988888\n",
      "Training step:  546\n",
      "Loss: 4.24721312621848\n",
      "Training step:  547\n",
      "Loss: 4.23682230227518\n",
      "Training step:  548\n",
      "Loss: 4.226466387874446\n",
      "Training step:  549\n",
      "Loss: 4.2161451676426225\n",
      "Training step:  550\n",
      "Loss: 4.205858428100114\n",
      "Training step:  551\n",
      "Loss: 4.195605957644603\n",
      "Training step:  552\n",
      "Loss: 4.185387546534403\n",
      "Training step:  553\n",
      "Loss: 4.175202986871943\n",
      "Training step:  554\n",
      "Loss: 4.165052072587401\n",
      "Training step:  555\n",
      "Loss: 4.154934599422425\n",
      "Training step:  556\n",
      "Loss: 4.144850364914019\n",
      "Training step:  557\n",
      "Loss: 4.13479916837858\n",
      "Training step:  558\n",
      "Loss: 4.124780810895928\n",
      "Training step:  559\n",
      "Loss: 4.114795095293669\n",
      "Training step:  560\n",
      "Loss: 4.104841826131439\n",
      "Training step:  561\n",
      "Loss: 4.094920809685541\n",
      "Training step:  562\n",
      "Loss: 4.085031853933452\n",
      "Training step:  563\n",
      "Loss: 4.075174768538607\n",
      "Training step:  564\n",
      "Loss: 4.065349364835244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  565\n",
      "Loss: 4.055555455813359\n",
      "Training step:  566\n",
      "Loss: 4.045792856103912\n",
      "Training step:  567\n",
      "Loss: 4.036061381963858\n",
      "Training step:  568\n",
      "Loss: 4.026360851261684\n",
      "Training step:  569\n",
      "Loss: 4.016691083462613\n",
      "Training step:  570\n",
      "Loss: 4.0070518996145275\n",
      "Training step:  571\n",
      "Loss: 3.997443122333145\n",
      "Training step:  572\n",
      "Loss: 3.987864575788451\n",
      "Training step:  573\n",
      "Loss: 3.9783160856897495\n",
      "Training step:  574\n",
      "Loss: 3.9687974792729364\n",
      "Training step:  575\n",
      "Loss: 3.95930858528484\n",
      "Training step:  576\n",
      "Loss: 3.949849233971892\n",
      "Training step:  577\n",
      "Loss: 3.9404192570632013\n",
      "Training step:  578\n",
      "Loss: 3.931018487761523\n",
      "Training step:  579\n",
      "Loss: 3.9216467607236125\n",
      "Training step:  580\n",
      "Loss: 3.912303912055545\n",
      "Training step:  581\n",
      "Loss: 3.9029897792874984\n",
      "Training step:  582\n",
      "Loss: 3.8937042013776266\n",
      "Training step:  583\n",
      "Loss: 3.8844470186752185\n",
      "Training step:  584\n",
      "Loss: 3.8752180729420127\n",
      "Training step:  585\n",
      "Loss: 3.8660172072916508\n",
      "Training step:  586\n",
      "Loss: 3.8568442662469447\n",
      "Training step:  587\n",
      "Loss: 3.8476990956310337\n",
      "Training step:  588\n",
      "Loss: 3.8385815427018843\n",
      "Training step:  589\n",
      "Loss: 3.8294914559466227\n",
      "Training step:  590\n",
      "Loss: 3.8204286853901257\n",
      "Training step:  591\n",
      "Loss: 3.8113930822078763\n",
      "Training step:  592\n",
      "Loss: 3.8023844994629794\n",
      "Training step:  593\n",
      "Loss: 3.793402791452523\n",
      "Training step:  594\n",
      "Loss: 3.78444781565902\n",
      "Training step:  595\n",
      "Loss: 3.7755194321660226\n",
      "Training step:  596\n",
      "Loss: 3.7666175097758368\n",
      "Training step:  597\n",
      "Loss: 3.7577419290396654\n",
      "Training step:  598\n",
      "Loss: 3.74889260571\n",
      "Training step:  599\n",
      "Loss: 3.740069520713705\n",
      "Training step:  600\n",
      "Loss: 3.731272827099056\n",
      "Training step:  601\n",
      "Loss: 3.7225030461265693\n",
      "Training step:  602\n",
      "Loss: 3.7137616154899433\n",
      "Training step:  603\n",
      "Loss: 3.705052065343171\n",
      "Training step:  604\n",
      "Loss: 3.696383035694707\n",
      "Training step:  605\n",
      "Loss: 3.6877752163432156\n",
      "Training step:  606\n",
      "Loss: 3.679278733321747\n",
      "Training step:  607\n",
      "Loss: 3.6710143629266505\n",
      "Training step:  608\n",
      "Loss: 3.6632772994644487\n",
      "Training step:  609\n",
      "Loss: 3.6567849877953273\n",
      "Training step:  610\n",
      "Loss: 3.6533176063512376\n",
      "Training step:  611\n",
      "Loss: 3.6572223964046167\n",
      "Training step:  612\n",
      "Loss: 3.679528268324623\n",
      "Training step:  613\n",
      "Loss: 3.7470231860577883\n",
      "Training step:  614\n",
      "Loss: 3.9302629499654036\n",
      "Training step:  615\n",
      "Loss: 4.395541788860529\n",
      "Training step:  616\n",
      "Loss: 5.6143248548979825\n",
      "Training step:  617\n",
      "Loss: 8.59915722160956\n",
      "Training step:  618\n",
      "Loss: 16.718147912156393\n",
      "Training step:  619\n",
      "Loss: 35.481531656429304\n",
      "Training step:  620\n",
      "Loss: 91.43874585270275\n",
      "Training step:  621\n",
      "Loss: 198.71558927652578\n",
      "Training step:  622\n",
      "Loss: 582.8492021838276\n",
      "Training step:  623\n",
      "Loss: 905.3653855073132\n",
      "Training step:  624\n",
      "Loss: 2703.044890502694\n",
      "Training step:  625\n",
      "Loss: 1030.3450803755045\n",
      "Training step:  626\n",
      "Loss: 1607.153198287807\n",
      "Training step:  627\n",
      "Loss: 690.0940618708314\n",
      "Training step:  628\n",
      "Loss: 966.3536564412293\n",
      "Training step:  629\n",
      "Loss: 545.9602949061544\n",
      "Training step:  630\n",
      "Loss: 820.7087951978439\n",
      "Training step:  631\n",
      "Loss: 496.3539643920053\n",
      "Training step:  632\n",
      "Loss: 726.2636909037185\n",
      "Training step:  633\n",
      "Loss: 433.12589540838366\n",
      "Training step:  634\n",
      "Loss: 586.418444216099\n",
      "Training step:  635\n",
      "Loss: 354.9913506930023\n",
      "Training step:  636\n",
      "Loss: 451.72678702571307\n",
      "Training step:  637\n",
      "Loss: 286.6048640359663\n",
      "Training step:  638\n",
      "Loss: 352.8178309433332\n",
      "Training step:  639\n",
      "Loss: 235.8379640379888\n",
      "Training step:  640\n",
      "Loss: 285.06217265003613\n",
      "Training step:  641\n",
      "Loss: 198.9854757315692\n",
      "Training step:  642\n",
      "Loss: 237.24104939358003\n",
      "Training step:  643\n",
      "Loss: 171.31608703663548\n",
      "Training step:  644\n",
      "Loss: 201.91999742992255\n",
      "Training step:  645\n",
      "Loss: 149.92250675451209\n",
      "Training step:  646\n",
      "Loss: 175.14248774479597\n",
      "Training step:  647\n",
      "Loss: 133.20053240067995\n",
      "Training step:  648\n",
      "Loss: 154.656615733178\n",
      "Training step:  649\n",
      "Loss: 120.13299813005604\n",
      "Training step:  650\n",
      "Loss: 138.97347395877875\n",
      "Training step:  651\n",
      "Loss: 109.9839896803043\n",
      "Training step:  652\n",
      "Loss: 127.03390995495295\n",
      "Training step:  653\n",
      "Loss: 102.2011503219728\n",
      "Training step:  654\n",
      "Loss: 118.06983023018782\n",
      "Training step:  655\n",
      "Loss: 96.36526140487067\n",
      "Training step:  656\n",
      "Loss: 111.51458465825085\n",
      "Training step:  657\n",
      "Loss: 92.15246549305157\n",
      "Training step:  658\n",
      "Loss: 106.94182637391691\n",
      "Training step:  659\n",
      "Loss: 89.3084005603313\n",
      "Training step:  660\n",
      "Loss: 104.02573734881788\n",
      "Training step:  661\n",
      "Loss: 87.63037848555686\n",
      "Training step:  662\n",
      "Loss: 102.51279268509779\n",
      "Training step:  663\n",
      "Loss: 86.95294725513726\n",
      "Training step:  664\n",
      "Loss: 102.19910614381686\n",
      "Training step:  665\n",
      "Loss: 87.13513522912416\n",
      "Training step:  666\n",
      "Loss: 102.91156180530875\n",
      "Training step:  667\n",
      "Loss: 88.04942033777671\n",
      "Training step:  668\n",
      "Loss: 104.4923362878389\n",
      "Training step:  669\n",
      "Loss: 89.57267630238557\n",
      "Training step:  670\n",
      "Loss: 106.78663208750424\n",
      "Training step:  671\n",
      "Loss: 91.57934147686377\n",
      "Training step:  672\n",
      "Loss: 109.63379128836509\n",
      "Training step:  673\n",
      "Loss: 93.93725527606101\n",
      "Training step:  674\n",
      "Loss: 112.8624178245183\n",
      "Training step:  675\n",
      "Loss: 96.50674502326626\n",
      "Training step:  676\n",
      "Loss: 116.29029525800651\n",
      "Training step:  677\n",
      "Loss: 99.14337357761832\n",
      "Training step:  678\n",
      "Loss: 119.7295355023217\n",
      "Training step:  679\n",
      "Loss: 101.70423723763075\n",
      "Training step:  680\n",
      "Loss: 122.9965470263752\n",
      "Training step:  681\n",
      "Loss: 104.05694477712728\n",
      "Training step:  682\n",
      "Loss: 125.9252648003711\n",
      "Training step:  683\n",
      "Loss: 106.08963950331534\n",
      "Training step:  684\n",
      "Loss: 128.38102558240814\n",
      "Training step:  685\n",
      "Loss: 107.71995615648129\n",
      "Training step:  686\n",
      "Loss: 130.27198791321172\n",
      "Training step:  687\n",
      "Loss: 108.90089863964086\n",
      "Training step:  688\n",
      "Loss: 131.55542724613724\n",
      "Training step:  689\n",
      "Loss: 109.62233820274737\n",
      "Training step:  690\n",
      "Loss: 132.2375347050238\n",
      "Training step:  691\n",
      "Loss: 109.90793856467226\n",
      "Training step:  692\n",
      "Loss: 132.3670453272599\n",
      "Training step:  693\n",
      "Loss: 109.8084066141942\n",
      "Training step:  694\n",
      "Loss: 132.0244698340977\n",
      "Training step:  695\n",
      "Loss: 109.39266719066488\n",
      "Training step:  696\n",
      "Loss: 131.30942063790448\n",
      "Training step:  697\n",
      "Loss: 108.73870064583491\n",
      "Training step:  698\n",
      "Loss: 130.3284069956998\n",
      "Training step:  699\n",
      "Loss: 107.92544434374845\n",
      "Training step:  700\n",
      "Loss: 129.18477297148848\n",
      "Training step:  701\n",
      "Loss: 107.02657796068608\n",
      "Training step:  702\n",
      "Loss: 127.9715551819348\n",
      "Training step:  703\n",
      "Loss: 106.10643092988205\n",
      "Training step:  704\n",
      "Loss: 126.76726899395669\n",
      "Training step:  705\n",
      "Loss: 105.21782410135182\n",
      "Training step:  706\n",
      "Loss: 125.63414903883805\n",
      "Training step:  707\n",
      "Loss: 104.40143270057152\n",
      "Training step:  708\n",
      "Loss: 124.61817642552968\n",
      "Training step:  709\n",
      "Loss: 103.68620257305419\n",
      "Training step:  710\n",
      "Loss: 123.75024025020544\n",
      "Training step:  711\n",
      "Loss: 103.09040376238076\n",
      "Training step:  712\n",
      "Loss: 123.04790648947242\n",
      "Training step:  713\n",
      "Loss: 102.62300473110663\n",
      "Training step:  714\n",
      "Loss: 122.51742518334918\n",
      "Training step:  715\n",
      "Loss: 102.28515513937957\n",
      "Training step:  716\n",
      "Loss: 122.15575033381266\n",
      "Training step:  717\n",
      "Loss: 102.0716527087082\n",
      "Training step:  718\n",
      "Loss: 121.9524560743412\n",
      "Training step:  719\n",
      "Loss: 101.97233252043024\n",
      "Training step:  720\n",
      "Loss: 121.89150424473777\n",
      "Training step:  721\n",
      "Loss: 101.9733558562371\n",
      "Training step:  722\n",
      "Loss: 121.95285784491432\n",
      "Training step:  723\n",
      "Loss: 102.0583950118245\n",
      "Training step:  724\n",
      "Loss: 122.11395021801249\n",
      "Training step:  725\n",
      "Loss: 102.20971615522876\n",
      "Training step:  726\n",
      "Loss: 122.35101962162898\n",
      "Training step:  727\n",
      "Loss: 102.4091597529491\n",
      "Training step:  728\n",
      "Loss: 122.64031041998874\n",
      "Training step:  729\n",
      "Loss: 102.63901201761787\n",
      "Training step:  730\n",
      "Loss: 122.95913137727614\n",
      "Training step:  731\n",
      "Loss: 102.88275487281014\n",
      "Training step:  732\n",
      "Loss: 123.28675283868394\n",
      "Training step:  733\n",
      "Loss: 103.12567858943038\n",
      "Training step:  734\n",
      "Loss: 123.60512075728424\n",
      "Training step:  735\n",
      "Loss: 103.35534185850032\n",
      "Training step:  736\n",
      "Loss: 123.8993677675802\n",
      "Training step:  737\n",
      "Loss: 103.56186882584522\n",
      "Training step:  738\n",
      "Loss: 124.15810950777585\n",
      "Training step:  739\n",
      "Loss: 103.73808073391407\n",
      "Training step:  740\n",
      "Loss: 124.37352658772514\n",
      "Training step:  741\n",
      "Loss: 103.8794698072572\n",
      "Training step:  742\n",
      "Loss: 124.5412466340796\n",
      "Training step:  743\n",
      "Loss: 103.98403308538904\n",
      "Training step:  744\n",
      "Loss: 124.66005415179195\n",
      "Training step:  745\n",
      "Loss: 104.05199236389998\n",
      "Training step:  746\n",
      "Loss: 124.73146631375258\n",
      "Training step:  747\n",
      "Loss: 104.08543201248497\n",
      "Training step:  748\n",
      "Loss: 124.7592187916913\n",
      "Training step:  749\n",
      "Loss: 104.08788860192836\n",
      "Training step:  750\n",
      "Loss: 124.7487068964835\n",
      "Training step:  751\n",
      "Loss: 104.06392505730383\n",
      "Training step:  752\n",
      "Loss: 124.7064240226748\n",
      "Training step:  753\n",
      "Loss: 104.0187180630825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  754\n",
      "Loss: 124.63943275649363\n",
      "Training step:  755\n",
      "Loss: 103.95768159500973\n",
      "Training step:  756\n",
      "Loss: 124.55489538559277\n",
      "Training step:  757\n",
      "Loss: 103.88614274552339\n",
      "Training step:  758\n",
      "Loss: 124.4596813128296\n",
      "Training step:  759\n",
      "Loss: 103.80907933887187\n",
      "Training step:  760\n",
      "Loss: 124.36006015486652\n",
      "Training step:  761\n",
      "Loss: 103.73092286634412\n",
      "Training step:  762\n",
      "Loss: 124.26148186516404\n",
      "Training step:  763\n",
      "Loss: 103.65542541143282\n",
      "Training step:  764\n",
      "Loss: 124.16843945012566\n",
      "Training step:  765\n",
      "Loss: 103.58558563140488\n",
      "Training step:  766\n",
      "Loss: 124.08440581728841\n",
      "Training step:  767\n",
      "Loss: 103.52362647782546\n",
      "Training step:  768\n",
      "Loss: 124.01183385225711\n",
      "Training step:  769\n",
      "Loss: 103.47101601447798\n",
      "Training step:  770\n",
      "Loss: 123.95220768973667\n",
      "Training step:  771\n",
      "Loss: 103.4285222124363\n",
      "Training step:  772\n",
      "Loss: 123.9061330063688\n",
      "Training step:  773\n",
      "Loss: 103.39629274634714\n",
      "Training step:  774\n",
      "Loss: 123.87345471966059\n",
      "Training step:  775\n",
      "Loss: 103.37395138730716\n",
      "Training step:  776\n",
      "Loss: 123.85339148018649\n",
      "Training step:  777\n",
      "Loss: 103.36070342769995\n",
      "Training step:  778\n",
      "Loss: 123.84467760476386\n",
      "Training step:  779\n",
      "Loss: 103.35544356661434\n",
      "Training step:  780\n",
      "Loss: 123.84570448727568\n",
      "Training step:  781\n",
      "Loss: 103.35686075072358\n",
      "Training step:  782\n",
      "Loss: 123.85465495563618\n",
      "Training step:  783\n",
      "Loss: 103.36353555156278\n",
      "Training step:  784\n",
      "Loss: 123.86962546566603\n",
      "Training step:  785\n",
      "Loss: 103.37402673059519\n",
      "Training step:  786\n",
      "Loss: 123.88873239945062\n",
      "Training step:  787\n",
      "Loss: 103.38694467120358\n",
      "Training step:  788\n",
      "Loss: 123.91020004044215\n",
      "Training step:  789\n",
      "Loss: 103.40101032049196\n",
      "Training step:  790\n",
      "Loss: 123.93242900576428\n",
      "Training step:  791\n",
      "Loss: 103.41509916178887\n",
      "Training step:  792\n",
      "Loss: 123.95404500211167\n",
      "Training step:  793\n",
      "Loss: 103.42827051175023\n",
      "Training step:  794\n",
      "Loss: 123.97392871221014\n",
      "Training step:  795\n",
      "Loss: 103.43978308625465\n",
      "Training step:  796\n",
      "Loss: 123.99122839202617\n",
      "Training step:  797\n",
      "Loss: 103.44909829333098\n",
      "Training step:  798\n",
      "Loss: 124.00535734994148\n",
      "Training step:  799\n",
      "Loss: 103.45587308169418\n",
      "Training step:  800\n",
      "Loss: 124.01597888071468\n",
      "Training step:  801\n",
      "Loss: 103.45994439954323\n",
      "Training step:  802\n",
      "Loss: 124.02298144222925\n",
      "Training step:  803\n",
      "Loss: 103.46130740724787\n",
      "Training step:  804\n",
      "Loss: 124.02644690456525\n",
      "Training step:  805\n",
      "Loss: 103.46008955338552\n",
      "Training step:  806\n",
      "Loss: 124.02661459029143\n",
      "Training step:  807\n",
      "Loss: 103.45652248596356\n",
      "Training step:  808\n",
      "Loss: 124.02384359050428\n",
      "Training step:  809\n",
      "Loss: 103.45091355267209\n",
      "Training step:  810\n",
      "Loss: 124.01857551463925\n",
      "Training step:  811\n",
      "Loss: 103.44361837043627\n",
      "Training step:  812\n",
      "Loss: 124.01129944664493\n",
      "Training step:  813\n",
      "Loss: 103.4350156398024\n",
      "Training step:  814\n",
      "Loss: 124.002520467221\n",
      "Training step:  815\n",
      "Loss: 103.42548506586421\n",
      "Training step:  816\n",
      "Loss: 123.9927326890045\n",
      "Training step:  817\n",
      "Loss: 103.41538894340441\n",
      "Training step:  818\n",
      "Loss: 123.9823973617118\n",
      "Training step:  819\n",
      "Loss: 103.40505768459529\n",
      "Training step:  820\n",
      "Loss: 123.97192625469316\n",
      "Training step:  821\n",
      "Loss: 103.39477932337712\n",
      "Training step:  822\n",
      "Loss: 123.96167022609511\n",
      "Training step:  823\n",
      "Loss: 103.38479282815983\n",
      "Training step:  824\n",
      "Loss: 123.95191264777519\n",
      "Training step:  825\n",
      "Loss: 103.37528489680903\n",
      "Training step:  826\n",
      "Loss: 123.94286717457622\n",
      "Training step:  827\n",
      "Loss: 103.36638979412236\n",
      "Training step:  828\n",
      "Loss: 123.934679223459\n",
      "Training step:  829\n",
      "Loss: 103.35819172076023\n",
      "Training step:  830\n",
      "Loss: 123.92743045855433\n",
      "Training step:  831\n",
      "Loss: 103.35072916856656\n",
      "Training step:  832\n",
      "Loss: 123.92114555502395\n",
      "Training step:  833\n",
      "Loss: 103.34400071588303\n",
      "Training step:  834\n",
      "Loss: 123.9158005307739\n",
      "Training step:  835\n",
      "Loss: 103.33797174154952\n",
      "Training step:  836\n",
      "Loss: 123.91133198273282\n",
      "Training step:  837\n",
      "Loss: 103.33258158222064\n",
      "Training step:  838\n",
      "Loss: 123.90764663522836\n",
      "Training step:  839\n",
      "Loss: 103.32775071772049\n",
      "Training step:  840\n",
      "Loss: 123.9046306944709\n",
      "Training step:  841\n",
      "Loss: 103.32338763916849\n",
      "Training step:  842\n",
      "Loss: 123.90215859916515\n",
      "Training step:  843\n",
      "Loss: 103.3193951283539\n",
      "Training step:  844\n",
      "Loss: 123.90010085542775\n",
      "Training step:  845\n",
      "Loss: 103.31567575108964\n",
      "Training step:  846\n",
      "Loss: 123.89833074087032\n",
      "Training step:  847\n",
      "Loss: 103.31213643807685\n",
      "Training step:  848\n",
      "Loss: 123.89672975267287\n",
      "Training step:  849\n",
      "Loss: 103.30869209144403\n",
      "Training step:  850\n",
      "Loss: 123.89519175508188\n",
      "Training step:  851\n",
      "Loss: 103.30526821163174\n",
      "Training step:  852\n",
      "Loss: 123.89362585074021\n",
      "Training step:  853\n",
      "Loss: 103.30180258662445\n",
      "Training step:  854\n",
      "Loss: 123.89195805650512\n",
      "Training step:  855\n",
      "Loss: 103.29824612254728\n",
      "Training step:  856\n",
      "Loss: 123.89013190704044\n",
      "Training step:  857\n",
      "Loss: 103.29456292195913\n",
      "Training step:  858\n",
      "Loss: 123.88810813933591\n",
      "Training step:  859\n",
      "Loss: 103.29072973345026\n",
      "Training step:  860\n",
      "Loss: 123.88586362838306\n",
      "Training step:  861\n",
      "Loss: 103.28673490477107\n",
      "Training step:  862\n",
      "Loss: 123.8833897507091\n",
      "Training step:  863\n",
      "Loss: 103.28257697271539\n",
      "Training step:  864\n",
      "Loss: 123.88069034940564\n",
      "Training step:  865\n",
      "Loss: 103.27826301734513\n",
      "Training step:  866\n",
      "Loss: 123.87777946342615\n",
      "Training step:  867\n",
      "Loss: 103.27380689743822\n",
      "Training step:  868\n",
      "Loss: 123.8746789671114\n",
      "Training step:  869\n",
      "Loss: 103.26922746961695\n",
      "Training step:  870\n",
      "Loss: 123.87141624528368\n",
      "Training step:  871\n",
      "Loss: 103.26454687695484\n",
      "Training step:  872\n",
      "Loss: 123.86802200614794\n",
      "Training step:  873\n",
      "Loss: 103.25978897486412\n",
      "Training step:  874\n",
      "Loss: 123.86452831028197\n",
      "Training step:  875\n",
      "Loss: 103.25497794406282\n",
      "Training step:  876\n",
      "Loss: 123.86096687043265\n",
      "Training step:  877\n",
      "Loss: 103.25013712308785\n",
      "Training step:  878\n",
      "Loss: 123.85736765484765\n",
      "Training step:  879\n",
      "Loss: 103.24528807708724\n",
      "Training step:  880\n",
      "Loss: 123.85375780709484\n",
      "Training step:  881\n",
      "Loss: 103.2404499056404\n",
      "Training step:  882\n",
      "Loss: 123.8501608783288\n",
      "Training step:  883\n",
      "Loss: 103.23563878091528\n",
      "Training step:  884\n",
      "Loss: 123.84659635432202\n",
      "Training step:  885\n",
      "Loss: 103.2308676982241\n",
      "Training step:  886\n",
      "Loss: 123.84307944870554\n",
      "Training step:  887\n",
      "Loss: 103.22614641411172\n",
      "Training step:  888\n",
      "Loss: 123.83962112649124\n",
      "Training step:  889\n",
      "Loss: 103.22148154299423\n",
      "Training step:  890\n",
      "Loss: 123.83622831769532\n",
      "Training step:  891\n",
      "Loss: 103.21687678078854\n",
      "Training step:  892\n",
      "Loss: 123.832904278674\n",
      "Training step:  893\n",
      "Loss: 103.2123332236511\n",
      "Training step:  894\n",
      "Loss: 123.8296490595385\n",
      "Training step:  895\n",
      "Loss: 103.20784975101938\n",
      "Training step:  896\n",
      "Loss: 123.82646003816451\n",
      "Training step:  897\n",
      "Loss: 103.20342344449745\n",
      "Training step:  898\n",
      "Loss: 123.82333248502124\n",
      "Training step:  899\n",
      "Loss: 103.19905001731436\n",
      "Training step:  900\n",
      "Loss: 123.82026012783422\n",
      "Training step:  901\n",
      "Loss: 103.19472423305842\n",
      "Training step:  902\n",
      "Loss: 123.81723569045933\n",
      "Training step:  903\n",
      "Loss: 103.1904402963995\n",
      "Training step:  904\n",
      "Loss: 123.81425138569956\n",
      "Training step:  905\n",
      "Loss: 103.18619220281839\n",
      "Training step:  906\n",
      "Loss: 123.81129934774702\n",
      "Training step:  907\n",
      "Loss: 103.18197403857414\n",
      "Training step:  908\n",
      "Loss: 123.80837199484269\n",
      "Training step:  909\n",
      "Loss: 103.17778022570943\n",
      "Training step:  910\n",
      "Loss: 123.80546231771979\n",
      "Training step:  911\n",
      "Loss: 103.17360571047918\n",
      "Training step:  912\n",
      "Loss: 123.80256409335682\n",
      "Training step:  913\n",
      "Loss: 103.16944609624213\n",
      "Training step:  914\n",
      "Loss: 123.79967202724237\n",
      "Training step:  915\n",
      "Loss: 103.16529772444994\n",
      "Training step:  916\n",
      "Loss: 123.79678182994522\n",
      "Training step:  917\n",
      "Loss: 103.16115770883542\n",
      "Training step:  918\n",
      "Loss: 123.79389023570332\n",
      "Training step:  919\n",
      "Loss: 103.15702392932161\n",
      "Training step:  920\n",
      "Loss: 123.7909949721749\n",
      "Training step:  921\n",
      "Loss: 103.15289499279625\n",
      "Training step:  922\n",
      "Loss: 123.78809469102893\n",
      "Training step:  923\n",
      "Loss: 103.14877016818721\n",
      "Training step:  924\n",
      "Loss: 123.78518886920827\n",
      "Training step:  925\n",
      "Loss: 103.14464930312302\n",
      "Training step:  926\n",
      "Loss: 123.78227769024566\n",
      "Training step:  927\n",
      "Loss: 103.14053272908255\n",
      "Training step:  928\n",
      "Loss: 123.77936191443193\n",
      "Training step:  929\n",
      "Loss: 103.13642116121335\n",
      "Training step:  930\n",
      "Loss: 123.77644274549547\n",
      "Training step:  931\n",
      "Loss: 103.13231559828125\n",
      "Training step:  932\n",
      "Loss: 123.77352170038175\n",
      "Training step:  933\n",
      "Loss: 103.12821722705846\n",
      "Training step:  934\n",
      "Loss: 123.77060048730854\n",
      "Training step:  935\n",
      "Loss: 103.12412733477274\n",
      "Training step:  936\n",
      "Loss: 123.76768089623872\n",
      "Training step:  937\n",
      "Loss: 103.12004723205024\n",
      "Training step:  938\n",
      "Loss: 123.76476470438168\n",
      "Training step:  939\n",
      "Loss: 103.11597818799876\n",
      "Training step:  940\n",
      "Loss: 123.76185359843267\n",
      "Training step:  941\n",
      "Loss: 103.11192137824652\n",
      "Training step:  942\n",
      "Loss: 123.75894911408146\n",
      "Training step:  943\n",
      "Loss: 103.10787784597171\n",
      "Training step:  944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 123.75605259247756\n",
      "Training step:  945\n",
      "Loss: 103.10384847544881\n",
      "Training step:  946\n",
      "Loss: 123.75316515277714\n",
      "Training step:  947\n",
      "Loss: 103.0998339771609\n",
      "Training step:  948\n",
      "Loss: 123.75028767908707\n",
      "Training step:  949\n",
      "Loss: 103.0958348830669\n",
      "Training step:  950\n",
      "Loss: 123.74742081999945\n",
      "Training step:  951\n",
      "Loss: 103.09185155054925\n",
      "Training step:  952\n",
      "Loss: 123.74456499851944\n",
      "Training step:  953\n",
      "Loss: 103.08788417337566\n",
      "Training step:  954\n",
      "Loss: 123.74172043024805\n",
      "Training step:  955\n",
      "Loss: 103.08393279798811\n",
      "Training step:  956\n",
      "Loss: 123.7388871474938\n",
      "Training step:  957\n",
      "Loss: 103.07999734340412\n",
      "Training step:  958\n",
      "Loss: 123.73606502727304\n",
      "Training step:  959\n",
      "Loss: 103.07607762338998\n",
      "Training step:  960\n",
      "Loss: 123.73325382139467\n",
      "Training step:  961\n",
      "Loss: 103.07217336942689\n",
      "Training step:  962\n",
      "Loss: 123.73045318682746\n",
      "Training step:  963\n",
      "Loss: 103.0682842533559\n",
      "Training step:  964\n",
      "Loss: 123.7276627150165\n",
      "Training step:  965\n",
      "Loss: 103.06440990879643\n",
      "Training step:  966\n",
      "Loss: 123.7248819591035\n",
      "Training step:  967\n",
      "Loss: 103.06054995057924\n",
      "Training step:  968\n",
      "Loss: 123.72211045813863\n",
      "Training step:  969\n",
      "Loss: 103.05670399167711\n",
      "Training step:  970\n",
      "Loss: 123.7193477577348\n",
      "Training step:  971\n",
      "Loss: 103.0528716573658\n",
      "Training step:  972\n",
      "Loss: 123.71659342703603\n",
      "Training step:  973\n",
      "Loss: 103.04905259649189\n",
      "Training step:  974\n",
      "Loss: 123.71384707173077\n",
      "Training step:  975\n",
      "Loss: 103.04524648978801\n",
      "Training step:  976\n",
      "Loss: 123.71110834328641\n",
      "Training step:  977\n",
      "Loss: 103.0414530554179\n",
      "Training step:  978\n",
      "Loss: 123.70837694463074\n",
      "Training step:  979\n",
      "Loss: 103.03767205200222\n",
      "Training step:  980\n",
      "Loss: 123.70565263271347\n",
      "Training step:  981\n",
      "Loss: 103.03390327939081\n",
      "Training step:  982\n",
      "Loss: 123.70293521825016\n",
      "Training step:  983\n",
      "Loss: 103.03014657758126\n",
      "Training step:  984\n",
      "Loss: 123.70022456332201\n",
      "Training step:  985\n",
      "Loss: 103.02640182412131\n",
      "Training step:  986\n",
      "Loss: 123.69752057711182\n",
      "Training step:  987\n",
      "Loss: 103.02266893035163\n",
      "Training step:  988\n",
      "Loss: 123.69482321040647\n",
      "Training step:  989\n",
      "Loss: 103.01894783689224\n",
      "Training step:  990\n",
      "Loss: 123.69213244930275\n",
      "Training step:  991\n",
      "Loss: 103.01523850867633\n",
      "Training step:  992\n",
      "Loss: 123.68944830845237\n",
      "Training step:  993\n",
      "Loss: 103.0115409298019\n",
      "Training step:  994\n",
      "Loss: 123.68677082429903\n",
      "Training step:  995\n",
      "Loss: 103.00785509846509\n",
      "Training step:  996\n",
      "Loss: 123.6841000484933\n",
      "Training step:  997\n",
      "Loss: 103.00418102220937\n",
      "Training step:  998\n",
      "Loss: 123.68143604193851\n",
      "Training step:  999\n",
      "Loss: 103.00051871363443\n",
      "Training step:  1000\n",
      "Loss: 123.67877886936269\n",
      "Training step:  1001\n",
      "Loss: 102.99686818657734\n",
      "Training step:  1002\n",
      "Loss: 123.67612859468802\n",
      "Training step:  1003\n",
      "Loss: 102.99322945296703\n",
      "Training step:  1004\n",
      "Loss: 123.67348527728285\n",
      "Training step:  1005\n",
      "Loss: 102.98960252032087\n",
      "Training step:  1006\n",
      "Loss: 123.67084896905133\n",
      "Training step:  1007\n",
      "Loss: 102.98598738985693\n",
      "Training step:  1008\n",
      "Loss: 123.66821971232183\n",
      "Training step:  1009\n",
      "Loss: 102.9823840552375\n",
      "Training step:  1010\n",
      "Loss: 123.66559753856596\n",
      "Training step:  1011\n",
      "Loss: 102.97879250184963\n",
      "Training step:  1012\n",
      "Loss: 123.66298246774592\n",
      "Training step:  1013\n",
      "Loss: 102.97521270655912\n",
      "Training step:  1014\n",
      "Loss: 123.66037450829255\n",
      "Training step:  1015\n",
      "Loss: 102.97164463795023\n",
      "Training step:  1016\n",
      "Loss: 123.657773657663\n",
      "Training step:  1017\n",
      "Loss: 102.96808825683235\n",
      "Training step:  1018\n",
      "Loss: 123.65517990314709\n",
      "Training step:  1019\n",
      "Loss: 102.96454351702309\n",
      "Training step:  1020\n",
      "Loss: 123.65259322305666\n",
      "Training step:  1021\n",
      "Loss: 102.96101036629044\n",
      "Training step:  1022\n",
      "Loss: 123.65001358804196\n",
      "Training step:  1023\n",
      "Loss: 102.95748874742823\n",
      "Training step:  1024\n",
      "Loss: 123.64744096259635\n",
      "Training step:  1025\n",
      "Loss: 102.95397859938609\n",
      "Training step:  1026\n",
      "Loss: 123.6448753064832\n",
      "Training step:  1027\n",
      "Loss: 102.95047985831457\n",
      "Training step:  1028\n",
      "Loss: 123.64231657616128\n",
      "Training step:  1029\n",
      "Loss: 102.94699245866146\n",
      "Training step:  1030\n",
      "Loss: 123.63976472616129\n",
      "Training step:  1031\n",
      "Loss: 102.94351633408229\n",
      "Training step:  1032\n",
      "Loss: 123.6372197101921\n",
      "Training step:  1033\n",
      "Loss: 102.94005141827017\n",
      "Training step:  1034\n",
      "Loss: 123.63468148221581\n",
      "Training step:  1035\n",
      "Loss: 102.93659764567198\n",
      "Training step:  1036\n",
      "Loss: 123.63214999728436\n",
      "Training step:  1037\n",
      "Loss: 102.93315495206058\n",
      "Training step:  1038\n",
      "Loss: 123.62962521221466\n",
      "Training step:  1039\n",
      "Loss: 102.92972327495247\n",
      "Training step:  1040\n",
      "Loss: 123.62710708605648\n",
      "Training step:  1041\n",
      "Loss: 102.92630255389888\n",
      "Training step:  1042\n",
      "Loss: 123.62459558040581\n",
      "Training step:  1043\n",
      "Loss: 102.92289273067007\n",
      "Training step:  1044\n",
      "Loss: 123.62209065958234\n",
      "Training step:  1045\n",
      "Loss: 102.91949374932013\n",
      "Training step:  1046\n",
      "Loss: 123.61959229066298\n",
      "Training step:  1047\n",
      "Loss: 102.91610555617554\n",
      "Training step:  1048\n",
      "Loss: 123.61710044340612\n",
      "Training step:  1049\n",
      "Loss: 102.91272809972017\n",
      "Training step:  1050\n",
      "Loss: 123.61461509005923\n",
      "Training step:  1051\n",
      "Loss: 102.9093613304386\n",
      "Training step:  1052\n",
      "Loss: 123.61213620514218\n",
      "Training step:  1053\n",
      "Loss: 102.90600520062887\n",
      "Training step:  1054\n",
      "Loss: 123.60966376517477\n",
      "Training step:  1055\n",
      "Loss: 102.90265966416364\n",
      "Training step:  1056\n",
      "Loss: 123.60719774833517\n",
      "Training step:  1057\n",
      "Loss: 102.89932467624891\n",
      "Training step:  1058\n",
      "Loss: 123.60473813416637\n",
      "Training step:  1059\n",
      "Loss: 102.89600019318546\n",
      "Training step:  1060\n",
      "Loss: 123.60228490327027\n",
      "Training step:  1061\n",
      "Loss: 102.89268617217192\n",
      "Training step:  1062\n",
      "Loss: 123.59983803703291\n",
      "Training step:  1063\n",
      "Loss: 102.88938257104503\n",
      "Training step:  1064\n",
      "Loss: 123.5973975172881\n",
      "Training step:  1065\n",
      "Loss: 102.88608934807738\n",
      "Training step:  1066\n",
      "Loss: 123.59496332610556\n",
      "Training step:  1067\n",
      "Loss: 102.88280646184464\n",
      "Training step:  1068\n",
      "Loss: 123.59253544563575\n",
      "Training step:  1069\n",
      "Loss: 102.87953387110214\n",
      "Training step:  1070\n",
      "Loss: 123.5901138579352\n",
      "Training step:  1071\n",
      "Loss: 102.8762715346518\n",
      "Training step:  1072\n",
      "Loss: 123.58769854482182\n",
      "Training step:  1073\n",
      "Loss: 102.87301941126674\n",
      "Training step:  1074\n",
      "Loss: 123.58528948780616\n",
      "Training step:  1075\n",
      "Loss: 102.86977745963712\n",
      "Training step:  1076\n",
      "Loss: 123.58288666801396\n",
      "Training step:  1077\n",
      "Loss: 102.86654563834507\n",
      "Training step:  1078\n",
      "Loss: 123.58049006621307\n",
      "Training step:  1079\n",
      "Loss: 102.86332390586905\n",
      "Training step:  1080\n",
      "Loss: 123.57809966277557\n",
      "Training step:  1081\n",
      "Loss: 102.86011222056281\n",
      "Training step:  1082\n",
      "Loss: 123.57571543769943\n",
      "Training step:  1083\n",
      "Loss: 102.85691054070027\n",
      "Training step:  1084\n",
      "Loss: 123.57333737067243\n",
      "Training step:  1085\n",
      "Loss: 102.85371882450323\n",
      "Training step:  1086\n",
      "Loss: 123.57096544110331\n",
      "Training step:  1087\n",
      "Loss: 102.8505370301836\n",
      "Training step:  1088\n",
      "Loss: 123.5685996281914\n",
      "Training step:  1089\n",
      "Loss: 102.84736511597025\n",
      "Training step:  1090\n",
      "Loss: 123.56623991096637\n",
      "Training step:  1091\n",
      "Loss: 102.84420304018985\n",
      "Training step:  1092\n",
      "Loss: 123.56388626840682\n",
      "Training step:  1093\n",
      "Loss: 102.84105076128783\n",
      "Training step:  1094\n",
      "Loss: 123.5615386794295\n",
      "Training step:  1095\n",
      "Loss: 102.83790823787007\n",
      "Training step:  1096\n",
      "Loss: 123.55919712299922\n",
      "Training step:  1097\n",
      "Loss: 102.83477542875123\n",
      "Training step:  1098\n",
      "Loss: 123.55686157814336\n",
      "Training step:  1099\n",
      "Loss: 102.83165229298135\n",
      "Training step:  1100\n",
      "Loss: 123.55453202402063\n",
      "Training step:  1101\n",
      "Loss: 102.8285387898843\n",
      "Training step:  1102\n",
      "Loss: 123.5522084399565\n",
      "Training step:  1103\n",
      "Loss: 102.82543487908083\n",
      "Training step:  1104\n",
      "Loss: 123.54989080545347\n",
      "Training step:  1105\n",
      "Loss: 102.82234052047426\n",
      "Training step:  1106\n",
      "Loss: 123.54757910020244\n",
      "Training step:  1107\n",
      "Loss: 102.81925567430582\n",
      "Training step:  1108\n",
      "Loss: 123.54527330413964\n",
      "Training step:  1109\n",
      "Loss: 102.81618030112739\n",
      "Training step:  1110\n",
      "Loss: 123.54297339740043\n",
      "Training step:  1111\n",
      "Loss: 102.81311436181416\n",
      "Training step:  1112\n",
      "Loss: 123.54067936034538\n",
      "Training step:  1113\n",
      "Loss: 102.81005781755422\n",
      "Training step:  1114\n",
      "Loss: 123.53839117355353\n",
      "Training step:  1115\n",
      "Loss: 102.80701062985737\n",
      "Training step:  1116\n",
      "Loss: 123.53610881781191\n",
      "Training step:  1117\n",
      "Loss: 102.80397276052608\n",
      "Training step:  1118\n",
      "Loss: 123.53383227412104\n",
      "Training step:  1119\n",
      "Loss: 102.80094417169815\n",
      "Training step:  1120\n",
      "Loss: 123.53156152368814\n",
      "Training step:  1121\n",
      "Loss: 102.79792482575432\n",
      "Training step:  1122\n",
      "Loss: 123.52929654784357\n",
      "Training step:  1123\n",
      "Loss: 102.79491468535859\n",
      "Training step:  1124\n",
      "Loss: 123.52703732812044\n",
      "Training step:  1125\n",
      "Loss: 102.79191371345239\n",
      "Training step:  1126\n",
      "Loss: 123.52478384618661\n",
      "Training step:  1127\n",
      "Loss: 102.7889218731973\n",
      "Training step:  1128\n",
      "Loss: 123.5225360838215\n",
      "Training step:  1129\n",
      "Loss: 102.78593912800775\n",
      "Training step:  1130\n",
      "Loss: 123.52029402294079\n",
      "Training step:  1131\n",
      "Loss: 102.78296544151446\n",
      "Training step:  1132\n",
      "Loss: 123.51805764555544\n",
      "Training step:  1133\n",
      "Loss: 102.78000077757356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1134\n",
      "Loss: 123.51582693379146\n",
      "Training step:  1135\n",
      "Loss: 102.77704510026432\n",
      "Training step:  1136\n",
      "Loss: 123.51360186987618\n",
      "Training step:  1137\n",
      "Loss: 102.77409837384474\n",
      "Training step:  1138\n",
      "Loss: 123.51138243605557\n",
      "Training step:  1139\n",
      "Loss: 102.77116056275919\n",
      "Training step:  1140\n",
      "Loss: 123.5091686147038\n",
      "Training step:  1141\n",
      "Loss: 102.76823163167649\n",
      "Training step:  1142\n",
      "Loss: 123.50696038825627\n",
      "Training step:  1143\n",
      "Loss: 102.76531154542776\n",
      "Training step:  1144\n",
      "Loss: 123.50475773921674\n",
      "Training step:  1145\n",
      "Loss: 102.76240026905262\n",
      "Training step:  1146\n",
      "Loss: 123.50256065016181\n",
      "Training step:  1147\n",
      "Loss: 102.75949776774695\n",
      "Training step:  1148\n",
      "Loss: 123.50036910371497\n",
      "Training step:  1149\n",
      "Loss: 102.75660400691459\n",
      "Training step:  1150\n",
      "Loss: 123.49818308261081\n",
      "Training step:  1151\n",
      "Loss: 102.7537189521418\n",
      "Training step:  1152\n",
      "Loss: 123.4960025696271\n",
      "Training step:  1153\n",
      "Loss: 102.75084256917908\n",
      "Training step:  1154\n",
      "Loss: 123.49382754760096\n",
      "Training step:  1155\n",
      "Loss: 102.74797482397666\n",
      "Training step:  1156\n",
      "Loss: 123.49165799948146\n",
      "Training step:  1157\n",
      "Loss: 102.74511568266968\n",
      "Training step:  1158\n",
      "Loss: 123.48949390825837\n",
      "Training step:  1159\n",
      "Loss: 102.74226511154977\n",
      "Training step:  1160\n",
      "Loss: 123.48733525698528\n",
      "Training step:  1161\n",
      "Loss: 102.7394230771112\n",
      "Training step:  1162\n",
      "Loss: 123.48518202882735\n",
      "Training step:  1163\n",
      "Loss: 102.73658954603346\n",
      "Training step:  1164\n",
      "Loss: 123.48303420701106\n",
      "Training step:  1165\n",
      "Loss: 102.7337644851699\n",
      "Training step:  1166\n",
      "Loss: 123.48089177483543\n",
      "Training step:  1167\n",
      "Loss: 102.73094786156089\n",
      "Training step:  1168\n",
      "Loss: 123.47875471570585\n",
      "Training step:  1169\n",
      "Loss: 102.72813964244513\n",
      "Training step:  1170\n",
      "Loss: 123.47662301309637\n",
      "Training step:  1171\n",
      "Loss: 102.72533979521995\n",
      "Training step:  1172\n",
      "Loss: 123.47449665054626\n",
      "Training step:  1173\n",
      "Loss: 102.72254828746667\n",
      "Training step:  1174\n",
      "Loss: 123.47237561168802\n",
      "Training step:  1175\n",
      "Loss: 102.71976508695836\n",
      "Training step:  1176\n",
      "Loss: 123.47025988024797\n",
      "Training step:  1177\n",
      "Loss: 102.71699016164519\n",
      "Training step:  1178\n",
      "Loss: 123.46814944001729\n",
      "Training step:  1179\n",
      "Loss: 102.71422347964207\n",
      "Training step:  1180\n",
      "Loss: 123.46604427485991\n",
      "Training step:  1181\n",
      "Loss: 102.71146500924962\n",
      "Training step:  1182\n",
      "Loss: 123.46394436873987\n",
      "Training step:  1183\n",
      "Loss: 102.70871471894188\n",
      "Training step:  1184\n",
      "Loss: 123.46184970567697\n",
      "Training step:  1185\n",
      "Loss: 102.70597257735622\n",
      "Training step:  1186\n",
      "Loss: 123.45976026978094\n",
      "Training step:  1187\n",
      "Loss: 102.70323855332052\n",
      "Training step:  1188\n",
      "Loss: 123.45767604524796\n",
      "Training step:  1189\n",
      "Loss: 102.70051261582019\n",
      "Training step:  1190\n",
      "Loss: 123.45559701633368\n",
      "Training step:  1191\n",
      "Loss: 102.69779473401046\n",
      "Training step:  1192\n",
      "Loss: 123.45352316736725\n",
      "Training step:  1193\n",
      "Loss: 102.69508487720361\n",
      "Training step:  1194\n",
      "Loss: 123.45145448274755\n",
      "Training step:  1195\n",
      "Loss: 102.69238301488016\n",
      "Training step:  1196\n",
      "Loss: 123.44939094695171\n",
      "Training step:  1197\n",
      "Loss: 102.68968911670078\n",
      "Training step:  1198\n",
      "Loss: 123.44733254454582\n",
      "Training step:  1199\n",
      "Loss: 102.68700315246802\n",
      "Training step:  1200\n",
      "Loss: 123.44527926012181\n",
      "Training step:  1201\n",
      "Loss: 102.68432509212914\n",
      "Training step:  1202\n",
      "Loss: 123.44323107835012\n",
      "Training step:  1203\n",
      "Loss: 102.68165490582173\n",
      "Training step:  1204\n",
      "Loss: 123.44118798400537\n",
      "Training step:  1205\n",
      "Loss: 102.67899256381642\n",
      "Training step:  1206\n",
      "Loss: 123.43914996188047\n",
      "Training step:  1207\n",
      "Loss: 102.67633803655339\n",
      "Training step:  1208\n",
      "Loss: 123.43711699687714\n",
      "Training step:  1209\n",
      "Loss: 102.67369129462453\n",
      "Training step:  1210\n",
      "Loss: 123.43508907393924\n",
      "Training step:  1211\n",
      "Loss: 102.67105230877134\n",
      "Training step:  1212\n",
      "Loss: 123.43306617807802\n",
      "Training step:  1213\n",
      "Loss: 102.66842104987349\n",
      "Training step:  1214\n",
      "Loss: 123.43104829434927\n",
      "Training step:  1215\n",
      "Loss: 102.66579748897237\n",
      "Training step:  1216\n",
      "Loss: 123.42903540790333\n",
      "Training step:  1217\n",
      "Loss: 102.66318159726508\n",
      "Training step:  1218\n",
      "Loss: 123.42702750394328\n",
      "Training step:  1219\n",
      "Loss: 102.6605733460887\n",
      "Training step:  1220\n",
      "Loss: 123.42502456773182\n",
      "Training step:  1221\n",
      "Loss: 102.6579727069277\n",
      "Training step:  1222\n",
      "Loss: 123.42302658459525\n",
      "Training step:  1223\n",
      "Loss: 102.65537965141029\n",
      "Training step:  1224\n",
      "Loss: 123.42103353990595\n",
      "Training step:  1225\n",
      "Loss: 102.65279415129717\n",
      "Training step:  1226\n",
      "Loss: 123.41904541910564\n",
      "Training step:  1227\n",
      "Loss: 102.65021617851454\n",
      "Training step:  1228\n",
      "Loss: 123.41706220771509\n",
      "Training step:  1229\n",
      "Loss: 102.64764570512415\n",
      "Training step:  1230\n",
      "Loss: 123.41508389129184\n",
      "Training step:  1231\n",
      "Loss: 102.64508270331558\n",
      "Training step:  1232\n",
      "Loss: 123.41311045545238\n",
      "Training step:  1233\n",
      "Loss: 102.64252714542927\n",
      "Training step:  1234\n",
      "Loss: 123.411141885883\n",
      "Training step:  1235\n",
      "Loss: 102.63997900394506\n",
      "Training step:  1236\n",
      "Loss: 123.40917816833162\n",
      "Training step:  1237\n",
      "Loss: 102.63743825148707\n",
      "Training step:  1238\n",
      "Loss: 123.40721928859679\n",
      "Training step:  1239\n",
      "Loss: 102.63490486080293\n",
      "Training step:  1240\n",
      "Loss: 123.40526523254383\n",
      "Training step:  1241\n",
      "Loss: 102.63237880479322\n",
      "Training step:  1242\n",
      "Loss: 123.40331598608383\n",
      "Training step:  1243\n",
      "Loss: 102.6298600564767\n",
      "Training step:  1244\n",
      "Loss: 123.40137153519034\n",
      "Training step:  1245\n",
      "Loss: 102.62734858901045\n",
      "Training step:  1246\n",
      "Loss: 123.39943186587742\n",
      "Training step:  1247\n",
      "Loss: 102.6248443756856\n",
      "Training step:  1248\n",
      "Loss: 123.39749696424403\n",
      "Training step:  1249\n",
      "Loss: 102.62234738993267\n",
      "Training step:  1250\n",
      "Loss: 123.39556681642101\n",
      "Training step:  1251\n",
      "Loss: 102.61985760530503\n",
      "Training step:  1252\n",
      "Loss: 123.39364140862222\n",
      "Training step:  1253\n",
      "Loss: 102.61737499551226\n",
      "Training step:  1254\n",
      "Loss: 123.39172072711348\n",
      "Training step:  1255\n",
      "Loss: 102.61489953437093\n",
      "Training step:  1256\n",
      "Loss: 123.38980475819689\n",
      "Training step:  1257\n",
      "Loss: 102.61243119582298\n",
      "Training step:  1258\n",
      "Loss: 123.38789348823006\n",
      "Training step:  1259\n",
      "Loss: 102.60996995394028\n",
      "Training step:  1260\n",
      "Loss: 123.38598690361668\n",
      "Training step:  1261\n",
      "Loss: 102.60751578292117\n",
      "Training step:  1262\n",
      "Loss: 123.38408499083\n",
      "Training step:  1263\n",
      "Loss: 102.60506865709269\n",
      "Training step:  1264\n",
      "Loss: 123.38218773638663\n",
      "Training step:  1265\n",
      "Loss: 102.60262855089643\n",
      "Training step:  1266\n",
      "Loss: 123.38029512683605\n",
      "Training step:  1267\n",
      "Loss: 102.60019543890975\n",
      "Training step:  1268\n",
      "Loss: 123.37840714883797\n",
      "Training step:  1269\n",
      "Loss: 102.59776929585033\n",
      "Training step:  1270\n",
      "Loss: 123.3765237890669\n",
      "Training step:  1271\n",
      "Loss: 102.5953500965356\n",
      "Training step:  1272\n",
      "Loss: 123.37464503424874\n",
      "Training step:  1273\n",
      "Loss: 102.59293781589713\n",
      "Training step:  1274\n",
      "Loss: 123.37277087114653\n",
      "Training step:  1275\n",
      "Loss: 102.59053242900302\n",
      "Training step:  1276\n",
      "Loss: 123.37090128660166\n",
      "Training step:  1277\n",
      "Loss: 102.58813391103408\n",
      "Training step:  1278\n",
      "Loss: 123.36903626749293\n",
      "Training step:  1279\n",
      "Loss: 102.58574223729615\n",
      "Training step:  1280\n",
      "Loss: 123.36717580074117\n",
      "Training step:  1281\n",
      "Loss: 102.58335738319249\n",
      "Training step:  1282\n",
      "Loss: 123.3653198733111\n",
      "Training step:  1283\n",
      "Loss: 102.58097932426658\n",
      "Training step:  1284\n",
      "Loss: 123.36346847225235\n",
      "Training step:  1285\n",
      "Loss: 102.57860803619101\n",
      "Training step:  1286\n",
      "Loss: 123.3616215846599\n",
      "Training step:  1287\n",
      "Loss: 102.57624349473016\n",
      "Training step:  1288\n",
      "Loss: 123.35977919764014\n",
      "Training step:  1289\n",
      "Loss: 102.5738856757633\n",
      "Training step:  1290\n",
      "Loss: 123.35794129836964\n",
      "Training step:  1291\n",
      "Loss: 102.57153455529021\n",
      "Training step:  1292\n",
      "Loss: 123.35610787407381\n",
      "Training step:  1293\n",
      "Loss: 102.56919010942548\n",
      "Training step:  1294\n",
      "Loss: 123.35427891201627\n",
      "Training step:  1295\n",
      "Loss: 102.56685231438698\n",
      "Training step:  1296\n",
      "Loss: 123.35245439951076\n",
      "Training step:  1297\n",
      "Loss: 102.56452114650843\n",
      "Training step:  1298\n",
      "Loss: 123.3506343239152\n",
      "Training step:  1299\n",
      "Loss: 102.56219658224016\n",
      "Training step:  1300\n",
      "Loss: 123.34881867265366\n",
      "Training step:  1301\n",
      "Loss: 102.55987859814785\n",
      "Training step:  1302\n",
      "Loss: 123.34700743317828\n",
      "Training step:  1303\n",
      "Loss: 102.55756717088185\n",
      "Training step:  1304\n",
      "Loss: 123.34520059296852\n",
      "Training step:  1305\n",
      "Loss: 102.55526227722244\n",
      "Training step:  1306\n",
      "Loss: 123.34339813959714\n",
      "Training step:  1307\n",
      "Loss: 102.55296389406374\n",
      "Training step:  1308\n",
      "Loss: 123.3416000606564\n",
      "Training step:  1309\n",
      "Loss: 102.550671998392\n",
      "Training step:  1310\n",
      "Loss: 123.33980634377515\n",
      "Training step:  1311\n",
      "Loss: 102.54838656730163\n",
      "Training step:  1312\n",
      "Loss: 123.33801697663662\n",
      "Training step:  1313\n",
      "Loss: 102.5461075779964\n",
      "Training step:  1314\n",
      "Loss: 123.3362319469734\n",
      "Training step:  1315\n",
      "Loss: 102.54383500779997\n",
      "Training step:  1316\n",
      "Loss: 123.33445124257226\n",
      "Training step:  1317\n",
      "Loss: 102.54156883411729\n",
      "Training step:  1318\n",
      "Loss: 123.33267485122796\n",
      "Training step:  1319\n",
      "Loss: 102.53930903447\n",
      "Training step:  1320\n",
      "Loss: 123.33090276082112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1321\n",
      "Loss: 102.53705558648426\n",
      "Training step:  1322\n",
      "Loss: 123.32913495924848\n",
      "Training step:  1323\n",
      "Loss: 102.53480846788108\n",
      "Training step:  1324\n",
      "Loss: 123.32737143445486\n",
      "Training step:  1325\n",
      "Loss: 102.53256765647932\n",
      "Training step:  1326\n",
      "Loss: 123.32561217441794\n",
      "Training step:  1327\n",
      "Loss: 102.5303331302149\n",
      "Training step:  1328\n",
      "Loss: 123.3238571671991\n",
      "Training step:  1329\n",
      "Loss: 102.52810486712353\n",
      "Training step:  1330\n",
      "Loss: 123.32210640085911\n",
      "Training step:  1331\n",
      "Loss: 102.52588284532806\n",
      "Training step:  1332\n",
      "Loss: 123.32035986352489\n",
      "Training step:  1333\n",
      "Loss: 102.52366704305864\n",
      "Training step:  1334\n",
      "Loss: 123.31861754334575\n",
      "Training step:  1335\n",
      "Loss: 102.52145743863497\n",
      "Training step:  1336\n",
      "Loss: 123.3168794285096\n",
      "Training step:  1337\n",
      "Loss: 102.51925401046748\n",
      "Training step:  1338\n",
      "Loss: 123.31514550725421\n",
      "Training step:  1339\n",
      "Loss: 102.51705673709137\n",
      "Training step:  1340\n",
      "Loss: 123.31341576788435\n",
      "Training step:  1341\n",
      "Loss: 102.51486559713577\n",
      "Training step:  1342\n",
      "Loss: 123.31169019873319\n",
      "Training step:  1343\n",
      "Loss: 102.51268056932153\n",
      "Training step:  1344\n",
      "Loss: 123.30996878816863\n",
      "Training step:  1345\n",
      "Loss: 102.5105016324551\n",
      "Training step:  1346\n",
      "Loss: 123.30825152458588\n",
      "Training step:  1347\n",
      "Loss: 102.50832876543468\n",
      "Training step:  1348\n",
      "Loss: 123.30653839642002\n",
      "Training step:  1349\n",
      "Loss: 102.50616194725772\n",
      "Training step:  1350\n",
      "Loss: 123.30482939216583\n",
      "Training step:  1351\n",
      "Loss: 102.50400115702499\n",
      "Training step:  1352\n",
      "Loss: 123.30312450034735\n",
      "Training step:  1353\n",
      "Loss: 102.50184637392478\n",
      "Training step:  1354\n",
      "Loss: 123.30142370953372\n",
      "Training step:  1355\n",
      "Loss: 102.49969757723548\n",
      "Training step:  1356\n",
      "Loss: 123.29972700832671\n",
      "Training step:  1357\n",
      "Loss: 102.49755474633349\n",
      "Training step:  1358\n",
      "Loss: 123.29803438537819\n",
      "Training step:  1359\n",
      "Loss: 102.49541786068515\n",
      "Training step:  1360\n",
      "Loss: 123.29634582936286\n",
      "Training step:  1361\n",
      "Loss: 102.4932868998356\n",
      "Training step:  1362\n",
      "Loss: 123.29466132900018\n",
      "Training step:  1363\n",
      "Loss: 102.49116184344436\n",
      "Training step:  1364\n",
      "Loss: 123.29298087306842\n",
      "Training step:  1365\n",
      "Loss: 102.48904267124605\n",
      "Training step:  1366\n",
      "Loss: 123.29130445035709\n",
      "Training step:  1367\n",
      "Loss: 102.48692936306654\n",
      "Training step:  1368\n",
      "Loss: 123.28963204970871\n",
      "Training step:  1369\n",
      "Loss: 102.4848218988241\n",
      "Training step:  1370\n",
      "Loss: 123.28796365999956\n",
      "Training step:  1371\n",
      "Loss: 102.4827202585171\n",
      "Training step:  1372\n",
      "Loss: 123.28629927013608\n",
      "Training step:  1373\n",
      "Loss: 102.48062442224122\n",
      "Training step:  1374\n",
      "Loss: 123.28463886908314\n",
      "Training step:  1375\n",
      "Loss: 102.47853437017616\n",
      "Training step:  1376\n",
      "Loss: 123.28298244581218\n",
      "Training step:  1377\n",
      "Loss: 102.47645008257773\n",
      "Training step:  1378\n",
      "Loss: 123.28132998935789\n",
      "Training step:  1379\n",
      "Loss: 102.4743715398118\n",
      "Training step:  1380\n",
      "Loss: 123.27968148879118\n",
      "Training step:  1381\n",
      "Loss: 102.47229872231244\n",
      "Training step:  1382\n",
      "Loss: 123.27803693319936\n",
      "Training step:  1383\n",
      "Loss: 102.47023161058938\n",
      "Training step:  1384\n",
      "Loss: 123.27639631170528\n",
      "Training step:  1385\n",
      "Loss: 102.46817018525527\n",
      "Training step:  1386\n",
      "Loss: 123.27475961350122\n",
      "Training step:  1387\n",
      "Loss: 102.4661144270101\n",
      "Training step:  1388\n",
      "Loss: 123.27312682778825\n",
      "Training step:  1389\n",
      "Loss: 102.46406431661616\n",
      "Training step:  1390\n",
      "Loss: 123.27149794380081\n",
      "Training step:  1391\n",
      "Loss: 102.46201983493708\n",
      "Training step:  1392\n",
      "Loss: 123.26987295083111\n",
      "Training step:  1393\n",
      "Loss: 102.4599809629229\n",
      "Training step:  1394\n",
      "Loss: 123.26825183820674\n",
      "Training step:  1395\n",
      "Loss: 102.45794768159985\n",
      "Training step:  1396\n",
      "Loss: 123.2666345952705\n",
      "Training step:  1397\n",
      "Loss: 102.45591997206583\n",
      "Training step:  1398\n",
      "Loss: 123.26502121140167\n",
      "Training step:  1399\n",
      "Loss: 102.4538978154974\n",
      "Training step:  1400\n",
      "Loss: 123.26341167601045\n",
      "Training step:  1401\n",
      "Loss: 102.45188119317449\n",
      "Training step:  1402\n",
      "Loss: 123.26180597857966\n",
      "Training step:  1403\n",
      "Loss: 102.44987008644091\n",
      "Training step:  1404\n",
      "Loss: 123.2602041085728\n",
      "Training step:  1405\n",
      "Loss: 102.44786447671027\n",
      "Training step:  1406\n",
      "Loss: 123.25860605551051\n",
      "Training step:  1407\n",
      "Loss: 102.44586434549757\n",
      "Training step:  1408\n",
      "Loss: 123.25701180897397\n",
      "Training step:  1409\n",
      "Loss: 102.44386967439524\n",
      "Training step:  1410\n",
      "Loss: 123.25542135854981\n",
      "Training step:  1411\n",
      "Loss: 102.44188044506787\n",
      "Training step:  1412\n",
      "Loss: 123.25383469387606\n",
      "Training step:  1413\n",
      "Loss: 102.43989663926217\n",
      "Training step:  1414\n",
      "Loss: 123.25225180461479\n",
      "Training step:  1415\n",
      "Loss: 102.43791823879317\n",
      "Training step:  1416\n",
      "Loss: 123.2506726804484\n",
      "Training step:  1417\n",
      "Loss: 102.4359452255542\n",
      "Training step:  1418\n",
      "Loss: 123.24909731111674\n",
      "Training step:  1419\n",
      "Loss: 102.43397758152692\n",
      "Training step:  1420\n",
      "Loss: 123.24752568637315\n",
      "Training step:  1421\n",
      "Loss: 102.43201528874606\n",
      "Training step:  1422\n",
      "Loss: 123.24595779600615\n",
      "Training step:  1423\n",
      "Loss: 102.43005832934624\n",
      "Training step:  1424\n",
      "Loss: 123.24439362985925\n",
      "Training step:  1425\n",
      "Loss: 102.42810668553396\n",
      "Training step:  1426\n",
      "Loss: 123.24283317778958\n",
      "Training step:  1427\n",
      "Loss: 102.42616033957808\n",
      "Training step:  1428\n",
      "Loss: 123.24127642968193\n",
      "Training step:  1429\n",
      "Loss: 102.42421927382374\n",
      "Training step:  1430\n",
      "Loss: 123.23972337546869\n",
      "Training step:  1431\n",
      "Loss: 102.42228347071482\n",
      "Training step:  1432\n",
      "Loss: 123.23817400513155\n",
      "Training step:  1433\n",
      "Loss: 102.42035291274976\n",
      "Training step:  1434\n",
      "Loss: 123.23662830864966\n",
      "Training step:  1435\n",
      "Loss: 102.41842758249717\n",
      "Training step:  1436\n",
      "Loss: 123.23508627604984\n",
      "Training step:  1437\n",
      "Loss: 102.41650746260557\n",
      "Training step:  1438\n",
      "Loss: 123.23354789739093\n",
      "Training step:  1439\n",
      "Loss: 102.41459253578344\n",
      "Training step:  1440\n",
      "Loss: 123.2320131627407\n",
      "Training step:  1441\n",
      "Loss: 102.41268278482322\n",
      "Training step:  1442\n",
      "Loss: 123.23048206224139\n",
      "Training step:  1443\n",
      "Loss: 102.41077819259444\n",
      "Training step:  1444\n",
      "Loss: 123.2289545860342\n",
      "Training step:  1445\n",
      "Loss: 102.40887874201394\n",
      "Training step:  1446\n",
      "Loss: 123.22743072428521\n",
      "Training step:  1447\n",
      "Loss: 102.40698441609173\n",
      "Training step:  1448\n",
      "Loss: 123.22591046723271\n",
      "Training step:  1449\n",
      "Loss: 102.40509519791335\n",
      "Training step:  1450\n",
      "Loss: 123.22439380512246\n",
      "Training step:  1451\n",
      "Loss: 102.40321107061814\n",
      "Training step:  1452\n",
      "Loss: 123.2228807282215\n",
      "Training step:  1453\n",
      "Loss: 102.40133201741486\n",
      "Training step:  1454\n",
      "Loss: 123.22137122683208\n",
      "Training step:  1455\n",
      "Loss: 102.39945802159185\n",
      "Training step:  1456\n",
      "Loss: 123.21986529130795\n",
      "Training step:  1457\n",
      "Loss: 102.39758906650573\n",
      "Training step:  1458\n",
      "Loss: 123.21836291200168\n",
      "Training step:  1459\n",
      "Loss: 102.395725135559\n",
      "Training step:  1460\n",
      "Loss: 123.21686407930088\n",
      "Training step:  1461\n",
      "Loss: 102.39386621225057\n",
      "Training step:  1462\n",
      "Loss: 123.21536878364664\n",
      "Training step:  1463\n",
      "Loss: 102.39201228013506\n",
      "Training step:  1464\n",
      "Loss: 123.21387701549155\n",
      "Training step:  1465\n",
      "Loss: 102.39016332283468\n",
      "Training step:  1466\n",
      "Loss: 123.21238876533015\n",
      "Training step:  1467\n",
      "Loss: 102.38831932406873\n",
      "Training step:  1468\n",
      "Loss: 123.21090402372735\n",
      "Training step:  1469\n",
      "Loss: 102.38648026759468\n",
      "Training step:  1470\n",
      "Loss: 123.20942278119013\n",
      "Training step:  1471\n",
      "Loss: 102.38464613721074\n",
      "Training step:  1472\n",
      "Loss: 123.2079450282832\n",
      "Training step:  1473\n",
      "Loss: 102.38281691681954\n",
      "Training step:  1474\n",
      "Loss: 123.20647075564328\n",
      "Training step:  1475\n",
      "Loss: 102.38099259038032\n",
      "Training step:  1476\n",
      "Loss: 123.20499995388779\n",
      "Training step:  1477\n",
      "Loss: 102.37917314190813\n",
      "Training step:  1478\n",
      "Loss: 123.2035326136855\n",
      "Training step:  1479\n",
      "Loss: 102.37735855549228\n",
      "Training step:  1480\n",
      "Loss: 123.20206872573874\n",
      "Training step:  1481\n",
      "Loss: 102.37554881528482\n",
      "Training step:  1482\n",
      "Loss: 123.20060828075981\n",
      "Training step:  1483\n",
      "Loss: 102.37374390549988\n",
      "Training step:  1484\n",
      "Loss: 123.19915126951115\n",
      "Training step:  1485\n",
      "Loss: 102.37194381041962\n",
      "Training step:  1486\n",
      "Loss: 123.19769768278005\n",
      "Training step:  1487\n",
      "Loss: 102.37014851439818\n",
      "Training step:  1488\n",
      "Loss: 123.19624751138181\n",
      "Training step:  1489\n",
      "Loss: 102.36835800183322\n",
      "Training step:  1490\n",
      "Loss: 123.19480074613975\n",
      "Training step:  1491\n",
      "Loss: 102.36657225718585\n",
      "Training step:  1492\n",
      "Loss: 123.19335737792274\n",
      "Training step:  1493\n",
      "Loss: 102.36479126500598\n",
      "Training step:  1494\n",
      "Loss: 123.1919173976513\n",
      "Training step:  1495\n",
      "Loss: 102.36301500988769\n",
      "Training step:  1496\n",
      "Loss: 123.1904807962333\n",
      "Training step:  1497\n",
      "Loss: 102.36124347647724\n",
      "Training step:  1498\n",
      "Loss: 123.1890475646151\n",
      "Training step:  1499\n",
      "Loss: 102.35947664950115\n",
      "Training step:  1500\n",
      "Loss: 123.18761769379417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1501\n",
      "Loss: 102.35771451374208\n",
      "Training step:  1502\n",
      "Loss: 123.1861911747777\n",
      "Training step:  1503\n",
      "Loss: 102.35595705404235\n",
      "Training step:  1504\n",
      "Loss: 123.1847679985995\n",
      "Training step:  1505\n",
      "Loss: 102.35420425529604\n",
      "Training step:  1506\n",
      "Loss: 123.18334815630305\n",
      "Training step:  1507\n",
      "Loss: 102.35245610244976\n",
      "Training step:  1508\n",
      "Loss: 123.18193163897615\n",
      "Training step:  1509\n",
      "Loss: 102.35071258053559\n",
      "Training step:  1510\n",
      "Loss: 123.18051843775056\n",
      "Training step:  1511\n",
      "Loss: 102.34897367463869\n",
      "Training step:  1512\n",
      "Loss: 123.179108543776\n",
      "Training step:  1513\n",
      "Loss: 102.34723936991017\n",
      "Training step:  1514\n",
      "Loss: 123.1777019482389\n",
      "Training step:  1515\n",
      "Loss: 102.34550965154754\n",
      "Training step:  1516\n",
      "Loss: 123.1762986423189\n",
      "Training step:  1517\n",
      "Loss: 102.34378450480308\n",
      "Training step:  1518\n",
      "Loss: 123.1748986172643\n",
      "Training step:  1519\n",
      "Loss: 102.34206391501218\n",
      "Training step:  1520\n",
      "Loss: 123.17350186431722\n",
      "Training step:  1521\n",
      "Loss: 102.34034786752316\n",
      "Training step:  1522\n",
      "Loss: 123.17210837473327\n",
      "Training step:  1523\n",
      "Loss: 102.33863634776951\n",
      "Training step:  1524\n",
      "Loss: 123.17071813983102\n",
      "Training step:  1525\n",
      "Loss: 102.33692934125592\n",
      "Training step:  1526\n",
      "Loss: 123.16933115095951\n",
      "Training step:  1527\n",
      "Loss: 102.33522683353463\n",
      "Training step:  1528\n",
      "Loss: 123.16794739947595\n",
      "Training step:  1529\n",
      "Loss: 102.3335288102083\n",
      "Training step:  1530\n",
      "Loss: 123.16656687676402\n",
      "Training step:  1531\n",
      "Loss: 102.331835256936\n",
      "Training step:  1532\n",
      "Loss: 123.16518957422927\n",
      "Training step:  1533\n",
      "Loss: 102.3301461594377\n",
      "Training step:  1534\n",
      "Loss: 123.16381548331532\n",
      "Training step:  1535\n",
      "Loss: 102.32846150348469\n",
      "Training step:  1536\n",
      "Loss: 123.16244459547516\n",
      "Training step:  1537\n",
      "Loss: 102.3267812749065\n",
      "Training step:  1538\n",
      "Loss: 123.16107690220643\n",
      "Training step:  1539\n",
      "Loss: 102.3251054595912\n",
      "Training step:  1540\n",
      "Loss: 123.159712395017\n",
      "Training step:  1541\n",
      "Loss: 102.32343404347444\n",
      "Training step:  1542\n",
      "Loss: 123.15835106545069\n",
      "Training step:  1543\n",
      "Loss: 102.32176701256782\n",
      "Training step:  1544\n",
      "Loss: 123.15699290509416\n",
      "Training step:  1545\n",
      "Loss: 102.3201043529164\n",
      "Training step:  1546\n",
      "Loss: 123.15563790551681\n",
      "Training step:  1547\n",
      "Loss: 102.31844605062079\n",
      "Training step:  1548\n",
      "Loss: 123.15428605834194\n",
      "Training step:  1549\n",
      "Loss: 102.31679209184573\n",
      "Training step:  1550\n",
      "Loss: 123.15293735521588\n",
      "Training step:  1551\n",
      "Loss: 102.31514246280653\n",
      "Training step:  1552\n",
      "Loss: 123.1515917878105\n",
      "Training step:  1553\n",
      "Loss: 102.31349714977614\n",
      "Training step:  1554\n",
      "Loss: 123.15024934782534\n",
      "Training step:  1555\n",
      "Loss: 102.31185613907044\n",
      "Training step:  1556\n",
      "Loss: 123.14891002695809\n",
      "Training step:  1557\n",
      "Loss: 102.31021941705701\n",
      "Training step:  1558\n",
      "Loss: 123.14757381696478\n",
      "Training step:  1559\n",
      "Loss: 102.30858697018007\n",
      "Training step:  1560\n",
      "Loss: 123.14624070962297\n",
      "Training step:  1561\n",
      "Loss: 102.30695878490094\n",
      "Training step:  1562\n",
      "Loss: 123.14491069669218\n",
      "Training step:  1563\n",
      "Loss: 102.30533484775353\n",
      "Training step:  1564\n",
      "Loss: 123.14358377001508\n",
      "Training step:  1565\n",
      "Loss: 102.30371514533383\n",
      "Training step:  1566\n",
      "Loss: 123.14225992143626\n",
      "Training step:  1567\n",
      "Loss: 102.30209966427533\n",
      "Training step:  1568\n",
      "Loss: 123.1409391428132\n",
      "Training step:  1569\n",
      "Loss: 102.300488391257\n",
      "Training step:  1570\n",
      "Loss: 123.13962142603191\n",
      "Training step:  1571\n",
      "Loss: 102.29888131302415\n",
      "Training step:  1572\n",
      "Loss: 123.13830676301073\n",
      "Training step:  1573\n",
      "Loss: 102.29727841636549\n",
      "Training step:  1574\n",
      "Loss: 123.13699514569947\n",
      "Training step:  1575\n",
      "Loss: 102.29567968812955\n",
      "Training step:  1576\n",
      "Loss: 123.13568656605487\n",
      "Training step:  1577\n",
      "Loss: 102.29408511519833\n",
      "Training step:  1578\n",
      "Loss: 123.13438101605502\n",
      "Training step:  1579\n",
      "Loss: 102.29249468451368\n",
      "Training step:  1580\n",
      "Loss: 123.13307848771151\n",
      "Training step:  1581\n",
      "Loss: 102.29090838305895\n",
      "Training step:  1582\n",
      "Loss: 123.13177897304726\n",
      "Training step:  1583\n",
      "Loss: 102.28932619788424\n",
      "Training step:  1584\n",
      "Loss: 123.1304824641419\n",
      "Training step:  1585\n",
      "Loss: 102.28774811608479\n",
      "Training step:  1586\n",
      "Loss: 123.1291889530727\n",
      "Training step:  1587\n",
      "Loss: 102.28617412480068\n",
      "Training step:  1588\n",
      "Loss: 123.1278984319405\n",
      "Training step:  1589\n",
      "Loss: 102.28460421121122\n",
      "Training step:  1590\n",
      "Loss: 123.12661089286291\n",
      "Training step:  1591\n",
      "Loss: 102.28303836255489\n",
      "Training step:  1592\n",
      "Loss: 123.12532632799719\n",
      "Training step:  1593\n",
      "Loss: 102.28147656612737\n",
      "Training step:  1594\n",
      "Loss: 123.12404472953241\n",
      "Training step:  1595\n",
      "Loss: 102.2799188092738\n",
      "Training step:  1596\n",
      "Loss: 123.12276608967518\n",
      "Training step:  1597\n",
      "Loss: 102.27836507936561\n",
      "Training step:  1598\n",
      "Loss: 123.12149040061438\n",
      "Training step:  1599\n",
      "Loss: 102.27681536382906\n",
      "Training step:  1600\n",
      "Loss: 123.12021765460977\n",
      "Training step:  1601\n",
      "Loss: 102.27526965014233\n",
      "Training step:  1602\n",
      "Loss: 123.11894784391593\n",
      "Training step:  1603\n",
      "Loss: 102.27372792584048\n",
      "Training step:  1604\n",
      "Loss: 123.11768096084933\n",
      "Training step:  1605\n",
      "Loss: 102.27219017850638\n",
      "Training step:  1606\n",
      "Loss: 123.11641699771582\n",
      "Training step:  1607\n",
      "Loss: 102.2706563957522\n",
      "Training step:  1608\n",
      "Loss: 123.1151559468441\n",
      "Training step:  1609\n",
      "Loss: 102.26912656524193\n",
      "Training step:  1610\n",
      "Loss: 123.11389780058465\n",
      "Training step:  1611\n",
      "Loss: 102.26760067468764\n",
      "Training step:  1612\n",
      "Loss: 123.11264255132558\n",
      "Training step:  1613\n",
      "Loss: 102.26607871186042\n",
      "Training step:  1614\n",
      "Loss: 123.11139019147868\n",
      "Training step:  1615\n",
      "Loss: 102.26456066456132\n",
      "Training step:  1616\n",
      "Loss: 123.11014071345119\n",
      "Training step:  1617\n",
      "Loss: 102.26304652063837\n",
      "Training step:  1618\n",
      "Loss: 123.10889410969942\n",
      "Training step:  1619\n",
      "Loss: 102.26153626799852\n",
      "Training step:  1620\n",
      "Loss: 123.10765037269742\n",
      "Training step:  1621\n",
      "Loss: 102.26002989457614\n",
      "Training step:  1622\n",
      "Loss: 123.10640949491605\n",
      "Training step:  1623\n",
      "Loss: 102.25852738835397\n",
      "Training step:  1624\n",
      "Loss: 123.10517146887308\n",
      "Training step:  1625\n",
      "Loss: 102.25702873737197\n",
      "Training step:  1626\n",
      "Loss: 123.10393628711036\n",
      "Training step:  1627\n",
      "Loss: 102.25553392971084\n",
      "Training step:  1628\n",
      "Loss: 123.10270394218988\n",
      "Training step:  1629\n",
      "Loss: 102.25404295349963\n",
      "Training step:  1630\n",
      "Loss: 123.10147442668976\n",
      "Training step:  1631\n",
      "Loss: 102.25255579690146\n",
      "Training step:  1632\n",
      "Loss: 123.10024773321064\n",
      "Training step:  1633\n",
      "Loss: 102.25107244812789\n",
      "Training step:  1634\n",
      "Loss: 123.09902385437671\n",
      "Training step:  1635\n",
      "Loss: 102.24959289544978\n",
      "Training step:  1636\n",
      "Loss: 123.0978027828469\n",
      "Training step:  1637\n",
      "Loss: 102.24811712715022\n",
      "Training step:  1638\n",
      "Loss: 123.09658451125559\n",
      "Training step:  1639\n",
      "Loss: 102.24664513157931\n",
      "Training step:  1640\n",
      "Loss: 123.09536903232606\n",
      "Training step:  1641\n",
      "Loss: 102.24517689713471\n",
      "Training step:  1642\n",
      "Loss: 123.09415633875075\n",
      "Training step:  1643\n",
      "Loss: 102.24371241223162\n",
      "Training step:  1644\n",
      "Loss: 123.09294642324909\n",
      "Training step:  1645\n",
      "Loss: 102.24225166533974\n",
      "Training step:  1646\n",
      "Loss: 123.09173927856743\n",
      "Training step:  1647\n",
      "Loss: 102.24079464497555\n",
      "Training step:  1648\n",
      "Loss: 123.09053489748634\n",
      "Training step:  1649\n",
      "Loss: 102.23934133969769\n",
      "Training step:  1650\n",
      "Loss: 123.08933327278625\n",
      "Training step:  1651\n",
      "Loss: 102.23789173810108\n",
      "Training step:  1652\n",
      "Loss: 123.08813439728803\n",
      "Training step:  1653\n",
      "Loss: 102.23644582884643\n",
      "Training step:  1654\n",
      "Loss: 123.08693826385594\n",
      "Training step:  1655\n",
      "Loss: 102.23500360062614\n",
      "Training step:  1656\n",
      "Loss: 123.08574486532483\n",
      "Training step:  1657\n",
      "Loss: 102.23356504214165\n",
      "Training step:  1658\n",
      "Loss: 123.0845541945555\n",
      "Training step:  1659\n",
      "Loss: 102.23213014217201\n",
      "Training step:  1660\n",
      "Loss: 123.08336624446967\n",
      "Training step:  1661\n",
      "Loss: 102.23069888953385\n",
      "Training step:  1662\n",
      "Loss: 123.08218100797171\n",
      "Training step:  1663\n",
      "Loss: 102.22927127306517\n",
      "Training step:  1664\n",
      "Loss: 123.08099847799578\n",
      "Training step:  1665\n",
      "Loss: 102.2278472816593\n",
      "Training step:  1666\n",
      "Loss: 123.07981864750165\n",
      "Training step:  1667\n",
      "Loss: 102.2264269042572\n",
      "Training step:  1668\n",
      "Loss: 123.07864150947542\n",
      "Training step:  1669\n",
      "Loss: 102.22501012982073\n",
      "Training step:  1670\n",
      "Loss: 123.07746705689826\n",
      "Training step:  1671\n",
      "Loss: 102.22359694736559\n",
      "Training step:  1672\n",
      "Loss: 123.07629528280559\n",
      "Training step:  1673\n",
      "Loss: 102.22218734595423\n",
      "Training step:  1674\n",
      "Loss: 123.07512618023131\n",
      "Training step:  1675\n",
      "Loss: 102.22078131467045\n",
      "Training step:  1676\n",
      "Loss: 123.07395974223017\n",
      "Training step:  1677\n",
      "Loss: 102.2193788426515\n",
      "Training step:  1678\n",
      "Loss: 123.07279596188565\n",
      "Training step:  1679\n",
      "Loss: 102.21797991907673\n",
      "Training step:  1680\n",
      "Loss: 123.07163483231443\n",
      "Training step:  1681\n",
      "Loss: 102.21658453317654\n",
      "Training step:  1682\n",
      "Loss: 123.07047634664914\n",
      "Training step:  1683\n",
      "Loss: 102.21519267419706\n",
      "Training step:  1684\n",
      "Loss: 123.06932049800464\n",
      "Training step:  1685\n",
      "Loss: 102.21380433141329\n",
      "Training step:  1686\n",
      "Loss: 123.06816727953411\n",
      "Training step:  1687\n",
      "Loss: 102.21241949416368\n",
      "Training step:  1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 123.0670166844224\n",
      "Training step:  1689\n",
      "Loss: 102.21103815180987\n",
      "Training step:  1690\n",
      "Loss: 123.06586870585791\n",
      "Training step:  1691\n",
      "Loss: 102.2096602937687\n",
      "Training step:  1692\n",
      "Loss: 123.06472333707487\n",
      "Training step:  1693\n",
      "Loss: 102.20828590949\n",
      "Training step:  1694\n",
      "Loss: 123.06358057130697\n",
      "Training step:  1695\n",
      "Loss: 102.20691498845234\n",
      "Training step:  1696\n",
      "Loss: 123.0624404018028\n",
      "Training step:  1697\n",
      "Loss: 102.20554752018288\n",
      "Training step:  1698\n",
      "Loss: 123.06130282184873\n",
      "Training step:  1699\n",
      "Loss: 102.20418349424317\n",
      "Training step:  1700\n",
      "Loss: 123.06016782473667\n",
      "Training step:  1701\n",
      "Loss: 102.20282290023529\n",
      "Training step:  1702\n",
      "Loss: 123.05903540378358\n",
      "Training step:  1703\n",
      "Loss: 102.20146572778886\n",
      "Training step:  1704\n",
      "Loss: 123.05790555231957\n",
      "Training step:  1705\n",
      "Loss: 102.20011196658956\n",
      "Training step:  1706\n",
      "Loss: 123.05677826370957\n",
      "Training step:  1707\n",
      "Loss: 102.1987616063465\n",
      "Training step:  1708\n",
      "Loss: 123.05565353132229\n",
      "Training step:  1709\n",
      "Loss: 102.19741463680573\n",
      "Training step:  1710\n",
      "Loss: 123.05453134853835\n",
      "Training step:  1711\n",
      "Loss: 102.1960710477444\n",
      "Training step:  1712\n",
      "Loss: 123.05341170875953\n",
      "Training step:  1713\n",
      "Loss: 102.19473082898683\n",
      "Training step:  1714\n",
      "Loss: 123.05229460543079\n",
      "Training step:  1715\n",
      "Loss: 102.1933939704039\n",
      "Training step:  1716\n",
      "Loss: 123.05118003200347\n",
      "Training step:  1717\n",
      "Loss: 102.1920604618908\n",
      "Training step:  1718\n",
      "Loss: 123.05006798194412\n",
      "Training step:  1719\n",
      "Loss: 102.19073029337531\n",
      "Training step:  1720\n",
      "Loss: 123.04895844873387\n",
      "Training step:  1721\n",
      "Loss: 102.1894034548322\n",
      "Training step:  1722\n",
      "Loss: 123.04785142588683\n",
      "Training step:  1723\n",
      "Loss: 102.18807993626164\n",
      "Training step:  1724\n",
      "Loss: 123.04674690690665\n",
      "Training step:  1725\n",
      "Loss: 102.1867597276943\n",
      "Training step:  1726\n",
      "Loss: 123.04564488533688\n",
      "Training step:  1727\n",
      "Loss: 102.1854428192134\n",
      "Training step:  1728\n",
      "Loss: 123.04454535474665\n",
      "Training step:  1729\n",
      "Loss: 102.18412920093327\n",
      "Training step:  1730\n",
      "Loss: 123.04344830870669\n",
      "Training step:  1731\n",
      "Loss: 102.18281886299255\n",
      "Training step:  1732\n",
      "Loss: 123.04235374081517\n",
      "Training step:  1733\n",
      "Loss: 102.18151179558981\n",
      "Training step:  1734\n",
      "Loss: 123.04126164471346\n",
      "Training step:  1735\n",
      "Loss: 102.18020798894598\n",
      "Training step:  1736\n",
      "Loss: 123.04017201400536\n",
      "Training step:  1737\n",
      "Loss: 102.17890743327976\n",
      "Training step:  1738\n",
      "Loss: 123.0390848423233\n",
      "Training step:  1739\n",
      "Loss: 102.17761011889162\n",
      "Training step:  1740\n",
      "Loss: 123.03800012335529\n",
      "Training step:  1741\n",
      "Loss: 102.17631603610815\n",
      "Training step:  1742\n",
      "Loss: 123.03691785079467\n",
      "Training step:  1743\n",
      "Loss: 102.17502517528926\n",
      "Training step:  1744\n",
      "Loss: 123.03583801834797\n",
      "Training step:  1745\n",
      "Loss: 102.17373752681827\n",
      "Training step:  1746\n",
      "Loss: 123.03476061971804\n",
      "Training step:  1747\n",
      "Loss: 102.17245308111431\n",
      "Training step:  1748\n",
      "Loss: 123.03368564866135\n",
      "Training step:  1749\n",
      "Loss: 102.17117182864826\n",
      "Training step:  1750\n",
      "Loss: 123.03261309893956\n",
      "Training step:  1751\n",
      "Loss: 102.16989375991008\n",
      "Training step:  1752\n",
      "Loss: 123.03154296432588\n",
      "Training step:  1753\n",
      "Loss: 102.16861886542537\n",
      "Training step:  1754\n",
      "Loss: 123.03047523861972\n",
      "Training step:  1755\n",
      "Loss: 102.16734713576147\n",
      "Training step:  1756\n",
      "Loss: 123.02940991563612\n",
      "Training step:  1757\n",
      "Loss: 102.16607856150313\n",
      "Training step:  1758\n",
      "Loss: 123.02834698919527\n",
      "Training step:  1759\n",
      "Loss: 102.16481313327961\n",
      "Training step:  1760\n",
      "Loss: 123.02728645314446\n",
      "Training step:  1761\n",
      "Loss: 102.16355084174309\n",
      "Training step:  1762\n",
      "Loss: 123.02622830134537\n",
      "Training step:  1763\n",
      "Loss: 102.1622916775962\n",
      "Training step:  1764\n",
      "Loss: 123.02517252768925\n",
      "Training step:  1765\n",
      "Loss: 102.16103563155889\n",
      "Training step:  1766\n",
      "Loss: 123.02411912606229\n",
      "Training step:  1767\n",
      "Loss: 102.15978269438041\n",
      "Training step:  1768\n",
      "Loss: 123.02306809037704\n",
      "Training step:  1769\n",
      "Loss: 102.15853285686016\n",
      "Training step:  1770\n",
      "Loss: 123.02201941457913\n",
      "Training step:  1771\n",
      "Loss: 102.15728610982022\n",
      "Training step:  1772\n",
      "Loss: 123.02097309260922\n",
      "Training step:  1773\n",
      "Loss: 102.15604244410717\n",
      "Training step:  1774\n",
      "Loss: 123.01992911842522\n",
      "Training step:  1775\n",
      "Loss: 102.15480185060855\n",
      "Training step:  1776\n",
      "Loss: 123.01888748602879\n",
      "Training step:  1777\n",
      "Loss: 102.15356432026327\n",
      "Training step:  1778\n",
      "Loss: 123.01784818943254\n",
      "Training step:  1779\n",
      "Loss: 102.15232984401332\n",
      "Training step:  1780\n",
      "Loss: 123.01681122264254\n",
      "Training step:  1781\n",
      "Loss: 102.15109841284122\n",
      "Training step:  1782\n",
      "Loss: 123.01577657969192\n",
      "Training step:  1783\n",
      "Loss: 102.14987001775577\n",
      "Training step:  1784\n",
      "Loss: 123.01474425462732\n",
      "Training step:  1785\n",
      "Loss: 102.14864464979833\n",
      "Training step:  1786\n",
      "Loss: 123.01371424150962\n",
      "Training step:  1787\n",
      "Loss: 102.14742230005159\n",
      "Training step:  1788\n",
      "Loss: 123.01268653445128\n",
      "Training step:  1789\n",
      "Loss: 102.14620295963832\n",
      "Training step:  1790\n",
      "Loss: 123.01166112754845\n",
      "Training step:  1791\n",
      "Loss: 102.14498661968496\n",
      "Training step:  1792\n",
      "Loss: 123.01063801491145\n",
      "Training step:  1793\n",
      "Loss: 102.14377327136195\n",
      "Training step:  1794\n",
      "Loss: 123.00961719066639\n",
      "Training step:  1795\n",
      "Loss: 102.14256290585718\n",
      "Training step:  1796\n",
      "Loss: 123.00859864896498\n",
      "Training step:  1797\n",
      "Loss: 102.14135551441782\n",
      "Training step:  1798\n",
      "Loss: 123.00758238398626\n",
      "Training step:  1799\n",
      "Loss: 102.14015108830087\n",
      "Training step:  1800\n",
      "Loss: 123.00656838991902\n",
      "Training step:  1801\n",
      "Loss: 102.13894961882008\n",
      "Training step:  1802\n",
      "Loss: 123.00555666098471\n",
      "Training step:  1803\n",
      "Loss: 102.13775109728815\n",
      "Training step:  1804\n",
      "Loss: 123.0045471913754\n",
      "Training step:  1805\n",
      "Loss: 102.13655551505583\n",
      "Training step:  1806\n",
      "Loss: 123.00353997533347\n",
      "Training step:  1807\n",
      "Loss: 102.1353628634984\n",
      "Training step:  1808\n",
      "Loss: 123.00253500708615\n",
      "Training step:  1809\n",
      "Loss: 102.1341731340263\n",
      "Training step:  1810\n",
      "Loss: 123.0015322809163\n",
      "Training step:  1811\n",
      "Loss: 102.13298631810025\n",
      "Training step:  1812\n",
      "Loss: 123.00053179112558\n",
      "Training step:  1813\n",
      "Loss: 102.13180240719716\n",
      "Training step:  1814\n",
      "Loss: 122.99953353200408\n",
      "Training step:  1815\n",
      "Loss: 102.13062139280348\n",
      "Training step:  1816\n",
      "Loss: 122.99853749784982\n",
      "Training step:  1817\n",
      "Loss: 102.12944326645557\n",
      "Training step:  1818\n",
      "Loss: 122.9975436829985\n",
      "Training step:  1819\n",
      "Loss: 102.1282680197107\n",
      "Training step:  1820\n",
      "Loss: 122.99655208180224\n",
      "Training step:  1821\n",
      "Loss: 102.12709564416497\n",
      "Training step:  1822\n",
      "Loss: 122.99556268862268\n",
      "Training step:  1823\n",
      "Loss: 102.12592613144086\n",
      "Training step:  1824\n",
      "Loss: 122.99457549784255\n",
      "Training step:  1825\n",
      "Loss: 102.12475947318403\n",
      "Training step:  1826\n",
      "Loss: 122.99359050385479\n",
      "Training step:  1827\n",
      "Loss: 102.12359566107268\n",
      "Training step:  1828\n",
      "Loss: 122.99260770106018\n",
      "Training step:  1829\n",
      "Loss: 102.12243468679834\n",
      "Training step:  1830\n",
      "Loss: 122.99162708387223\n",
      "Training step:  1831\n",
      "Loss: 102.12127654210009\n",
      "Training step:  1832\n",
      "Loss: 122.99064864674757\n",
      "Training step:  1833\n",
      "Loss: 102.12012121875274\n",
      "Training step:  1834\n",
      "Loss: 122.9896723841481\n",
      "Training step:  1835\n",
      "Loss: 102.11896870854167\n",
      "Training step:  1836\n",
      "Loss: 122.98869829054593\n",
      "Training step:  1837\n",
      "Loss: 102.11781900329404\n",
      "Training step:  1838\n",
      "Loss: 122.98772636043174\n",
      "Training step:  1839\n",
      "Loss: 102.1166720948555\n",
      "Training step:  1840\n",
      "Loss: 122.9867565883066\n",
      "Training step:  1841\n",
      "Loss: 102.11552797509584\n",
      "Training step:  1842\n",
      "Loss: 122.98578896867825\n",
      "Training step:  1843\n",
      "Loss: 102.11438663591889\n",
      "Training step:  1844\n",
      "Loss: 122.98482349609095\n",
      "Training step:  1845\n",
      "Loss: 102.11324806925532\n",
      "Training step:  1846\n",
      "Loss: 122.98386016507713\n",
      "Training step:  1847\n",
      "Loss: 102.11211226705295\n",
      "Training step:  1848\n",
      "Loss: 122.98289897020364\n",
      "Training step:  1849\n",
      "Loss: 102.11097922131506\n",
      "Training step:  1850\n",
      "Loss: 122.98193990607406\n",
      "Training step:  1851\n",
      "Loss: 102.10984892405732\n",
      "Training step:  1852\n",
      "Loss: 122.98098296727113\n",
      "Training step:  1853\n",
      "Loss: 102.10872136731594\n",
      "Training step:  1854\n",
      "Loss: 122.98002814840474\n",
      "Training step:  1855\n",
      "Loss: 102.10759654315544\n",
      "Training step:  1856\n",
      "Loss: 122.97907544409163\n",
      "Training step:  1857\n",
      "Loss: 102.10647444366705\n",
      "Training step:  1858\n",
      "Loss: 122.97812484895927\n",
      "Training step:  1859\n",
      "Loss: 102.10535506096393\n",
      "Training step:  1860\n",
      "Loss: 122.97717635767327\n",
      "Training step:  1861\n",
      "Loss: 102.10423838721167\n",
      "Training step:  1862\n",
      "Loss: 122.97622996491305\n",
      "Training step:  1863\n",
      "Loss: 102.1031244145914\n",
      "Training step:  1864\n",
      "Loss: 122.97528566536805\n",
      "Training step:  1865\n",
      "Loss: 102.10201313529518\n",
      "Training step:  1866\n",
      "Loss: 122.97434345372201\n",
      "Training step:  1867\n",
      "Loss: 102.10090454155556\n",
      "Training step:  1868\n",
      "Loss: 122.97340332469948\n",
      "Training step:  1869\n",
      "Loss: 102.0997986256289\n",
      "Training step:  1870\n",
      "Loss: 122.9724652730289\n",
      "Training step:  1871\n",
      "Loss: 102.0986953798035\n",
      "Training step:  1872\n",
      "Loss: 122.97152929346207\n",
      "Training step:  1873\n",
      "Loss: 102.09759479637832\n",
      "Training step:  1874\n",
      "Loss: 122.97059538073896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1875\n",
      "Loss: 102.09649686768931\n",
      "Training step:  1876\n",
      "Loss: 122.96966352964493\n",
      "Training step:  1877\n",
      "Loss: 102.09540158609438\n",
      "Training step:  1878\n",
      "Loss: 122.96873373495423\n",
      "Training step:  1879\n",
      "Loss: 102.09430894398064\n",
      "Training step:  1880\n",
      "Loss: 122.96780599148131\n",
      "Training step:  1881\n",
      "Loss: 102.09321893375794\n",
      "Training step:  1882\n",
      "Loss: 122.96688029403222\n",
      "Training step:  1883\n",
      "Loss: 102.09213154787045\n",
      "Training step:  1884\n",
      "Loss: 122.96595663745059\n",
      "Training step:  1885\n",
      "Loss: 102.09104677876894\n",
      "Training step:  1886\n",
      "Loss: 122.96503501655377\n",
      "Training step:  1887\n",
      "Loss: 102.08996461893838\n",
      "Training step:  1888\n",
      "Loss: 122.96411542621483\n",
      "Training step:  1889\n",
      "Loss: 102.08888506090622\n",
      "Training step:  1890\n",
      "Loss: 122.96319786131983\n",
      "Training step:  1891\n",
      "Loss: 102.0878080972053\n",
      "Training step:  1892\n",
      "Loss: 122.96228231674033\n",
      "Training step:  1893\n",
      "Loss: 102.08673372040124\n",
      "Training step:  1894\n",
      "Loss: 122.9613687873955\n",
      "Training step:  1895\n",
      "Loss: 102.08566192308948\n",
      "Training step:  1896\n",
      "Loss: 122.96045726818687\n",
      "Training step:  1897\n",
      "Loss: 102.08459269786233\n",
      "Training step:  1898\n",
      "Loss: 122.9595477540311\n",
      "Training step:  1899\n",
      "Loss: 102.08352603737727\n",
      "Training step:  1900\n",
      "Loss: 122.95864023990967\n",
      "Training step:  1901\n",
      "Loss: 102.08246193430853\n",
      "Training step:  1902\n",
      "Loss: 122.95773472077627\n",
      "Training step:  1903\n",
      "Loss: 102.08140038133743\n",
      "Training step:  1904\n",
      "Loss: 122.95683119159305\n",
      "Training step:  1905\n",
      "Loss: 102.08034137117193\n",
      "Training step:  1906\n",
      "Loss: 122.95592964734469\n",
      "Training step:  1907\n",
      "Loss: 102.07928489655454\n",
      "Training step:  1908\n",
      "Loss: 122.955030083045\n",
      "Training step:  1909\n",
      "Loss: 102.0782309502468\n",
      "Training step:  1910\n",
      "Loss: 122.95413249368448\n",
      "Training step:  1911\n",
      "Loss: 102.07717952502165\n",
      "Training step:  1912\n",
      "Loss: 122.95323687430265\n",
      "Training step:  1913\n",
      "Loss: 102.07613061371133\n",
      "Training step:  1914\n",
      "Loss: 122.95234321996153\n",
      "Training step:  1915\n",
      "Loss: 102.0750842091441\n",
      "Training step:  1916\n",
      "Loss: 122.95145152569074\n",
      "Training step:  1917\n",
      "Loss: 102.0740403041668\n",
      "Training step:  1918\n",
      "Loss: 122.95056178655676\n",
      "Training step:  1919\n",
      "Loss: 102.07299889166009\n",
      "Training step:  1920\n",
      "Loss: 122.9496739976481\n",
      "Training step:  1921\n",
      "Loss: 102.07195996454566\n",
      "Training step:  1922\n",
      "Loss: 122.94878815407807\n",
      "Training step:  1923\n",
      "Loss: 102.07092351574812\n",
      "Training step:  1924\n",
      "Loss: 122.94790425093288\n",
      "Training step:  1925\n",
      "Loss: 102.06988953820522\n",
      "Training step:  1926\n",
      "Loss: 122.9470222833329\n",
      "Training step:  1927\n",
      "Loss: 102.06885802490329\n",
      "Training step:  1928\n",
      "Loss: 122.94614224642591\n",
      "Training step:  1929\n",
      "Loss: 102.06782896884877\n",
      "Training step:  1930\n",
      "Loss: 122.9452641353769\n",
      "Training step:  1931\n",
      "Loss: 102.06680236307439\n",
      "Training step:  1932\n",
      "Loss: 122.9443879453482\n",
      "Training step:  1933\n",
      "Loss: 102.06577820061378\n",
      "Training step:  1934\n",
      "Loss: 122.94351367149622\n",
      "Training step:  1935\n",
      "Loss: 102.06475647454154\n",
      "Training step:  1936\n",
      "Loss: 122.94264130903998\n",
      "Training step:  1937\n",
      "Loss: 102.0637371779569\n",
      "Training step:  1938\n",
      "Loss: 122.94177085316552\n",
      "Training step:  1939\n",
      "Loss: 102.06272030396079\n",
      "Training step:  1940\n",
      "Loss: 122.9409022990787\n",
      "Training step:  1941\n",
      "Loss: 102.06170584569261\n",
      "Training step:  1942\n",
      "Loss: 122.94003564200933\n",
      "Training step:  1943\n",
      "Loss: 102.06069379630972\n",
      "Training step:  1944\n",
      "Loss: 122.93917087721017\n",
      "Training step:  1945\n",
      "Loss: 102.05968414900914\n",
      "Training step:  1946\n",
      "Loss: 122.938307999939\n",
      "Training step:  1947\n",
      "Loss: 102.05867689699718\n",
      "Training step:  1948\n",
      "Loss: 122.93744700547383\n",
      "Training step:  1949\n",
      "Loss: 102.0576720335048\n",
      "Training step:  1950\n",
      "Loss: 122.9365878890929\n",
      "Training step:  1951\n",
      "Loss: 102.05666955178458\n",
      "Training step:  1952\n",
      "Loss: 122.93573064609197\n",
      "Training step:  1953\n",
      "Loss: 102.055669445106\n",
      "Training step:  1954\n",
      "Loss: 122.93487527177709\n",
      "Training step:  1955\n",
      "Loss: 102.0546717067667\n",
      "Training step:  1956\n",
      "Loss: 122.93402176146942\n",
      "Training step:  1957\n",
      "Loss: 102.05367633008645\n",
      "Training step:  1958\n",
      "Loss: 122.9331701105032\n",
      "Training step:  1959\n",
      "Loss: 102.05268330840018\n",
      "Training step:  1960\n",
      "Loss: 122.9323203142201\n",
      "Training step:  1961\n",
      "Loss: 102.05169263506546\n",
      "Training step:  1962\n",
      "Loss: 122.93147236796942\n",
      "Training step:  1963\n",
      "Loss: 102.05070430347637\n",
      "Training step:  1964\n",
      "Loss: 122.9306262671597\n",
      "Training step:  1965\n",
      "Loss: 102.04971830705249\n",
      "Training step:  1966\n",
      "Loss: 122.92978200716853\n",
      "Training step:  1967\n",
      "Loss: 102.04873463922054\n",
      "Training step:  1968\n",
      "Loss: 122.92893958340747\n",
      "Training step:  1969\n",
      "Loss: 102.04775329343016\n",
      "Training step:  1970\n",
      "Loss: 122.92809899126198\n",
      "Training step:  1971\n",
      "Loss: 102.046774263131\n",
      "Training step:  1972\n",
      "Loss: 122.92726022614832\n",
      "Training step:  1973\n",
      "Loss: 102.04579754183031\n",
      "Training step:  1974\n",
      "Loss: 122.92642328352667\n",
      "Training step:  1975\n",
      "Loss: 102.04482312304654\n",
      "Training step:  1976\n",
      "Loss: 122.9255881588311\n",
      "Training step:  1977\n",
      "Loss: 102.04385100029948\n",
      "Training step:  1978\n",
      "Loss: 122.92475484751736\n",
      "Training step:  1979\n",
      "Loss: 102.04288116715469\n",
      "Training step:  1980\n",
      "Loss: 122.92392334507272\n",
      "Training step:  1981\n",
      "Loss: 102.04191361720025\n",
      "Training step:  1982\n",
      "Loss: 122.92309364699109\n",
      "Training step:  1983\n",
      "Loss: 102.04094834402541\n",
      "Training step:  1984\n",
      "Loss: 122.92226574874799\n",
      "Training step:  1985\n",
      "Loss: 102.03998534124197\n",
      "Training step:  1986\n",
      "Loss: 122.92143964585739\n",
      "Training step:  1987\n",
      "Loss: 102.03902460249489\n",
      "Training step:  1988\n",
      "Loss: 122.92061533385147\n",
      "Training step:  1989\n",
      "Loss: 102.03806612146126\n",
      "Training step:  1990\n",
      "Loss: 122.91979280828004\n",
      "Training step:  1991\n",
      "Loss: 102.03710989181538\n",
      "Training step:  1992\n",
      "Loss: 122.91897206467397\n",
      "Training step:  1993\n",
      "Loss: 102.036155907258\n",
      "Training step:  1994\n",
      "Loss: 122.91815309860246\n",
      "Training step:  1995\n",
      "Loss: 102.03520416152011\n",
      "Training step:  1996\n",
      "Loss: 122.91733590563389\n",
      "Training step:  1997\n",
      "Loss: 102.03425464833438\n",
      "Training step:  1998\n",
      "Loss: 122.91652048134392\n",
      "Training step:  1999\n",
      "Loss: 102.03330736146738\n",
      "Loss_min: tensor(3.6533, grad_fn=<AddBackward0>)\n",
      "[ 36  49  63  86 110 170 196 226 269 289 314 334 351 364 368]\n",
      "out\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "out\n",
      "4\n",
      "{'beta': -0.011667957698391032, 'gamma_2': 0.02185521739434857, 'theta': 9.836929108058766e-05}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "citys=['湖北','武汉','深圳','全国']\n",
    "N_inits=[59170000.,2870000.,13026600.]\n",
    "datetime='02-10'\n",
    "time='0209'\n",
    "paths=['./ncov/data/hubei_截至'+time+'_24时.csv','./ncov/data/wuhan_截至'+time+'_24时.csv','./ncov/data/shenzhen_截至'+time+'_24时.csv','./ncov/data/nation_截至'+time+'_24时.csv']\n",
    "for i in range(4):\n",
    "#     i=2\n",
    "    data=read_data(paths[i])\n",
    "    city_name=citys[i]\n",
    "    N=0\n",
    "    if i == 3:\n",
    "        N = (max(data['E']) + max(data['I']) + max(data['cured']) + max(data['dead'])) * 100.\n",
    "    else :\n",
    "        N = N_inits[i]\n",
    "    model_city_date_path = train_with_city_data(data,N,datetime,city_name)\n",
    "    load_model_predict(model_city_date_path, data, city_name=city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_acc(data, accumulated_confirmed, accumulated_pred_confirmed, xlen=10, city=u'武汉', pred_date_len=0):\n",
    "    # len_data = len(list(set(data.index)))\n",
    "    # print(len_data)\n",
    "    T_name = 'time'\n",
    "    plt.figure(figsize=(xlen, 6))\n",
    "    # accumulated_confirmed = data[I_name]\n",
    "    # accumulated_death = data['accumulated_death']\n",
    "    # accumulated_recovered = data[R_name]\n",
    "    time_val = data[T_name].values\n",
    "    \n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1,pred_date_len+1):\n",
    "        pred_time.append(max_time_val+np.timedelta64(i,'D')) \n",
    "    # print(pred_time)\n",
    "    if pred_time==[]:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time),axis=0)\n",
    "    plt.plot(time_val, accumulated_confirmed, color = 'red', label = '累计确诊人数',marker = 'x')\n",
    "    plt.plot(merge_time, accumulated_pred_confirmed, color = 'blue',label = '预测的累计确诊人数',marker = 'x')\n",
    "    # plt.plot(accumulated_death, color = 'gray',label = '累计死亡人数',marker = 'x')\n",
    "    # plt.plot(time_val, accumulated_recovered, color = 'green', label = '累计治愈人数',marker = '.')\n",
    "    # plt.plot(merge_time, pred_R, color = 'black', label = '预测的累计治愈人数',marker = '.')\n",
    "    # plt.plot(RES[:,2],color = 'orange',label = 'The Exposed',marker = '.')\n",
    "    # plt.plot(RES[:,3],color = 'green',label = 'The Recovered',marker = '.')\n",
    "    # for a, b in zip(merge_time, pred_I):\n",
    "    #     plt.text(a, b+0.3, b, ha='center', va='bottom', fontsize=12, color='blue')\n",
    "    # for a, b in zip(time_val, accumulated_confirmed):\n",
    "    #     plt.text(a, b-10, b, ha='center', va='bottom', fontsize=12, color='red')\n",
    "    for a,b in zip(merge_time, accumulated_pred_confirmed):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,5), textcoords='offset points',color='blue')\n",
    "    for a,b in zip(time_val, accumulated_confirmed):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,20), textcoords='offset points',color='red')\n",
    "\n",
    "    city_title = u'疫情状况-'+city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')   \n",
    "    plt.ylabel(u'人数')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_new(data, new_confirm, pred_new_confirm, xlen=10, city=u'武汉', pred_date_len=0):\n",
    "    # len_data = len(list(set(data.index)))\n",
    "    # print(len_data)\n",
    "    plt.figure(figsize=(xlen, 6))\n",
    "    T_name = 'time'\n",
    "    time_val = data[T_name].values\n",
    "    time_val = time_val[1:]\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1,pred_date_len+1):\n",
    "        pred_time.append(max_time_val+np.timedelta64(i,'D')) \n",
    "    # print(pred_time)\n",
    "    if pred_time==[]:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time),axis=0)\n",
    "    plt.plot(time_val, new_confirm, color = 'red', label = '新增确诊人数',marker = 'x')\n",
    "    plt.plot(merge_time, pred_new_confirm, color = 'blue',label = '新增累计确诊人数',marker = 'x')\n",
    "    # plt.plot(accumulated_death, color = 'gray',label = '累计死亡人数',marker = 'x')\n",
    "    # plt.plot(time_val, accumulated_recovered, color = 'green', label = '累计治愈人数',marker = '.')\n",
    "    # plt.plot(merge_time, pred_R, color = 'black', label = '预测的累计治愈人数',marker = '.')\n",
    "    # plt.plot(RES[:,2],color = 'orange',label = 'The Exposed',marker = '.')\n",
    "    # plt.plot(RES[:,3],color = 'green',label = 'The Recovered',marker = '.')\n",
    "    # for a, b in zip(merge_time, pred_I):\n",
    "    #     plt.text(a, b+0.3, b, ha='center', va='bottom', fontsize=12, color='blue')\n",
    "    # for a, b in zip(time_val, accumulated_confirmed):\n",
    "    #     plt.text(a, b-10, b, ha='center', va='bottom', fontsize=12, color='red')\n",
    "    for a,b in zip(merge_time, pred_new_confirm):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,5), textcoords='offset points',color='blue')\n",
    "    for a,b in zip(time_val, new_confirm):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,20), textcoords='offset points',color='red')\n",
    "\n",
    "    city_title = u'疫情状况-'+city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')   \n",
    "    plt.ylabel(u'人数')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import os\n",
    "# def loss_fn(pred, gt):\n",
    "#     T = gt.shape\n",
    "#     loss = torch.tensor([0.])\n",
    "#     for i in range(T.data.numpy()):\n",
    "#         loss = loss + torch.mean((i+1)*torch.pow(pred[i]-gt[i],2))\n",
    "    # return loss\n",
    "def make_dir(city, date):\n",
    "    save_root_path = 'models/'\n",
    "    model_city_path = os.path.join(save_root_path,city)\n",
    "    \n",
    "    model_city_date_path = os.path.join(model_city_path,date)\n",
    "\n",
    "    if not os.path.exists(model_city_date_path):\n",
    "        print(model_city_date_path)\n",
    "        os.makedirs(model_city_date_path)\n",
    "    return model_city_date_path\n",
    "\n",
    "def train(data, model_city_date_path, N=1e7, I_init=1e-6, R_init=1e-6/2., D_init=1e-6/6., features=['accumulated_confirmed', 'accumulated_recovered', 'accumulated_death'], max_epoches = 400):\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    data_feat = data[features]\n",
    "    Input = np.array(data_feat,dtype=np.float)\n",
    "    print(Input.shape)\n",
    "    date_len = len(Input)\n",
    "    print(date_len)\n",
    "    model = SEIR_model(date_len,  pred_date_len = 10, N=N, I_init=I_init, R_init=R_init, D_init=D_init)\n",
    "\n",
    "    lr = 0.01\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    loss_min = 1e8\n",
    "    for step in range(max_epoches):\n",
    "        print(\"Training step: \", step)\n",
    "        Input = torch.tensor(Input)\n",
    "        model_inp = Input[:-1]\n",
    "        S,I,E,R,D, beta,gamma_2 = model(model_inp.float())\n",
    "        # print(output)\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        pred_confirmed = I\n",
    "        pred_recovered = R\n",
    "        pred_dead = D\n",
    "        # print(pred_confirmed)\n",
    "        \n",
    "        confirmed_gt_tensor = Input[:,0]\n",
    "        recovered_gt_tensor = Input[:,1]\n",
    "        dead_gt_tensor = Input[:,2]\n",
    "        # print(recovered_gt_tensor)\n",
    "        # print(pred_confirmed.shape)\n",
    "        # loss = loss_fn(pred_confirmed,confirmed_gt_tensor)\n",
    "        loss = loss_fn(pred_confirmed, confirmed_gt_tensor) + loss_fn(pred_recovered, recovered_gt_tensor) + loss_fn(pred_dead, dead_gt_tensor)\n",
    "        print(\"Loss: {}\".format(loss))\n",
    "        if loss<loss_min:\n",
    "            loss_min = loss\n",
    "            torch.save(model, model_pt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss_min:\",loss_min)\n",
    "    return S,I,E,R,D\n",
    "\n",
    "\n",
    "# model_city_date_path = make_dir('wuhan','02-03')\n",
    "# features=['accumulated_confirmed', 'accumulated_recovered']\n",
    "# S,I,E,R,model = train(data_wh_feat, model_city_date_path, N=2870000., I_init=41, R_init=2., features=features, max_epoches=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_predict(model_city_date_path, data, N_cur=0,beta=0,gamma_2=0,theta=0, city_name='深圳',c='confirmed', features=['I','cured','dead'], pred_date_len=5):\n",
    "    I_name,recover_name,dead_name = features\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    I = model.I_tensor_cur\n",
    "    R = model.R_tensor_cur\n",
    "    D = model.D_tensor_cur\n",
    "    I_pred_old = (I.detach().numpy()).astype(np.int)\n",
    "    R_pred_old = (R.detach().numpy()).astype(np.int)\n",
    "    D_pred_old = (D.detach().numpy()).astype(np.int)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    print(confirm_origin)\n",
    "    plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name)\n",
    "\n",
    "\n",
    "    new_confirm = cal_new_confirm(np.array(data[I_name]),np.array(data[recover_name]),np.array(data[dead_name]))\n",
    "    cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    new_confirm_pred = cal_new_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "\n",
    "    S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(N_cur=N_cur,beta=beta,gamma_2=gamma_2,theta=theta, pred_date_len = pred_date_len)\n",
    "    I_pred_new = (I_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    R_pred_new = (R_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    D_pred_new = (D_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    I_pred_total = np.concatenate((I_pred_old,I_pred_new),axis=0)\n",
    "    R_pred_total = np.concatenate((R_pred_old,R_pred_new),axis=0)\n",
    "    D_pred_total = np.concatenate((D_pred_old,D_pred_new),axis=0)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name, pred_date_len=pred_date_len)\n",
    "\n",
    "    new_confirm_pred_total = cal_new_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    new_confirm_pred_total\n",
    "\n",
    "    plot_daily_new(data, new_confirm, new_confirm_pred_total, city=city_name, pred_date_len=pred_date_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_china = pd.read_excel('./ncov/data/nation_data.xlsx')\n",
    "# data_china = pd.read_csv('./ncov/data/nation/nation.csv')\n",
    "# data_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_china['time'] = data_china['time'].apply(lambda x: '2020/'+x.replace('月','/').replace('日',''))\n",
    "# data_china['time'] = pd.to_datetime(data_china['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_china['accumulated_confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_city_date_path = make_dir('china','02-08')\n",
    "# features=['accumulated_confirmed', 'accumulated_cured', 'accumulated_death']\n",
    "# I_init = float(data_china['accumulated_confirmed'].iloc[0])\n",
    "# R_init = float(data_china['accumulated_cured'].iloc[0])\n",
    "# D_init = float(data_china['accumulated_death'].iloc[0])\n",
    "# N = 13000000000.\n",
    "# S_china,I_china,E_china,R_china,D_china = train(data_china, model_city_date_path, N=N, I_init=I_init, R_init=R_init, D_init=D_init, features=features, max_epoches=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_city_date_path='models/china/02-08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'beta_model_3': 0.09111736783585582, 'gamma_2_model_3': 0.016532860820465893, 'N_model_3': 13000000000.106674, 'theta_model_3': 0.006605514213817316}\n",
    "# def change_key(param,i):\n",
    "#     for k in list(param.keys()):\n",
    "#         old_key = k\n",
    "#         new_key = k.replace(f'_model_{i}','')\n",
    "#         param[new_key]=param.pop(old_key)\n",
    "#     return param\n",
    "# param = change_key(param,3)\n",
    "# param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model_predict(model_city_date_path, data_china, N_cur=param['N'],beta=param['beta'],gamma_2=param['gamma_2'],theta=param['theta'],city_name='全国', c='accumulated_confirmed', features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data = pd.read_csv('./ncov/data/nation/allcity_20200209.csv')\n",
    "# merge_data = merge_data.rename(columns = {'updatetime':'time'})\n",
    "# merge_data['time'] = merge_data['time'].apply(lambda x: '2020/'+x)\n",
    "# merge_data['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data['I'] = merge_data['confirmed']-merge_data['dead']-merge_data['cured']\n",
    "# merge_data['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data['time']= pd.to_datetime(merge_data['time'])\n",
    "# merge_data['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data['I'] = data['confirmed']-data['dead']-data['cured']\n",
    "    # data['E']=data['suspected']+data['close_contact']+data['under_medical_observation']\n",
    "    data['time']= pd.to_datetime(data['time'])\n",
    "    # data['time'] = data['time'].apply(lambda x:x-np.timedelta64(1,'D'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>suspected</th>\n",
       "      <th>dead</th>\n",
       "      <th>cured</th>\n",
       "      <th>close_contact</th>\n",
       "      <th>time</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>291</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>325</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>327</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>569</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>662</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>904</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>878</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>947</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>958</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1045</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1153</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1104</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confirmed  suspected  dead  cured  close_contact       time    I\n",
       "0          36          0     0      2              0 2020-01-26   34\n",
       "1          49          0     0      3              0 2020-01-27   46\n",
       "2          63          0     0      4              0 2020-01-28   59\n",
       "3          86          0     0      4            291 2020-01-29   82\n",
       "4         110          0     0      4            325 2020-01-30  106\n",
       "5         170          0     0      4            327 2020-01-31  166\n",
       "6         196          0     0      5            569 2020-02-01  191\n",
       "7         226          0     0      5            662 2020-02-02  221\n",
       "8         269          0     0     10            904 2020-02-03  259\n",
       "9         289          0     0     13            878 2020-02-04  276\n",
       "10        314          0     0     16            947 2020-02-05  298\n",
       "11        334          0     0     22            958 2020-02-06  312\n",
       "12        351          0     0     31           1045 2020-02-07  320\n",
       "13        364          0     0     31           1153 2020-02-08  333\n",
       "14        368          0     0     46           1104 2020-02-09  322"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sz = read_data('./ncov/data/shenzhen_截至0209_24时.csv')\n",
    "# data_sz['I'] = data_sz['confirmed']-data_sz['dead']-data_sz['cured']\n",
    "# data_sz['time']= pd.to_datetime(data_sz['time'])\n",
    "data_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc_confirm(I,R,D):\n",
    "    return I+R+D\n",
    "def cal_new_confirm(I,R,D):\n",
    "    acc_confirm = cal_acc_confirm(I,R,D)\n",
    "    new_confirm = np.zeros((len(acc_confirm)-1))\n",
    "    for i in range(len(acc_confirm)-1):\n",
    "        new_confirm[i] = acc_confirm[i+1]-acc_confirm[i]\n",
    "    return new_confirm\n",
    "def get_data_acc_confirm(data,c='confirmed'):\n",
    "    return np.array(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3)\n",
      "15\n",
      "Training step:  0\n",
      "Loss: 14933.243517727318\n",
      "Training step:  1\n",
      "Loss: 5765.4618840347875\n",
      "Training step:  2\n",
      "Loss: 5757.817207723621\n",
      "Training step:  3\n",
      "Loss: 6019.973681905188\n",
      "Training step:  4\n",
      "Loss: 5443.304327550675\n",
      "Training step:  5\n",
      "Loss: 4708.770600577024\n",
      "Training step:  6\n",
      "Loss: 4333.876125140409\n",
      "Training step:  7\n",
      "Loss: 4143.34768297394\n",
      "Training step:  8\n",
      "Loss: 3864.521298208378\n",
      "Training step:  9\n",
      "Loss: 3587.69783784463\n",
      "Training step:  10\n",
      "Loss: 3361.115383745678\n",
      "Training step:  11\n",
      "Loss: 3139.6730191619336\n",
      "Training step:  12\n",
      "Loss: 2923.4880141890953\n",
      "Training step:  13\n",
      "Loss: 2723.520314327383\n",
      "Training step:  14\n",
      "Loss: 2534.029236329779\n",
      "Training step:  15\n",
      "Loss: 2353.93449395042\n",
      "Training step:  16\n",
      "Loss: 2184.9203400346223\n",
      "Training step:  17\n",
      "Loss: 2026.078274745615\n",
      "Training step:  18\n",
      "Loss: 1877.3053914969419\n",
      "Training step:  19\n",
      "Loss: 1738.6800414881275\n",
      "Training step:  20\n",
      "Loss: 1609.8818230341026\n",
      "Training step:  21\n",
      "Loss: 1490.721333975655\n",
      "Training step:  22\n",
      "Loss: 1380.9156654547132\n",
      "Training step:  23\n",
      "Loss: 1280.081553824605\n",
      "Training step:  24\n",
      "Loss: 1187.792605682183\n",
      "Training step:  25\n",
      "Loss: 1103.5527923012974\n",
      "Training step:  26\n",
      "Loss: 1026.829910767321\n",
      "Training step:  27\n",
      "Loss: 957.0669897431785\n",
      "Training step:  28\n",
      "Loss: 893.694471379671\n",
      "Training step:  29\n",
      "Loss: 836.1466279913531\n",
      "Training step:  30\n",
      "Loss: 783.8725752328064\n",
      "Training step:  31\n",
      "Loss: 736.3467866443052\n",
      "Training step:  32\n",
      "Loss: 693.075876172745\n",
      "Training step:  33\n",
      "Loss: 653.6032501475354\n",
      "Training step:  34\n",
      "Loss: 617.5117738195604\n",
      "Training step:  35\n",
      "Loss: 584.4245532052914\n",
      "Training step:  36\n",
      "Loss: 554.0042956473462\n",
      "Training step:  37\n",
      "Loss: 525.9515426669129\n",
      "Training step:  38\n",
      "Loss: 500.00220093288726\n",
      "Training step:  39\n",
      "Loss: 475.9246209556661\n",
      "Training step:  40\n",
      "Loss: 453.5164618400445\n",
      "Training step:  41\n",
      "Loss: 432.601520666684\n",
      "Training step:  42\n",
      "Loss: 413.0266624475344\n",
      "Training step:  43\n",
      "Loss: 394.65893733446467\n",
      "Training step:  44\n",
      "Loss: 377.3829359013581\n",
      "Training step:  45\n",
      "Loss: 361.0984078115795\n",
      "Training step:  46\n",
      "Loss: 345.71814878563555\n",
      "Training step:  47\n",
      "Loss: 331.1661468917392\n",
      "Training step:  48\n",
      "Loss: 317.3759706724893\n",
      "Training step:  49\n",
      "Loss: 304.2893773330228\n",
      "Training step:  50\n",
      "Loss: 291.85511725793936\n",
      "Training step:  51\n",
      "Loss: 280.02791115688615\n",
      "Training step:  52\n",
      "Loss: 268.76757747251554\n",
      "Training step:  53\n",
      "Loss: 258.0382896549916\n",
      "Training step:  54\n",
      "Loss: 247.80794506398348\n",
      "Training step:  55\n",
      "Loss: 238.04762947146094\n",
      "Training step:  56\n",
      "Loss: 228.73116326104486\n",
      "Training step:  57\n",
      "Loss: 219.83471733217618\n",
      "Training step:  58\n",
      "Loss: 211.33648839070815\n",
      "Training step:  59\n",
      "Loss: 203.21642476604114\n",
      "Training step:  60\n",
      "Loss: 195.45599515298102\n",
      "Training step:  61\n",
      "Loss: 188.03799375093723\n",
      "Training step:  62\n",
      "Loss: 180.94637619341358\n",
      "Training step:  63\n",
      "Loss: 174.16612145500662\n",
      "Training step:  64\n",
      "Loss: 167.6831156105045\n",
      "Training step:  65\n",
      "Loss: 161.48405391739257\n",
      "Training step:  66\n",
      "Loss: 155.55635821335082\n",
      "Training step:  67\n",
      "Loss: 149.88810707467115\n",
      "Training step:  68\n",
      "Loss: 144.46797657750375\n",
      "Training step:  69\n",
      "Loss: 139.28518984801866\n",
      "Training step:  70\n",
      "Loss: 134.3294738853033\n",
      "Training step:  71\n",
      "Loss: 129.59102239671938\n",
      "Training step:  72\n",
      "Loss: 125.06046360376644\n",
      "Training step:  73\n",
      "Loss: 120.72883216123772\n",
      "Training step:  74\n",
      "Loss: 116.58754448753146\n",
      "Training step:  75\n",
      "Loss: 112.62837693289845\n",
      "Training step:  76\n",
      "Loss: 108.84344631878764\n",
      "Training step:  77\n",
      "Loss: 105.22519246846753\n",
      "Training step:  78\n",
      "Loss: 101.7663624197298\n",
      "Training step:  79\n",
      "Loss: 98.4599960674696\n",
      "Training step:  80\n",
      "Loss: 95.29941302962737\n",
      "Training step:  81\n",
      "Loss: 92.27820056649234\n",
      "Training step:  82\n",
      "Loss: 89.39020241247503\n",
      "Training step:  83\n",
      "Loss: 86.62950840267683\n",
      "Training step:  84\n",
      "Loss: 83.99044479514319\n",
      "Training step:  85\n",
      "Loss: 81.46756520463103\n",
      "Training step:  86\n",
      "Loss: 79.05564207583917\n",
      "Training step:  87\n",
      "Loss: 76.74965863398705\n",
      "Training step:  88\n",
      "Loss: 74.5448012589252\n",
      "Training step:  89\n",
      "Loss: 72.43645223592037\n",
      "Training step:  90\n",
      "Loss: 70.42018284226637\n",
      "Training step:  91\n",
      "Loss: 68.49174673405474\n",
      "Training step:  92\n",
      "Loss: 66.64707360201604\n",
      "Training step:  93\n",
      "Loss: 64.88226306938869\n",
      "Training step:  94\n",
      "Loss: 63.19357880838736\n",
      "Training step:  95\n",
      "Loss: 61.577442855079255\n",
      "Training step:  96\n",
      "Loss: 60.03043010536673\n",
      "Training step:  97\n",
      "Loss: 58.549262977376586\n",
      "Training step:  98\n",
      "Loss: 57.130806227849774\n",
      "Training step:  99\n",
      "Loss: 55.77206191218028\n",
      "Training step:  100\n",
      "Loss: 54.470164479542\n",
      "Training step:  101\n",
      "Loss: 53.22237599611125\n",
      "Training step:  102\n",
      "Loss: 52.02608149074494\n",
      "Training step:  103\n",
      "Loss: 50.878784418626275\n",
      "Training step:  104\n",
      "Loss: 49.77810223936401\n",
      "Training step:  105\n",
      "Loss: 48.721762106828386\n",
      "Training step:  106\n",
      "Loss: 47.707596668667534\n",
      "Training step:  107\n",
      "Loss: 46.73353997395921\n",
      "Training step:  108\n",
      "Loss: 45.7976234878558\n",
      "Training step:  109\n",
      "Loss: 44.897972212373574\n",
      "Training step:  110\n",
      "Loss: 44.03280091267891\n",
      "Training step:  111\n",
      "Loss: 43.20041044835225\n",
      "Training step:  112\n",
      "Loss: 42.39918420917497\n",
      "Training step:  113\n",
      "Loss: 41.62758465498705\n",
      "Training step:  114\n",
      "Loss: 40.884149959133254\n",
      "Training step:  115\n",
      "Loss: 40.16749075494676\n",
      "Training step:  116\n",
      "Loss: 39.476286984622355\n",
      "Training step:  117\n",
      "Loss: 38.80928484971945\n",
      "Training step:  118\n",
      "Loss: 38.16529386241158\n",
      "Training step:  119\n",
      "Loss: 37.54318399646024\n",
      "Training step:  120\n",
      "Loss: 36.941882936761615\n",
      "Training step:  121\n",
      "Loss: 36.36037342617497\n",
      "Training step:  122\n",
      "Loss: 35.797690708211235\n",
      "Training step:  123\n",
      "Loss: 35.25292006403284\n",
      "Training step:  124\n",
      "Loss: 34.725194442104645\n",
      "Training step:  125\n",
      "Loss: 34.21369217871463\n",
      "Training step:  126\n",
      "Loss: 33.71763480749753\n",
      "Training step:  127\n",
      "Loss: 33.23628495599927\n",
      "Training step:  128\n",
      "Loss: 32.76894432724279\n",
      "Training step:  129\n",
      "Loss: 32.31495176419422\n",
      "Training step:  130\n",
      "Loss: 31.87368139496995\n",
      "Training step:  131\n",
      "Loss: 31.444540856580392\n",
      "Training step:  132\n",
      "Loss: 31.02696959497633\n",
      "Training step:  133\n",
      "Loss: 30.620437239133334\n",
      "Training step:  134\n",
      "Loss: 30.224442046900457\n",
      "Training step:  135\n",
      "Loss: 29.838509420327824\n",
      "Training step:  136\n",
      "Loss: 29.462190488193816\n",
      "Training step:  137\n",
      "Loss: 29.09506075345665\n",
      "Training step:  138\n",
      "Loss: 28.736718803374206\n",
      "Training step:  139\n",
      "Loss: 28.386785080055326\n",
      "Training step:  140\n",
      "Loss: 28.044900709233367\n",
      "Training step:  141\n",
      "Loss: 27.710726385084484\n",
      "Training step:  142\n",
      "Loss: 27.383941308948643\n",
      "Training step:  143\n",
      "Loss: 27.064242179851217\n",
      "Training step:  144\n",
      "Loss: 26.751342234765705\n",
      "Training step:  145\n",
      "Loss: 26.44497033660406\n",
      "Training step:  146\n",
      "Loss: 26.144870107969176\n",
      "Training step:  147\n",
      "Loss: 25.850799108751417\n",
      "Training step:  148\n",
      "Loss: 25.562528055706558\n",
      "Training step:  149\n",
      "Loss: 25.279840082201325\n",
      "Training step:  150\n",
      "Loss: 25.002530036366913\n",
      "Training step:  151\n",
      "Loss: 24.730403815956535\n",
      "Training step:  152\n",
      "Loss: 24.463277738253854\n",
      "Training step:  153\n",
      "Loss: 24.2009779434361\n",
      "Training step:  154\n",
      "Loss: 23.943339829848917\n",
      "Training step:  155\n",
      "Loss: 23.690207519703513\n",
      "Training step:  156\n",
      "Loss: 23.4414333537599\n",
      "Training step:  157\n",
      "Loss: 23.196877413613123\n",
      "Training step:  158\n",
      "Loss: 22.956407070251768\n",
      "Training step:  159\n",
      "Loss: 22.719896557607026\n",
      "Training step:  160\n",
      "Loss: 22.487226569864134\n",
      "Training step:  161\n",
      "Loss: 22.25828388135311\n",
      "Training step:  162\n",
      "Loss: 22.032960987888412\n",
      "Training step:  163\n",
      "Loss: 21.81115576846859\n",
      "Training step:  164\n",
      "Loss: 21.592771166297908\n",
      "Training step:  165\n",
      "Loss: 21.37771488813284\n",
      "Training step:  166\n",
      "Loss: 21.165899121001473\n",
      "Training step:  167\n",
      "Loss: 20.957240265383383\n",
      "Training step:  168\n",
      "Loss: 20.751658683982924\n",
      "Training step:  169\n",
      "Loss: 20.549078465261946\n",
      "Training step:  170\n",
      "Loss: 20.349427200941182\n",
      "Training step:  171\n",
      "Loss: 20.15263577671339\n",
      "Training step:  172\n",
      "Loss: 19.958638175448815\n",
      "Training step:  173\n",
      "Loss: 19.767371292205034\n",
      "Training step:  174\n",
      "Loss: 19.578774760389592\n",
      "Training step:  175\n",
      "Loss: 19.392790788452782\n",
      "Training step:  176\n",
      "Loss: 19.209364006519202\n",
      "Training step:  177\n",
      "Loss: 19.028441322396784\n",
      "Training step:  178\n",
      "Loss: 18.849971786430054\n",
      "Training step:  179\n",
      "Loss: 18.673906464688727\n",
      "Training step:  180\n",
      "Loss: 18.500198320013833\n",
      "Training step:  181\n",
      "Loss: 18.328802100462067\n",
      "Training step:  182\n",
      "Loss: 18.159674234717755\n",
      "Training step:  183\n",
      "Loss: 17.992772734063177\n",
      "Training step:  184\n",
      "Loss: 17.82805710051644\n",
      "Training step:  185\n",
      "Loss: 17.665488240772813\n",
      "Training step:  186\n",
      "Loss: 17.50502838559932\n",
      "Training step:  187\n",
      "Loss: 17.34664101435515\n",
      "Training step:  188\n",
      "Loss: 17.190290784326386\n",
      "Training step:  189\n",
      "Loss: 17.03594346458211\n",
      "Training step:  190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 16.883565874073586\n",
      "Training step:  191\n",
      "Loss: 16.733125823715053\n",
      "Training step:  192\n",
      "Loss: 16.58459206219989\n",
      "Training step:  193\n",
      "Loss: 16.43793422531712\n",
      "Training step:  194\n",
      "Loss: 16.29312278855084\n",
      "Training step:  195\n",
      "Loss: 16.150129022753763\n",
      "Training step:  196\n",
      "Loss: 16.008924952701108\n",
      "Training step:  197\n",
      "Loss: 15.86948331834003\n",
      "Training step:  198\n",
      "Loss: 15.73177753856297\n",
      "Training step:  199\n",
      "Loss: 15.595781677341897\n",
      "Training step:  200\n",
      "Loss: 15.461470412069945\n",
      "Training step:  201\n",
      "Loss: 15.328819003968244\n",
      "Training step:  202\n",
      "Loss: 15.19780327042152\n",
      "Training step:  203\n",
      "Loss: 15.068399559116743\n",
      "Training step:  204\n",
      "Loss: 14.940584723865072\n",
      "Training step:  205\n",
      "Loss: 14.814336101996386\n",
      "Training step:  206\n",
      "Loss: 14.689631493220876\n",
      "Training step:  207\n",
      "Loss: 14.566449139859676\n",
      "Training step:  208\n",
      "Loss: 14.444767708353131\n",
      "Training step:  209\n",
      "Loss: 14.32456627196003\n",
      "Training step:  210\n",
      "Loss: 14.205824294566764\n",
      "Training step:  211\n",
      "Loss: 14.08852161553217\n",
      "Training step:  212\n",
      "Loss: 13.972638435495575\n",
      "Training step:  213\n",
      "Loss: 13.858155303084267\n",
      "Training step:  214\n",
      "Loss: 13.74505310245545\n",
      "Training step:  215\n",
      "Loss: 13.633313041619573\n",
      "Training step:  216\n",
      "Loss: 13.522916641484645\n",
      "Training step:  217\n",
      "Loss: 13.4138457255802\n",
      "Training step:  218\n",
      "Loss: 13.306082410400789\n",
      "Training step:  219\n",
      "Loss: 13.199609096344762\n",
      "Training step:  220\n",
      "Loss: 13.094408459178563\n",
      "Training step:  221\n",
      "Loss: 12.990463442031158\n",
      "Training step:  222\n",
      "Loss: 12.887757247818405\n",
      "Training step:  223\n",
      "Loss: 12.786273332163757\n",
      "Training step:  224\n",
      "Loss: 12.685995396630519\n",
      "Training step:  225\n",
      "Loss: 12.586907382477017\n",
      "Training step:  226\n",
      "Loss: 12.488993464530898\n",
      "Training step:  227\n",
      "Loss: 12.392238045754215\n",
      "Training step:  228\n",
      "Loss: 12.296625751527445\n",
      "Training step:  229\n",
      "Loss: 12.202141425152124\n",
      "Training step:  230\n",
      "Loss: 12.108770122101436\n",
      "Training step:  231\n",
      "Loss: 12.016497106987938\n",
      "Training step:  232\n",
      "Loss: 11.925307846740125\n",
      "Training step:  233\n",
      "Loss: 11.835188010721774\n",
      "Training step:  234\n",
      "Loss: 11.746123460213491\n",
      "Training step:  235\n",
      "Loss: 11.658100257179031\n",
      "Training step:  236\n",
      "Loss: 11.571104644240561\n",
      "Training step:  237\n",
      "Loss: 11.485123083396681\n",
      "Training step:  238\n",
      "Loss: 11.40014222544156\n",
      "Training step:  239\n",
      "Loss: 11.316149093413559\n",
      "Training step:  240\n",
      "Loss: 11.233131201730599\n",
      "Training step:  241\n",
      "Loss: 11.151077765605425\n",
      "Training step:  242\n",
      "Loss: 11.069982201298048\n",
      "Training step:  243\n",
      "Loss: 10.989852870220194\n",
      "Training step:  244\n",
      "Loss: 10.91074422373282\n",
      "Training step:  245\n",
      "Loss: 10.832869398498003\n",
      "Training step:  246\n",
      "Loss: 10.756965961954274\n",
      "Training step:  247\n",
      "Loss: 10.685581618845607\n",
      "Training step:  248\n",
      "Loss: 10.62742112826826\n",
      "Training step:  249\n",
      "Loss: 10.612930083094033\n",
      "Training step:  250\n",
      "Loss: 10.74710927345207\n",
      "Training step:  251\n",
      "Loss: 11.410647412051267\n",
      "Training step:  252\n",
      "Loss: 13.899916813374634\n",
      "Training step:  253\n",
      "Loss: 23.28456542562884\n",
      "Training step:  254\n",
      "Loss: 55.14614295120313\n",
      "Training step:  255\n",
      "Loss: 183.1593600292103\n",
      "Training step:  256\n",
      "Loss: 529.9783143382901\n",
      "Training step:  257\n",
      "Loss: 2088.902506328456\n",
      "Training step:  258\n",
      "Loss: 1996.4148368115586\n",
      "Training step:  259\n",
      "Loss: 5282.036888001939\n",
      "Training step:  260\n",
      "Loss: 29.99835161661332\n",
      "Training step:  261\n",
      "Loss: 1775.1097920510083\n",
      "Training step:  262\n",
      "Loss: 5362.2597011442795\n",
      "Training step:  263\n",
      "Loss: 119.54847464112645\n",
      "Training step:  264\n",
      "Loss: 3918.1015800749615\n",
      "Training step:  265\n",
      "Loss: 8173.091957528702\n",
      "Training step:  266\n",
      "Loss: 3167.7697800344417\n",
      "Training step:  267\n",
      "Loss: 4798.744485891757\n",
      "Training step:  268\n",
      "Loss: 4246.262677571925\n",
      "Training step:  269\n",
      "Loss: 1712.890723722127\n",
      "Training step:  270\n",
      "Loss: 2032.5000074878492\n",
      "Training step:  271\n",
      "Loss: 662.2450812035968\n",
      "Training step:  272\n",
      "Loss: 214.57024700787983\n",
      "Training step:  273\n",
      "Loss: 397.7448051389758\n",
      "Training step:  274\n",
      "Loss: 79.93051795240746\n",
      "Training step:  275\n",
      "Loss: 42.16100700792692\n",
      "Training step:  276\n",
      "Loss: 61.38293138705451\n",
      "Training step:  277\n",
      "Loss: 14.199482816474987\n",
      "Training step:  278\n",
      "Loss: 16.33643379908411\n",
      "Training step:  279\n",
      "Loss: 15.556287930040885\n",
      "Training step:  280\n",
      "Loss: 10.130350791345258\n",
      "Training step:  281\n",
      "Loss: 11.06569575241363\n",
      "Training step:  282\n",
      "Loss: 10.409928204753001\n",
      "Training step:  283\n",
      "Loss: 9.84675762605735\n",
      "Training step:  284\n",
      "Loss: 9.933697998219522\n",
      "Training step:  285\n",
      "Loss: 9.744023041303752\n",
      "Training step:  286\n",
      "Loss: 9.648646603441714\n",
      "Training step:  287\n",
      "Loss: 9.606368828389828\n",
      "Training step:  288\n",
      "Loss: 9.530615511854474\n",
      "Training step:  289\n",
      "Loss: 9.475414582190751\n",
      "Training step:  290\n",
      "Loss: 9.424181150176171\n",
      "Training step:  291\n",
      "Loss: 9.370808563624282\n",
      "Training step:  292\n",
      "Loss: 9.321695496015641\n",
      "Training step:  293\n",
      "Loss: 9.273720123171554\n",
      "Training step:  294\n",
      "Loss: 9.226626906240506\n",
      "Training step:  295\n",
      "Loss: 9.181026168097178\n",
      "Training step:  296\n",
      "Loss: 9.136400003667429\n",
      "Training step:  297\n",
      "Loss: 9.092719148727088\n",
      "Training step:  298\n",
      "Loss: 9.049987847812057\n",
      "Training step:  299\n",
      "Loss: 9.008089678295159\n",
      "Training step:  300\n",
      "Loss: 8.96698212537759\n",
      "Training step:  301\n",
      "Loss: 8.926622882811284\n",
      "Training step:  302\n",
      "Loss: 8.88696005298538\n",
      "Training step:  303\n",
      "Loss: 8.84795446773125\n",
      "Training step:  304\n",
      "Loss: 8.809569101182532\n",
      "Training step:  305\n",
      "Loss: 8.771768466468576\n",
      "Training step:  306\n",
      "Loss: 8.734520977630595\n",
      "Training step:  307\n",
      "Loss: 8.697797376628218\n",
      "Training step:  308\n",
      "Loss: 8.66157053502985\n",
      "Training step:  309\n",
      "Loss: 8.625815568181645\n",
      "Training step:  310\n",
      "Loss: 8.590509494679049\n",
      "Training step:  311\n",
      "Loss: 8.555631077170927\n",
      "Training step:  312\n",
      "Loss: 8.521160712385633\n",
      "Training step:  313\n",
      "Loss: 8.487080278634693\n",
      "Training step:  314\n",
      "Loss: 8.453373012320826\n",
      "Training step:  315\n",
      "Loss: 8.420023400255964\n",
      "Training step:  316\n",
      "Loss: 8.387017075560316\n",
      "Training step:  317\n",
      "Loss: 8.35434072328493\n",
      "Training step:  318\n",
      "Loss: 8.321981994941716\n",
      "Training step:  319\n",
      "Loss: 8.289929429814562\n",
      "Training step:  320\n",
      "Loss: 8.258172382624165\n",
      "Training step:  321\n",
      "Loss: 8.226700957451374\n",
      "Training step:  322\n",
      "Loss: 8.195505947210286\n",
      "Training step:  323\n",
      "Loss: 8.16457877800794\n",
      "Training step:  324\n",
      "Loss: 8.133911458188074\n",
      "Training step:  325\n",
      "Loss: 8.103496531629379\n",
      "Training step:  326\n",
      "Loss: 8.073327034849946\n",
      "Training step:  327\n",
      "Loss: 8.043396457680455\n",
      "Training step:  328\n",
      "Loss: 8.013698707192688\n",
      "Training step:  329\n",
      "Loss: 7.984228074579635\n",
      "Training step:  330\n",
      "Loss: 7.954979204771706\n",
      "Training step:  331\n",
      "Loss: 7.925947068552366\n",
      "Training step:  332\n",
      "Loss: 7.8971269369561945\n",
      "Training step:  333\n",
      "Loss: 7.86851435777036\n",
      "Training step:  334\n",
      "Loss: 7.840105133960515\n",
      "Training step:  335\n",
      "Loss: 7.8118953038590195\n",
      "Training step:  336\n",
      "Loss: 7.783881122973443\n",
      "Training step:  337\n",
      "Loss: 7.75605904727875\n",
      "Training step:  338\n",
      "Loss: 7.7284257178700155\n",
      "Training step:  339\n",
      "Loss: 7.70097794686496\n",
      "Training step:  340\n",
      "Loss: 7.673712704451102\n",
      "Training step:  341\n",
      "Loss: 7.646627106984198\n",
      "Training step:  342\n",
      "Loss: 7.6197184060506835\n",
      "Training step:  343\n",
      "Loss: 7.592983978415147\n",
      "Training step:  344\n",
      "Loss: 7.566421316779117\n",
      "Training step:  345\n",
      "Loss: 7.540028021285382\n",
      "Training step:  346\n",
      "Loss: 7.513801791705939\n",
      "Training step:  347\n",
      "Loss: 7.487740420257426\n",
      "Training step:  348\n",
      "Loss: 7.461841784992893\n",
      "Training step:  349\n",
      "Loss: 7.436103843722285\n",
      "Training step:  350\n",
      "Loss: 7.410524628418659\n",
      "Training step:  351\n",
      "Loss: 7.385102240070128\n",
      "Training step:  352\n",
      "Loss: 7.359834843941199\n",
      "Training step:  353\n",
      "Loss: 7.334720665209896\n",
      "Training step:  354\n",
      "Loss: 7.309757984950588\n",
      "Training step:  355\n",
      "Loss: 7.28494513643344\n",
      "Training step:  356\n",
      "Loss: 7.2602805017155285\n",
      "Training step:  357\n",
      "Loss: 7.23576250849942\n",
      "Training step:  358\n",
      "Loss: 7.211389627237596\n",
      "Training step:  359\n",
      "Loss: 7.187160368462803\n",
      "Training step:  360\n",
      "Loss: 7.163073280326239\n",
      "Training step:  361\n",
      "Loss: 7.139126946326124\n",
      "Training step:  362\n",
      "Loss: 7.115319983211872\n",
      "Training step:  363\n",
      "Loss: 7.091651039049676\n",
      "Training step:  364\n",
      "Loss: 7.068118791435737\n",
      "Training step:  365\n",
      "Loss: 7.044721945846379\n",
      "Training step:  366\n",
      "Loss: 7.021459234112904\n",
      "Training step:  367\n",
      "Loss: 6.998329413012192\n",
      "Training step:  368\n",
      "Loss: 6.975331262962919\n",
      "Training step:  369\n",
      "Loss: 6.9524635868194355\n",
      "Training step:  370\n",
      "Loss: 6.9297252087553805\n",
      "Training step:  371\n",
      "Loss: 6.907114973229747\n",
      "Training step:  372\n",
      "Loss: 6.88463174402903\n",
      "Training step:  373\n",
      "Loss: 6.862274403379128\n",
      "Training step:  374\n",
      "Loss: 6.840041851121906\n",
      "Training step:  375\n",
      "Loss: 6.817933003950707\n",
      "Training step:  376\n",
      "Loss: 6.795946794700585\n",
      "Training step:  377\n",
      "Loss: 6.774082171689013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  378\n",
      "Loss: 6.75233809810255\n",
      "Training step:  379\n",
      "Loss: 6.730713551426276\n",
      "Training step:  380\n",
      "Loss: 6.709207522912934\n",
      "Training step:  381\n",
      "Loss: 6.687819017087669\n",
      "Training step:  382\n",
      "Loss: 6.666547051286732\n",
      "Training step:  383\n",
      "Loss: 6.645390655226962\n",
      "Training step:  384\n",
      "Loss: 6.624348870603181\n",
      "Training step:  385\n",
      "Loss: 6.603420750712556\n",
      "Training step:  386\n",
      "Loss: 6.582605360102614\n",
      "Training step:  387\n",
      "Loss: 6.561901774241959\n",
      "Training step:  388\n",
      "Loss: 6.541309079211384\n",
      "Training step:  389\n",
      "Loss: 6.5208263714141435\n",
      "Training step:  390\n",
      "Loss: 6.500452757303851\n",
      "Training step:  391\n",
      "Loss: 6.480187353128766\n",
      "Training step:  392\n",
      "Loss: 6.460029284690716\n",
      "Training step:  393\n",
      "Loss: 6.439977687118536\n",
      "Training step:  394\n",
      "Loss: 6.420031704653915\n",
      "Training step:  395\n",
      "Loss: 6.400190490449309\n",
      "Training step:  396\n",
      "Loss: 6.380453206377023\n",
      "Training step:  397\n",
      "Loss: 6.3608190228482755\n",
      "Training step:  398\n",
      "Loss: 6.341287118641967\n",
      "Training step:  399\n",
      "Loss: 6.321856680742092\n",
      "Training step:  400\n",
      "Loss: 6.302526904183298\n",
      "Training step:  401\n",
      "Loss: 6.283296991904054\n",
      "Training step:  402\n",
      "Loss: 6.2641661546069045\n",
      "Training step:  403\n",
      "Loss: 6.2451336106251265\n",
      "Training step:  404\n",
      "Loss: 6.226198585795416\n",
      "Training step:  405\n",
      "Loss: 6.207360313336472\n",
      "Training step:  406\n",
      "Loss: 6.188618033732441\n",
      "Training step:  407\n",
      "Loss: 6.169970994621611\n",
      "Training step:  408\n",
      "Loss: 6.151418450689474\n",
      "Training step:  409\n",
      "Loss: 6.132959663565921\n",
      "Training step:  410\n",
      "Loss: 6.114593901726833\n",
      "Training step:  411\n",
      "Loss: 6.096320440398748\n",
      "Training step:  412\n",
      "Loss: 6.078138561467515\n",
      "Training step:  413\n",
      "Loss: 6.0600475533899125\n",
      "Training step:  414\n",
      "Loss: 6.042046711108395\n",
      "Training step:  415\n",
      "Loss: 6.024135335968593\n",
      "Training step:  416\n",
      "Loss: 6.00631273563949\n",
      "Training step:  417\n",
      "Loss: 5.988578224036125\n",
      "Training step:  418\n",
      "Loss: 5.9709311212446705\n",
      "Training step:  419\n",
      "Loss: 5.953370753449533\n",
      "Training step:  420\n",
      "Loss: 5.935896452862761\n",
      "Training step:  421\n",
      "Loss: 5.918507557655191\n",
      "Training step:  422\n",
      "Loss: 5.901203411889513\n",
      "Training step:  423\n",
      "Loss: 5.883983365455143\n",
      "Training step:  424\n",
      "Loss: 5.866846774004563\n",
      "Training step:  425\n",
      "Loss: 5.849792998891345\n",
      "Training step:  426\n",
      "Loss: 5.832821407109543\n",
      "Training step:  427\n",
      "Loss: 5.815931371234521\n",
      "Training step:  428\n",
      "Loss: 5.7991222693651405\n",
      "Training step:  429\n",
      "Loss: 5.782393485066984\n",
      "Training step:  430\n",
      "Loss: 5.765744407317003\n",
      "Training step:  431\n",
      "Loss: 5.749174430449202\n",
      "Training step:  432\n",
      "Loss: 5.732682954101326\n",
      "Training step:  433\n",
      "Loss: 5.716269383162634\n",
      "Training step:  434\n",
      "Loss: 5.69993312772262\n",
      "Training step:  435\n",
      "Loss: 5.683673603020665\n",
      "Training step:  436\n",
      "Loss: 5.667490229396609\n",
      "Training step:  437\n",
      "Loss: 5.6513824322421184\n",
      "Training step:  438\n",
      "Loss: 5.635349641952874\n",
      "Training step:  439\n",
      "Loss: 5.619391293881552\n",
      "Training step:  440\n",
      "Loss: 5.603506828291627\n",
      "Training step:  441\n",
      "Loss: 5.58769569031158\n",
      "Training step:  442\n",
      "Loss: 5.571957329890388\n",
      "Training step:  443\n",
      "Loss: 5.556291201752954\n",
      "Training step:  444\n",
      "Loss: 5.540696765356766\n",
      "Training step:  445\n",
      "Loss: 5.525173484848891\n",
      "Training step:  446\n",
      "Loss: 5.509720829023631\n",
      "Training step:  447\n",
      "Loss: 5.494338271280588\n",
      "Training step:  448\n",
      "Loss: 5.479025289583706\n",
      "Training step:  449\n",
      "Loss: 5.463781366420252\n",
      "Training step:  450\n",
      "Loss: 5.448605988760995\n",
      "Training step:  451\n",
      "Loss: 5.433498648020191\n",
      "Training step:  452\n",
      "Loss: 5.418458840016576\n",
      "Training step:  453\n",
      "Loss: 5.403486064934677\n",
      "Training step:  454\n",
      "Loss: 5.388579827286523\n",
      "Training step:  455\n",
      "Loss: 5.373739635873686\n",
      "Training step:  456\n",
      "Loss: 5.358965003750196\n",
      "Training step:  457\n",
      "Loss: 5.3442554481853115\n",
      "Training step:  458\n",
      "Loss: 5.3296104906271715\n",
      "Training step:  459\n",
      "Loss: 5.315029656666569\n",
      "Training step:  460\n",
      "Loss: 5.300512476001234\n",
      "Training step:  461\n",
      "Loss: 5.2860584824003825\n",
      "Training step:  462\n",
      "Loss: 5.27166721366987\n",
      "Training step:  463\n",
      "Loss: 5.257338211617459\n",
      "Training step:  464\n",
      "Loss: 5.243071022018528\n",
      "Training step:  465\n",
      "Loss: 5.2288651945822355\n",
      "Training step:  466\n",
      "Loss: 5.214720282917815\n",
      "Training step:  467\n",
      "Loss: 5.200635844501421\n",
      "Training step:  468\n",
      "Loss: 5.186611440643146\n",
      "Training step:  469\n",
      "Loss: 5.172646636454388\n",
      "Training step:  470\n",
      "Loss: 5.158741000815662\n",
      "Training step:  471\n",
      "Loss: 5.144894106344417\n",
      "Training step:  472\n",
      "Loss: 5.131105529363539\n",
      "Training step:  473\n",
      "Loss: 5.1173748498698695\n",
      "Training step:  474\n",
      "Loss: 5.103701651503039\n",
      "Training step:  475\n",
      "Loss: 5.0900855215147995\n",
      "Training step:  476\n",
      "Loss: 5.076526050738323\n",
      "Training step:  477\n",
      "Loss: 5.063022833558032\n",
      "Training step:  478\n",
      "Loss: 5.049575467879597\n",
      "Training step:  479\n",
      "Loss: 5.036183555100185\n",
      "Training step:  480\n",
      "Loss: 5.0228467000789765\n",
      "Training step:  481\n",
      "Loss: 5.009564511107978\n",
      "Training step:  482\n",
      "Loss: 4.996336599883089\n",
      "Training step:  483\n",
      "Loss: 4.983162581475381\n",
      "Training step:  484\n",
      "Loss: 4.970042074302577\n",
      "Training step:  485\n",
      "Loss: 4.9569747001009805\n",
      "Training step:  486\n",
      "Loss: 4.943960083897284\n",
      "Training step:  487\n",
      "Loss: 4.930997853981023\n",
      "Training step:  488\n",
      "Loss: 4.9180876418770145\n",
      "Training step:  489\n",
      "Loss: 4.905229082317995\n",
      "Training step:  490\n",
      "Loss: 4.892421813217658\n",
      "Training step:  491\n",
      "Loss: 4.879665475643815\n",
      "Training step:  492\n",
      "Loss: 4.866959713791739\n",
      "Training step:  493\n",
      "Loss: 4.854304174957773\n",
      "Training step:  494\n",
      "Loss: 4.8416985095132725\n",
      "Training step:  495\n",
      "Loss: 4.829142370878456\n",
      "Training step:  496\n",
      "Loss: 4.81663541549682\n",
      "Training step:  497\n",
      "Loss: 4.804177302809473\n",
      "Training step:  498\n",
      "Loss: 4.7917676952298995\n",
      "Training step:  499\n",
      "Loss: 4.779406258118726\n",
      "Training step:  500\n",
      "Loss: 4.767092659758861\n",
      "Training step:  501\n",
      "Loss: 4.754826571330713\n",
      "Training step:  502\n",
      "Loss: 4.742607666887673\n",
      "Training step:  503\n",
      "Loss: 4.730435623331732\n",
      "Training step:  504\n",
      "Loss: 4.718310120389382\n",
      "Training step:  505\n",
      "Loss: 4.706230840587641\n",
      "Training step:  506\n",
      "Loss: 4.694197469230225\n",
      "Training step:  507\n",
      "Loss: 4.682209694373982\n",
      "Training step:  508\n",
      "Loss: 4.670267206805553\n",
      "Training step:  509\n",
      "Loss: 4.658369700018064\n",
      "Training step:  510\n",
      "Loss: 4.6465168701881225\n",
      "Training step:  511\n",
      "Loss: 4.634708416152956\n",
      "Training step:  512\n",
      "Loss: 4.622944039387751\n",
      "Training step:  513\n",
      "Loss: 4.611223443983065\n",
      "Training step:  514\n",
      "Loss: 4.5995463366226\n",
      "Training step:  515\n",
      "Loss: 4.587912426560996\n",
      "Training step:  516\n",
      "Loss: 4.576321425601803\n",
      "Training step:  517\n",
      "Loss: 4.564773048075714\n",
      "Training step:  518\n",
      "Loss: 4.553267010818912\n",
      "Training step:  519\n",
      "Loss: 4.541803033151573\n",
      "Training step:  520\n",
      "Loss: 4.530380836856555\n",
      "Training step:  521\n",
      "Loss: 4.51900014615824\n",
      "Training step:  522\n",
      "Loss: 4.5076606877015175\n",
      "Training step:  523\n",
      "Loss: 4.496362190531018\n",
      "Training step:  524\n",
      "Loss: 4.485104386070422\n",
      "Training step:  525\n",
      "Loss: 4.473887008101889\n",
      "Training step:  526\n",
      "Loss: 4.462709792745792\n",
      "Training step:  527\n",
      "Loss: 4.451572478440475\n",
      "Training step:  528\n",
      "Loss: 4.4404748059221895\n",
      "Training step:  529\n",
      "Loss: 4.429416518205353\n",
      "Training step:  530\n",
      "Loss: 4.418397360562523\n",
      "Training step:  531\n",
      "Loss: 4.407417080505129\n",
      "Training step:  532\n",
      "Loss: 4.396475427763869\n",
      "Training step:  533\n",
      "Loss: 4.385572154269461\n",
      "Training step:  534\n",
      "Loss: 4.374707014133495\n",
      "Training step:  535\n",
      "Loss: 4.363879763629478\n",
      "Training step:  536\n",
      "Loss: 4.353090161173992\n",
      "Training step:  537\n",
      "Loss: 4.342337967307973\n",
      "Training step:  538\n",
      "Loss: 4.33162294467812\n",
      "Training step:  539\n",
      "Loss: 4.3209448580186\n",
      "Training step:  540\n",
      "Loss: 4.310303474132682\n",
      "Training step:  541\n",
      "Loss: 4.299698561874647\n",
      "Training step:  542\n",
      "Loss: 4.289129892131808\n",
      "Training step:  543\n",
      "Loss: 4.2785972378066335\n",
      "Training step:  544\n",
      "Loss: 4.268100373799062\n",
      "Training step:  545\n",
      "Loss: 4.257639076988888\n",
      "Training step:  546\n",
      "Loss: 4.24721312621848\n",
      "Training step:  547\n",
      "Loss: 4.23682230227518\n",
      "Training step:  548\n",
      "Loss: 4.226466387874446\n",
      "Training step:  549\n",
      "Loss: 4.2161451676426225\n",
      "Training step:  550\n",
      "Loss: 4.205858428100114\n",
      "Training step:  551\n",
      "Loss: 4.195605957644603\n",
      "Training step:  552\n",
      "Loss: 4.185387546534403\n",
      "Training step:  553\n",
      "Loss: 4.175202986871943\n",
      "Training step:  554\n",
      "Loss: 4.165052072587401\n",
      "Training step:  555\n",
      "Loss: 4.154934599422425\n",
      "Training step:  556\n",
      "Loss: 4.144850364914019\n",
      "Training step:  557\n",
      "Loss: 4.13479916837858\n",
      "Training step:  558\n",
      "Loss: 4.124780810895928\n",
      "Training step:  559\n",
      "Loss: 4.114795095293669\n",
      "Training step:  560\n",
      "Loss: 4.104841826131439\n",
      "Training step:  561\n",
      "Loss: 4.094920809685541\n",
      "Training step:  562\n",
      "Loss: 4.085031853933452\n",
      "Training step:  563\n",
      "Loss: 4.075174768538607\n",
      "Training step:  564\n",
      "Loss: 4.065349364835244\n",
      "Training step:  565\n",
      "Loss: 4.055555455813359\n",
      "Training step:  566\n",
      "Loss: 4.045792856103912\n",
      "Training step:  567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.036061381963858\n",
      "Training step:  568\n",
      "Loss: 4.026360851261684\n",
      "Training step:  569\n",
      "Loss: 4.016691083462613\n",
      "Training step:  570\n",
      "Loss: 4.0070518996145275\n",
      "Training step:  571\n",
      "Loss: 3.997443122333145\n",
      "Training step:  572\n",
      "Loss: 3.987864575788451\n",
      "Training step:  573\n",
      "Loss: 3.9783160856897495\n",
      "Training step:  574\n",
      "Loss: 3.9687974792729364\n",
      "Training step:  575\n",
      "Loss: 3.95930858528484\n",
      "Training step:  576\n",
      "Loss: 3.949849233971892\n",
      "Training step:  577\n",
      "Loss: 3.9404192570632013\n",
      "Training step:  578\n",
      "Loss: 3.931018487761523\n",
      "Training step:  579\n",
      "Loss: 3.9216467607236125\n",
      "Training step:  580\n",
      "Loss: 3.912303912055545\n",
      "Training step:  581\n",
      "Loss: 3.9029897792874984\n",
      "Training step:  582\n",
      "Loss: 3.8937042013776266\n",
      "Training step:  583\n",
      "Loss: 3.8844470186752185\n",
      "Training step:  584\n",
      "Loss: 3.8752180729420127\n",
      "Training step:  585\n",
      "Loss: 3.8660172072916508\n",
      "Training step:  586\n",
      "Loss: 3.8568442662469447\n",
      "Training step:  587\n",
      "Loss: 3.8476990956310337\n",
      "Training step:  588\n",
      "Loss: 3.8385815427018843\n",
      "Training step:  589\n",
      "Loss: 3.8294914559466227\n",
      "Training step:  590\n",
      "Loss: 3.8204286853901257\n",
      "Training step:  591\n",
      "Loss: 3.8113930822078763\n",
      "Training step:  592\n",
      "Loss: 3.8023844994629794\n",
      "Training step:  593\n",
      "Loss: 3.793402791452523\n",
      "Training step:  594\n",
      "Loss: 3.78444781565902\n",
      "Training step:  595\n",
      "Loss: 3.7755194321660226\n",
      "Training step:  596\n",
      "Loss: 3.7666175097758368\n",
      "Training step:  597\n",
      "Loss: 3.7577419290396654\n",
      "Training step:  598\n",
      "Loss: 3.74889260571\n",
      "Training step:  599\n",
      "Loss: 3.740069520713705\n",
      "Training step:  600\n",
      "Loss: 3.731272827099056\n",
      "Training step:  601\n",
      "Loss: 3.7225030461265693\n",
      "Training step:  602\n",
      "Loss: 3.7137616154899433\n",
      "Training step:  603\n",
      "Loss: 3.705052065343171\n",
      "Training step:  604\n",
      "Loss: 3.696383035694707\n",
      "Training step:  605\n",
      "Loss: 3.6877752163432156\n",
      "Training step:  606\n",
      "Loss: 3.679278733321747\n",
      "Training step:  607\n",
      "Loss: 3.6710143629266505\n",
      "Training step:  608\n",
      "Loss: 3.6632772994644487\n",
      "Training step:  609\n",
      "Loss: 3.6567849877953273\n",
      "Training step:  610\n",
      "Loss: 3.6533176063512376\n",
      "Training step:  611\n",
      "Loss: 3.6572223964046167\n",
      "Training step:  612\n",
      "Loss: 3.679528268324623\n",
      "Training step:  613\n",
      "Loss: 3.7470231860577883\n",
      "Training step:  614\n",
      "Loss: 3.9302629499654036\n",
      "Training step:  615\n",
      "Loss: 4.395541788860529\n",
      "Training step:  616\n",
      "Loss: 5.6143248548979825\n",
      "Training step:  617\n",
      "Loss: 8.59915722160956\n",
      "Training step:  618\n",
      "Loss: 16.718147912156393\n",
      "Training step:  619\n",
      "Loss: 35.481531656429304\n",
      "Training step:  620\n",
      "Loss: 91.43874585270275\n",
      "Training step:  621\n",
      "Loss: 198.71558927652578\n",
      "Training step:  622\n",
      "Loss: 582.8492021838276\n",
      "Training step:  623\n",
      "Loss: 905.3653855073132\n",
      "Training step:  624\n",
      "Loss: 2703.044890502694\n",
      "Training step:  625\n",
      "Loss: 1030.3450803755045\n",
      "Training step:  626\n",
      "Loss: 1607.153198287807\n",
      "Training step:  627\n",
      "Loss: 690.0940618708314\n",
      "Training step:  628\n",
      "Loss: 966.3536564412293\n",
      "Training step:  629\n",
      "Loss: 545.9602949061544\n",
      "Training step:  630\n",
      "Loss: 820.7087951978439\n",
      "Training step:  631\n",
      "Loss: 496.3539643920053\n",
      "Training step:  632\n",
      "Loss: 726.2636909037185\n",
      "Training step:  633\n",
      "Loss: 433.12589540838366\n",
      "Training step:  634\n",
      "Loss: 586.418444216099\n",
      "Training step:  635\n",
      "Loss: 354.9913506930023\n",
      "Training step:  636\n",
      "Loss: 451.72678702571307\n",
      "Training step:  637\n",
      "Loss: 286.6048640359663\n",
      "Training step:  638\n",
      "Loss: 352.8178309433332\n",
      "Training step:  639\n",
      "Loss: 235.8379640379888\n",
      "Training step:  640\n",
      "Loss: 285.06217265003613\n",
      "Training step:  641\n",
      "Loss: 198.9854757315692\n",
      "Training step:  642\n",
      "Loss: 237.24104939358003\n",
      "Training step:  643\n",
      "Loss: 171.31608703663548\n",
      "Training step:  644\n",
      "Loss: 201.91999742992255\n",
      "Training step:  645\n",
      "Loss: 149.92250675451209\n",
      "Training step:  646\n",
      "Loss: 175.14248774479597\n",
      "Training step:  647\n",
      "Loss: 133.20053240067995\n",
      "Training step:  648\n",
      "Loss: 154.656615733178\n",
      "Training step:  649\n",
      "Loss: 120.13299813005604\n",
      "Training step:  650\n",
      "Loss: 138.97347395877875\n",
      "Training step:  651\n",
      "Loss: 109.9839896803043\n",
      "Training step:  652\n",
      "Loss: 127.03390995495295\n",
      "Training step:  653\n",
      "Loss: 102.2011503219728\n",
      "Training step:  654\n",
      "Loss: 118.06983023018782\n",
      "Training step:  655\n",
      "Loss: 96.36526140487067\n",
      "Training step:  656\n",
      "Loss: 111.51458465825085\n",
      "Training step:  657\n",
      "Loss: 92.15246549305157\n",
      "Training step:  658\n",
      "Loss: 106.94182637391691\n",
      "Training step:  659\n",
      "Loss: 89.3084005603313\n",
      "Training step:  660\n",
      "Loss: 104.02573734881788\n",
      "Training step:  661\n",
      "Loss: 87.63037848555686\n",
      "Training step:  662\n",
      "Loss: 102.51279268509779\n",
      "Training step:  663\n",
      "Loss: 86.95294725513726\n",
      "Training step:  664\n",
      "Loss: 102.19910614381686\n",
      "Training step:  665\n",
      "Loss: 87.13513522912416\n",
      "Training step:  666\n",
      "Loss: 102.91156180530875\n",
      "Training step:  667\n",
      "Loss: 88.04942033777671\n",
      "Training step:  668\n",
      "Loss: 104.4923362878389\n",
      "Training step:  669\n",
      "Loss: 89.57267630238557\n",
      "Training step:  670\n",
      "Loss: 106.78663208750424\n",
      "Training step:  671\n",
      "Loss: 91.57934147686377\n",
      "Training step:  672\n",
      "Loss: 109.63379128836509\n",
      "Training step:  673\n",
      "Loss: 93.93725527606101\n",
      "Training step:  674\n",
      "Loss: 112.8624178245183\n",
      "Training step:  675\n",
      "Loss: 96.50674502326626\n",
      "Training step:  676\n",
      "Loss: 116.29029525800651\n",
      "Training step:  677\n",
      "Loss: 99.14337357761832\n",
      "Training step:  678\n",
      "Loss: 119.7295355023217\n",
      "Training step:  679\n",
      "Loss: 101.70423723763075\n",
      "Training step:  680\n",
      "Loss: 122.9965470263752\n",
      "Training step:  681\n",
      "Loss: 104.05694477712728\n",
      "Training step:  682\n",
      "Loss: 125.9252648003711\n",
      "Training step:  683\n",
      "Loss: 106.08963950331534\n",
      "Training step:  684\n",
      "Loss: 128.38102558240814\n",
      "Training step:  685\n",
      "Loss: 107.71995615648129\n",
      "Training step:  686\n",
      "Loss: 130.27198791321172\n",
      "Training step:  687\n",
      "Loss: 108.90089863964086\n",
      "Training step:  688\n",
      "Loss: 131.55542724613724\n",
      "Training step:  689\n",
      "Loss: 109.62233820274737\n",
      "Training step:  690\n",
      "Loss: 132.2375347050238\n",
      "Training step:  691\n",
      "Loss: 109.90793856467226\n",
      "Training step:  692\n",
      "Loss: 132.3670453272599\n",
      "Training step:  693\n",
      "Loss: 109.8084066141942\n",
      "Training step:  694\n",
      "Loss: 132.0244698340977\n",
      "Training step:  695\n",
      "Loss: 109.39266719066488\n",
      "Training step:  696\n",
      "Loss: 131.30942063790448\n",
      "Training step:  697\n",
      "Loss: 108.73870064583491\n",
      "Training step:  698\n",
      "Loss: 130.3284069956998\n",
      "Training step:  699\n",
      "Loss: 107.92544434374845\n",
      "Training step:  700\n",
      "Loss: 129.18477297148848\n",
      "Training step:  701\n",
      "Loss: 107.02657796068608\n",
      "Training step:  702\n",
      "Loss: 127.9715551819348\n",
      "Training step:  703\n",
      "Loss: 106.10643092988205\n",
      "Training step:  704\n",
      "Loss: 126.76726899395669\n",
      "Training step:  705\n",
      "Loss: 105.21782410135182\n",
      "Training step:  706\n",
      "Loss: 125.63414903883805\n",
      "Training step:  707\n",
      "Loss: 104.40143270057152\n",
      "Training step:  708\n",
      "Loss: 124.61817642552968\n",
      "Training step:  709\n",
      "Loss: 103.68620257305419\n",
      "Training step:  710\n",
      "Loss: 123.75024025020544\n",
      "Training step:  711\n",
      "Loss: 103.09040376238076\n",
      "Training step:  712\n",
      "Loss: 123.04790648947242\n",
      "Training step:  713\n",
      "Loss: 102.62300473110663\n",
      "Training step:  714\n",
      "Loss: 122.51742518334918\n",
      "Training step:  715\n",
      "Loss: 102.28515513937957\n",
      "Training step:  716\n",
      "Loss: 122.15575033381266\n",
      "Training step:  717\n",
      "Loss: 102.0716527087082\n",
      "Training step:  718\n",
      "Loss: 121.9524560743412\n",
      "Training step:  719\n",
      "Loss: 101.97233252043024\n",
      "Training step:  720\n",
      "Loss: 121.89150424473777\n",
      "Training step:  721\n",
      "Loss: 101.9733558562371\n",
      "Training step:  722\n",
      "Loss: 121.95285784491432\n",
      "Training step:  723\n",
      "Loss: 102.0583950118245\n",
      "Training step:  724\n",
      "Loss: 122.11395021801249\n",
      "Training step:  725\n",
      "Loss: 102.20971615522876\n",
      "Training step:  726\n",
      "Loss: 122.35101962162898\n",
      "Training step:  727\n",
      "Loss: 102.4091597529491\n",
      "Training step:  728\n",
      "Loss: 122.64031041998874\n",
      "Training step:  729\n",
      "Loss: 102.63901201761787\n",
      "Training step:  730\n",
      "Loss: 122.95913137727614\n",
      "Training step:  731\n",
      "Loss: 102.88275487281014\n",
      "Training step:  732\n",
      "Loss: 123.28675283868394\n",
      "Training step:  733\n",
      "Loss: 103.12567858943038\n",
      "Training step:  734\n",
      "Loss: 123.60512075728424\n",
      "Training step:  735\n",
      "Loss: 103.35534185850032\n",
      "Training step:  736\n",
      "Loss: 123.8993677675802\n",
      "Training step:  737\n",
      "Loss: 103.56186882584522\n",
      "Training step:  738\n",
      "Loss: 124.15810950777585\n",
      "Training step:  739\n",
      "Loss: 103.73808073391407\n",
      "Training step:  740\n",
      "Loss: 124.37352658772514\n",
      "Training step:  741\n",
      "Loss: 103.8794698072572\n",
      "Training step:  742\n",
      "Loss: 124.5412466340796\n",
      "Training step:  743\n",
      "Loss: 103.98403308538904\n",
      "Training step:  744\n",
      "Loss: 124.66005415179195\n",
      "Training step:  745\n",
      "Loss: 104.05199236389998\n",
      "Training step:  746\n",
      "Loss: 124.73146631375258\n",
      "Training step:  747\n",
      "Loss: 104.08543201248497\n",
      "Training step:  748\n",
      "Loss: 124.7592187916913\n",
      "Training step:  749\n",
      "Loss: 104.08788860192836\n",
      "Training step:  750\n",
      "Loss: 124.7487068964835\n",
      "Training step:  751\n",
      "Loss: 104.06392505730383\n",
      "Training step:  752\n",
      "Loss: 124.7064240226748\n",
      "Training step:  753\n",
      "Loss: 104.0187180630825\n",
      "Training step:  754\n",
      "Loss: 124.63943275649363\n",
      "Training step:  755\n",
      "Loss: 103.95768159500973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  756\n",
      "Loss: 124.55489538559277\n",
      "Training step:  757\n",
      "Loss: 103.88614274552339\n",
      "Training step:  758\n",
      "Loss: 124.4596813128296\n",
      "Training step:  759\n",
      "Loss: 103.80907933887187\n",
      "Training step:  760\n",
      "Loss: 124.36006015486652\n",
      "Training step:  761\n",
      "Loss: 103.73092286634412\n",
      "Training step:  762\n",
      "Loss: 124.26148186516404\n",
      "Training step:  763\n",
      "Loss: 103.65542541143282\n",
      "Training step:  764\n",
      "Loss: 124.16843945012566\n",
      "Training step:  765\n",
      "Loss: 103.58558563140488\n",
      "Training step:  766\n",
      "Loss: 124.08440581728841\n",
      "Training step:  767\n",
      "Loss: 103.52362647782546\n",
      "Training step:  768\n",
      "Loss: 124.01183385225711\n",
      "Training step:  769\n",
      "Loss: 103.47101601447798\n",
      "Training step:  770\n",
      "Loss: 123.95220768973667\n",
      "Training step:  771\n",
      "Loss: 103.4285222124363\n",
      "Training step:  772\n",
      "Loss: 123.9061330063688\n",
      "Training step:  773\n",
      "Loss: 103.39629274634714\n",
      "Training step:  774\n",
      "Loss: 123.87345471966059\n",
      "Training step:  775\n",
      "Loss: 103.37395138730716\n",
      "Training step:  776\n",
      "Loss: 123.85339148018649\n",
      "Training step:  777\n",
      "Loss: 103.36070342769995\n",
      "Training step:  778\n",
      "Loss: 123.84467760476386\n",
      "Training step:  779\n",
      "Loss: 103.35544356661434\n",
      "Training step:  780\n",
      "Loss: 123.84570448727568\n",
      "Training step:  781\n",
      "Loss: 103.35686075072358\n",
      "Training step:  782\n",
      "Loss: 123.85465495563618\n",
      "Training step:  783\n",
      "Loss: 103.36353555156278\n",
      "Training step:  784\n",
      "Loss: 123.86962546566603\n",
      "Training step:  785\n",
      "Loss: 103.37402673059519\n",
      "Training step:  786\n",
      "Loss: 123.88873239945062\n",
      "Training step:  787\n",
      "Loss: 103.38694467120358\n",
      "Training step:  788\n",
      "Loss: 123.91020004044215\n",
      "Training step:  789\n",
      "Loss: 103.40101032049196\n",
      "Training step:  790\n",
      "Loss: 123.93242900576428\n",
      "Training step:  791\n",
      "Loss: 103.41509916178887\n",
      "Training step:  792\n",
      "Loss: 123.95404500211167\n",
      "Training step:  793\n",
      "Loss: 103.42827051175023\n",
      "Training step:  794\n",
      "Loss: 123.97392871221014\n",
      "Training step:  795\n",
      "Loss: 103.43978308625465\n",
      "Training step:  796\n",
      "Loss: 123.99122839202617\n",
      "Training step:  797\n",
      "Loss: 103.44909829333098\n",
      "Training step:  798\n",
      "Loss: 124.00535734994148\n",
      "Training step:  799\n",
      "Loss: 103.45587308169418\n",
      "Training step:  800\n",
      "Loss: 124.01597888071468\n",
      "Training step:  801\n",
      "Loss: 103.45994439954323\n",
      "Training step:  802\n",
      "Loss: 124.02298144222925\n",
      "Training step:  803\n",
      "Loss: 103.46130740724787\n",
      "Training step:  804\n",
      "Loss: 124.02644690456525\n",
      "Training step:  805\n",
      "Loss: 103.46008955338552\n",
      "Training step:  806\n",
      "Loss: 124.02661459029143\n",
      "Training step:  807\n",
      "Loss: 103.45652248596356\n",
      "Training step:  808\n",
      "Loss: 124.02384359050428\n",
      "Training step:  809\n",
      "Loss: 103.45091355267209\n",
      "Training step:  810\n",
      "Loss: 124.01857551463925\n",
      "Training step:  811\n",
      "Loss: 103.44361837043627\n",
      "Training step:  812\n",
      "Loss: 124.01129944664493\n",
      "Training step:  813\n",
      "Loss: 103.4350156398024\n",
      "Training step:  814\n",
      "Loss: 124.002520467221\n",
      "Training step:  815\n",
      "Loss: 103.42548506586421\n",
      "Training step:  816\n",
      "Loss: 123.9927326890045\n",
      "Training step:  817\n",
      "Loss: 103.41538894340441\n",
      "Training step:  818\n",
      "Loss: 123.9823973617118\n",
      "Training step:  819\n",
      "Loss: 103.40505768459529\n",
      "Training step:  820\n",
      "Loss: 123.97192625469316\n",
      "Training step:  821\n",
      "Loss: 103.39477932337712\n",
      "Training step:  822\n",
      "Loss: 123.96167022609511\n",
      "Training step:  823\n",
      "Loss: 103.38479282815983\n",
      "Training step:  824\n",
      "Loss: 123.95191264777519\n",
      "Training step:  825\n",
      "Loss: 103.37528489680903\n",
      "Training step:  826\n",
      "Loss: 123.94286717457622\n",
      "Training step:  827\n",
      "Loss: 103.36638979412236\n",
      "Training step:  828\n",
      "Loss: 123.934679223459\n",
      "Training step:  829\n",
      "Loss: 103.35819172076023\n",
      "Training step:  830\n",
      "Loss: 123.92743045855433\n",
      "Training step:  831\n",
      "Loss: 103.35072916856656\n",
      "Training step:  832\n",
      "Loss: 123.92114555502395\n",
      "Training step:  833\n",
      "Loss: 103.34400071588303\n",
      "Training step:  834\n",
      "Loss: 123.9158005307739\n",
      "Training step:  835\n",
      "Loss: 103.33797174154952\n",
      "Training step:  836\n",
      "Loss: 123.91133198273282\n",
      "Training step:  837\n",
      "Loss: 103.33258158222064\n",
      "Training step:  838\n",
      "Loss: 123.90764663522836\n",
      "Training step:  839\n",
      "Loss: 103.32775071772049\n",
      "Training step:  840\n",
      "Loss: 123.9046306944709\n",
      "Training step:  841\n",
      "Loss: 103.32338763916849\n",
      "Training step:  842\n",
      "Loss: 123.90215859916515\n",
      "Training step:  843\n",
      "Loss: 103.3193951283539\n",
      "Training step:  844\n",
      "Loss: 123.90010085542775\n",
      "Training step:  845\n",
      "Loss: 103.31567575108964\n",
      "Training step:  846\n",
      "Loss: 123.89833074087032\n",
      "Training step:  847\n",
      "Loss: 103.31213643807685\n",
      "Training step:  848\n",
      "Loss: 123.89672975267287\n",
      "Training step:  849\n",
      "Loss: 103.30869209144403\n",
      "Training step:  850\n",
      "Loss: 123.89519175508188\n",
      "Training step:  851\n",
      "Loss: 103.30526821163174\n",
      "Training step:  852\n",
      "Loss: 123.89362585074021\n",
      "Training step:  853\n",
      "Loss: 103.30180258662445\n",
      "Training step:  854\n",
      "Loss: 123.89195805650512\n",
      "Training step:  855\n",
      "Loss: 103.29824612254728\n",
      "Training step:  856\n",
      "Loss: 123.89013190704044\n",
      "Training step:  857\n",
      "Loss: 103.29456292195913\n",
      "Training step:  858\n",
      "Loss: 123.88810813933591\n",
      "Training step:  859\n",
      "Loss: 103.29072973345026\n",
      "Training step:  860\n",
      "Loss: 123.88586362838306\n",
      "Training step:  861\n",
      "Loss: 103.28673490477107\n",
      "Training step:  862\n",
      "Loss: 123.8833897507091\n",
      "Training step:  863\n",
      "Loss: 103.28257697271539\n",
      "Training step:  864\n",
      "Loss: 123.88069034940564\n",
      "Training step:  865\n",
      "Loss: 103.27826301734513\n",
      "Training step:  866\n",
      "Loss: 123.87777946342615\n",
      "Training step:  867\n",
      "Loss: 103.27380689743822\n",
      "Training step:  868\n",
      "Loss: 123.8746789671114\n",
      "Training step:  869\n",
      "Loss: 103.26922746961695\n",
      "Training step:  870\n",
      "Loss: 123.87141624528368\n",
      "Training step:  871\n",
      "Loss: 103.26454687695484\n",
      "Training step:  872\n",
      "Loss: 123.86802200614794\n",
      "Training step:  873\n",
      "Loss: 103.25978897486412\n",
      "Training step:  874\n",
      "Loss: 123.86452831028197\n",
      "Training step:  875\n",
      "Loss: 103.25497794406282\n",
      "Training step:  876\n",
      "Loss: 123.86096687043265\n",
      "Training step:  877\n",
      "Loss: 103.25013712308785\n",
      "Training step:  878\n",
      "Loss: 123.85736765484765\n",
      "Training step:  879\n",
      "Loss: 103.24528807708724\n",
      "Training step:  880\n",
      "Loss: 123.85375780709484\n",
      "Training step:  881\n",
      "Loss: 103.2404499056404\n",
      "Training step:  882\n",
      "Loss: 123.8501608783288\n",
      "Training step:  883\n",
      "Loss: 103.23563878091528\n",
      "Training step:  884\n",
      "Loss: 123.84659635432202\n",
      "Training step:  885\n",
      "Loss: 103.2308676982241\n",
      "Training step:  886\n",
      "Loss: 123.84307944870554\n",
      "Training step:  887\n",
      "Loss: 103.22614641411172\n",
      "Training step:  888\n",
      "Loss: 123.83962112649124\n",
      "Training step:  889\n",
      "Loss: 103.22148154299423\n",
      "Training step:  890\n",
      "Loss: 123.83622831769532\n",
      "Training step:  891\n",
      "Loss: 103.21687678078854\n",
      "Training step:  892\n",
      "Loss: 123.832904278674\n",
      "Training step:  893\n",
      "Loss: 103.2123332236511\n",
      "Training step:  894\n",
      "Loss: 123.8296490595385\n",
      "Training step:  895\n",
      "Loss: 103.20784975101938\n",
      "Training step:  896\n",
      "Loss: 123.82646003816451\n",
      "Training step:  897\n",
      "Loss: 103.20342344449745\n",
      "Training step:  898\n",
      "Loss: 123.82333248502124\n",
      "Training step:  899\n",
      "Loss: 103.19905001731436\n",
      "Training step:  900\n",
      "Loss: 123.82026012783422\n",
      "Training step:  901\n",
      "Loss: 103.19472423305842\n",
      "Training step:  902\n",
      "Loss: 123.81723569045933\n",
      "Training step:  903\n",
      "Loss: 103.1904402963995\n",
      "Training step:  904\n",
      "Loss: 123.81425138569956\n",
      "Training step:  905\n",
      "Loss: 103.18619220281839\n",
      "Training step:  906\n",
      "Loss: 123.81129934774702\n",
      "Training step:  907\n",
      "Loss: 103.18197403857414\n",
      "Training step:  908\n",
      "Loss: 123.80837199484269\n",
      "Training step:  909\n",
      "Loss: 103.17778022570943\n",
      "Training step:  910\n",
      "Loss: 123.80546231771979\n",
      "Training step:  911\n",
      "Loss: 103.17360571047918\n",
      "Training step:  912\n",
      "Loss: 123.80256409335682\n",
      "Training step:  913\n",
      "Loss: 103.16944609624213\n",
      "Training step:  914\n",
      "Loss: 123.79967202724237\n",
      "Training step:  915\n",
      "Loss: 103.16529772444994\n",
      "Training step:  916\n",
      "Loss: 123.79678182994522\n",
      "Training step:  917\n",
      "Loss: 103.16115770883542\n",
      "Training step:  918\n",
      "Loss: 123.79389023570332\n",
      "Training step:  919\n",
      "Loss: 103.15702392932161\n",
      "Training step:  920\n",
      "Loss: 123.7909949721749\n",
      "Training step:  921\n",
      "Loss: 103.15289499279625\n",
      "Training step:  922\n",
      "Loss: 123.78809469102893\n",
      "Training step:  923\n",
      "Loss: 103.14877016818721\n",
      "Training step:  924\n",
      "Loss: 123.78518886920827\n",
      "Training step:  925\n",
      "Loss: 103.14464930312302\n",
      "Training step:  926\n",
      "Loss: 123.78227769024566\n",
      "Training step:  927\n",
      "Loss: 103.14053272908255\n",
      "Training step:  928\n",
      "Loss: 123.77936191443193\n",
      "Training step:  929\n",
      "Loss: 103.13642116121335\n",
      "Training step:  930\n",
      "Loss: 123.77644274549547\n",
      "Training step:  931\n",
      "Loss: 103.13231559828125\n",
      "Training step:  932\n",
      "Loss: 123.77352170038175\n",
      "Training step:  933\n",
      "Loss: 103.12821722705846\n",
      "Training step:  934\n",
      "Loss: 123.77060048730854\n",
      "Training step:  935\n",
      "Loss: 103.12412733477274\n",
      "Training step:  936\n",
      "Loss: 123.76768089623872\n",
      "Training step:  937\n",
      "Loss: 103.12004723205024\n",
      "Training step:  938\n",
      "Loss: 123.76476470438168\n",
      "Training step:  939\n",
      "Loss: 103.11597818799876\n",
      "Training step:  940\n",
      "Loss: 123.76185359843267\n",
      "Training step:  941\n",
      "Loss: 103.11192137824652\n",
      "Training step:  942\n",
      "Loss: 123.75894911408146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  943\n",
      "Loss: 103.10787784597171\n",
      "Training step:  944\n",
      "Loss: 123.75605259247756\n",
      "Training step:  945\n",
      "Loss: 103.10384847544881\n",
      "Training step:  946\n",
      "Loss: 123.75316515277714\n",
      "Training step:  947\n",
      "Loss: 103.0998339771609\n",
      "Training step:  948\n",
      "Loss: 123.75028767908707\n",
      "Training step:  949\n",
      "Loss: 103.0958348830669\n",
      "Training step:  950\n",
      "Loss: 123.74742081999945\n",
      "Training step:  951\n",
      "Loss: 103.09185155054925\n",
      "Training step:  952\n",
      "Loss: 123.74456499851944\n",
      "Training step:  953\n",
      "Loss: 103.08788417337566\n",
      "Training step:  954\n",
      "Loss: 123.74172043024805\n",
      "Training step:  955\n",
      "Loss: 103.08393279798811\n",
      "Training step:  956\n",
      "Loss: 123.7388871474938\n",
      "Training step:  957\n",
      "Loss: 103.07999734340412\n",
      "Training step:  958\n",
      "Loss: 123.73606502727304\n",
      "Training step:  959\n",
      "Loss: 103.07607762338998\n",
      "Training step:  960\n",
      "Loss: 123.73325382139467\n",
      "Training step:  961\n",
      "Loss: 103.07217336942689\n",
      "Training step:  962\n",
      "Loss: 123.73045318682746\n",
      "Training step:  963\n",
      "Loss: 103.0682842533559\n",
      "Training step:  964\n",
      "Loss: 123.7276627150165\n",
      "Training step:  965\n",
      "Loss: 103.06440990879643\n",
      "Training step:  966\n",
      "Loss: 123.7248819591035\n",
      "Training step:  967\n",
      "Loss: 103.06054995057924\n",
      "Training step:  968\n",
      "Loss: 123.72211045813863\n",
      "Training step:  969\n",
      "Loss: 103.05670399167711\n",
      "Training step:  970\n",
      "Loss: 123.7193477577348\n",
      "Training step:  971\n",
      "Loss: 103.0528716573658\n",
      "Training step:  972\n",
      "Loss: 123.71659342703603\n",
      "Training step:  973\n",
      "Loss: 103.04905259649189\n",
      "Training step:  974\n",
      "Loss: 123.71384707173077\n",
      "Training step:  975\n",
      "Loss: 103.04524648978801\n",
      "Training step:  976\n",
      "Loss: 123.71110834328641\n",
      "Training step:  977\n",
      "Loss: 103.0414530554179\n",
      "Training step:  978\n",
      "Loss: 123.70837694463074\n",
      "Training step:  979\n",
      "Loss: 103.03767205200222\n",
      "Training step:  980\n",
      "Loss: 123.70565263271347\n",
      "Training step:  981\n",
      "Loss: 103.03390327939081\n",
      "Training step:  982\n",
      "Loss: 123.70293521825016\n",
      "Training step:  983\n",
      "Loss: 103.03014657758126\n",
      "Training step:  984\n",
      "Loss: 123.70022456332201\n",
      "Training step:  985\n",
      "Loss: 103.02640182412131\n",
      "Training step:  986\n",
      "Loss: 123.69752057711182\n",
      "Training step:  987\n",
      "Loss: 103.02266893035163\n",
      "Training step:  988\n",
      "Loss: 123.69482321040647\n",
      "Training step:  989\n",
      "Loss: 103.01894783689224\n",
      "Training step:  990\n",
      "Loss: 123.69213244930275\n",
      "Training step:  991\n",
      "Loss: 103.01523850867633\n",
      "Training step:  992\n",
      "Loss: 123.68944830845237\n",
      "Training step:  993\n",
      "Loss: 103.0115409298019\n",
      "Training step:  994\n",
      "Loss: 123.68677082429903\n",
      "Training step:  995\n",
      "Loss: 103.00785509846509\n",
      "Training step:  996\n",
      "Loss: 123.6841000484933\n",
      "Training step:  997\n",
      "Loss: 103.00418102220937\n",
      "Training step:  998\n",
      "Loss: 123.68143604193851\n",
      "Training step:  999\n",
      "Loss: 103.00051871363443\n",
      "Training step:  1000\n",
      "Loss: 123.67877886936269\n",
      "Training step:  1001\n",
      "Loss: 102.99686818657734\n",
      "Training step:  1002\n",
      "Loss: 123.67612859468802\n",
      "Training step:  1003\n",
      "Loss: 102.99322945296703\n",
      "Training step:  1004\n",
      "Loss: 123.67348527728285\n",
      "Training step:  1005\n",
      "Loss: 102.98960252032087\n",
      "Training step:  1006\n",
      "Loss: 123.67084896905133\n",
      "Training step:  1007\n",
      "Loss: 102.98598738985693\n",
      "Training step:  1008\n",
      "Loss: 123.66821971232183\n",
      "Training step:  1009\n",
      "Loss: 102.9823840552375\n",
      "Training step:  1010\n",
      "Loss: 123.66559753856596\n",
      "Training step:  1011\n",
      "Loss: 102.97879250184963\n",
      "Training step:  1012\n",
      "Loss: 123.66298246774592\n",
      "Training step:  1013\n",
      "Loss: 102.97521270655912\n",
      "Training step:  1014\n",
      "Loss: 123.66037450829255\n",
      "Training step:  1015\n",
      "Loss: 102.97164463795023\n",
      "Training step:  1016\n",
      "Loss: 123.657773657663\n",
      "Training step:  1017\n",
      "Loss: 102.96808825683235\n",
      "Training step:  1018\n",
      "Loss: 123.65517990314709\n",
      "Training step:  1019\n",
      "Loss: 102.96454351702309\n",
      "Training step:  1020\n",
      "Loss: 123.65259322305666\n",
      "Training step:  1021\n",
      "Loss: 102.96101036629044\n",
      "Training step:  1022\n",
      "Loss: 123.65001358804196\n",
      "Training step:  1023\n",
      "Loss: 102.95748874742823\n",
      "Training step:  1024\n",
      "Loss: 123.64744096259635\n",
      "Training step:  1025\n",
      "Loss: 102.95397859938609\n",
      "Training step:  1026\n",
      "Loss: 123.6448753064832\n",
      "Training step:  1027\n",
      "Loss: 102.95047985831457\n",
      "Training step:  1028\n",
      "Loss: 123.64231657616128\n",
      "Training step:  1029\n",
      "Loss: 102.94699245866146\n",
      "Training step:  1030\n",
      "Loss: 123.63976472616129\n",
      "Training step:  1031\n",
      "Loss: 102.94351633408229\n",
      "Training step:  1032\n",
      "Loss: 123.6372197101921\n",
      "Training step:  1033\n",
      "Loss: 102.94005141827017\n",
      "Training step:  1034\n",
      "Loss: 123.63468148221581\n",
      "Training step:  1035\n",
      "Loss: 102.93659764567198\n",
      "Training step:  1036\n",
      "Loss: 123.63214999728436\n",
      "Training step:  1037\n",
      "Loss: 102.93315495206058\n",
      "Training step:  1038\n",
      "Loss: 123.62962521221466\n",
      "Training step:  1039\n",
      "Loss: 102.92972327495247\n",
      "Training step:  1040\n",
      "Loss: 123.62710708605648\n",
      "Training step:  1041\n",
      "Loss: 102.92630255389888\n",
      "Training step:  1042\n",
      "Loss: 123.62459558040581\n",
      "Training step:  1043\n",
      "Loss: 102.92289273067007\n",
      "Training step:  1044\n",
      "Loss: 123.62209065958234\n",
      "Training step:  1045\n",
      "Loss: 102.91949374932013\n",
      "Training step:  1046\n",
      "Loss: 123.61959229066298\n",
      "Training step:  1047\n",
      "Loss: 102.91610555617554\n",
      "Training step:  1048\n",
      "Loss: 123.61710044340612\n",
      "Training step:  1049\n",
      "Loss: 102.91272809972017\n",
      "Training step:  1050\n",
      "Loss: 123.61461509005923\n",
      "Training step:  1051\n",
      "Loss: 102.9093613304386\n",
      "Training step:  1052\n",
      "Loss: 123.61213620514218\n",
      "Training step:  1053\n",
      "Loss: 102.90600520062887\n",
      "Training step:  1054\n",
      "Loss: 123.60966376517477\n",
      "Training step:  1055\n",
      "Loss: 102.90265966416364\n",
      "Training step:  1056\n",
      "Loss: 123.60719774833517\n",
      "Training step:  1057\n",
      "Loss: 102.89932467624891\n",
      "Training step:  1058\n",
      "Loss: 123.60473813416637\n",
      "Training step:  1059\n",
      "Loss: 102.89600019318546\n",
      "Training step:  1060\n",
      "Loss: 123.60228490327027\n",
      "Training step:  1061\n",
      "Loss: 102.89268617217192\n",
      "Training step:  1062\n",
      "Loss: 123.59983803703291\n",
      "Training step:  1063\n",
      "Loss: 102.88938257104503\n",
      "Training step:  1064\n",
      "Loss: 123.5973975172881\n",
      "Training step:  1065\n",
      "Loss: 102.88608934807738\n",
      "Training step:  1066\n",
      "Loss: 123.59496332610556\n",
      "Training step:  1067\n",
      "Loss: 102.88280646184464\n",
      "Training step:  1068\n",
      "Loss: 123.59253544563575\n",
      "Training step:  1069\n",
      "Loss: 102.87953387110214\n",
      "Training step:  1070\n",
      "Loss: 123.5901138579352\n",
      "Training step:  1071\n",
      "Loss: 102.8762715346518\n",
      "Training step:  1072\n",
      "Loss: 123.58769854482182\n",
      "Training step:  1073\n",
      "Loss: 102.87301941126674\n",
      "Training step:  1074\n",
      "Loss: 123.58528948780616\n",
      "Training step:  1075\n",
      "Loss: 102.86977745963712\n",
      "Training step:  1076\n",
      "Loss: 123.58288666801396\n",
      "Training step:  1077\n",
      "Loss: 102.86654563834507\n",
      "Training step:  1078\n",
      "Loss: 123.58049006621307\n",
      "Training step:  1079\n",
      "Loss: 102.86332390586905\n",
      "Training step:  1080\n",
      "Loss: 123.57809966277557\n",
      "Training step:  1081\n",
      "Loss: 102.86011222056281\n",
      "Training step:  1082\n",
      "Loss: 123.57571543769943\n",
      "Training step:  1083\n",
      "Loss: 102.85691054070027\n",
      "Training step:  1084\n",
      "Loss: 123.57333737067243\n",
      "Training step:  1085\n",
      "Loss: 102.85371882450323\n",
      "Training step:  1086\n",
      "Loss: 123.57096544110331\n",
      "Training step:  1087\n",
      "Loss: 102.8505370301836\n",
      "Training step:  1088\n",
      "Loss: 123.5685996281914\n",
      "Training step:  1089\n",
      "Loss: 102.84736511597025\n",
      "Training step:  1090\n",
      "Loss: 123.56623991096637\n",
      "Training step:  1091\n",
      "Loss: 102.84420304018985\n",
      "Training step:  1092\n",
      "Loss: 123.56388626840682\n",
      "Training step:  1093\n",
      "Loss: 102.84105076128783\n",
      "Training step:  1094\n",
      "Loss: 123.5615386794295\n",
      "Training step:  1095\n",
      "Loss: 102.83790823787007\n",
      "Training step:  1096\n",
      "Loss: 123.55919712299922\n",
      "Training step:  1097\n",
      "Loss: 102.83477542875123\n",
      "Training step:  1098\n",
      "Loss: 123.55686157814336\n",
      "Training step:  1099\n",
      "Loss: 102.83165229298135\n",
      "Training step:  1100\n",
      "Loss: 123.55453202402063\n",
      "Training step:  1101\n",
      "Loss: 102.8285387898843\n",
      "Training step:  1102\n",
      "Loss: 123.5522084399565\n",
      "Training step:  1103\n",
      "Loss: 102.82543487908083\n",
      "Training step:  1104\n",
      "Loss: 123.54989080545347\n",
      "Training step:  1105\n",
      "Loss: 102.82234052047426\n",
      "Training step:  1106\n",
      "Loss: 123.54757910020244\n",
      "Training step:  1107\n",
      "Loss: 102.81925567430582\n",
      "Training step:  1108\n",
      "Loss: 123.54527330413964\n",
      "Training step:  1109\n",
      "Loss: 102.81618030112739\n",
      "Training step:  1110\n",
      "Loss: 123.54297339740043\n",
      "Training step:  1111\n",
      "Loss: 102.81311436181416\n",
      "Training step:  1112\n",
      "Loss: 123.54067936034538\n",
      "Training step:  1113\n",
      "Loss: 102.81005781755422\n",
      "Training step:  1114\n",
      "Loss: 123.53839117355353\n",
      "Training step:  1115\n",
      "Loss: 102.80701062985737\n",
      "Training step:  1116\n",
      "Loss: 123.53610881781191\n",
      "Training step:  1117\n",
      "Loss: 102.80397276052608\n",
      "Training step:  1118\n",
      "Loss: 123.53383227412104\n",
      "Training step:  1119\n",
      "Loss: 102.80094417169815\n",
      "Training step:  1120\n",
      "Loss: 123.53156152368814\n",
      "Training step:  1121\n",
      "Loss: 102.79792482575432\n",
      "Training step:  1122\n",
      "Loss: 123.52929654784357\n",
      "Training step:  1123\n",
      "Loss: 102.79491468535859\n",
      "Training step:  1124\n",
      "Loss: 123.52703732812044\n",
      "Training step:  1125\n",
      "Loss: 102.79191371345239\n",
      "Training step:  1126\n",
      "Loss: 123.52478384618661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1127\n",
      "Loss: 102.7889218731973\n",
      "Training step:  1128\n",
      "Loss: 123.5225360838215\n",
      "Training step:  1129\n",
      "Loss: 102.78593912800775\n",
      "Training step:  1130\n",
      "Loss: 123.52029402294079\n",
      "Training step:  1131\n",
      "Loss: 102.78296544151446\n",
      "Training step:  1132\n",
      "Loss: 123.51805764555544\n",
      "Training step:  1133\n",
      "Loss: 102.78000077757356\n",
      "Training step:  1134\n",
      "Loss: 123.51582693379146\n",
      "Training step:  1135\n",
      "Loss: 102.77704510026432\n",
      "Training step:  1136\n",
      "Loss: 123.51360186987618\n",
      "Training step:  1137\n",
      "Loss: 102.77409837384474\n",
      "Training step:  1138\n",
      "Loss: 123.51138243605557\n",
      "Training step:  1139\n",
      "Loss: 102.77116056275919\n",
      "Training step:  1140\n",
      "Loss: 123.5091686147038\n",
      "Training step:  1141\n",
      "Loss: 102.76823163167649\n",
      "Training step:  1142\n",
      "Loss: 123.50696038825627\n",
      "Training step:  1143\n",
      "Loss: 102.76531154542776\n",
      "Training step:  1144\n",
      "Loss: 123.50475773921674\n",
      "Training step:  1145\n",
      "Loss: 102.76240026905262\n",
      "Training step:  1146\n",
      "Loss: 123.50256065016181\n",
      "Training step:  1147\n",
      "Loss: 102.75949776774695\n",
      "Training step:  1148\n",
      "Loss: 123.50036910371497\n",
      "Training step:  1149\n",
      "Loss: 102.75660400691459\n",
      "Training step:  1150\n",
      "Loss: 123.49818308261081\n",
      "Training step:  1151\n",
      "Loss: 102.7537189521418\n",
      "Training step:  1152\n",
      "Loss: 123.4960025696271\n",
      "Training step:  1153\n",
      "Loss: 102.75084256917908\n",
      "Training step:  1154\n",
      "Loss: 123.49382754760096\n",
      "Training step:  1155\n",
      "Loss: 102.74797482397666\n",
      "Training step:  1156\n",
      "Loss: 123.49165799948146\n",
      "Training step:  1157\n",
      "Loss: 102.74511568266968\n",
      "Training step:  1158\n",
      "Loss: 123.48949390825837\n",
      "Training step:  1159\n",
      "Loss: 102.74226511154977\n",
      "Training step:  1160\n",
      "Loss: 123.48733525698528\n",
      "Training step:  1161\n",
      "Loss: 102.7394230771112\n",
      "Training step:  1162\n",
      "Loss: 123.48518202882735\n",
      "Training step:  1163\n",
      "Loss: 102.73658954603346\n",
      "Training step:  1164\n",
      "Loss: 123.48303420701106\n",
      "Training step:  1165\n",
      "Loss: 102.7337644851699\n",
      "Training step:  1166\n",
      "Loss: 123.48089177483543\n",
      "Training step:  1167\n",
      "Loss: 102.73094786156089\n",
      "Training step:  1168\n",
      "Loss: 123.47875471570585\n",
      "Training step:  1169\n",
      "Loss: 102.72813964244513\n",
      "Training step:  1170\n",
      "Loss: 123.47662301309637\n",
      "Training step:  1171\n",
      "Loss: 102.72533979521995\n",
      "Training step:  1172\n",
      "Loss: 123.47449665054626\n",
      "Training step:  1173\n",
      "Loss: 102.72254828746667\n",
      "Training step:  1174\n",
      "Loss: 123.47237561168802\n",
      "Training step:  1175\n",
      "Loss: 102.71976508695836\n",
      "Training step:  1176\n",
      "Loss: 123.47025988024797\n",
      "Training step:  1177\n",
      "Loss: 102.71699016164519\n",
      "Training step:  1178\n",
      "Loss: 123.46814944001729\n",
      "Training step:  1179\n",
      "Loss: 102.71422347964207\n",
      "Training step:  1180\n",
      "Loss: 123.46604427485991\n",
      "Training step:  1181\n",
      "Loss: 102.71146500924962\n",
      "Training step:  1182\n",
      "Loss: 123.46394436873987\n",
      "Training step:  1183\n",
      "Loss: 102.70871471894188\n",
      "Training step:  1184\n",
      "Loss: 123.46184970567697\n",
      "Training step:  1185\n",
      "Loss: 102.70597257735622\n",
      "Training step:  1186\n",
      "Loss: 123.45976026978094\n",
      "Training step:  1187\n",
      "Loss: 102.70323855332052\n",
      "Training step:  1188\n",
      "Loss: 123.45767604524796\n",
      "Training step:  1189\n",
      "Loss: 102.70051261582019\n",
      "Training step:  1190\n",
      "Loss: 123.45559701633368\n",
      "Training step:  1191\n",
      "Loss: 102.69779473401046\n",
      "Training step:  1192\n",
      "Loss: 123.45352316736725\n",
      "Training step:  1193\n",
      "Loss: 102.69508487720361\n",
      "Training step:  1194\n",
      "Loss: 123.45145448274755\n",
      "Training step:  1195\n",
      "Loss: 102.69238301488016\n",
      "Training step:  1196\n",
      "Loss: 123.44939094695171\n",
      "Training step:  1197\n",
      "Loss: 102.68968911670078\n",
      "Training step:  1198\n",
      "Loss: 123.44733254454582\n",
      "Training step:  1199\n",
      "Loss: 102.68700315246802\n",
      "Training step:  1200\n",
      "Loss: 123.44527926012181\n",
      "Training step:  1201\n",
      "Loss: 102.68432509212914\n",
      "Training step:  1202\n",
      "Loss: 123.44323107835012\n",
      "Training step:  1203\n",
      "Loss: 102.68165490582173\n",
      "Training step:  1204\n",
      "Loss: 123.44118798400537\n",
      "Training step:  1205\n",
      "Loss: 102.67899256381642\n",
      "Training step:  1206\n",
      "Loss: 123.43914996188047\n",
      "Training step:  1207\n",
      "Loss: 102.67633803655339\n",
      "Training step:  1208\n",
      "Loss: 123.43711699687714\n",
      "Training step:  1209\n",
      "Loss: 102.67369129462453\n",
      "Training step:  1210\n",
      "Loss: 123.43508907393924\n",
      "Training step:  1211\n",
      "Loss: 102.67105230877134\n",
      "Training step:  1212\n",
      "Loss: 123.43306617807802\n",
      "Training step:  1213\n",
      "Loss: 102.66842104987349\n",
      "Training step:  1214\n",
      "Loss: 123.43104829434927\n",
      "Training step:  1215\n",
      "Loss: 102.66579748897237\n",
      "Training step:  1216\n",
      "Loss: 123.42903540790333\n",
      "Training step:  1217\n",
      "Loss: 102.66318159726508\n",
      "Training step:  1218\n",
      "Loss: 123.42702750394328\n",
      "Training step:  1219\n",
      "Loss: 102.6605733460887\n",
      "Training step:  1220\n",
      "Loss: 123.42502456773182\n",
      "Training step:  1221\n",
      "Loss: 102.6579727069277\n",
      "Training step:  1222\n",
      "Loss: 123.42302658459525\n",
      "Training step:  1223\n",
      "Loss: 102.65537965141029\n",
      "Training step:  1224\n",
      "Loss: 123.42103353990595\n",
      "Training step:  1225\n",
      "Loss: 102.65279415129717\n",
      "Training step:  1226\n",
      "Loss: 123.41904541910564\n",
      "Training step:  1227\n",
      "Loss: 102.65021617851454\n",
      "Training step:  1228\n",
      "Loss: 123.41706220771509\n",
      "Training step:  1229\n",
      "Loss: 102.64764570512415\n",
      "Training step:  1230\n",
      "Loss: 123.41508389129184\n",
      "Training step:  1231\n",
      "Loss: 102.64508270331558\n",
      "Training step:  1232\n",
      "Loss: 123.41311045545238\n",
      "Training step:  1233\n",
      "Loss: 102.64252714542927\n",
      "Training step:  1234\n",
      "Loss: 123.411141885883\n",
      "Training step:  1235\n",
      "Loss: 102.63997900394506\n",
      "Training step:  1236\n",
      "Loss: 123.40917816833162\n",
      "Training step:  1237\n",
      "Loss: 102.63743825148707\n",
      "Training step:  1238\n",
      "Loss: 123.40721928859679\n",
      "Training step:  1239\n",
      "Loss: 102.63490486080293\n",
      "Training step:  1240\n",
      "Loss: 123.40526523254383\n",
      "Training step:  1241\n",
      "Loss: 102.63237880479322\n",
      "Training step:  1242\n",
      "Loss: 123.40331598608383\n",
      "Training step:  1243\n",
      "Loss: 102.6298600564767\n",
      "Training step:  1244\n",
      "Loss: 123.40137153519034\n",
      "Training step:  1245\n",
      "Loss: 102.62734858901045\n",
      "Training step:  1246\n",
      "Loss: 123.39943186587742\n",
      "Training step:  1247\n",
      "Loss: 102.6248443756856\n",
      "Training step:  1248\n",
      "Loss: 123.39749696424403\n",
      "Training step:  1249\n",
      "Loss: 102.62234738993267\n",
      "Training step:  1250\n",
      "Loss: 123.39556681642101\n",
      "Training step:  1251\n",
      "Loss: 102.61985760530503\n",
      "Training step:  1252\n",
      "Loss: 123.39364140862222\n",
      "Training step:  1253\n",
      "Loss: 102.61737499551226\n",
      "Training step:  1254\n",
      "Loss: 123.39172072711348\n",
      "Training step:  1255\n",
      "Loss: 102.61489953437093\n",
      "Training step:  1256\n",
      "Loss: 123.38980475819689\n",
      "Training step:  1257\n",
      "Loss: 102.61243119582298\n",
      "Training step:  1258\n",
      "Loss: 123.38789348823006\n",
      "Training step:  1259\n",
      "Loss: 102.60996995394028\n",
      "Training step:  1260\n",
      "Loss: 123.38598690361668\n",
      "Training step:  1261\n",
      "Loss: 102.60751578292117\n",
      "Training step:  1262\n",
      "Loss: 123.38408499083\n",
      "Training step:  1263\n",
      "Loss: 102.60506865709269\n",
      "Training step:  1264\n",
      "Loss: 123.38218773638663\n",
      "Training step:  1265\n",
      "Loss: 102.60262855089643\n",
      "Training step:  1266\n",
      "Loss: 123.38029512683605\n",
      "Training step:  1267\n",
      "Loss: 102.60019543890975\n",
      "Training step:  1268\n",
      "Loss: 123.37840714883797\n",
      "Training step:  1269\n",
      "Loss: 102.59776929585033\n",
      "Training step:  1270\n",
      "Loss: 123.3765237890669\n",
      "Training step:  1271\n",
      "Loss: 102.5953500965356\n",
      "Training step:  1272\n",
      "Loss: 123.37464503424874\n",
      "Training step:  1273\n",
      "Loss: 102.59293781589713\n",
      "Training step:  1274\n",
      "Loss: 123.37277087114653\n",
      "Training step:  1275\n",
      "Loss: 102.59053242900302\n",
      "Training step:  1276\n",
      "Loss: 123.37090128660166\n",
      "Training step:  1277\n",
      "Loss: 102.58813391103408\n",
      "Training step:  1278\n",
      "Loss: 123.36903626749293\n",
      "Training step:  1279\n",
      "Loss: 102.58574223729615\n",
      "Training step:  1280\n",
      "Loss: 123.36717580074117\n",
      "Training step:  1281\n",
      "Loss: 102.58335738319249\n",
      "Training step:  1282\n",
      "Loss: 123.3653198733111\n",
      "Training step:  1283\n",
      "Loss: 102.58097932426658\n",
      "Training step:  1284\n",
      "Loss: 123.36346847225235\n",
      "Training step:  1285\n",
      "Loss: 102.57860803619101\n",
      "Training step:  1286\n",
      "Loss: 123.3616215846599\n",
      "Training step:  1287\n",
      "Loss: 102.57624349473016\n",
      "Training step:  1288\n",
      "Loss: 123.35977919764014\n",
      "Training step:  1289\n",
      "Loss: 102.5738856757633\n",
      "Training step:  1290\n",
      "Loss: 123.35794129836964\n",
      "Training step:  1291\n",
      "Loss: 102.57153455529021\n",
      "Training step:  1292\n",
      "Loss: 123.35610787407381\n",
      "Training step:  1293\n",
      "Loss: 102.56919010942548\n",
      "Training step:  1294\n",
      "Loss: 123.35427891201627\n",
      "Training step:  1295\n",
      "Loss: 102.56685231438698\n",
      "Training step:  1296\n",
      "Loss: 123.35245439951076\n",
      "Training step:  1297\n",
      "Loss: 102.56452114650843\n",
      "Training step:  1298\n",
      "Loss: 123.3506343239152\n",
      "Training step:  1299\n",
      "Loss: 102.56219658224016\n",
      "Training step:  1300\n",
      "Loss: 123.34881867265366\n",
      "Training step:  1301\n",
      "Loss: 102.55987859814785\n",
      "Training step:  1302\n",
      "Loss: 123.34700743317828\n",
      "Training step:  1303\n",
      "Loss: 102.55756717088185\n",
      "Training step:  1304\n",
      "Loss: 123.34520059296852\n",
      "Training step:  1305\n",
      "Loss: 102.55526227722244\n",
      "Training step:  1306\n",
      "Loss: 123.34339813959714\n",
      "Training step:  1307\n",
      "Loss: 102.55296389406374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1308\n",
      "Loss: 123.3416000606564\n",
      "Training step:  1309\n",
      "Loss: 102.550671998392\n",
      "Training step:  1310\n",
      "Loss: 123.33980634377515\n",
      "Training step:  1311\n",
      "Loss: 102.54838656730163\n",
      "Training step:  1312\n",
      "Loss: 123.33801697663662\n",
      "Training step:  1313\n",
      "Loss: 102.5461075779964\n",
      "Training step:  1314\n",
      "Loss: 123.3362319469734\n",
      "Training step:  1315\n",
      "Loss: 102.54383500779997\n",
      "Training step:  1316\n",
      "Loss: 123.33445124257226\n",
      "Training step:  1317\n",
      "Loss: 102.54156883411729\n",
      "Training step:  1318\n",
      "Loss: 123.33267485122796\n",
      "Training step:  1319\n",
      "Loss: 102.53930903447\n",
      "Training step:  1320\n",
      "Loss: 123.33090276082112\n",
      "Training step:  1321\n",
      "Loss: 102.53705558648426\n",
      "Training step:  1322\n",
      "Loss: 123.32913495924848\n",
      "Training step:  1323\n",
      "Loss: 102.53480846788108\n",
      "Training step:  1324\n",
      "Loss: 123.32737143445486\n",
      "Training step:  1325\n",
      "Loss: 102.53256765647932\n",
      "Training step:  1326\n",
      "Loss: 123.32561217441794\n",
      "Training step:  1327\n",
      "Loss: 102.5303331302149\n",
      "Training step:  1328\n",
      "Loss: 123.3238571671991\n",
      "Training step:  1329\n",
      "Loss: 102.52810486712353\n",
      "Training step:  1330\n",
      "Loss: 123.32210640085911\n",
      "Training step:  1331\n",
      "Loss: 102.52588284532806\n",
      "Training step:  1332\n",
      "Loss: 123.32035986352489\n",
      "Training step:  1333\n",
      "Loss: 102.52366704305864\n",
      "Training step:  1334\n",
      "Loss: 123.31861754334575\n",
      "Training step:  1335\n",
      "Loss: 102.52145743863497\n",
      "Training step:  1336\n",
      "Loss: 123.3168794285096\n",
      "Training step:  1337\n",
      "Loss: 102.51925401046748\n",
      "Training step:  1338\n",
      "Loss: 123.31514550725421\n",
      "Training step:  1339\n",
      "Loss: 102.51705673709137\n",
      "Training step:  1340\n",
      "Loss: 123.31341576788435\n",
      "Training step:  1341\n",
      "Loss: 102.51486559713577\n",
      "Training step:  1342\n",
      "Loss: 123.31169019873319\n",
      "Training step:  1343\n",
      "Loss: 102.51268056932153\n",
      "Training step:  1344\n",
      "Loss: 123.30996878816863\n",
      "Training step:  1345\n",
      "Loss: 102.5105016324551\n",
      "Training step:  1346\n",
      "Loss: 123.30825152458588\n",
      "Training step:  1347\n",
      "Loss: 102.50832876543468\n",
      "Training step:  1348\n",
      "Loss: 123.30653839642002\n",
      "Training step:  1349\n",
      "Loss: 102.50616194725772\n",
      "Training step:  1350\n",
      "Loss: 123.30482939216583\n",
      "Training step:  1351\n",
      "Loss: 102.50400115702499\n",
      "Training step:  1352\n",
      "Loss: 123.30312450034735\n",
      "Training step:  1353\n",
      "Loss: 102.50184637392478\n",
      "Training step:  1354\n",
      "Loss: 123.30142370953372\n",
      "Training step:  1355\n",
      "Loss: 102.49969757723548\n",
      "Training step:  1356\n",
      "Loss: 123.29972700832671\n",
      "Training step:  1357\n",
      "Loss: 102.49755474633349\n",
      "Training step:  1358\n",
      "Loss: 123.29803438537819\n",
      "Training step:  1359\n",
      "Loss: 102.49541786068515\n",
      "Training step:  1360\n",
      "Loss: 123.29634582936286\n",
      "Training step:  1361\n",
      "Loss: 102.4932868998356\n",
      "Training step:  1362\n",
      "Loss: 123.29466132900018\n",
      "Training step:  1363\n",
      "Loss: 102.49116184344436\n",
      "Training step:  1364\n",
      "Loss: 123.29298087306842\n",
      "Training step:  1365\n",
      "Loss: 102.48904267124605\n",
      "Training step:  1366\n",
      "Loss: 123.29130445035709\n",
      "Training step:  1367\n",
      "Loss: 102.48692936306654\n",
      "Training step:  1368\n",
      "Loss: 123.28963204970871\n",
      "Training step:  1369\n",
      "Loss: 102.4848218988241\n",
      "Training step:  1370\n",
      "Loss: 123.28796365999956\n",
      "Training step:  1371\n",
      "Loss: 102.4827202585171\n",
      "Training step:  1372\n",
      "Loss: 123.28629927013608\n",
      "Training step:  1373\n",
      "Loss: 102.48062442224122\n",
      "Training step:  1374\n",
      "Loss: 123.28463886908314\n",
      "Training step:  1375\n",
      "Loss: 102.47853437017616\n",
      "Training step:  1376\n",
      "Loss: 123.28298244581218\n",
      "Training step:  1377\n",
      "Loss: 102.47645008257773\n",
      "Training step:  1378\n",
      "Loss: 123.28132998935789\n",
      "Training step:  1379\n",
      "Loss: 102.4743715398118\n",
      "Training step:  1380\n",
      "Loss: 123.27968148879118\n",
      "Training step:  1381\n",
      "Loss: 102.47229872231244\n",
      "Training step:  1382\n",
      "Loss: 123.27803693319936\n",
      "Training step:  1383\n",
      "Loss: 102.47023161058938\n",
      "Training step:  1384\n",
      "Loss: 123.27639631170528\n",
      "Training step:  1385\n",
      "Loss: 102.46817018525527\n",
      "Training step:  1386\n",
      "Loss: 123.27475961350122\n",
      "Training step:  1387\n",
      "Loss: 102.4661144270101\n",
      "Training step:  1388\n",
      "Loss: 123.27312682778825\n",
      "Training step:  1389\n",
      "Loss: 102.46406431661616\n",
      "Training step:  1390\n",
      "Loss: 123.27149794380081\n",
      "Training step:  1391\n",
      "Loss: 102.46201983493708\n",
      "Training step:  1392\n",
      "Loss: 123.26987295083111\n",
      "Training step:  1393\n",
      "Loss: 102.4599809629229\n",
      "Training step:  1394\n",
      "Loss: 123.26825183820674\n",
      "Training step:  1395\n",
      "Loss: 102.45794768159985\n",
      "Training step:  1396\n",
      "Loss: 123.2666345952705\n",
      "Training step:  1397\n",
      "Loss: 102.45591997206583\n",
      "Training step:  1398\n",
      "Loss: 123.26502121140167\n",
      "Training step:  1399\n",
      "Loss: 102.4538978154974\n",
      "Training step:  1400\n",
      "Loss: 123.26341167601045\n",
      "Training step:  1401\n",
      "Loss: 102.45188119317449\n",
      "Training step:  1402\n",
      "Loss: 123.26180597857966\n",
      "Training step:  1403\n",
      "Loss: 102.44987008644091\n",
      "Training step:  1404\n",
      "Loss: 123.2602041085728\n",
      "Training step:  1405\n",
      "Loss: 102.44786447671027\n",
      "Training step:  1406\n",
      "Loss: 123.25860605551051\n",
      "Training step:  1407\n",
      "Loss: 102.44586434549757\n",
      "Training step:  1408\n",
      "Loss: 123.25701180897397\n",
      "Training step:  1409\n",
      "Loss: 102.44386967439524\n",
      "Training step:  1410\n",
      "Loss: 123.25542135854981\n",
      "Training step:  1411\n",
      "Loss: 102.44188044506787\n",
      "Training step:  1412\n",
      "Loss: 123.25383469387606\n",
      "Training step:  1413\n",
      "Loss: 102.43989663926217\n",
      "Training step:  1414\n",
      "Loss: 123.25225180461479\n",
      "Training step:  1415\n",
      "Loss: 102.43791823879317\n",
      "Training step:  1416\n",
      "Loss: 123.2506726804484\n",
      "Training step:  1417\n",
      "Loss: 102.4359452255542\n",
      "Training step:  1418\n",
      "Loss: 123.24909731111674\n",
      "Training step:  1419\n",
      "Loss: 102.43397758152692\n",
      "Training step:  1420\n",
      "Loss: 123.24752568637315\n",
      "Training step:  1421\n",
      "Loss: 102.43201528874606\n",
      "Training step:  1422\n",
      "Loss: 123.24595779600615\n",
      "Training step:  1423\n",
      "Loss: 102.43005832934624\n",
      "Training step:  1424\n",
      "Loss: 123.24439362985925\n",
      "Training step:  1425\n",
      "Loss: 102.42810668553396\n",
      "Training step:  1426\n",
      "Loss: 123.24283317778958\n",
      "Training step:  1427\n",
      "Loss: 102.42616033957808\n",
      "Training step:  1428\n",
      "Loss: 123.24127642968193\n",
      "Training step:  1429\n",
      "Loss: 102.42421927382374\n",
      "Training step:  1430\n",
      "Loss: 123.23972337546869\n",
      "Training step:  1431\n",
      "Loss: 102.42228347071482\n",
      "Training step:  1432\n",
      "Loss: 123.23817400513155\n",
      "Training step:  1433\n",
      "Loss: 102.42035291274976\n",
      "Training step:  1434\n",
      "Loss: 123.23662830864966\n",
      "Training step:  1435\n",
      "Loss: 102.41842758249717\n",
      "Training step:  1436\n",
      "Loss: 123.23508627604984\n",
      "Training step:  1437\n",
      "Loss: 102.41650746260557\n",
      "Training step:  1438\n",
      "Loss: 123.23354789739093\n",
      "Training step:  1439\n",
      "Loss: 102.41459253578344\n",
      "Training step:  1440\n",
      "Loss: 123.2320131627407\n",
      "Training step:  1441\n",
      "Loss: 102.41268278482322\n",
      "Training step:  1442\n",
      "Loss: 123.23048206224139\n",
      "Training step:  1443\n",
      "Loss: 102.41077819259444\n",
      "Training step:  1444\n",
      "Loss: 123.2289545860342\n",
      "Training step:  1445\n",
      "Loss: 102.40887874201394\n",
      "Training step:  1446\n",
      "Loss: 123.22743072428521\n",
      "Training step:  1447\n",
      "Loss: 102.40698441609173\n",
      "Training step:  1448\n",
      "Loss: 123.22591046723271\n",
      "Training step:  1449\n",
      "Loss: 102.40509519791335\n",
      "Training step:  1450\n",
      "Loss: 123.22439380512246\n",
      "Training step:  1451\n",
      "Loss: 102.40321107061814\n",
      "Training step:  1452\n",
      "Loss: 123.2228807282215\n",
      "Training step:  1453\n",
      "Loss: 102.40133201741486\n",
      "Training step:  1454\n",
      "Loss: 123.22137122683208\n",
      "Training step:  1455\n",
      "Loss: 102.39945802159185\n",
      "Training step:  1456\n",
      "Loss: 123.21986529130795\n",
      "Training step:  1457\n",
      "Loss: 102.39758906650573\n",
      "Training step:  1458\n",
      "Loss: 123.21836291200168\n",
      "Training step:  1459\n",
      "Loss: 102.395725135559\n",
      "Training step:  1460\n",
      "Loss: 123.21686407930088\n",
      "Training step:  1461\n",
      "Loss: 102.39386621225057\n",
      "Training step:  1462\n",
      "Loss: 123.21536878364664\n",
      "Training step:  1463\n",
      "Loss: 102.39201228013506\n",
      "Training step:  1464\n",
      "Loss: 123.21387701549155\n",
      "Training step:  1465\n",
      "Loss: 102.39016332283468\n",
      "Training step:  1466\n",
      "Loss: 123.21238876533015\n",
      "Training step:  1467\n",
      "Loss: 102.38831932406873\n",
      "Training step:  1468\n",
      "Loss: 123.21090402372735\n",
      "Training step:  1469\n",
      "Loss: 102.38648026759468\n",
      "Training step:  1470\n",
      "Loss: 123.20942278119013\n",
      "Training step:  1471\n",
      "Loss: 102.38464613721074\n",
      "Training step:  1472\n",
      "Loss: 123.2079450282832\n",
      "Training step:  1473\n",
      "Loss: 102.38281691681954\n",
      "Training step:  1474\n",
      "Loss: 123.20647075564328\n",
      "Training step:  1475\n",
      "Loss: 102.38099259038032\n",
      "Training step:  1476\n",
      "Loss: 123.20499995388779\n",
      "Training step:  1477\n",
      "Loss: 102.37917314190813\n",
      "Training step:  1478\n",
      "Loss: 123.2035326136855\n",
      "Training step:  1479\n",
      "Loss: 102.37735855549228\n",
      "Training step:  1480\n",
      "Loss: 123.20206872573874\n",
      "Training step:  1481\n",
      "Loss: 102.37554881528482\n",
      "Training step:  1482\n",
      "Loss: 123.20060828075981\n",
      "Training step:  1483\n",
      "Loss: 102.37374390549988\n",
      "Training step:  1484\n",
      "Loss: 123.19915126951115\n",
      "Training step:  1485\n",
      "Loss: 102.37194381041962\n",
      "Training step:  1486\n",
      "Loss: 123.19769768278005\n",
      "Training step:  1487\n",
      "Loss: 102.37014851439818\n",
      "Training step:  1488\n",
      "Loss: 123.19624751138181\n",
      "Training step:  1489\n",
      "Loss: 102.36835800183322\n",
      "Training step:  1490\n",
      "Loss: 123.19480074613975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1491\n",
      "Loss: 102.36657225718585\n",
      "Training step:  1492\n",
      "Loss: 123.19335737792274\n",
      "Training step:  1493\n",
      "Loss: 102.36479126500598\n",
      "Training step:  1494\n",
      "Loss: 123.1919173976513\n",
      "Training step:  1495\n",
      "Loss: 102.36301500988769\n",
      "Training step:  1496\n",
      "Loss: 123.1904807962333\n",
      "Training step:  1497\n",
      "Loss: 102.36124347647724\n",
      "Training step:  1498\n",
      "Loss: 123.1890475646151\n",
      "Training step:  1499\n",
      "Loss: 102.35947664950115\n",
      "Training step:  1500\n",
      "Loss: 123.18761769379417\n",
      "Training step:  1501\n",
      "Loss: 102.35771451374208\n",
      "Training step:  1502\n",
      "Loss: 123.1861911747777\n",
      "Training step:  1503\n",
      "Loss: 102.35595705404235\n",
      "Training step:  1504\n",
      "Loss: 123.1847679985995\n",
      "Training step:  1505\n",
      "Loss: 102.35420425529604\n",
      "Training step:  1506\n",
      "Loss: 123.18334815630305\n",
      "Training step:  1507\n",
      "Loss: 102.35245610244976\n",
      "Training step:  1508\n",
      "Loss: 123.18193163897615\n",
      "Training step:  1509\n",
      "Loss: 102.35071258053559\n",
      "Training step:  1510\n",
      "Loss: 123.18051843775056\n",
      "Training step:  1511\n",
      "Loss: 102.34897367463869\n",
      "Training step:  1512\n",
      "Loss: 123.179108543776\n",
      "Training step:  1513\n",
      "Loss: 102.34723936991017\n",
      "Training step:  1514\n",
      "Loss: 123.1777019482389\n",
      "Training step:  1515\n",
      "Loss: 102.34550965154754\n",
      "Training step:  1516\n",
      "Loss: 123.1762986423189\n",
      "Training step:  1517\n",
      "Loss: 102.34378450480308\n",
      "Training step:  1518\n",
      "Loss: 123.1748986172643\n",
      "Training step:  1519\n",
      "Loss: 102.34206391501218\n",
      "Training step:  1520\n",
      "Loss: 123.17350186431722\n",
      "Training step:  1521\n",
      "Loss: 102.34034786752316\n",
      "Training step:  1522\n",
      "Loss: 123.17210837473327\n",
      "Training step:  1523\n",
      "Loss: 102.33863634776951\n",
      "Training step:  1524\n",
      "Loss: 123.17071813983102\n",
      "Training step:  1525\n",
      "Loss: 102.33692934125592\n",
      "Training step:  1526\n",
      "Loss: 123.16933115095951\n",
      "Training step:  1527\n",
      "Loss: 102.33522683353463\n",
      "Training step:  1528\n",
      "Loss: 123.16794739947595\n",
      "Training step:  1529\n",
      "Loss: 102.3335288102083\n",
      "Training step:  1530\n",
      "Loss: 123.16656687676402\n",
      "Training step:  1531\n",
      "Loss: 102.331835256936\n",
      "Training step:  1532\n",
      "Loss: 123.16518957422927\n",
      "Training step:  1533\n",
      "Loss: 102.3301461594377\n",
      "Training step:  1534\n",
      "Loss: 123.16381548331532\n",
      "Training step:  1535\n",
      "Loss: 102.32846150348469\n",
      "Training step:  1536\n",
      "Loss: 123.16244459547516\n",
      "Training step:  1537\n",
      "Loss: 102.3267812749065\n",
      "Training step:  1538\n",
      "Loss: 123.16107690220643\n",
      "Training step:  1539\n",
      "Loss: 102.3251054595912\n",
      "Training step:  1540\n",
      "Loss: 123.159712395017\n",
      "Training step:  1541\n",
      "Loss: 102.32343404347444\n",
      "Training step:  1542\n",
      "Loss: 123.15835106545069\n",
      "Training step:  1543\n",
      "Loss: 102.32176701256782\n",
      "Training step:  1544\n",
      "Loss: 123.15699290509416\n",
      "Training step:  1545\n",
      "Loss: 102.3201043529164\n",
      "Training step:  1546\n",
      "Loss: 123.15563790551681\n",
      "Training step:  1547\n",
      "Loss: 102.31844605062079\n",
      "Training step:  1548\n",
      "Loss: 123.15428605834194\n",
      "Training step:  1549\n",
      "Loss: 102.31679209184573\n",
      "Training step:  1550\n",
      "Loss: 123.15293735521588\n",
      "Training step:  1551\n",
      "Loss: 102.31514246280653\n",
      "Training step:  1552\n",
      "Loss: 123.1515917878105\n",
      "Training step:  1553\n",
      "Loss: 102.31349714977614\n",
      "Training step:  1554\n",
      "Loss: 123.15024934782534\n",
      "Training step:  1555\n",
      "Loss: 102.31185613907044\n",
      "Training step:  1556\n",
      "Loss: 123.14891002695809\n",
      "Training step:  1557\n",
      "Loss: 102.31021941705701\n",
      "Training step:  1558\n",
      "Loss: 123.14757381696478\n",
      "Training step:  1559\n",
      "Loss: 102.30858697018007\n",
      "Training step:  1560\n",
      "Loss: 123.14624070962297\n",
      "Training step:  1561\n",
      "Loss: 102.30695878490094\n",
      "Training step:  1562\n",
      "Loss: 123.14491069669218\n",
      "Training step:  1563\n",
      "Loss: 102.30533484775353\n",
      "Training step:  1564\n",
      "Loss: 123.14358377001508\n",
      "Training step:  1565\n",
      "Loss: 102.30371514533383\n",
      "Training step:  1566\n",
      "Loss: 123.14225992143626\n",
      "Training step:  1567\n",
      "Loss: 102.30209966427533\n",
      "Training step:  1568\n",
      "Loss: 123.1409391428132\n",
      "Training step:  1569\n",
      "Loss: 102.300488391257\n",
      "Training step:  1570\n",
      "Loss: 123.13962142603191\n",
      "Training step:  1571\n",
      "Loss: 102.29888131302415\n",
      "Training step:  1572\n",
      "Loss: 123.13830676301073\n",
      "Training step:  1573\n",
      "Loss: 102.29727841636549\n",
      "Training step:  1574\n",
      "Loss: 123.13699514569947\n",
      "Training step:  1575\n",
      "Loss: 102.29567968812955\n",
      "Training step:  1576\n",
      "Loss: 123.13568656605487\n",
      "Training step:  1577\n",
      "Loss: 102.29408511519833\n",
      "Training step:  1578\n",
      "Loss: 123.13438101605502\n",
      "Training step:  1579\n",
      "Loss: 102.29249468451368\n",
      "Training step:  1580\n",
      "Loss: 123.13307848771151\n",
      "Training step:  1581\n",
      "Loss: 102.29090838305895\n",
      "Training step:  1582\n",
      "Loss: 123.13177897304726\n",
      "Training step:  1583\n",
      "Loss: 102.28932619788424\n",
      "Training step:  1584\n",
      "Loss: 123.1304824641419\n",
      "Training step:  1585\n",
      "Loss: 102.28774811608479\n",
      "Training step:  1586\n",
      "Loss: 123.1291889530727\n",
      "Training step:  1587\n",
      "Loss: 102.28617412480068\n",
      "Training step:  1588\n",
      "Loss: 123.1278984319405\n",
      "Training step:  1589\n",
      "Loss: 102.28460421121122\n",
      "Training step:  1590\n",
      "Loss: 123.12661089286291\n",
      "Training step:  1591\n",
      "Loss: 102.28303836255489\n",
      "Training step:  1592\n",
      "Loss: 123.12532632799719\n",
      "Training step:  1593\n",
      "Loss: 102.28147656612737\n",
      "Training step:  1594\n",
      "Loss: 123.12404472953241\n",
      "Training step:  1595\n",
      "Loss: 102.2799188092738\n",
      "Training step:  1596\n",
      "Loss: 123.12276608967518\n",
      "Training step:  1597\n",
      "Loss: 102.27836507936561\n",
      "Training step:  1598\n",
      "Loss: 123.12149040061438\n",
      "Training step:  1599\n",
      "Loss: 102.27681536382906\n",
      "Training step:  1600\n",
      "Loss: 123.12021765460977\n",
      "Training step:  1601\n",
      "Loss: 102.27526965014233\n",
      "Training step:  1602\n",
      "Loss: 123.11894784391593\n",
      "Training step:  1603\n",
      "Loss: 102.27372792584048\n",
      "Training step:  1604\n",
      "Loss: 123.11768096084933\n",
      "Training step:  1605\n",
      "Loss: 102.27219017850638\n",
      "Training step:  1606\n",
      "Loss: 123.11641699771582\n",
      "Training step:  1607\n",
      "Loss: 102.2706563957522\n",
      "Training step:  1608\n",
      "Loss: 123.1151559468441\n",
      "Training step:  1609\n",
      "Loss: 102.26912656524193\n",
      "Training step:  1610\n",
      "Loss: 123.11389780058465\n",
      "Training step:  1611\n",
      "Loss: 102.26760067468764\n",
      "Training step:  1612\n",
      "Loss: 123.11264255132558\n",
      "Training step:  1613\n",
      "Loss: 102.26607871186042\n",
      "Training step:  1614\n",
      "Loss: 123.11139019147868\n",
      "Training step:  1615\n",
      "Loss: 102.26456066456132\n",
      "Training step:  1616\n",
      "Loss: 123.11014071345119\n",
      "Training step:  1617\n",
      "Loss: 102.26304652063837\n",
      "Training step:  1618\n",
      "Loss: 123.10889410969942\n",
      "Training step:  1619\n",
      "Loss: 102.26153626799852\n",
      "Training step:  1620\n",
      "Loss: 123.10765037269742\n",
      "Training step:  1621\n",
      "Loss: 102.26002989457614\n",
      "Training step:  1622\n",
      "Loss: 123.10640949491605\n",
      "Training step:  1623\n",
      "Loss: 102.25852738835397\n",
      "Training step:  1624\n",
      "Loss: 123.10517146887308\n",
      "Training step:  1625\n",
      "Loss: 102.25702873737197\n",
      "Training step:  1626\n",
      "Loss: 123.10393628711036\n",
      "Training step:  1627\n",
      "Loss: 102.25553392971084\n",
      "Training step:  1628\n",
      "Loss: 123.10270394218988\n",
      "Training step:  1629\n",
      "Loss: 102.25404295349963\n",
      "Training step:  1630\n",
      "Loss: 123.10147442668976\n",
      "Training step:  1631\n",
      "Loss: 102.25255579690146\n",
      "Training step:  1632\n",
      "Loss: 123.10024773321064\n",
      "Training step:  1633\n",
      "Loss: 102.25107244812789\n",
      "Training step:  1634\n",
      "Loss: 123.09902385437671\n",
      "Training step:  1635\n",
      "Loss: 102.24959289544978\n",
      "Training step:  1636\n",
      "Loss: 123.0978027828469\n",
      "Training step:  1637\n",
      "Loss: 102.24811712715022\n",
      "Training step:  1638\n",
      "Loss: 123.09658451125559\n",
      "Training step:  1639\n",
      "Loss: 102.24664513157931\n",
      "Training step:  1640\n",
      "Loss: 123.09536903232606\n",
      "Training step:  1641\n",
      "Loss: 102.24517689713471\n",
      "Training step:  1642\n",
      "Loss: 123.09415633875075\n",
      "Training step:  1643\n",
      "Loss: 102.24371241223162\n",
      "Training step:  1644\n",
      "Loss: 123.09294642324909\n",
      "Training step:  1645\n",
      "Loss: 102.24225166533974\n",
      "Training step:  1646\n",
      "Loss: 123.09173927856743\n",
      "Training step:  1647\n",
      "Loss: 102.24079464497555\n",
      "Training step:  1648\n",
      "Loss: 123.09053489748634\n",
      "Training step:  1649\n",
      "Loss: 102.23934133969769\n",
      "Training step:  1650\n",
      "Loss: 123.08933327278625\n",
      "Training step:  1651\n",
      "Loss: 102.23789173810108\n",
      "Training step:  1652\n",
      "Loss: 123.08813439728803\n",
      "Training step:  1653\n",
      "Loss: 102.23644582884643\n",
      "Training step:  1654\n",
      "Loss: 123.08693826385594\n",
      "Training step:  1655\n",
      "Loss: 102.23500360062614\n",
      "Training step:  1656\n",
      "Loss: 123.08574486532483\n",
      "Training step:  1657\n",
      "Loss: 102.23356504214165\n",
      "Training step:  1658\n",
      "Loss: 123.0845541945555\n",
      "Training step:  1659\n",
      "Loss: 102.23213014217201\n",
      "Training step:  1660\n",
      "Loss: 123.08336624446967\n",
      "Training step:  1661\n",
      "Loss: 102.23069888953385\n",
      "Training step:  1662\n",
      "Loss: 123.08218100797171\n",
      "Training step:  1663\n",
      "Loss: 102.22927127306517\n",
      "Training step:  1664\n",
      "Loss: 123.08099847799578\n",
      "Training step:  1665\n",
      "Loss: 102.2278472816593\n",
      "Training step:  1666\n",
      "Loss: 123.07981864750165\n",
      "Training step:  1667\n",
      "Loss: 102.2264269042572\n",
      "Training step:  1668\n",
      "Loss: 123.07864150947542\n",
      "Training step:  1669\n",
      "Loss: 102.22501012982073\n",
      "Training step:  1670\n",
      "Loss: 123.07746705689826\n",
      "Training step:  1671\n",
      "Loss: 102.22359694736559\n",
      "Training step:  1672\n",
      "Loss: 123.07629528280559\n",
      "Training step:  1673\n",
      "Loss: 102.22218734595423\n",
      "Training step:  1674\n",
      "Loss: 123.07512618023131\n",
      "Training step:  1675\n",
      "Loss: 102.22078131467045\n",
      "Training step:  1676\n",
      "Loss: 123.07395974223017\n",
      "Training step:  1677\n",
      "Loss: 102.2193788426515\n",
      "Training step:  1678\n",
      "Loss: 123.07279596188565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1679\n",
      "Loss: 102.21797991907673\n",
      "Training step:  1680\n",
      "Loss: 123.07163483231443\n",
      "Training step:  1681\n",
      "Loss: 102.21658453317654\n",
      "Training step:  1682\n",
      "Loss: 123.07047634664914\n",
      "Training step:  1683\n",
      "Loss: 102.21519267419706\n",
      "Training step:  1684\n",
      "Loss: 123.06932049800464\n",
      "Training step:  1685\n",
      "Loss: 102.21380433141329\n",
      "Training step:  1686\n",
      "Loss: 123.06816727953411\n",
      "Training step:  1687\n",
      "Loss: 102.21241949416368\n",
      "Training step:  1688\n",
      "Loss: 123.0670166844224\n",
      "Training step:  1689\n",
      "Loss: 102.21103815180987\n",
      "Training step:  1690\n",
      "Loss: 123.06586870585791\n",
      "Training step:  1691\n",
      "Loss: 102.2096602937687\n",
      "Training step:  1692\n",
      "Loss: 123.06472333707487\n",
      "Training step:  1693\n",
      "Loss: 102.20828590949\n",
      "Training step:  1694\n",
      "Loss: 123.06358057130697\n",
      "Training step:  1695\n",
      "Loss: 102.20691498845234\n",
      "Training step:  1696\n",
      "Loss: 123.0624404018028\n",
      "Training step:  1697\n",
      "Loss: 102.20554752018288\n",
      "Training step:  1698\n",
      "Loss: 123.06130282184873\n",
      "Training step:  1699\n",
      "Loss: 102.20418349424317\n",
      "Training step:  1700\n",
      "Loss: 123.06016782473667\n",
      "Training step:  1701\n",
      "Loss: 102.20282290023529\n",
      "Training step:  1702\n",
      "Loss: 123.05903540378358\n",
      "Training step:  1703\n",
      "Loss: 102.20146572778886\n",
      "Training step:  1704\n",
      "Loss: 123.05790555231957\n",
      "Training step:  1705\n",
      "Loss: 102.20011196658956\n",
      "Training step:  1706\n",
      "Loss: 123.05677826370957\n",
      "Training step:  1707\n",
      "Loss: 102.1987616063465\n",
      "Training step:  1708\n",
      "Loss: 123.05565353132229\n",
      "Training step:  1709\n",
      "Loss: 102.19741463680573\n",
      "Training step:  1710\n",
      "Loss: 123.05453134853835\n",
      "Training step:  1711\n",
      "Loss: 102.1960710477444\n",
      "Training step:  1712\n",
      "Loss: 123.05341170875953\n",
      "Training step:  1713\n",
      "Loss: 102.19473082898683\n",
      "Training step:  1714\n",
      "Loss: 123.05229460543079\n",
      "Training step:  1715\n",
      "Loss: 102.1933939704039\n",
      "Training step:  1716\n",
      "Loss: 123.05118003200347\n",
      "Training step:  1717\n",
      "Loss: 102.1920604618908\n",
      "Training step:  1718\n",
      "Loss: 123.05006798194412\n",
      "Training step:  1719\n",
      "Loss: 102.19073029337531\n",
      "Training step:  1720\n",
      "Loss: 123.04895844873387\n",
      "Training step:  1721\n",
      "Loss: 102.1894034548322\n",
      "Training step:  1722\n",
      "Loss: 123.04785142588683\n",
      "Training step:  1723\n",
      "Loss: 102.18807993626164\n",
      "Training step:  1724\n",
      "Loss: 123.04674690690665\n",
      "Training step:  1725\n",
      "Loss: 102.1867597276943\n",
      "Training step:  1726\n",
      "Loss: 123.04564488533688\n",
      "Training step:  1727\n",
      "Loss: 102.1854428192134\n",
      "Training step:  1728\n",
      "Loss: 123.04454535474665\n",
      "Training step:  1729\n",
      "Loss: 102.18412920093327\n",
      "Training step:  1730\n",
      "Loss: 123.04344830870669\n",
      "Training step:  1731\n",
      "Loss: 102.18281886299255\n",
      "Training step:  1732\n",
      "Loss: 123.04235374081517\n",
      "Training step:  1733\n",
      "Loss: 102.18151179558981\n",
      "Training step:  1734\n",
      "Loss: 123.04126164471346\n",
      "Training step:  1735\n",
      "Loss: 102.18020798894598\n",
      "Training step:  1736\n",
      "Loss: 123.04017201400536\n",
      "Training step:  1737\n",
      "Loss: 102.17890743327976\n",
      "Training step:  1738\n",
      "Loss: 123.0390848423233\n",
      "Training step:  1739\n",
      "Loss: 102.17761011889162\n",
      "Training step:  1740\n",
      "Loss: 123.03800012335529\n",
      "Training step:  1741\n",
      "Loss: 102.17631603610815\n",
      "Training step:  1742\n",
      "Loss: 123.03691785079467\n",
      "Training step:  1743\n",
      "Loss: 102.17502517528926\n",
      "Training step:  1744\n",
      "Loss: 123.03583801834797\n",
      "Training step:  1745\n",
      "Loss: 102.17373752681827\n",
      "Training step:  1746\n",
      "Loss: 123.03476061971804\n",
      "Training step:  1747\n",
      "Loss: 102.17245308111431\n",
      "Training step:  1748\n",
      "Loss: 123.03368564866135\n",
      "Training step:  1749\n",
      "Loss: 102.17117182864826\n",
      "Training step:  1750\n",
      "Loss: 123.03261309893956\n",
      "Training step:  1751\n",
      "Loss: 102.16989375991008\n",
      "Training step:  1752\n",
      "Loss: 123.03154296432588\n",
      "Training step:  1753\n",
      "Loss: 102.16861886542537\n",
      "Training step:  1754\n",
      "Loss: 123.03047523861972\n",
      "Training step:  1755\n",
      "Loss: 102.16734713576147\n",
      "Training step:  1756\n",
      "Loss: 123.02940991563612\n",
      "Training step:  1757\n",
      "Loss: 102.16607856150313\n",
      "Training step:  1758\n",
      "Loss: 123.02834698919527\n",
      "Training step:  1759\n",
      "Loss: 102.16481313327961\n",
      "Training step:  1760\n",
      "Loss: 123.02728645314446\n",
      "Training step:  1761\n",
      "Loss: 102.16355084174309\n",
      "Training step:  1762\n",
      "Loss: 123.02622830134537\n",
      "Training step:  1763\n",
      "Loss: 102.1622916775962\n",
      "Training step:  1764\n",
      "Loss: 123.02517252768925\n",
      "Training step:  1765\n",
      "Loss: 102.16103563155889\n",
      "Training step:  1766\n",
      "Loss: 123.02411912606229\n",
      "Training step:  1767\n",
      "Loss: 102.15978269438041\n",
      "Training step:  1768\n",
      "Loss: 123.02306809037704\n",
      "Training step:  1769\n",
      "Loss: 102.15853285686016\n",
      "Training step:  1770\n",
      "Loss: 123.02201941457913\n",
      "Training step:  1771\n",
      "Loss: 102.15728610982022\n",
      "Training step:  1772\n",
      "Loss: 123.02097309260922\n",
      "Training step:  1773\n",
      "Loss: 102.15604244410717\n",
      "Training step:  1774\n",
      "Loss: 123.01992911842522\n",
      "Training step:  1775\n",
      "Loss: 102.15480185060855\n",
      "Training step:  1776\n",
      "Loss: 123.01888748602879\n",
      "Training step:  1777\n",
      "Loss: 102.15356432026327\n",
      "Training step:  1778\n",
      "Loss: 123.01784818943254\n",
      "Training step:  1779\n",
      "Loss: 102.15232984401332\n",
      "Training step:  1780\n",
      "Loss: 123.01681122264254\n",
      "Training step:  1781\n",
      "Loss: 102.15109841284122\n",
      "Training step:  1782\n",
      "Loss: 123.01577657969192\n",
      "Training step:  1783\n",
      "Loss: 102.14987001775577\n",
      "Training step:  1784\n",
      "Loss: 123.01474425462732\n",
      "Training step:  1785\n",
      "Loss: 102.14864464979833\n",
      "Training step:  1786\n",
      "Loss: 123.01371424150962\n",
      "Training step:  1787\n",
      "Loss: 102.14742230005159\n",
      "Training step:  1788\n",
      "Loss: 123.01268653445128\n",
      "Training step:  1789\n",
      "Loss: 102.14620295963832\n",
      "Training step:  1790\n",
      "Loss: 123.01166112754845\n",
      "Training step:  1791\n",
      "Loss: 102.14498661968496\n",
      "Training step:  1792\n",
      "Loss: 123.01063801491145\n",
      "Training step:  1793\n",
      "Loss: 102.14377327136195\n",
      "Training step:  1794\n",
      "Loss: 123.00961719066639\n",
      "Training step:  1795\n",
      "Loss: 102.14256290585718\n",
      "Training step:  1796\n",
      "Loss: 123.00859864896498\n",
      "Training step:  1797\n",
      "Loss: 102.14135551441782\n",
      "Training step:  1798\n",
      "Loss: 123.00758238398626\n",
      "Training step:  1799\n",
      "Loss: 102.14015108830087\n",
      "Training step:  1800\n",
      "Loss: 123.00656838991902\n",
      "Training step:  1801\n",
      "Loss: 102.13894961882008\n",
      "Training step:  1802\n",
      "Loss: 123.00555666098471\n",
      "Training step:  1803\n",
      "Loss: 102.13775109728815\n",
      "Training step:  1804\n",
      "Loss: 123.0045471913754\n",
      "Training step:  1805\n",
      "Loss: 102.13655551505583\n",
      "Training step:  1806\n",
      "Loss: 123.00353997533347\n",
      "Training step:  1807\n",
      "Loss: 102.1353628634984\n",
      "Training step:  1808\n",
      "Loss: 123.00253500708615\n",
      "Training step:  1809\n",
      "Loss: 102.1341731340263\n",
      "Training step:  1810\n",
      "Loss: 123.0015322809163\n",
      "Training step:  1811\n",
      "Loss: 102.13298631810025\n",
      "Training step:  1812\n",
      "Loss: 123.00053179112558\n",
      "Training step:  1813\n",
      "Loss: 102.13180240719716\n",
      "Training step:  1814\n",
      "Loss: 122.99953353200408\n",
      "Training step:  1815\n",
      "Loss: 102.13062139280348\n",
      "Training step:  1816\n",
      "Loss: 122.99853749784982\n",
      "Training step:  1817\n",
      "Loss: 102.12944326645557\n",
      "Training step:  1818\n",
      "Loss: 122.9975436829985\n",
      "Training step:  1819\n",
      "Loss: 102.1282680197107\n",
      "Training step:  1820\n",
      "Loss: 122.99655208180224\n",
      "Training step:  1821\n",
      "Loss: 102.12709564416497\n",
      "Training step:  1822\n",
      "Loss: 122.99556268862268\n",
      "Training step:  1823\n",
      "Loss: 102.12592613144086\n",
      "Training step:  1824\n",
      "Loss: 122.99457549784255\n",
      "Training step:  1825\n",
      "Loss: 102.12475947318403\n",
      "Training step:  1826\n",
      "Loss: 122.99359050385479\n",
      "Training step:  1827\n",
      "Loss: 102.12359566107268\n",
      "Training step:  1828\n",
      "Loss: 122.99260770106018\n",
      "Training step:  1829\n",
      "Loss: 102.12243468679834\n",
      "Training step:  1830\n",
      "Loss: 122.99162708387223\n",
      "Training step:  1831\n",
      "Loss: 102.12127654210009\n",
      "Training step:  1832\n",
      "Loss: 122.99064864674757\n",
      "Training step:  1833\n",
      "Loss: 102.12012121875274\n",
      "Training step:  1834\n",
      "Loss: 122.9896723841481\n",
      "Training step:  1835\n",
      "Loss: 102.11896870854167\n",
      "Training step:  1836\n",
      "Loss: 122.98869829054593\n",
      "Training step:  1837\n",
      "Loss: 102.11781900329404\n",
      "Training step:  1838\n",
      "Loss: 122.98772636043174\n",
      "Training step:  1839\n",
      "Loss: 102.1166720948555\n",
      "Training step:  1840\n",
      "Loss: 122.9867565883066\n",
      "Training step:  1841\n",
      "Loss: 102.11552797509584\n",
      "Training step:  1842\n",
      "Loss: 122.98578896867825\n",
      "Training step:  1843\n",
      "Loss: 102.11438663591889\n",
      "Training step:  1844\n",
      "Loss: 122.98482349609095\n",
      "Training step:  1845\n",
      "Loss: 102.11324806925532\n",
      "Training step:  1846\n",
      "Loss: 122.98386016507713\n",
      "Training step:  1847\n",
      "Loss: 102.11211226705295\n",
      "Training step:  1848\n",
      "Loss: 122.98289897020364\n",
      "Training step:  1849\n",
      "Loss: 102.11097922131506\n",
      "Training step:  1850\n",
      "Loss: 122.98193990607406\n",
      "Training step:  1851\n",
      "Loss: 102.10984892405732\n",
      "Training step:  1852\n",
      "Loss: 122.98098296727113\n",
      "Training step:  1853\n",
      "Loss: 102.10872136731594\n",
      "Training step:  1854\n",
      "Loss: 122.98002814840474\n",
      "Training step:  1855\n",
      "Loss: 102.10759654315544\n",
      "Training step:  1856\n",
      "Loss: 122.97907544409163\n",
      "Training step:  1857\n",
      "Loss: 102.10647444366705\n",
      "Training step:  1858\n",
      "Loss: 122.97812484895927\n",
      "Training step:  1859\n",
      "Loss: 102.10535506096393\n",
      "Training step:  1860\n",
      "Loss: 122.97717635767327\n",
      "Training step:  1861\n",
      "Loss: 102.10423838721167\n",
      "Training step:  1862\n",
      "Loss: 122.97622996491305\n",
      "Training step:  1863\n",
      "Loss: 102.1031244145914\n",
      "Training step:  1864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 122.97528566536805\n",
      "Training step:  1865\n",
      "Loss: 102.10201313529518\n",
      "Training step:  1866\n",
      "Loss: 122.97434345372201\n",
      "Training step:  1867\n",
      "Loss: 102.10090454155556\n",
      "Training step:  1868\n",
      "Loss: 122.97340332469948\n",
      "Training step:  1869\n",
      "Loss: 102.0997986256289\n",
      "Training step:  1870\n",
      "Loss: 122.9724652730289\n",
      "Training step:  1871\n",
      "Loss: 102.0986953798035\n",
      "Training step:  1872\n",
      "Loss: 122.97152929346207\n",
      "Training step:  1873\n",
      "Loss: 102.09759479637832\n",
      "Training step:  1874\n",
      "Loss: 122.97059538073896\n",
      "Training step:  1875\n",
      "Loss: 102.09649686768931\n",
      "Training step:  1876\n",
      "Loss: 122.96966352964493\n",
      "Training step:  1877\n",
      "Loss: 102.09540158609438\n",
      "Training step:  1878\n",
      "Loss: 122.96873373495423\n",
      "Training step:  1879\n",
      "Loss: 102.09430894398064\n",
      "Training step:  1880\n",
      "Loss: 122.96780599148131\n",
      "Training step:  1881\n",
      "Loss: 102.09321893375794\n",
      "Training step:  1882\n",
      "Loss: 122.96688029403222\n",
      "Training step:  1883\n",
      "Loss: 102.09213154787045\n",
      "Training step:  1884\n",
      "Loss: 122.96595663745059\n",
      "Training step:  1885\n",
      "Loss: 102.09104677876894\n",
      "Training step:  1886\n",
      "Loss: 122.96503501655377\n",
      "Training step:  1887\n",
      "Loss: 102.08996461893838\n",
      "Training step:  1888\n",
      "Loss: 122.96411542621483\n",
      "Training step:  1889\n",
      "Loss: 102.08888506090622\n",
      "Training step:  1890\n",
      "Loss: 122.96319786131983\n",
      "Training step:  1891\n",
      "Loss: 102.0878080972053\n",
      "Training step:  1892\n",
      "Loss: 122.96228231674033\n",
      "Training step:  1893\n",
      "Loss: 102.08673372040124\n",
      "Training step:  1894\n",
      "Loss: 122.9613687873955\n",
      "Training step:  1895\n",
      "Loss: 102.08566192308948\n",
      "Training step:  1896\n",
      "Loss: 122.96045726818687\n",
      "Training step:  1897\n",
      "Loss: 102.08459269786233\n",
      "Training step:  1898\n",
      "Loss: 122.9595477540311\n",
      "Training step:  1899\n",
      "Loss: 102.08352603737727\n",
      "Training step:  1900\n",
      "Loss: 122.95864023990967\n",
      "Training step:  1901\n",
      "Loss: 102.08246193430853\n",
      "Training step:  1902\n",
      "Loss: 122.95773472077627\n",
      "Training step:  1903\n",
      "Loss: 102.08140038133743\n",
      "Training step:  1904\n",
      "Loss: 122.95683119159305\n",
      "Training step:  1905\n",
      "Loss: 102.08034137117193\n",
      "Training step:  1906\n",
      "Loss: 122.95592964734469\n",
      "Training step:  1907\n",
      "Loss: 102.07928489655454\n",
      "Training step:  1908\n",
      "Loss: 122.955030083045\n",
      "Training step:  1909\n",
      "Loss: 102.0782309502468\n",
      "Training step:  1910\n",
      "Loss: 122.95413249368448\n",
      "Training step:  1911\n",
      "Loss: 102.07717952502165\n",
      "Training step:  1912\n",
      "Loss: 122.95323687430265\n",
      "Training step:  1913\n",
      "Loss: 102.07613061371133\n",
      "Training step:  1914\n",
      "Loss: 122.95234321996153\n",
      "Training step:  1915\n",
      "Loss: 102.0750842091441\n",
      "Training step:  1916\n",
      "Loss: 122.95145152569074\n",
      "Training step:  1917\n",
      "Loss: 102.0740403041668\n",
      "Training step:  1918\n",
      "Loss: 122.95056178655676\n",
      "Training step:  1919\n",
      "Loss: 102.07299889166009\n",
      "Training step:  1920\n",
      "Loss: 122.9496739976481\n",
      "Training step:  1921\n",
      "Loss: 102.07195996454566\n",
      "Training step:  1922\n",
      "Loss: 122.94878815407807\n",
      "Training step:  1923\n",
      "Loss: 102.07092351574812\n",
      "Training step:  1924\n",
      "Loss: 122.94790425093288\n",
      "Training step:  1925\n",
      "Loss: 102.06988953820522\n",
      "Training step:  1926\n",
      "Loss: 122.9470222833329\n",
      "Training step:  1927\n",
      "Loss: 102.06885802490329\n",
      "Training step:  1928\n",
      "Loss: 122.94614224642591\n",
      "Training step:  1929\n",
      "Loss: 102.06782896884877\n",
      "Training step:  1930\n",
      "Loss: 122.9452641353769\n",
      "Training step:  1931\n",
      "Loss: 102.06680236307439\n",
      "Training step:  1932\n",
      "Loss: 122.9443879453482\n",
      "Training step:  1933\n",
      "Loss: 102.06577820061378\n",
      "Training step:  1934\n",
      "Loss: 122.94351367149622\n",
      "Training step:  1935\n",
      "Loss: 102.06475647454154\n",
      "Training step:  1936\n",
      "Loss: 122.94264130903998\n",
      "Training step:  1937\n",
      "Loss: 102.0637371779569\n",
      "Training step:  1938\n",
      "Loss: 122.94177085316552\n",
      "Training step:  1939\n",
      "Loss: 102.06272030396079\n",
      "Training step:  1940\n",
      "Loss: 122.9409022990787\n",
      "Training step:  1941\n",
      "Loss: 102.06170584569261\n",
      "Training step:  1942\n",
      "Loss: 122.94003564200933\n",
      "Training step:  1943\n",
      "Loss: 102.06069379630972\n",
      "Training step:  1944\n",
      "Loss: 122.93917087721017\n",
      "Training step:  1945\n",
      "Loss: 102.05968414900914\n",
      "Training step:  1946\n",
      "Loss: 122.938307999939\n",
      "Training step:  1947\n",
      "Loss: 102.05867689699718\n",
      "Training step:  1948\n",
      "Loss: 122.93744700547383\n",
      "Training step:  1949\n",
      "Loss: 102.0576720335048\n",
      "Training step:  1950\n",
      "Loss: 122.9365878890929\n",
      "Training step:  1951\n",
      "Loss: 102.05666955178458\n",
      "Training step:  1952\n",
      "Loss: 122.93573064609197\n",
      "Training step:  1953\n",
      "Loss: 102.055669445106\n",
      "Training step:  1954\n",
      "Loss: 122.93487527177709\n",
      "Training step:  1955\n",
      "Loss: 102.0546717067667\n",
      "Training step:  1956\n",
      "Loss: 122.93402176146942\n",
      "Training step:  1957\n",
      "Loss: 102.05367633008645\n",
      "Training step:  1958\n",
      "Loss: 122.9331701105032\n",
      "Training step:  1959\n",
      "Loss: 102.05268330840018\n",
      "Training step:  1960\n",
      "Loss: 122.9323203142201\n",
      "Training step:  1961\n",
      "Loss: 102.05169263506546\n",
      "Training step:  1962\n",
      "Loss: 122.93147236796942\n",
      "Training step:  1963\n",
      "Loss: 102.05070430347637\n",
      "Training step:  1964\n",
      "Loss: 122.9306262671597\n",
      "Training step:  1965\n",
      "Loss: 102.04971830705249\n",
      "Training step:  1966\n",
      "Loss: 122.92978200716853\n",
      "Training step:  1967\n",
      "Loss: 102.04873463922054\n",
      "Training step:  1968\n",
      "Loss: 122.92893958340747\n",
      "Training step:  1969\n",
      "Loss: 102.04775329343016\n",
      "Training step:  1970\n",
      "Loss: 122.92809899126198\n",
      "Training step:  1971\n",
      "Loss: 102.046774263131\n",
      "Training step:  1972\n",
      "Loss: 122.92726022614832\n",
      "Training step:  1973\n",
      "Loss: 102.04579754183031\n",
      "Training step:  1974\n",
      "Loss: 122.92642328352667\n",
      "Training step:  1975\n",
      "Loss: 102.04482312304654\n",
      "Training step:  1976\n",
      "Loss: 122.9255881588311\n",
      "Training step:  1977\n",
      "Loss: 102.04385100029948\n",
      "Training step:  1978\n",
      "Loss: 122.92475484751736\n",
      "Training step:  1979\n",
      "Loss: 102.04288116715469\n",
      "Training step:  1980\n",
      "Loss: 122.92392334507272\n",
      "Training step:  1981\n",
      "Loss: 102.04191361720025\n",
      "Training step:  1982\n",
      "Loss: 122.92309364699109\n",
      "Training step:  1983\n",
      "Loss: 102.04094834402541\n",
      "Training step:  1984\n",
      "Loss: 122.92226574874799\n",
      "Training step:  1985\n",
      "Loss: 102.03998534124197\n",
      "Training step:  1986\n",
      "Loss: 122.92143964585739\n",
      "Training step:  1987\n",
      "Loss: 102.03902460249489\n",
      "Training step:  1988\n",
      "Loss: 122.92061533385147\n",
      "Training step:  1989\n",
      "Loss: 102.03806612146126\n",
      "Training step:  1990\n",
      "Loss: 122.91979280828004\n",
      "Training step:  1991\n",
      "Loss: 102.03710989181538\n",
      "Training step:  1992\n",
      "Loss: 122.91897206467397\n",
      "Training step:  1993\n",
      "Loss: 102.036155907258\n",
      "Training step:  1994\n",
      "Loss: 122.91815309860246\n",
      "Training step:  1995\n",
      "Loss: 102.03520416152011\n",
      "Training step:  1996\n",
      "Loss: 122.91733590563389\n",
      "Training step:  1997\n",
      "Loss: 102.03425464833438\n",
      "Training step:  1998\n",
      "Loss: 122.91652048134392\n",
      "Training step:  1999\n",
      "Loss: 102.03330736146738\n",
      "Loss_min: tensor(3.6533, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_city_date_path = make_dir('shenzhen','02-10')\n",
    "features=['I', 'cured','dead']\n",
    "I_init = float(data_sz['I'].iloc[0])\n",
    "R_init = float(data_sz['cured'].iloc[0])\n",
    "D_init = float(data_sz['dead'].iloc[0])\n",
    "N = 13026600.\n",
    "S,I,E,R,D = train(data_sz, model_city_date_path, N=N, I_init=I_init, R_init=R_init, D_init=D_init, features=features, max_epoches=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_predict(model_city_date_path, data, N_cur=-1,beta=1e7,gamma_2=1e7,theta=1e7, city_name='深圳',c='confirmed', features=['I','cured','dead'], pred_date_len=5):\n",
    "    I_name,recover_name,dead_name = features\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    I = model.I_tensor_cur\n",
    "    R = model.R_tensor_cur\n",
    "    D = model.D_tensor_cur\n",
    "    I_pred_old = (I.detach().numpy()).astype(np.int)\n",
    "    R_pred_old = (R.detach().numpy()).astype(np.int)\n",
    "    D_pred_old = (D.detach().numpy()).astype(np.int)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    print(confirm_origin)\n",
    "    plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name)\n",
    "\n",
    "\n",
    "    new_confirm = cal_new_confirm(np.array(data[I_name]),np.array(data[recover_name]),np.array(data[dead_name]))\n",
    "    cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    new_confirm_pred = cal_new_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    beta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "    gamma_2 = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "    theta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "    param = model.param_pred(beta,gamma_2,theta)\n",
    "    print(param)\n",
    "    S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(beta=param['beta'],gamma_2=param['gamma_2'],theta=param['theta'], pred_date_len = pred_date_len)\n",
    "    I_pred_new = (I_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    R_pred_new = (R_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    D_pred_new = (D_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    I_pred_total = np.concatenate((I_pred_old,I_pred_new),axis=0)\n",
    "    R_pred_total = np.concatenate((R_pred_old,R_pred_new),axis=0)\n",
    "    D_pred_total = np.concatenate((D_pred_old,D_pred_new),axis=0)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name, pred_date_len=pred_date_len)\n",
    "\n",
    "    new_confirm_pred_total = cal_new_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    new_confirm_pred_total\n",
    "\n",
    "    plot_daily_new(data, new_confirm, new_confirm_pred_total, city=city_name, pred_date_len=pred_date_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_city_date_path = 'models/shenzhen/02-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36  49  63  86 110 170 196 226 269 289 314 334 351 364 368]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beta': -0.011667957698391032, 'gamma_2': 0.02185521739434857, 'theta': 0.0012506750246709815}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model_predict(model_city_date_path, data_sz, city_name='深圳')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>suspected</th>\n",
       "      <th>dead</th>\n",
       "      <th>cured</th>\n",
       "      <th>time</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>618</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1590</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>45</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1905</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>78</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2261</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>85</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2639</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>106</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3215</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>142</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4109</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>174</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>3711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5142</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>227</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6384</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>306</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>5765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8351</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>374</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>7615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10117</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>459</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>9244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11618</td>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>542</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>10598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13603</td>\n",
       "      <td>0</td>\n",
       "      <td>545</td>\n",
       "      <td>747</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>12311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14982</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>877</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>13497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16902</td>\n",
       "      <td>0</td>\n",
       "      <td>681</td>\n",
       "      <td>1045</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>15176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confirmed  suspected  dead  cured       time      I\n",
       "0         258          0     6     25 2020-01-20    227\n",
       "1         363          0     9     28 2020-01-21    326\n",
       "2         425          0    17     28 2020-01-22    380\n",
       "3         495          0    23     31 2020-01-23    441\n",
       "4         572          0    38     32 2020-01-24    502\n",
       "5         618          0    45     40 2020-01-25    533\n",
       "6         698          0    63     42 2020-01-26    593\n",
       "7        1590          0    85     45 2020-01-27   1460\n",
       "8        1905          0   104     78 2020-01-28   1723\n",
       "9        2261          0   129     85 2020-01-29   2047\n",
       "10       2639          0   159    106 2020-01-30   2374\n",
       "11       3215          0   192    142 2020-01-31   2881\n",
       "12       4109          0   224    174 2020-02-01   3711\n",
       "13       5142          0   265    227 2020-02-02   4650\n",
       "14       6384          0   313    306 2020-02-03   5765\n",
       "15       8351          0   362    374 2020-02-04   7615\n",
       "16      10117          0   414    459 2020-02-05   9244\n",
       "17      11618          0   478    542 2020-02-06  10598\n",
       "18      13603          0   545    747 2020-02-07  12311\n",
       "19      14982          0   608    877 2020-02-08  13497\n",
       "20      16902          0   681   1045 2020-02-09  15176"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wh = read_data('./ncov/data/wuhan_截至0209_24时.csv')\n",
    "data_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/wuhan\\02-09\n",
      "(21, 3)\n",
      "21\n",
      "Training step:  0\n",
      "Loss: 1075744.3220813368\n",
      "Training step:  1\n",
      "Loss: 5600076.553611361\n",
      "Training step:  2\n",
      "Loss: 812536.7321220154\n",
      "Training step:  3\n",
      "Loss: 2105007.2196322363\n",
      "Training step:  4\n",
      "Loss: 1081961.9312569764\n",
      "Training step: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SEIR_model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SEIR_cell. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5\n",
      "Loss: 393231.3027475004\n",
      "Training step:  6\n",
      "Loss: 652136.6463882716\n",
      "Training step:  7\n",
      "Loss: 331509.4730027067\n",
      "Training step:  8\n",
      "Loss: 369693.2141843825\n",
      "Training step:  9\n",
      "Loss: 302937.5816170784\n",
      "Training step:  10\n",
      "Loss: 282633.8885012685\n",
      "Training step:  11\n",
      "Loss: 262321.5250830837\n",
      "Training step:  12\n",
      "Loss: 245222.79773570335\n",
      "Training step:  13\n",
      "Loss: 231359.28645861117\n",
      "Training step:  14\n",
      "Loss: 218236.89402041634\n",
      "Training step:  15\n",
      "Loss: 206217.39417449833\n",
      "Training step:  16\n",
      "Loss: 195216.85058802782\n",
      "Training step:  17\n",
      "Loss: 184559.75568020996\n",
      "Training step:  18\n",
      "Loss: 174811.77948031138\n",
      "Training step:  19\n",
      "Loss: 165427.40289190284\n",
      "Training step:  20\n",
      "Loss: 156715.1703875006\n",
      "Training step:  21\n",
      "Loss: 148467.4715854879\n",
      "Training step:  22\n",
      "Loss: 140733.88324505714\n",
      "Training step:  23\n",
      "Loss: 133474.13637594317\n",
      "Training step:  24\n",
      "Loss: 126656.07552166059\n",
      "Training step:  25\n",
      "Loss: 120265.1744470463\n",
      "Training step:  26\n",
      "Loss: 114271.58218457669\n",
      "Training step:  27\n",
      "Loss: 108652.84991879636\n",
      "Training step:  28\n",
      "Loss: 103386.78657920074\n",
      "Training step:  29\n",
      "Loss: 98450.65436707757\n",
      "Training step:  30\n",
      "Loss: 93823.62493940331\n",
      "Training step:  31\n",
      "Loss: 89485.79053741365\n",
      "Training step:  32\n",
      "Loss: 85418.14804132355\n",
      "Training step:  33\n",
      "Loss: 81602.88335312121\n",
      "Training step:  34\n",
      "Loss: 78023.27369240843\n",
      "Training step:  35\n",
      "Loss: 74663.64201911929\n",
      "Training step:  36\n",
      "Loss: 71509.34815344501\n",
      "Training step:  37\n",
      "Loss: 68546.74848236164\n",
      "Training step:  38\n",
      "Loss: 65763.14626883785\n",
      "Training step:  39\n",
      "Loss: 63146.737238105874\n",
      "Training step:  40\n",
      "Loss: 60686.557133337614\n",
      "Training step:  41\n",
      "Loss: 58372.42692214892\n",
      "Training step:  42\n",
      "Loss: 56194.89687924631\n",
      "Training step:  43\n",
      "Loss: 54145.19320950625\n",
      "Training step:  44\n",
      "Loss: 52215.16605720153\n",
      "Training step:  45\n",
      "Loss: 50397.24055298099\n",
      "Training step:  46\n",
      "Loss: 48684.37078989745\n",
      "Training step:  47\n",
      "Loss: 47069.997055464824\n",
      "Training step:  48\n",
      "Loss: 45548.00653808848\n",
      "Training step:  49\n",
      "Loss: 44112.69731302708\n",
      "Training step:  50\n",
      "Loss: 42758.74565814423\n",
      "Training step:  51\n",
      "Loss: 41481.17639388412\n",
      "Training step:  52\n",
      "Loss: 40275.33612595391\n",
      "Training step:  53\n",
      "Loss: 39136.86907421519\n",
      "Training step:  54\n",
      "Loss: 38061.69528962384\n",
      "Training step:  55\n",
      "Loss: 37045.99096366744\n",
      "Training step:  56\n",
      "Loss: 36086.17062600632\n",
      "Training step:  57\n",
      "Loss: 35178.870974918435\n",
      "Training step:  58\n",
      "Loss: 34320.93616395061\n",
      "Training step:  59\n",
      "Loss: 33509.40433993602\n",
      "Training step:  60\n",
      "Loss: 32741.495291110346\n",
      "Training step:  61\n",
      "Loss: 32014.59905756941\n",
      "Training step:  62\n",
      "Loss: 31326.26538498584\n",
      "Training step:  63\n",
      "Loss: 30674.193949087014\n",
      "Training step:  64\n",
      "Loss: 30056.225214069877\n",
      "Training step:  65\n",
      "Loss: 29470.332007617366\n",
      "Training step:  66\n",
      "Loss: 28914.61158587149\n",
      "Training step:  67\n",
      "Loss: 28387.278819527928\n",
      "Training step:  68\n",
      "Loss: 27886.66038652612\n",
      "Training step:  69\n",
      "Loss: 27411.193839509604\n",
      "Training step:  70\n",
      "Loss: 26959.437075192545\n",
      "Training step:  71\n",
      "Loss: 26530.121791422334\n",
      "Training step:  72\n",
      "Loss: 26122.34427094577\n",
      "Training step:  73\n",
      "Loss: 25736.29171613184\n",
      "Training step:  74\n",
      "Loss: 25375.888240850003\n",
      "Training step:  75\n",
      "Loss: 25059.115356643346\n",
      "Training step:  76\n",
      "Loss: 24857.37174589312\n",
      "Training step:  77\n",
      "Loss: 25060.86712040164\n",
      "Training step:  78\n",
      "Loss: 26812.665485047717\n",
      "Training step:  79\n",
      "Loss: 35163.419585241005\n",
      "Training step:  80\n",
      "Loss: 69236.09956761205\n",
      "Training step:  81\n",
      "Loss: 229513.38798059474\n",
      "Training step:  82\n",
      "Loss: 746128.8452397707\n",
      "Training step:  83\n",
      "Loss: 3282390.4489748175\n",
      "Training step:  84\n",
      "Loss: 1446580.6961123415\n",
      "Training step:  85\n",
      "Loss: 2879060.8380318703\n",
      "Training step:  86\n",
      "Loss: 327972.5069514044\n",
      "Training step:  87\n",
      "Loss: 29994.701192406108\n",
      "Training step:  88\n",
      "Loss: 42723.478575797795\n",
      "Training step:  89\n",
      "Loss: 91712.5595814065\n",
      "Training step:  90\n",
      "Loss: 173556.37419437524\n",
      "Training step:  91\n",
      "Loss: 213439.45586984995\n",
      "Training step:  92\n",
      "Loss: 384757.6576822783\n",
      "Training step:  93\n",
      "Loss: 370075.1177231787\n",
      "Training step:  94\n",
      "Loss: 649221.3329463347\n",
      "Training step:  95\n",
      "Loss: 449930.1914353277\n",
      "Training step:  96\n",
      "Loss: 664264.4223703447\n",
      "Training step:  97\n",
      "Loss: 372820.8742849406\n",
      "Training step:  98\n",
      "Loss: 441877.35134206526\n",
      "Training step:  99\n",
      "Loss: 257317.67281179468\n",
      "Training step:  100\n",
      "Loss: 281607.2442188214\n",
      "Training step:  101\n",
      "Loss: 186937.03039480545\n",
      "Training step:  102\n",
      "Loss: 208978.11236278774\n",
      "Training step:  103\n",
      "Loss: 156560.97653511938\n",
      "Training step:  104\n",
      "Loss: 184056.74716964993\n",
      "Training step:  105\n",
      "Loss: 149482.0939248816\n",
      "Training step:  106\n",
      "Loss: 184901.1151119499\n",
      "Training step:  107\n",
      "Loss: 156825.2857778953\n",
      "Training step:  108\n",
      "Loss: 202873.90033913587\n",
      "Training step:  109\n",
      "Loss: 174342.8423387013\n",
      "Training step:  110\n",
      "Loss: 233673.26332265994\n",
      "Training step:  111\n",
      "Loss: 198278.2425155643\n",
      "Training step:  112\n",
      "Loss: 271545.41981130734\n",
      "Training step:  113\n",
      "Loss: 222839.12342132634\n",
      "Training step:  114\n",
      "Loss: 306344.0945515225\n",
      "Training step:  115\n",
      "Loss: 240545.81054198995\n",
      "Training step:  116\n",
      "Loss: 326239.42660902813\n",
      "Training step:  117\n",
      "Loss: 246092.5678830516\n",
      "Training step:  118\n",
      "Loss: 325819.77407108713\n",
      "Training step:  119\n",
      "Loss: 240042.74447714468\n",
      "Training step:  120\n",
      "Loss: 310208.61381418485\n",
      "Training step:  121\n",
      "Loss: 227708.2949206189\n",
      "Training step:  122\n",
      "Loss: 289483.8334460788\n",
      "Training step:  123\n",
      "Loss: 214863.62592502034\n",
      "Training step:  124\n",
      "Loss: 271418.6214658258\n",
      "Training step:  125\n",
      "Loss: 205027.83940913941\n",
      "Training step:  126\n",
      "Loss: 259425.02875641102\n",
      "Training step:  127\n",
      "Loss: 199387.82468335703\n",
      "Training step:  128\n",
      "Loss: 253909.30051034622\n",
      "Training step:  129\n",
      "Loss: 197719.26593588988\n",
      "Training step:  130\n",
      "Loss: 253849.6736237813\n",
      "Training step:  131\n",
      "Loss: 199132.12366989584\n",
      "Training step:  132\n",
      "Loss: 257647.3407154832\n",
      "Training step:  133\n",
      "Loss: 202463.15904999626\n",
      "Training step:  134\n",
      "Loss: 263495.69788971037\n",
      "Training step:  135\n",
      "Loss: 206495.97228749254\n",
      "Training step:  136\n",
      "Loss: 269627.2883337417\n",
      "Training step:  137\n",
      "Loss: 210154.9852435784\n",
      "Training step:  138\n",
      "Loss: 274595.9170412635\n",
      "Training step:  139\n",
      "Loss: 212693.85110908648\n",
      "Training step:  140\n",
      "Loss: 277544.778571019\n",
      "Training step:  141\n",
      "Loss: 213811.41168895594\n",
      "Training step:  142\n",
      "Loss: 278318.41347657144\n",
      "Training step:  143\n",
      "Loss: 213631.64422583353\n",
      "Training step:  144\n",
      "Loss: 277343.20022145775\n",
      "Training step:  145\n",
      "Loss: 212558.5573698034\n",
      "Training step:  146\n",
      "Loss: 275347.25473169424\n",
      "Training step:  147\n",
      "Loss: 211084.80938522267\n",
      "Training step:  148\n",
      "Loss: 273069.80759316596\n",
      "Training step:  149\n",
      "Loss: 209637.0578541567\n",
      "Training step:  150\n",
      "Loss: 271070.73132071533\n",
      "Training step:  151\n",
      "Loss: 208496.26539738796\n",
      "Training step:  152\n",
      "Loss: 269662.8692874608\n",
      "Training step:  153\n",
      "Loss: 207785.7549418406\n",
      "Training step:  154\n",
      "Loss: 268932.09689239005\n",
      "Training step:  155\n",
      "Loss: 207500.22984047997\n",
      "Training step:  156\n",
      "Loss: 268799.37663590023\n",
      "Training step:  157\n",
      "Loss: 207550.83352475357\n",
      "Training step:  158\n",
      "Loss: 269092.39301372215\n",
      "Training step:  159\n",
      "Loss: 207810.40793068332\n",
      "Training step:  160\n",
      "Loss: 269609.54946993256\n",
      "Training step:  161\n",
      "Loss: 208150.7396671033\n",
      "Training step:  162\n",
      "Loss: 270168.438840183\n",
      "Training step:  163\n",
      "Loss: 208468.10184943484\n",
      "Training step:  164\n",
      "Loss: 270635.66132529837\n",
      "Training step:  165\n",
      "Loss: 208696.1497963937\n",
      "Training step:  166\n",
      "Loss: 270938.0661557898\n",
      "Training step:  167\n",
      "Loss: 208807.41523625908\n",
      "Training step:  168\n",
      "Loss: 271058.4620320639\n",
      "Training step:  169\n",
      "Loss: 208806.42450774548\n",
      "Training step:  170\n",
      "Loss: 271021.1639593362\n",
      "Training step:  171\n",
      "Loss: 208718.41491079208\n",
      "Training step:  172\n",
      "Loss: 270873.56317608315\n",
      "Training step:  173\n",
      "Loss: 208577.46302015393\n",
      "Training step:  174\n",
      "Loss: 270669.00580722233\n",
      "Training step:  175\n",
      "Loss: 208416.77739112373\n",
      "Training step:  176\n",
      "Loss: 270454.2517074854\n",
      "Training step:  177\n",
      "Loss: 208262.48534211074\n",
      "Training step:  178\n",
      "Loss: 270262.5930688776\n",
      "Training step:  179\n",
      "Loss: 208130.9863791894\n",
      "Training step:  180\n",
      "Loss: 270112.0492250264\n",
      "Training step:  181\n",
      "Loss: 208029.13997270635\n",
      "Training step:  182\n",
      "Loss: 270007.1736436552\n",
      "Training step:  183\n",
      "Loss: 207956.23124314178\n",
      "Training step:  184\n",
      "Loss: 269942.81018077966\n",
      "Training step:  185\n",
      "Loss: 207906.6915168826\n",
      "Training step:  186\n",
      "Loss: 269908.37024421094\n",
      "Training step:  187\n",
      "Loss: 207872.7817577022\n",
      "Training step:  188\n",
      "Loss: 269891.6315808882\n",
      "Training step:  189\n",
      "Loss: 207846.74444770237\n",
      "Training step:  190\n",
      "Loss: 269881.51529442\n",
      "Training step:  191\n",
      "Loss: 207822.20898682225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  192\n",
      "Loss: 269869.6848178018\n",
      "Training step:  193\n",
      "Loss: 207794.85261776857\n",
      "Training step:  194\n",
      "Loss: 269851.0858345969\n",
      "Training step:  195\n",
      "Loss: 207762.4572582953\n",
      "Training step:  196\n",
      "Loss: 269823.7011564033\n",
      "Training step:  197\n",
      "Loss: 207724.56547398123\n",
      "Training step:  198\n",
      "Loss: 269787.84360532067\n",
      "Training step:  199\n",
      "Loss: 207681.94116254526\n",
      "Training step:  200\n",
      "Loss: 269745.2808657637\n",
      "Training step:  201\n",
      "Loss: 207636.00321897856\n",
      "Training step:  202\n",
      "Loss: 269698.41199073364\n",
      "Training step:  203\n",
      "Loss: 207588.34474815754\n",
      "Training step:  204\n",
      "Loss: 269649.62618346454\n",
      "Training step:  205\n",
      "Loss: 207540.39368659572\n",
      "Training step:  206\n",
      "Loss: 269600.89326247235\n",
      "Training step:  207\n",
      "Loss: 207493.22432039815\n",
      "Training step:  208\n",
      "Loss: 269553.5746965384\n",
      "Training step:  209\n",
      "Loss: 207447.4982305352\n",
      "Training step:  210\n",
      "Loss: 269508.40817181586\n",
      "Training step:  211\n",
      "Loss: 207403.49776900627\n",
      "Training step:  212\n",
      "Loss: 269465.6048638573\n",
      "Training step:  213\n",
      "Loss: 207361.2122933467\n",
      "Training step:  214\n",
      "Loss: 269425.0010928275\n",
      "Training step:  215\n",
      "Loss: 207320.44281357745\n",
      "Training step:  216\n",
      "Loss: 269386.21814490826\n",
      "Training step:  217\n",
      "Loss: 207280.90026187905\n",
      "Training step:  218\n",
      "Loss: 269348.7998510416\n",
      "Training step:  219\n",
      "Loss: 207242.2829599542\n",
      "Training step:  220\n",
      "Loss: 269312.312741867\n",
      "Training step:  221\n",
      "Loss: 207204.32785385626\n",
      "Training step:  222\n",
      "Loss: 269276.40573587397\n",
      "Training step:  223\n",
      "Loss: 207166.83662930285\n",
      "Training step:  224\n",
      "Loss: 269240.8343901798\n",
      "Training step:  225\n",
      "Loss: 207129.68168936943\n",
      "Training step:  226\n",
      "Loss: 269205.4588802179\n",
      "Training step:  227\n",
      "Loss: 207092.79851490978\n",
      "Training step:  228\n",
      "Loss: 269170.2258596\n",
      "Training step:  229\n",
      "Loss: 207056.17076081922\n",
      "Training step:  230\n",
      "Loss: 269135.1432218702\n",
      "Training step:  231\n",
      "Loss: 207019.81325283292\n",
      "Training step:  232\n",
      "Loss: 269100.25455193437\n",
      "Training step:  233\n",
      "Loss: 206983.75643932068\n",
      "Training step:  234\n",
      "Loss: 269065.61752747785\n",
      "Training step:  235\n",
      "Loss: 206948.03425998043\n",
      "Training step:  236\n",
      "Loss: 269031.2882573543\n",
      "Training step:  237\n",
      "Loss: 206912.67608448621\n",
      "Training step:  238\n",
      "Loss: 268997.311813274\n",
      "Training step:  239\n",
      "Loss: 206877.70246039066\n",
      "Training step:  240\n",
      "Loss: 268963.7181057661\n",
      "Training step:  241\n",
      "Loss: 206843.1238929669\n",
      "Training step:  242\n",
      "Loss: 268930.52171881316\n",
      "Training step:  243\n",
      "Loss: 206808.94169001246\n",
      "Training step:  244\n",
      "Loss: 268897.7242140447\n",
      "Training step:  245\n",
      "Loss: 206775.1499468419\n",
      "Training step:  246\n",
      "Loss: 268865.3175968745\n",
      "Training step:  247\n",
      "Loss: 206741.73792317818\n",
      "Training step:  248\n",
      "Loss: 268833.28795852273\n",
      "Training step:  249\n",
      "Loss: 206708.69229112312\n",
      "Training step:  250\n",
      "Loss: 268801.6186617055\n",
      "Training step:  251\n",
      "Loss: 206675.9989558324\n",
      "Training step:  252\n",
      "Loss: 268770.2927557761\n",
      "Training step:  253\n",
      "Loss: 206643.64433394928\n",
      "Training step:  254\n",
      "Loss: 268739.2945493758\n",
      "Training step:  255\n",
      "Loss: 206611.61610314006\n",
      "Training step:  256\n",
      "Loss: 268708.61042661936\n",
      "Training step:  257\n",
      "Loss: 206579.90351308766\n",
      "Training step:  258\n",
      "Loss: 268678.2290763932\n",
      "Training step:  259\n",
      "Loss: 206548.49738014626\n",
      "Training step:  260\n",
      "Loss: 268648.1413274305\n",
      "Training step:  261\n",
      "Loss: 206517.3898881576\n",
      "Training step:  262\n",
      "Loss: 268618.33976609283\n",
      "Training step:  263\n",
      "Loss: 206486.57429930515\n",
      "Training step:  264\n",
      "Loss: 268588.8182771333\n",
      "Training step:  265\n",
      "Loss: 206456.04465148537\n",
      "Training step:  266\n",
      "Loss: 268559.5716040217\n",
      "Training step:  267\n",
      "Loss: 206425.79549071396\n",
      "Training step:  268\n",
      "Loss: 268530.59498452494\n",
      "Training step:  269\n",
      "Loss: 206395.8216626021\n",
      "Training step:  270\n",
      "Loss: 268501.8838835713\n",
      "Training step:  271\n",
      "Loss: 206366.1181686386\n",
      "Training step:  272\n",
      "Loss: 268473.43382287596\n",
      "Training step:  273\n",
      "Loss: 206336.68008152535\n",
      "Training step:  274\n",
      "Loss: 268445.2402925218\n",
      "Training step:  275\n",
      "Loss: 206307.50250708102\n",
      "Training step:  276\n",
      "Loss: 268417.29872362834\n",
      "Training step:  277\n",
      "Loss: 206278.5805789249\n",
      "Training step:  278\n",
      "Loss: 268389.60450121085\n",
      "Training step:  279\n",
      "Loss: 206249.9094726749\n",
      "Training step:  280\n",
      "Loss: 268362.15299817006\n",
      "Training step:  281\n",
      "Loss: 206221.48442894532\n",
      "Training step:  282\n",
      "Loss: 268334.93961661303\n",
      "Training step:  283\n",
      "Loss: 206193.30077751042\n",
      "Training step:  284\n",
      "Loss: 268307.95982669754\n",
      "Training step:  285\n",
      "Loss: 206165.35395813192\n",
      "Training step:  286\n",
      "Loss: 268281.2091983718\n",
      "Training step:  287\n",
      "Loss: 206137.63953578976\n",
      "Training step:  288\n",
      "Loss: 268254.6834234617\n",
      "Training step:  289\n",
      "Loss: 206110.15320961984\n",
      "Training step:  290\n",
      "Loss: 268228.3783282619\n",
      "Training step:  291\n",
      "Loss: 206082.8908161889\n",
      "Training step:  292\n",
      "Loss: 268202.28987803304\n",
      "Training step:  293\n",
      "Loss: 206055.8483283492\n",
      "Training step:  294\n",
      "Loss: 268176.4141758428\n",
      "Training step:  295\n",
      "Loss: 206029.02185116036\n",
      "Training step:  296\n",
      "Loss: 268150.74745733506\n",
      "Training step:  297\n",
      "Loss: 206002.40761581014\n",
      "Training step:  298\n",
      "Loss: 268125.28608327813\n",
      "Training step:  299\n",
      "Loss: 205976.0019727053\n",
      "Training step:  300\n",
      "Loss: 268100.0265313415\n",
      "Training step:  301\n",
      "Loss: 205949.80138455814\n",
      "Training step:  302\n",
      "Loss: 268074.96538804524\n",
      "Training step:  303\n",
      "Loss: 205923.8024198099\n",
      "Training step:  304\n",
      "Loss: 268050.09934147866\n",
      "Training step:  305\n",
      "Loss: 205898.00174674043\n",
      "Training step:  306\n",
      "Loss: 268025.425174869\n",
      "Training step:  307\n",
      "Loss: 205872.3961282497\n",
      "Training step:  308\n",
      "Loss: 268000.93976126105\n",
      "Training step:  309\n",
      "Loss: 205846.9824173768\n",
      "Training step:  310\n",
      "Loss: 267976.64005900454\n",
      "Training step:  311\n",
      "Loss: 205821.7575533308\n",
      "Training step:  312\n",
      "Loss: 267952.5231079807\n",
      "Training step:  313\n",
      "Loss: 205796.7185581\n",
      "Training step:  314\n",
      "Loss: 267928.5860265096\n",
      "Training step:  315\n",
      "Loss: 205771.86253334137\n",
      "Training step:  316\n",
      "Loss: 267904.82600847527\n",
      "Training step:  317\n",
      "Loss: 205747.18665757804\n",
      "Training step:  318\n",
      "Loss: 267881.2403209146\n",
      "Training step:  319\n",
      "Loss: 205722.68818362462\n",
      "Training step:  320\n",
      "Loss: 267857.82630166743\n",
      "Training step:  321\n",
      "Loss: 205698.36443601933\n",
      "Training step:  322\n",
      "Loss: 267834.5813570801\n",
      "Training step:  323\n",
      "Loss: 205674.21280868188\n",
      "Training step:  324\n",
      "Loss: 267811.5029599116\n",
      "Training step:  325\n",
      "Loss: 205650.23076253603\n",
      "Training step:  326\n",
      "Loss: 267788.588647072\n",
      "Training step:  327\n",
      "Loss: 205626.41582325462\n",
      "Training step:  328\n",
      "Loss: 267765.83601765713\n",
      "Training step:  329\n",
      "Loss: 205602.7655791451\n",
      "Training step:  330\n",
      "Loss: 267743.24273097183\n",
      "Training step:  331\n",
      "Loss: 205579.27767897106\n",
      "Training step:  332\n",
      "Loss: 267720.8065043405\n",
      "Training step:  333\n",
      "Loss: 205555.94982983003\n",
      "Training step:  334\n",
      "Loss: 267698.52511118323\n",
      "Training step:  335\n",
      "Loss: 205532.77979513476\n",
      "Training step:  336\n",
      "Loss: 267676.3963790901\n",
      "Training step:  337\n",
      "Loss: 205509.76539275658\n",
      "Training step:  338\n",
      "Loss: 267654.41818808153\n",
      "Training step:  339\n",
      "Loss: 205486.9044931368\n",
      "Training step:  340\n",
      "Loss: 267632.588468776\n",
      "Training step:  341\n",
      "Loss: 205464.19501747625\n",
      "Training step:  342\n",
      "Loss: 267610.9052006554\n",
      "Training step:  343\n",
      "Loss: 205441.63493606544\n",
      "Training step:  344\n",
      "Loss: 267589.3664105487\n",
      "Training step:  345\n",
      "Loss: 205419.22226660507\n",
      "Training step:  346\n",
      "Loss: 267567.970170901\n",
      "Training step:  347\n",
      "Loss: 205396.95507261562\n",
      "Training step:  348\n",
      "Loss: 267546.71459837275\n",
      "Training step:  349\n",
      "Loss: 205374.83146194209\n",
      "Training step:  350\n",
      "Loss: 267525.59785234573\n",
      "Training step:  351\n",
      "Loss: 205352.84958527668\n",
      "Training step:  352\n",
      "Loss: 267504.618133585\n",
      "Training step:  353\n",
      "Loss: 205331.0076348561\n",
      "Training step:  354\n",
      "Loss: 267483.77368295315\n",
      "Training step:  355\n",
      "Loss: 205309.3038429969\n",
      "Training step:  356\n",
      "Loss: 267463.06277998234\n",
      "Training step:  357\n",
      "Loss: 205287.7364808912\n",
      "Training step:  358\n",
      "Loss: 267442.48374181084\n",
      "Training step:  359\n",
      "Loss: 205266.30385732136\n",
      "Training step:  360\n",
      "Loss: 267422.03492183035\n",
      "Training step:  361\n",
      "Loss: 205245.00431744618\n",
      "Training step:  362\n",
      "Loss: 267401.7147086253\n",
      "Training step:  363\n",
      "Loss: 205223.8362417505\n",
      "Training step:  364\n",
      "Loss: 267381.52152502525\n",
      "Training step:  365\n",
      "Loss: 205202.79804490702\n",
      "Training step:  366\n",
      "Loss: 267361.4538268481\n",
      "Training step:  367\n",
      "Loss: 205181.88817468332\n",
      "Training step:  368\n",
      "Loss: 267341.51010199264\n",
      "Training step:  369\n",
      "Loss: 205161.10511094276\n",
      "Training step:  370\n",
      "Loss: 267321.6888693782\n",
      "Training step:  371\n",
      "Loss: 205140.44736463038\n",
      "Training step:  372\n",
      "Loss: 267301.98867804743\n",
      "Training step:  373\n",
      "Loss: 205119.91347689484\n",
      "Training step:  374\n",
      "Loss: 267282.40810635465\n",
      "Training step:  375\n",
      "Loss: 205099.50201815672\n",
      "Training step:  376\n",
      "Loss: 267262.94576095865\n",
      "Training step:  377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 205079.21158719994\n",
      "Training step:  378\n",
      "Loss: 267243.6002760233\n",
      "Training step:  379\n",
      "Loss: 205059.0408103447\n",
      "Training step:  380\n",
      "Loss: 267224.3703124546\n",
      "Training step:  381\n",
      "Loss: 205038.98834070106\n",
      "Training step:  382\n",
      "Loss: 267205.2545571598\n",
      "Training step:  383\n",
      "Loss: 205019.0528573349\n",
      "Training step:  384\n",
      "Loss: 267186.2517222185\n",
      "Training step:  385\n",
      "Loss: 204999.2330645067\n",
      "Training step:  386\n",
      "Loss: 267167.3605441074\n",
      "Training step:  387\n",
      "Loss: 204979.52769085654\n",
      "Training step:  388\n",
      "Loss: 267148.57978295325\n",
      "Training step:  389\n",
      "Loss: 204959.93548881813\n",
      "Training step:  390\n",
      "Loss: 267129.90822207596\n",
      "Training step:  391\n",
      "Loss: 204940.45523399292\n",
      "Training step:  392\n",
      "Loss: 267111.3446672931\n",
      "Training step:  393\n",
      "Loss: 204921.085724412\n",
      "Training step:  394\n",
      "Loss: 267092.8879461876\n",
      "Training step:  395\n",
      "Loss: 204901.82577992024\n",
      "Training step:  396\n",
      "Loss: 267074.5369075457\n",
      "Training step:  397\n",
      "Loss: 204882.67424158854\n",
      "Training step:  398\n",
      "Loss: 267056.2904208129\n",
      "Training step:  399\n",
      "Loss: 204863.62997112292\n",
      "Training step:  400\n",
      "Loss: 267038.14737547276\n",
      "Training step:  401\n",
      "Loss: 204844.6918502762\n",
      "Training step:  402\n",
      "Loss: 267020.10668050224\n",
      "Training step:  403\n",
      "Loss: 204825.85878033124\n",
      "Training step:  404\n",
      "Loss: 267002.1672638892\n",
      "Training step:  405\n",
      "Loss: 204807.12968158835\n",
      "Training step:  406\n",
      "Loss: 266984.3280721779\n",
      "Training step:  407\n",
      "Loss: 204788.50349289205\n",
      "Training step:  408\n",
      "Loss: 266966.5880699222\n",
      "Training step:  409\n",
      "Loss: 204769.97917103136\n",
      "Training step:  410\n",
      "Loss: 266948.94623909076\n",
      "Training step:  411\n",
      "Loss: 204751.55569032772\n",
      "Training step:  412\n",
      "Loss: 266931.40157881036\n",
      "Training step:  413\n",
      "Loss: 204733.232042226\n",
      "Training step:  414\n",
      "Loss: 266913.95310486254\n",
      "Training step:  415\n",
      "Loss: 204715.0072347969\n",
      "Training step:  416\n",
      "Loss: 266896.59984922386\n",
      "Training step:  417\n",
      "Loss: 204696.88029235962\n",
      "Training step:  418\n",
      "Loss: 266879.3408597191\n",
      "Training step:  419\n",
      "Loss: 204678.85025501344\n",
      "Training step:  420\n",
      "Loss: 266862.17519953405\n",
      "Training step:  421\n",
      "Loss: 204660.91617826946\n",
      "Training step:  422\n",
      "Loss: 266845.1019468564\n",
      "Training step:  423\n",
      "Loss: 204643.07713262748\n",
      "Training step:  424\n",
      "Loss: 266828.12019454985\n",
      "Training step:  425\n",
      "Loss: 204625.33220333915\n",
      "Training step:  426\n",
      "Loss: 266811.2290498606\n",
      "Training step:  427\n",
      "Loss: 204607.6804898843\n",
      "Training step:  428\n",
      "Loss: 266794.4276338629\n",
      "Training step:  429\n",
      "Loss: 204590.1211057205\n",
      "Training step:  430\n",
      "Loss: 266777.7150813279\n",
      "Training step:  431\n",
      "Loss: 204572.6531779135\n",
      "Training step:  432\n",
      "Loss: 266761.0905402857\n",
      "Training step:  433\n",
      "Loss: 204555.27584683328\n",
      "Training step:  434\n",
      "Loss: 266744.5531717587\n",
      "Training step:  435\n",
      "Loss: 204537.98826582718\n",
      "Training step:  436\n",
      "Loss: 266728.1021494389\n",
      "Training step:  437\n",
      "Loss: 204520.78960089007\n",
      "Training step:  438\n",
      "Loss: 266711.73665934755\n",
      "Training step:  439\n",
      "Loss: 204503.6790303971\n",
      "Training step:  440\n",
      "Loss: 266695.4558996178\n",
      "Training step:  441\n",
      "Loss: 204486.6557448189\n",
      "Training step:  442\n",
      "Loss: 266679.2590801921\n",
      "Training step:  443\n",
      "Loss: 204469.71894643275\n",
      "Training step:  444\n",
      "Loss: 266663.14542257396\n",
      "Training step:  445\n",
      "Loss: 204452.867849131\n",
      "Training step:  446\n",
      "Loss: 266647.11415965256\n",
      "Training step:  447\n",
      "Loss: 204436.10167807614\n",
      "Training step:  448\n",
      "Loss: 266631.1645352554\n",
      "Training step:  449\n",
      "Loss: 204419.41966942052\n",
      "Training step:  450\n",
      "Loss: 266615.29580396786\n",
      "Training step:  451\n",
      "Loss: 204402.82107012044\n",
      "Training step:  452\n",
      "Loss: 266599.5072309649\n",
      "Training step:  453\n",
      "Loss: 204386.30513770785\n",
      "Training step:  454\n",
      "Loss: 266583.79809177446\n",
      "Training step:  455\n",
      "Loss: 204369.87114006354\n",
      "Training step:  456\n",
      "Loss: 266568.167672039\n",
      "Training step:  457\n",
      "Loss: 204353.51835516206\n",
      "Training step:  458\n",
      "Loss: 266552.61526726827\n",
      "Training step:  459\n",
      "Loss: 204337.24607086828\n",
      "Training step:  460\n",
      "Loss: 266537.1401826663\n",
      "Training step:  461\n",
      "Loss: 204321.05358475563\n",
      "Training step:  462\n",
      "Loss: 266521.74173295044\n",
      "Training step:  463\n",
      "Loss: 204304.9402038834\n",
      "Training step:  464\n",
      "Loss: 266506.4192421046\n",
      "Training step:  465\n",
      "Loss: 204288.9052445532\n",
      "Training step:  466\n",
      "Loss: 266491.1720431187\n",
      "Training step:  467\n",
      "Loss: 204272.94803217836\n",
      "Training step:  468\n",
      "Loss: 266475.9994780136\n",
      "Training step:  469\n",
      "Loss: 204257.06790113132\n",
      "Training step:  470\n",
      "Loss: 266460.9008975196\n",
      "Training step:  471\n",
      "Loss: 204241.26419447007\n",
      "Training step:  472\n",
      "Loss: 266445.87566086644\n",
      "Training step:  473\n",
      "Loss: 204225.5362638135\n",
      "Training step:  474\n",
      "Loss: 266430.92313568364\n",
      "Training step:  475\n",
      "Loss: 204209.88346915145\n",
      "Training step:  476\n",
      "Loss: 266416.04269782855\n",
      "Training step:  477\n",
      "Loss: 204194.30517874478\n",
      "Training step:  478\n",
      "Loss: 266401.2337312479\n",
      "Training step:  479\n",
      "Loss: 204178.8007688776\n",
      "Training step:  480\n",
      "Loss: 266386.4956277614\n",
      "Training step:  481\n",
      "Loss: 204163.3696237606\n",
      "Training step:  482\n",
      "Loss: 266371.8277869499\n",
      "Training step:  483\n",
      "Loss: 204148.01113533517\n",
      "Training step:  484\n",
      "Loss: 266357.2296159668\n",
      "Training step:  485\n",
      "Loss: 204132.7247031488\n",
      "Training step:  486\n",
      "Loss: 266342.70052943897\n",
      "Training step:  487\n",
      "Loss: 204117.50973421775\n",
      "Training step:  488\n",
      "Loss: 266328.2399493319\n",
      "Training step:  489\n",
      "Loss: 204102.36564288725\n",
      "Training step:  490\n",
      "Loss: 266313.8473047593\n",
      "Training step:  491\n",
      "Loss: 204087.29185068342\n",
      "Training step:  492\n",
      "Loss: 266299.52203196584\n",
      "Training step:  493\n",
      "Loss: 204072.28778620742\n",
      "Training step:  494\n",
      "Loss: 266285.26357403415\n",
      "Training step:  495\n",
      "Loss: 204057.35288495914\n",
      "Training step:  496\n",
      "Loss: 266271.0713808874\n",
      "Training step:  497\n",
      "Loss: 204042.48658923001\n",
      "Training step:  498\n",
      "Loss: 266256.9449090532\n",
      "Training step:  499\n",
      "Loss: 204027.68834798824\n",
      "Training step:  500\n",
      "Loss: 266242.88362169743\n",
      "Training step:  501\n",
      "Loss: 204012.95761681863\n",
      "Training step:  502\n",
      "Loss: 266228.88698844536\n",
      "Training step:  503\n",
      "Loss: 203998.29385772918\n",
      "Training step:  504\n",
      "Loss: 266214.9544852613\n",
      "Training step:  505\n",
      "Loss: 203983.6965390839\n",
      "Training step:  506\n",
      "Loss: 266201.08559428836\n",
      "Training step:  507\n",
      "Loss: 203969.16513539755\n",
      "Training step:  508\n",
      "Loss: 266187.27980370796\n",
      "Training step:  509\n",
      "Loss: 203954.69912729404\n",
      "Training step:  510\n",
      "Loss: 266173.5366077501\n",
      "Training step:  511\n",
      "Loss: 203940.29800145965\n",
      "Training step:  512\n",
      "Loss: 266159.8555065691\n",
      "Training step:  513\n",
      "Loss: 203925.96125044132\n",
      "Training step:  514\n",
      "Loss: 266146.2360061104\n",
      "Training step:  515\n",
      "Loss: 203911.6883726614\n",
      "Training step:  516\n",
      "Loss: 266132.6776180797\n",
      "Training step:  517\n",
      "Loss: 203897.47887218793\n",
      "Training step:  518\n",
      "Loss: 266119.1798597057\n",
      "Training step:  519\n",
      "Loss: 203883.3322587481\n",
      "Training step:  520\n",
      "Loss: 266105.74225382647\n",
      "Training step:  521\n",
      "Loss: 203869.24804758417\n",
      "Training step:  522\n",
      "Loss: 266092.36432867683\n",
      "Training step:  523\n",
      "Loss: 203855.22575939787\n",
      "Training step:  524\n",
      "Loss: 266079.04561789596\n",
      "Training step:  525\n",
      "Loss: 203841.2649202082\n",
      "Training step:  526\n",
      "Loss: 266065.7856602551\n",
      "Training step:  527\n",
      "Loss: 203827.36506126495\n",
      "Training step:  528\n",
      "Loss: 266052.5839997184\n",
      "Training step:  529\n",
      "Loss: 203813.52571898187\n",
      "Training step:  530\n",
      "Loss: 266039.44018532906\n",
      "Training step:  531\n",
      "Loss: 203799.74643492996\n",
      "Training step:  532\n",
      "Loss: 266026.35377126734\n",
      "Training step:  533\n",
      "Loss: 203786.02675569177\n",
      "Training step:  534\n",
      "Loss: 266013.32431653596\n",
      "Training step:  535\n",
      "Loss: 203772.36623274846\n",
      "Training step:  536\n",
      "Loss: 266000.35138503124\n",
      "Training step:  537\n",
      "Loss: 203758.76442247775\n",
      "Training step:  538\n",
      "Loss: 265987.43454544526\n",
      "Training step:  539\n",
      "Loss: 203745.2208860052\n",
      "Training step:  540\n",
      "Loss: 265974.5733710818\n",
      "Training step:  541\n",
      "Loss: 203731.73518915536\n",
      "Training step:  542\n",
      "Loss: 265961.7674399379\n",
      "Training step:  543\n",
      "Loss: 203718.30690241844\n",
      "Training step:  544\n",
      "Loss: 265949.01633461093\n",
      "Training step:  545\n",
      "Loss: 203704.93560088874\n",
      "Training step:  546\n",
      "Loss: 265936.3196421916\n",
      "Training step:  547\n",
      "Loss: 203691.620864117\n",
      "Training step:  548\n",
      "Loss: 265923.6769541326\n",
      "Training step:  549\n",
      "Loss: 203678.36227606243\n",
      "Training step:  550\n",
      "Loss: 265911.08786626643\n",
      "Training step:  551\n",
      "Loss: 203665.15942510465\n",
      "Training step:  552\n",
      "Loss: 265898.5519787619\n",
      "Training step:  553\n",
      "Loss: 203652.01190389344\n",
      "Training step:  554\n",
      "Loss: 265886.06889599125\n",
      "Training step:  555\n",
      "Loss: 203638.9193093395\n",
      "Training step:  556\n",
      "Loss: 265873.63822651084\n",
      "Training step:  557\n",
      "Loss: 203625.8812425294\n",
      "Training step:  558\n",
      "Loss: 265861.25958302757\n",
      "Training step:  559\n",
      "Loss: 203612.8973086922\n",
      "Training step:  560\n",
      "Loss: 265848.9325822692\n",
      "Training step:  561\n",
      "Loss: 203599.96711705433\n",
      "Training step:  562\n",
      "Loss: 265836.6568448854\n",
      "Training step:  563\n",
      "Loss: 203587.09028086526\n",
      "Training step:  564\n",
      "Loss: 265824.4319955552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  565\n",
      "Loss: 203574.26641736514\n",
      "Training step:  566\n",
      "Loss: 265812.2576628419\n",
      "Training step:  567\n",
      "Loss: 203561.49514761922\n",
      "Training step:  568\n",
      "Loss: 265800.1334790497\n",
      "Training step:  569\n",
      "Loss: 203548.77609657627\n",
      "Training step:  570\n",
      "Loss: 265788.05908040254\n",
      "Training step:  571\n",
      "Loss: 203536.10889298687\n",
      "Training step:  572\n",
      "Loss: 265776.03410675126\n",
      "Training step:  573\n",
      "Loss: 203523.4931692599\n",
      "Training step:  574\n",
      "Loss: 265764.0582015942\n",
      "Training step:  575\n",
      "Loss: 203510.92856153921\n",
      "Training step:  576\n",
      "Loss: 265752.1310121527\n",
      "Training step:  577\n",
      "Loss: 203498.41470960673\n",
      "Training step:  578\n",
      "Loss: 265740.25218914676\n",
      "Training step:  579\n",
      "Loss: 203485.95125676083\n",
      "Training step:  580\n",
      "Loss: 265728.42138678476\n",
      "Training step:  581\n",
      "Loss: 203473.53784987636\n",
      "Training step:  582\n",
      "Loss: 265716.63826282194\n",
      "Training step:  583\n",
      "Loss: 203461.1741392939\n",
      "Training step:  584\n",
      "Loss: 265704.9024783949\n",
      "Training step:  585\n",
      "Loss: 203448.8597788143\n",
      "Training step:  586\n",
      "Loss: 265693.21369808255\n",
      "Training step:  587\n",
      "Loss: 203436.59442562208\n",
      "Training step:  588\n",
      "Loss: 265681.57158975495\n",
      "Training step:  589\n",
      "Loss: 203424.37774024392\n",
      "Training step:  590\n",
      "Loss: 265669.9758246008\n",
      "Training step:  591\n",
      "Loss: 203412.20938651392\n",
      "Training step:  592\n",
      "Loss: 265658.4260770104\n",
      "Training step:  593\n",
      "Loss: 203400.08903147586\n",
      "Training step:  594\n",
      "Loss: 265646.9220245781\n",
      "Training step:  595\n",
      "Loss: 203388.0163454478\n",
      "Training step:  596\n",
      "Loss: 265635.463348128\n",
      "Training step:  597\n",
      "Loss: 203375.99100192977\n",
      "Training step:  598\n",
      "Loss: 265624.0497316305\n",
      "Training step:  599\n",
      "Loss: 203364.0126775464\n",
      "Training step:  600\n",
      "Loss: 265612.6808620567\n",
      "Training step:  601\n",
      "Loss: 203352.081051993\n",
      "Training step:  602\n",
      "Loss: 265601.356429453\n",
      "Training step:  603\n",
      "Loss: 203340.1958080028\n",
      "Training step:  604\n",
      "Loss: 265590.0761268269\n",
      "Training step:  605\n",
      "Loss: 203328.3566313987\n",
      "Training step:  606\n",
      "Loss: 265578.8396503082\n",
      "Training step:  607\n",
      "Loss: 203316.56321093233\n",
      "Training step:  608\n",
      "Loss: 265567.6466987817\n",
      "Training step:  609\n",
      "Loss: 203304.81523829693\n",
      "Training step:  610\n",
      "Loss: 265556.4969741156\n",
      "Training step:  611\n",
      "Loss: 203293.11240809792\n",
      "Training step:  612\n",
      "Loss: 265545.3901810087\n",
      "Training step:  613\n",
      "Loss: 203281.45441781\n",
      "Training step:  614\n",
      "Loss: 265534.32602699887\n",
      "Training step:  615\n",
      "Loss: 203269.84096774194\n",
      "Training step:  616\n",
      "Loss: 265523.3042223897\n",
      "Training step:  617\n",
      "Loss: 203258.2717609646\n",
      "Training step:  618\n",
      "Loss: 265512.32448018936\n",
      "Training step:  619\n",
      "Loss: 203246.74650334357\n",
      "Training step:  620\n",
      "Loss: 265501.38651620003\n",
      "Training step:  621\n",
      "Loss: 203235.26490347326\n",
      "Training step:  622\n",
      "Loss: 265490.49004889623\n",
      "Training step:  623\n",
      "Loss: 203223.82667265975\n",
      "Training step:  624\n",
      "Loss: 265479.63479941426\n",
      "Training step:  625\n",
      "Loss: 203212.43152486283\n",
      "Training step:  626\n",
      "Loss: 265468.8204914734\n",
      "Training step:  627\n",
      "Loss: 203201.07917663912\n",
      "Training step:  628\n",
      "Loss: 265458.04685137107\n",
      "Training step:  629\n",
      "Loss: 203189.76934719973\n",
      "Training step:  630\n",
      "Loss: 265447.31360804854\n",
      "Training step:  631\n",
      "Loss: 203178.5017582951\n",
      "Training step:  632\n",
      "Loss: 265436.6204928339\n",
      "Training step:  633\n",
      "Loss: 203167.2761341669\n",
      "Training step:  634\n",
      "Loss: 265425.9672396123\n",
      "Training step:  635\n",
      "Loss: 203156.09220165154\n",
      "Training step:  636\n",
      "Loss: 265415.3535847908\n",
      "Training step:  637\n",
      "Loss: 203144.949690008\n",
      "Training step:  638\n",
      "Loss: 265404.7792671166\n",
      "Training step:  639\n",
      "Loss: 203133.84833094437\n",
      "Training step:  640\n",
      "Loss: 265394.24402779725\n",
      "Training step:  641\n",
      "Loss: 203122.78785864037\n",
      "Training step:  642\n",
      "Loss: 265383.74761047476\n",
      "Training step:  643\n",
      "Loss: 203111.76800962907\n",
      "Training step:  644\n",
      "Loss: 265373.2897610233\n",
      "Training step:  645\n",
      "Loss: 203100.78852277115\n",
      "Training step:  646\n",
      "Loss: 265362.87022766896\n",
      "Training step:  647\n",
      "Loss: 203089.84913933525\n",
      "Training step:  648\n",
      "Loss: 265352.48876102595\n",
      "Training step:  649\n",
      "Loss: 203078.9496028732\n",
      "Training step:  650\n",
      "Loss: 265342.14511388354\n",
      "Training step:  651\n",
      "Loss: 203068.08965919845\n",
      "Training step:  652\n",
      "Loss: 265331.8390412776\n",
      "Training step:  653\n",
      "Loss: 203057.2690563864\n",
      "Training step:  654\n",
      "Loss: 265321.57030048396\n",
      "Training step:  655\n",
      "Loss: 203046.4875447621\n",
      "Training step:  656\n",
      "Loss: 265311.33865096496\n",
      "Training step:  657\n",
      "Loss: 203035.74487683145\n",
      "Training step:  658\n",
      "Loss: 265301.14385431807\n",
      "Training step:  659\n",
      "Loss: 203025.04080730685\n",
      "Training step:  660\n",
      "Loss: 265290.9856743735\n",
      "Training step:  661\n",
      "Loss: 203014.37509307853\n",
      "Training step:  662\n",
      "Loss: 265280.86387702485\n",
      "Training step:  663\n",
      "Loss: 203003.7474931143\n",
      "Training step:  664\n",
      "Loss: 265270.7782302049\n",
      "Training step:  665\n",
      "Loss: 202993.15776850478\n",
      "Training step:  666\n",
      "Loss: 265260.7285039675\n",
      "Training step:  667\n",
      "Loss: 202982.60568243268\n",
      "Training step:  668\n",
      "Loss: 265250.7144704067\n",
      "Training step:  669\n",
      "Loss: 202972.09100014035\n",
      "Training step:  670\n",
      "Loss: 265240.73590360995\n",
      "Training step:  671\n",
      "Loss: 202961.61348890842\n",
      "Training step:  672\n",
      "Loss: 265230.7925797212\n",
      "Training step:  673\n",
      "Loss: 202951.17291802843\n",
      "Training step:  674\n",
      "Loss: 265220.88427680195\n",
      "Training step:  675\n",
      "Loss: 202940.76905881512\n",
      "Training step:  676\n",
      "Loss: 265211.0107749566\n",
      "Training step:  677\n",
      "Loss: 202930.4016845323\n",
      "Training step:  678\n",
      "Loss: 265201.17185611965\n",
      "Training step:  679\n",
      "Loss: 202920.07057034422\n",
      "Training step:  680\n",
      "Loss: 265191.3673041047\n",
      "Training step:  681\n",
      "Loss: 202909.77549339685\n",
      "Training step:  682\n",
      "Loss: 265181.59690477897\n",
      "Training step:  683\n",
      "Loss: 202899.5162327814\n",
      "Training step:  684\n",
      "Loss: 265171.8604457924\n",
      "Training step:  685\n",
      "Loss: 202889.2925694085\n",
      "Training step:  686\n",
      "Loss: 265162.1577166156\n",
      "Training step:  687\n",
      "Loss: 202879.10428606928\n",
      "Training step:  688\n",
      "Loss: 265152.48850855546\n",
      "Training step:  689\n",
      "Loss: 202868.95116741225\n",
      "Training step:  690\n",
      "Loss: 265142.8526147807\n",
      "Training step:  691\n",
      "Loss: 202858.83299992327\n",
      "Training step:  692\n",
      "Loss: 265133.24983020837\n",
      "Training step:  693\n",
      "Loss: 202848.74957186804\n",
      "Training step:  694\n",
      "Loss: 265123.6799515127\n",
      "Training step:  695\n",
      "Loss: 202838.700673315\n",
      "Training step:  696\n",
      "Loss: 265114.142777152\n",
      "Training step:  697\n",
      "Loss: 202828.68609610447\n",
      "Training step:  698\n",
      "Loss: 265104.63810731395\n",
      "Training step:  699\n",
      "Loss: 202818.70563382507\n",
      "Training step:  700\n",
      "Loss: 265095.16574388015\n",
      "Training step:  701\n",
      "Loss: 202808.75908178894\n",
      "Training step:  702\n",
      "Loss: 265085.7254904317\n",
      "Training step:  703\n",
      "Loss: 202798.84623701038\n",
      "Training step:  704\n",
      "Loss: 265076.3171521791\n",
      "Training step:  705\n",
      "Loss: 202788.96689817915\n",
      "Training step:  706\n",
      "Loss: 265066.9405360368\n",
      "Training step:  707\n",
      "Loss: 202779.1208657267\n",
      "Training step:  708\n",
      "Loss: 265057.5954506032\n",
      "Training step:  709\n",
      "Loss: 202769.30794170641\n",
      "Training step:  710\n",
      "Loss: 265048.2817060384\n",
      "Training step:  711\n",
      "Loss: 202759.52792980714\n",
      "Training step:  712\n",
      "Loss: 265038.9991141062\n",
      "Training step:  713\n",
      "Loss: 202749.78063533697\n",
      "Training step:  714\n",
      "Loss: 265029.74748816906\n",
      "Training step:  715\n",
      "Loss: 202740.06586522443\n",
      "Training step:  716\n",
      "Loss: 265020.5266431833\n",
      "Training step:  717\n",
      "Loss: 202730.38342802643\n",
      "Training step:  718\n",
      "Loss: 265011.3363957216\n",
      "Training step:  719\n",
      "Loss: 202720.73313384375\n",
      "Training step:  720\n",
      "Loss: 265002.176563766\n",
      "Training step:  721\n",
      "Loss: 202711.1147942684\n",
      "Training step:  722\n",
      "Loss: 264993.0469668043\n",
      "Training step:  723\n",
      "Loss: 202701.52822252063\n",
      "Training step:  724\n",
      "Loss: 264983.94742600946\n",
      "Training step:  725\n",
      "Loss: 202691.97323334633\n",
      "Training step:  726\n",
      "Loss: 264974.87776390376\n",
      "Training step:  727\n",
      "Loss: 202682.44964294642\n",
      "Training step:  728\n",
      "Loss: 264965.83780450403\n",
      "Training step:  729\n",
      "Loss: 202672.95726904293\n",
      "Training step:  730\n",
      "Loss: 264956.8273733001\n",
      "Training step:  731\n",
      "Loss: 202663.49593084844\n",
      "Training step:  732\n",
      "Loss: 264947.8462972356\n",
      "Training step:  733\n",
      "Loss: 202654.06544902912\n",
      "Training step:  734\n",
      "Loss: 264938.89440469345\n",
      "Training step:  735\n",
      "Loss: 202644.66564570513\n",
      "Training step:  736\n",
      "Loss: 264929.97152544017\n",
      "Training step:  737\n",
      "Loss: 202635.29634445798\n",
      "Training step:  738\n",
      "Loss: 264921.0774907335\n",
      "Training step:  739\n",
      "Loss: 202625.95737025677\n",
      "Training step:  740\n",
      "Loss: 264912.21213306976\n",
      "Training step:  741\n",
      "Loss: 202616.6485494362\n",
      "Training step:  742\n",
      "Loss: 264903.37528634345\n",
      "Training step:  743\n",
      "Loss: 202607.36970977014\n",
      "Training step:  744\n",
      "Loss: 264894.56678591116\n",
      "Training step:  745\n",
      "Loss: 202598.1206804424\n",
      "Training step:  746\n",
      "Loss: 264885.78646841866\n",
      "Training step:  747\n",
      "Loss: 202588.90129196574\n",
      "Training step:  748\n",
      "Loss: 264877.03417186794\n",
      "Training step:  749\n",
      "Loss: 202579.71137621521\n",
      "Training step:  750\n",
      "Loss: 264868.30973552336\n",
      "Training step:  751\n",
      "Loss: 202570.55076637308\n",
      "Training step:  752\n",
      "Loss: 264859.6129999894\n",
      "Training step:  753\n",
      "Loss: 202561.41929697944\n",
      "Training step:  754\n",
      "Loss: 264850.94380713935\n",
      "Training step:  755\n",
      "Loss: 202552.31680385664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  756\n",
      "Loss: 264842.3020001342\n",
      "Training step:  757\n",
      "Loss: 202543.24312415693\n",
      "Training step:  758\n",
      "Loss: 264833.6874234544\n",
      "Training step:  759\n",
      "Loss: 202534.19809634337\n",
      "Training step:  760\n",
      "Loss: 264825.0999227934\n",
      "Training step:  761\n",
      "Loss: 202525.18156003277\n",
      "Training step:  762\n",
      "Loss: 264816.53934493946\n",
      "Training step:  763\n",
      "Loss: 202516.19335620393\n",
      "Training step:  764\n",
      "Loss: 264808.00553816085\n",
      "Training step:  765\n",
      "Loss: 202507.23332707034\n",
      "Training step:  766\n",
      "Loss: 264799.4983517747\n",
      "Training step:  767\n",
      "Loss: 202498.30131606394\n",
      "Training step:  768\n",
      "Loss: 264791.0176363644\n",
      "Training step:  769\n",
      "Loss: 202489.39716784365\n",
      "Training step:  770\n",
      "Loss: 264782.56324367196\n",
      "Training step:  771\n",
      "Loss: 202480.52072828994\n",
      "Training step:  772\n",
      "Loss: 264774.1350266757\n",
      "Training step:  773\n",
      "Loss: 202471.67184448658\n",
      "Training step:  774\n",
      "Loss: 264765.7328394556\n",
      "Training step:  775\n",
      "Loss: 202462.85036465438\n",
      "Training step:  776\n",
      "Loss: 264757.35653720645\n",
      "Training step:  777\n",
      "Loss: 202454.05613822213\n",
      "Training step:  778\n",
      "Loss: 264749.0059763762\n",
      "Training step:  779\n",
      "Loss: 202445.28901581507\n",
      "Training step:  780\n",
      "Loss: 264740.6810144984\n",
      "Training step:  781\n",
      "Loss: 202436.548849181\n",
      "Training step:  782\n",
      "Loss: 264732.3815102432\n",
      "Training step:  783\n",
      "Loss: 202427.83549122344\n",
      "Training step:  784\n",
      "Loss: 264724.10732337827\n",
      "Training step:  785\n",
      "Loss: 202419.14879598402\n",
      "Training step:  786\n",
      "Loss: 264715.8583147891\n",
      "Training step:  787\n",
      "Loss: 202410.4886185673\n",
      "Training step:  788\n",
      "Loss: 264707.63434633205\n",
      "Training step:  789\n",
      "Loss: 202401.85481523254\n",
      "Training step:  790\n",
      "Loss: 264699.43528111716\n",
      "Training step:  791\n",
      "Loss: 202393.2472433651\n",
      "Training step:  792\n",
      "Loss: 264691.26098325464\n",
      "Training step:  793\n",
      "Loss: 202384.6657614202\n",
      "Training step:  794\n",
      "Loss: 264683.1113179082\n",
      "Training step:  795\n",
      "Loss: 202376.1102288896\n",
      "Training step:  796\n",
      "Loss: 264674.98615123157\n",
      "Training step:  797\n",
      "Loss: 202367.58050639357\n",
      "Training step:  798\n",
      "Loss: 264666.885350548\n",
      "Training step:  799\n",
      "Loss: 202359.07645558397\n",
      "Training step:  800\n",
      "Loss: 264658.8087840915\n",
      "Training step:  801\n",
      "Loss: 202350.59793915282\n",
      "Training step:  802\n",
      "Loss: 264650.7563211512\n",
      "Training step:  803\n",
      "Loss: 202342.14482083358\n",
      "Training step:  804\n",
      "Loss: 264642.7278320096\n",
      "Training step:  805\n",
      "Loss: 202333.7169653789\n",
      "Training step:  806\n",
      "Loss: 264634.72318796616\n",
      "Training step:  807\n",
      "Loss: 202325.31423860695\n",
      "Training step:  808\n",
      "Loss: 264626.74226135033\n",
      "Training step:  809\n",
      "Loss: 202316.9365073117\n",
      "Training step:  810\n",
      "Loss: 264618.78492540313\n",
      "Training step:  811\n",
      "Loss: 202308.58363928014\n",
      "Training step:  812\n",
      "Loss: 264610.8510543552\n",
      "Training step:  813\n",
      "Loss: 202300.25550328367\n",
      "Training step:  814\n",
      "Loss: 264602.9405233618\n",
      "Training step:  815\n",
      "Loss: 202291.951969076\n",
      "Training step:  816\n",
      "Loss: 264595.05320856837\n",
      "Training step:  817\n",
      "Loss: 202283.67290740652\n",
      "Training step:  818\n",
      "Loss: 264587.1889870917\n",
      "Training step:  819\n",
      "Loss: 202275.41819000576\n",
      "Training step:  820\n",
      "Loss: 264579.34773698833\n",
      "Training step:  821\n",
      "Loss: 202267.18768951797\n",
      "Training step:  822\n",
      "Loss: 264571.52933714486\n",
      "Training step:  823\n",
      "Loss: 202258.98127952247\n",
      "Training step:  824\n",
      "Loss: 264563.73366745\n",
      "Training step:  825\n",
      "Loss: 202250.79883458777\n",
      "Training step:  826\n",
      "Loss: 264555.96060864814\n",
      "Training step:  827\n",
      "Loss: 202242.64023012537\n",
      "Training step:  828\n",
      "Loss: 264548.2100423628\n",
      "Training step:  829\n",
      "Loss: 202234.5053425323\n",
      "Training step:  830\n",
      "Loss: 264540.4818511742\n",
      "Training step:  831\n",
      "Loss: 202226.39404912177\n",
      "Training step:  832\n",
      "Loss: 264532.77591855155\n",
      "Training step:  833\n",
      "Loss: 202218.3062280944\n",
      "Training step:  834\n",
      "Loss: 264525.092128784\n",
      "Training step:  835\n",
      "Loss: 202210.24175853608\n",
      "Training step:  836\n",
      "Loss: 264517.43036706303\n",
      "Training step:  837\n",
      "Loss: 202202.20052044123\n",
      "Training step:  838\n",
      "Loss: 264509.7905194438\n",
      "Training step:  839\n",
      "Loss: 202194.182394672\n",
      "Training step:  840\n",
      "Loss: 264502.17247279425\n",
      "Training step:  841\n",
      "Loss: 202186.18726293533\n",
      "Training step:  842\n",
      "Loss: 264494.5761148053\n",
      "Training step:  843\n",
      "Loss: 202178.21500778155\n",
      "Training step:  844\n",
      "Loss: 264487.0013339994\n",
      "Training step:  845\n",
      "Loss: 202170.26551269516\n",
      "Training step:  846\n",
      "Loss: 264479.4480198217\n",
      "Training step:  847\n",
      "Loss: 202162.338661921\n",
      "Training step:  848\n",
      "Loss: 264471.916062375\n",
      "Training step:  849\n",
      "Loss: 202154.4343406011\n",
      "Training step:  850\n",
      "Loss: 264464.4053527838\n",
      "Training step:  851\n",
      "Loss: 202146.5524347471\n",
      "Training step:  852\n",
      "Loss: 264456.91578286386\n",
      "Training step:  853\n",
      "Loss: 202138.69283110992\n",
      "Training step:  854\n",
      "Loss: 264449.44724519394\n",
      "Training step:  855\n",
      "Loss: 202130.85541728465\n",
      "Training step:  856\n",
      "Loss: 264441.9996331509\n",
      "Training step:  857\n",
      "Loss: 202123.04008163352\n",
      "Training step:  858\n",
      "Loss: 264434.5728408531\n",
      "Training step:  859\n",
      "Loss: 202115.24671337887\n",
      "Training step:  860\n",
      "Loss: 264427.1667633082\n",
      "Training step:  861\n",
      "Loss: 202107.4752025227\n",
      "Training step:  862\n",
      "Loss: 264419.78129622363\n",
      "Training step:  863\n",
      "Loss: 202099.72543988473\n",
      "Training step:  864\n",
      "Loss: 264412.4163361288\n",
      "Training step:  865\n",
      "Loss: 202091.9973170146\n",
      "Training step:  866\n",
      "Loss: 264405.07178019505\n",
      "Training step:  867\n",
      "Loss: 202084.29072624046\n",
      "Training step:  868\n",
      "Loss: 264397.7475263978\n",
      "Training step:  869\n",
      "Loss: 202076.60556067945\n",
      "Training step:  870\n",
      "Loss: 264390.4434734821\n",
      "Training step:  871\n",
      "Loss: 202068.94171419865\n",
      "Training step:  872\n",
      "Loss: 264383.15952086187\n",
      "Training step:  873\n",
      "Loss: 202061.29908139133\n",
      "Training step:  874\n",
      "Loss: 264375.89556869114\n",
      "Training step:  875\n",
      "Loss: 202053.6775576443\n",
      "Training step:  876\n",
      "Loss: 264368.65151793306\n",
      "Training step:  877\n",
      "Loss: 202046.07703909389\n",
      "Training step:  878\n",
      "Loss: 264361.42727017944\n",
      "Training step:  879\n",
      "Loss: 202038.49742255342\n",
      "Training step:  880\n",
      "Loss: 264354.2227277442\n",
      "Training step:  881\n",
      "Loss: 202030.93860559684\n",
      "Training step:  882\n",
      "Loss: 264347.03779362363\n",
      "Training step:  883\n",
      "Loss: 202023.40048648915\n",
      "Training step:  884\n",
      "Loss: 264339.87237149064\n",
      "Training step:  885\n",
      "Loss: 202015.88296419443\n",
      "Training step:  886\n",
      "Loss: 264332.72636570764\n",
      "Training step:  887\n",
      "Loss: 202008.38593844706\n",
      "Training step:  888\n",
      "Loss: 264325.5996814043\n",
      "Training step:  889\n",
      "Loss: 202000.90930965202\n",
      "Training step:  890\n",
      "Loss: 264318.49222431466\n",
      "Training step:  891\n",
      "Loss: 201993.45297892237\n",
      "Training step:  892\n",
      "Loss: 264311.4039008988\n",
      "Training step:  893\n",
      "Loss: 201986.01684806994\n",
      "Training step:  894\n",
      "Loss: 264304.3346182372\n",
      "Training step:  895\n",
      "Loss: 201978.60081954338\n",
      "Training step:  896\n",
      "Loss: 264297.2842840329\n",
      "Training step:  897\n",
      "Loss: 201971.20479648237\n",
      "Training step:  898\n",
      "Loss: 264290.2528066548\n",
      "Training step:  899\n",
      "Loss: 201963.82868269677\n",
      "Training step:  900\n",
      "Loss: 264283.24009515584\n",
      "Training step:  901\n",
      "Loss: 201956.47238268296\n",
      "Training step:  902\n",
      "Loss: 264276.246059192\n",
      "Training step:  903\n",
      "Loss: 201949.13580159185\n",
      "Training step:  904\n",
      "Loss: 264269.27060912905\n",
      "Training step:  905\n",
      "Loss: 201941.81884523257\n",
      "Training step:  906\n",
      "Loss: 264262.31365587126\n",
      "Training step:  907\n",
      "Loss: 201934.5214200391\n",
      "Training step:  908\n",
      "Loss: 264255.37511096796\n",
      "Training step:  909\n",
      "Loss: 201927.2434330945\n",
      "Training step:  910\n",
      "Loss: 264248.4548866212\n",
      "Training step:  911\n",
      "Loss: 201919.98479214686\n",
      "Training step:  912\n",
      "Loss: 264241.552895607\n",
      "Training step:  913\n",
      "Loss: 201912.74540550812\n",
      "Training step:  914\n",
      "Loss: 264234.66905125376\n",
      "Training step:  915\n",
      "Loss: 201905.5251821679\n",
      "Training step:  916\n",
      "Loss: 264227.8032676426\n",
      "Training step:  917\n",
      "Loss: 201898.32403177736\n",
      "Training step:  918\n",
      "Loss: 264220.95545937604\n",
      "Training step:  919\n",
      "Loss: 201891.14186453546\n",
      "Training step:  920\n",
      "Loss: 264214.1255416222\n",
      "Training step:  921\n",
      "Loss: 201883.97859127173\n",
      "Training step:  922\n",
      "Loss: 264207.31343014474\n",
      "Training step:  923\n",
      "Loss: 201876.83412341622\n",
      "Training step:  924\n",
      "Loss: 264200.5190412963\n",
      "Training step:  925\n",
      "Loss: 201869.70837299517\n",
      "Training step:  926\n",
      "Loss: 264193.74229199736\n",
      "Training step:  927\n",
      "Loss: 201862.60125266132\n",
      "Training step:  928\n",
      "Loss: 264186.98309979856\n",
      "Training step:  929\n",
      "Loss: 201855.51267562553\n",
      "Training step:  930\n",
      "Loss: 264180.2413826861\n",
      "Training step:  931\n",
      "Loss: 201848.4425556408\n",
      "Training step:  932\n",
      "Loss: 264173.5170592544\n",
      "Training step:  933\n",
      "Loss: 201841.39080709047\n",
      "Training step:  934\n",
      "Loss: 264166.8100486988\n",
      "Training step:  935\n",
      "Loss: 201834.3573449603\n",
      "Training step:  936\n",
      "Loss: 264160.120270804\n",
      "Training step:  937\n",
      "Loss: 201827.34208478784\n",
      "Training step:  938\n",
      "Loss: 264153.4476458482\n",
      "Training step:  939\n",
      "Loss: 201820.34494267084\n",
      "Training step:  940\n",
      "Loss: 264146.7920946721\n",
      "Training step:  941\n",
      "Loss: 201813.36583527402\n",
      "Training step:  942\n",
      "Loss: 264140.153538621\n",
      "Training step:  943\n",
      "Loss: 201806.40467976715\n",
      "Training step:  944\n",
      "Loss: 264133.531899533\n",
      "Training step:  945\n",
      "Loss: 201799.4613939105\n",
      "Training step:  946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 264126.92709985183\n",
      "Training step:  947\n",
      "Loss: 201792.53589600633\n",
      "Training step:  948\n",
      "Loss: 264120.3390625014\n",
      "Training step:  949\n",
      "Loss: 201785.62810489515\n",
      "Training step:  950\n",
      "Loss: 264113.76771091623\n",
      "Training step:  951\n",
      "Loss: 201778.7379399373\n",
      "Training step:  952\n",
      "Loss: 264107.2129690841\n",
      "Training step:  953\n",
      "Loss: 201771.86532108803\n",
      "Training step:  954\n",
      "Loss: 264100.67476152856\n",
      "Training step:  955\n",
      "Loss: 201765.0101687831\n",
      "Training step:  956\n",
      "Loss: 264094.1530132096\n",
      "Training step:  957\n",
      "Loss: 201758.17240396712\n",
      "Training step:  958\n",
      "Loss: 264087.6476495863\n",
      "Training step:  959\n",
      "Loss: 201751.35194813053\n",
      "Training step:  960\n",
      "Loss: 264081.1585966877\n",
      "Training step:  961\n",
      "Loss: 201744.54872330095\n",
      "Training step:  962\n",
      "Loss: 264074.6857810127\n",
      "Training step:  963\n",
      "Loss: 201737.76265197803\n",
      "Training step:  964\n",
      "Loss: 264068.22912948695\n",
      "Training step:  965\n",
      "Loss: 201730.9936571549\n",
      "Training step:  966\n",
      "Loss: 264061.7885695432\n",
      "Training step:  967\n",
      "Loss: 201724.24166233718\n",
      "Training step:  968\n",
      "Loss: 264055.36402909347\n",
      "Training step:  969\n",
      "Loss: 201717.5065915467\n",
      "Training step:  970\n",
      "Loss: 264048.9554365614\n",
      "Training step:  971\n",
      "Loss: 201710.7883693012\n",
      "Training step:  972\n",
      "Loss: 264042.56272085186\n",
      "Training step:  973\n",
      "Loss: 201704.08692062405\n",
      "Training step:  974\n",
      "Loss: 264036.1858113253\n",
      "Training step:  975\n",
      "Loss: 201697.40217098704\n",
      "Training step:  976\n",
      "Loss: 264029.82463776885\n",
      "Training step:  977\n",
      "Loss: 201690.73404635108\n",
      "Training step:  978\n",
      "Loss: 264023.47913045797\n",
      "Training step:  979\n",
      "Loss: 201684.08247316704\n",
      "Training step:  980\n",
      "Loss: 264017.1492201116\n",
      "Training step:  981\n",
      "Loss: 201677.44737833802\n",
      "Training step:  982\n",
      "Loss: 264010.8348378948\n",
      "Training step:  983\n",
      "Loss: 201670.82868927147\n",
      "Training step:  984\n",
      "Loss: 264004.5359155025\n",
      "Training step:  985\n",
      "Loss: 201664.2263338343\n",
      "Training step:  986\n",
      "Loss: 263998.25238497375\n",
      "Training step:  987\n",
      "Loss: 201657.64024034163\n",
      "Training step:  988\n",
      "Loss: 263991.984178844\n",
      "Training step:  989\n",
      "Loss: 201651.07033755357\n",
      "Training step:  990\n",
      "Loss: 263985.73123003775\n",
      "Training step:  991\n",
      "Loss: 201644.51655472332\n",
      "Training step:  992\n",
      "Loss: 263979.4934720047\n",
      "Training step:  993\n",
      "Loss: 201637.97882154447\n",
      "Training step:  994\n",
      "Loss: 263973.27083853644\n",
      "Training step:  995\n",
      "Loss: 201631.45706812368\n",
      "Training step:  996\n",
      "Loss: 263967.063263857\n",
      "Training step:  997\n",
      "Loss: 201624.95122502567\n",
      "Training step:  998\n",
      "Loss: 263960.87068263366\n",
      "Training step:  999\n",
      "Loss: 201618.46122326862\n",
      "Training step:  1000\n",
      "Loss: 263954.69302993966\n",
      "Training step:  1001\n",
      "Loss: 201611.98699427748\n",
      "Training step:  1002\n",
      "Loss: 263948.53024127136\n",
      "Training step:  1003\n",
      "Loss: 201605.5284699671\n",
      "Training step:  1004\n",
      "Loss: 263942.38225261035\n",
      "Training step:  1005\n",
      "Loss: 201599.08558267498\n",
      "Training step:  1006\n",
      "Loss: 263936.2490002968\n",
      "Training step:  1007\n",
      "Loss: 201592.6582651338\n",
      "Training step:  1008\n",
      "Loss: 263930.1304210341\n",
      "Training step:  1009\n",
      "Loss: 201586.24645048185\n",
      "Training step:  1010\n",
      "Loss: 263924.0264519519\n",
      "Training step:  1011\n",
      "Loss: 201579.8500723213\n",
      "Training step:  1012\n",
      "Loss: 263917.93703062116\n",
      "Training step:  1013\n",
      "Loss: 201573.4690646539\n",
      "Training step:  1014\n",
      "Loss: 263911.8620949681\n",
      "Training step:  1015\n",
      "Loss: 201567.10336188742\n",
      "Training step:  1016\n",
      "Loss: 263905.80158331926\n",
      "Training step:  1017\n",
      "Loss: 201560.75289883587\n",
      "Training step:  1018\n",
      "Loss: 263899.7554343632\n",
      "Training step:  1019\n",
      "Loss: 201554.41761070373\n",
      "Training step:  1020\n",
      "Loss: 263893.72358721367\n",
      "Training step:  1021\n",
      "Loss: 201548.0974331708\n",
      "Training step:  1022\n",
      "Loss: 263887.7059814355\n",
      "Training step:  1023\n",
      "Loss: 201541.79230226652\n",
      "Training step:  1024\n",
      "Loss: 263881.7025568514\n",
      "Training step:  1025\n",
      "Loss: 201535.5021543912\n",
      "Training step:  1026\n",
      "Loss: 263875.7132536874\n",
      "Training step:  1027\n",
      "Loss: 201529.22692635763\n",
      "Training step:  1028\n",
      "Loss: 263869.7380125758\n",
      "Training step:  1029\n",
      "Loss: 201522.9665554126\n",
      "Training step:  1030\n",
      "Loss: 263863.7767745663\n",
      "Training step:  1031\n",
      "Loss: 201516.72097913816\n",
      "Training step:  1032\n",
      "Loss: 263857.829480957\n",
      "Training step:  1033\n",
      "Loss: 201510.4901355056\n",
      "Training step:  1034\n",
      "Loss: 263851.8960734763\n",
      "Training step:  1035\n",
      "Loss: 201504.27396284268\n",
      "Training step:  1036\n",
      "Loss: 263845.97649416985\n",
      "Training step:  1037\n",
      "Loss: 201498.07239992567\n",
      "Training step:  1038\n",
      "Loss: 263840.07068558136\n",
      "Training step:  1039\n",
      "Loss: 201491.8853859055\n",
      "Training step:  1040\n",
      "Loss: 263834.17859052785\n",
      "Training step:  1041\n",
      "Loss: 201485.71286025867\n",
      "Training step:  1042\n",
      "Loss: 263828.3001521461\n",
      "Training step:  1043\n",
      "Loss: 201479.55476283035\n",
      "Training step:  1044\n",
      "Loss: 263822.43531392596\n",
      "Training step:  1045\n",
      "Loss: 201473.41103382912\n",
      "Training step:  1046\n",
      "Loss: 263816.5840197275\n",
      "Training step:  1047\n",
      "Loss: 201467.28161385216\n",
      "Training step:  1048\n",
      "Loss: 263810.7462137446\n",
      "Training step:  1049\n",
      "Loss: 201461.16644384485\n",
      "Training step:  1050\n",
      "Loss: 263804.92184056423\n",
      "Training step:  1051\n",
      "Loss: 201455.0654651342\n",
      "Training step:  1052\n",
      "Loss: 263799.1108450692\n",
      "Training step:  1053\n",
      "Loss: 201448.97861936624\n",
      "Training step:  1054\n",
      "Loss: 263793.313172464\n",
      "Training step:  1055\n",
      "Loss: 201442.9058485482\n",
      "Training step:  1056\n",
      "Loss: 263787.52876831114\n",
      "Training step:  1057\n",
      "Loss: 201436.84709504142\n",
      "Training step:  1058\n",
      "Loss: 263781.7575784963\n",
      "Training step:  1059\n",
      "Loss: 201430.80230156487\n",
      "Training step:  1060\n",
      "Loss: 263775.9995492631\n",
      "Training step:  1061\n",
      "Loss: 201424.77141117054\n",
      "Training step:  1062\n",
      "Loss: 263770.25462713453\n",
      "Training step:  1063\n",
      "Loss: 201418.7543672376\n",
      "Training step:  1064\n",
      "Loss: 263764.52275899064\n",
      "Training step:  1065\n",
      "Loss: 201412.75111353223\n",
      "Training step:  1066\n",
      "Loss: 263758.8038920653\n",
      "Training step:  1067\n",
      "Loss: 201406.76159411485\n",
      "Training step:  1068\n",
      "Loss: 263753.09797381546\n",
      "Training step:  1069\n",
      "Loss: 201400.7857533443\n",
      "Training step:  1070\n",
      "Loss: 263747.404952035\n",
      "Training step:  1071\n",
      "Loss: 201394.8235359923\n",
      "Training step:  1072\n",
      "Loss: 263741.72477497073\n",
      "Training step:  1073\n",
      "Loss: 201388.8748871641\n",
      "Training step:  1074\n",
      "Loss: 263736.05739107786\n",
      "Training step:  1075\n",
      "Loss: 201382.93975220958\n",
      "Training step:  1076\n",
      "Loss: 263730.40274905786\n",
      "Training step:  1077\n",
      "Loss: 201377.01807683983\n",
      "Training step:  1078\n",
      "Loss: 263724.76079802256\n",
      "Training step:  1079\n",
      "Loss: 201371.10980710713\n",
      "Training step:  1080\n",
      "Loss: 263719.1314873296\n",
      "Training step:  1081\n",
      "Loss: 201365.2148893435\n",
      "Training step:  1082\n",
      "Loss: 263713.5147666493\n",
      "Training step:  1083\n",
      "Loss: 201359.33327021648\n",
      "Training step:  1084\n",
      "Loss: 263707.91058595735\n",
      "Training step:  1085\n",
      "Loss: 201353.46489671923\n",
      "Training step:  1086\n",
      "Loss: 263702.31889554113\n",
      "Training step:  1087\n",
      "Loss: 201347.6097161397\n",
      "Training step:  1088\n",
      "Loss: 263696.7396459572\n",
      "Training step:  1089\n",
      "Loss: 201341.7676760666\n",
      "Training step:  1090\n",
      "Loss: 263691.1727880401\n",
      "Training step:  1091\n",
      "Loss: 201335.9387244173\n",
      "Training step:  1092\n",
      "Loss: 263685.6182730062\n",
      "Training step:  1093\n",
      "Loss: 201330.12280945442\n",
      "Training step:  1094\n",
      "Loss: 263680.07605232287\n",
      "Training step:  1095\n",
      "Loss: 201324.3198796566\n",
      "Training step:  1096\n",
      "Loss: 263674.5460776455\n",
      "Training step:  1097\n",
      "Loss: 201318.52988381585\n",
      "Training step:  1098\n",
      "Loss: 263669.0283009658\n",
      "Training step:  1099\n",
      "Loss: 201312.75277105696\n",
      "Training step:  1100\n",
      "Loss: 263663.5226746218\n",
      "Training step:  1101\n",
      "Loss: 201306.98849078626\n",
      "Training step:  1102\n",
      "Loss: 263658.02915114514\n",
      "Training step:  1103\n",
      "Loss: 201301.23699269822\n",
      "Training step:  1104\n",
      "Loss: 263652.5476834\n",
      "Training step:  1105\n",
      "Loss: 201295.4982267819\n",
      "Training step:  1106\n",
      "Loss: 263647.07822450134\n",
      "Training step:  1107\n",
      "Loss: 201289.77214333872\n",
      "Training step:  1108\n",
      "Loss: 263641.6207278997\n",
      "Training step:  1109\n",
      "Loss: 201284.05869294747\n",
      "Training step:  1110\n",
      "Loss: 263636.17514725286\n",
      "Training step:  1111\n",
      "Loss: 201278.35782645564\n",
      "Training step:  1112\n",
      "Loss: 263630.7414365096\n",
      "Training step:  1113\n",
      "Loss: 201272.66949499678\n",
      "Training step:  1114\n",
      "Loss: 263625.3195498486\n",
      "Training step:  1115\n",
      "Loss: 201266.9936499639\n",
      "Training step:  1116\n",
      "Loss: 263619.9094417183\n",
      "Training step:  1117\n",
      "Loss: 201261.33024303318\n",
      "Training step:  1118\n",
      "Loss: 263614.5110668413\n",
      "Training step:  1119\n",
      "Loss: 201255.67922620196\n",
      "Training step:  1120\n",
      "Loss: 263609.12438026845\n",
      "Training step:  1121\n",
      "Loss: 201250.0405516973\n",
      "Training step:  1122\n",
      "Loss: 263603.7493371884\n",
      "Training step:  1123\n",
      "Loss: 201244.41417203035\n",
      "Training step:  1124\n",
      "Loss: 263598.3858931541\n",
      "Training step:  1125\n",
      "Loss: 201238.80003998964\n",
      "Training step:  1126\n",
      "Loss: 263593.0340039028\n",
      "Training step:  1127\n",
      "Loss: 201233.1981086144\n",
      "Training step:  1128\n",
      "Loss: 263587.6936254661\n",
      "Training step:  1129\n",
      "Loss: 201227.60833125006\n",
      "Training step:  1130\n",
      "Loss: 263582.36471414653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1131\n",
      "Loss: 201222.03066145815\n",
      "Training step:  1132\n",
      "Loss: 263577.04722639907\n",
      "Training step:  1133\n",
      "Loss: 201216.46505306353\n",
      "Training step:  1134\n",
      "Loss: 263571.74111900595\n",
      "Training step:  1135\n",
      "Loss: 201210.91146017256\n",
      "Training step:  1136\n",
      "Loss: 263566.4463489599\n",
      "Training step:  1137\n",
      "Loss: 201205.36983714995\n",
      "Training step:  1138\n",
      "Loss: 263561.16287355276\n",
      "Training step:  1139\n",
      "Loss: 201199.8401386251\n",
      "Training step:  1140\n",
      "Loss: 263555.8906502614\n",
      "Training step:  1141\n",
      "Loss: 201194.32231943638\n",
      "Training step:  1142\n",
      "Loss: 263550.6296368058\n",
      "Training step:  1143\n",
      "Loss: 201188.81633474593\n",
      "Training step:  1144\n",
      "Loss: 263545.3797912146\n",
      "Training step:  1145\n",
      "Loss: 201183.32213990533\n",
      "Training step:  1146\n",
      "Loss: 263540.1410716329\n",
      "Training step:  1147\n",
      "Loss: 201177.83969052194\n",
      "Training step:  1148\n",
      "Loss: 263534.91343652457\n",
      "Training step:  1149\n",
      "Loss: 201172.36894247966\n",
      "Training step:  1150\n",
      "Loss: 263529.6968445871\n",
      "Training step:  1151\n",
      "Loss: 201166.90985191052\n",
      "Training step:  1152\n",
      "Loss: 263524.49125474045\n",
      "Training step:  1153\n",
      "Loss: 201161.46237514587\n",
      "Training step:  1154\n",
      "Loss: 263519.2966260714\n",
      "Training step:  1155\n",
      "Loss: 201156.02646876726\n",
      "Training step:  1156\n",
      "Loss: 263514.112917948\n",
      "Training step:  1157\n",
      "Loss: 201150.60208962715\n",
      "Training step:  1158\n",
      "Loss: 263508.940089973\n",
      "Training step:  1159\n",
      "Loss: 201145.18919479186\n",
      "Training step:  1160\n",
      "Loss: 263503.778101963\n",
      "Training step:  1161\n",
      "Loss: 201139.78774159256\n",
      "Training step:  1162\n",
      "Loss: 263498.626913986\n",
      "Training step:  1163\n",
      "Loss: 201134.3976875968\n",
      "Training step:  1164\n",
      "Loss: 263493.48648632807\n",
      "Training step:  1165\n",
      "Loss: 201129.01899055816\n",
      "Training step:  1166\n",
      "Loss: 263488.35677940794\n",
      "Training step:  1167\n",
      "Loss: 201123.65160849458\n",
      "Training step:  1168\n",
      "Loss: 263483.2377539576\n",
      "Training step:  1169\n",
      "Loss: 201118.29549963804\n",
      "Training step:  1170\n",
      "Loss: 263478.12937087845\n",
      "Training step:  1171\n",
      "Loss: 201112.95062247672\n",
      "Training step:  1172\n",
      "Loss: 263473.03159132536\n",
      "Training step:  1173\n",
      "Loss: 201107.61693568935\n",
      "Training step:  1174\n",
      "Loss: 263467.94437660725\n",
      "Training step:  1175\n",
      "Loss: 201102.29439820055\n",
      "Training step:  1176\n",
      "Loss: 263462.86768830183\n",
      "Training step:  1177\n",
      "Loss: 201096.98296915356\n",
      "Training step:  1178\n",
      "Loss: 263457.8014881653\n",
      "Training step:  1179\n",
      "Loss: 201091.68260791613\n",
      "Training step:  1180\n",
      "Loss: 263452.74573817727\n",
      "Training step:  1181\n",
      "Loss: 201086.39327406805\n",
      "Training step:  1182\n",
      "Loss: 263447.70040051\n",
      "Training step:  1183\n",
      "Loss: 201081.11492741073\n",
      "Training step:  1184\n",
      "Loss: 263442.66543754993\n",
      "Training step:  1185\n",
      "Loss: 201075.84752796005\n",
      "Training step:  1186\n",
      "Loss: 263437.64081187634\n",
      "Training step:  1187\n",
      "Loss: 201070.5910359611\n",
      "Training step:  1188\n",
      "Loss: 263432.6264863237\n",
      "Training step:  1189\n",
      "Loss: 201065.3454118593\n",
      "Training step:  1190\n",
      "Loss: 263427.6224238381\n",
      "Training step:  1191\n",
      "Loss: 201060.11061630904\n",
      "Training step:  1192\n",
      "Loss: 263422.6285876317\n",
      "Training step:  1193\n",
      "Loss: 201054.88661017752\n",
      "Training step:  1194\n",
      "Loss: 263417.6449410854\n",
      "Training step:  1195\n",
      "Loss: 201049.67335455227\n",
      "Training step:  1196\n",
      "Loss: 263412.67144780746\n",
      "Training step:  1197\n",
      "Loss: 201044.47081073167\n",
      "Training step:  1198\n",
      "Loss: 263407.70807158883\n",
      "Training step:  1199\n",
      "Loss: 201039.27894021352\n",
      "Training step:  1200\n",
      "Loss: 263402.7547764085\n",
      "Training step:  1201\n",
      "Loss: 201034.0977046856\n",
      "Training step:  1202\n",
      "Loss: 263397.8115264257\n",
      "Training step:  1203\n",
      "Loss: 201028.92706605414\n",
      "Training step:  1204\n",
      "Loss: 263392.87828600366\n",
      "Training step:  1205\n",
      "Loss: 201023.7669864243\n",
      "Training step:  1206\n",
      "Loss: 263387.95501969336\n",
      "Training step:  1207\n",
      "Loss: 201018.61742808446\n",
      "Training step:  1208\n",
      "Loss: 263383.0416922011\n",
      "Training step:  1209\n",
      "Loss: 201013.47835354338\n",
      "Training step:  1210\n",
      "Loss: 263378.13826850906\n",
      "Training step:  1211\n",
      "Loss: 201008.3497255444\n",
      "Training step:  1212\n",
      "Loss: 263373.2447137548\n",
      "Training step:  1213\n",
      "Loss: 201003.231506963\n",
      "Training step:  1214\n",
      "Loss: 263368.3609931894\n",
      "Training step:  1215\n",
      "Loss: 200998.12366089056\n",
      "Training step:  1216\n",
      "Loss: 263363.48707232036\n",
      "Training step:  1217\n",
      "Loss: 200993.02615061606\n",
      "Training step:  1218\n",
      "Loss: 263358.62291678565\n",
      "Training step:  1219\n",
      "Loss: 200987.93893960104\n",
      "Training step:  1220\n",
      "Loss: 263353.76849242055\n",
      "Training step:  1221\n",
      "Loss: 200982.86199153544\n",
      "Training step:  1222\n",
      "Loss: 263348.9237652946\n",
      "Training step:  1223\n",
      "Loss: 200977.79527028213\n",
      "Training step:  1224\n",
      "Loss: 263344.0887015846\n",
      "Training step:  1225\n",
      "Loss: 200972.7387398984\n",
      "Training step:  1226\n",
      "Loss: 263339.2632677027\n",
      "Training step:  1227\n",
      "Loss: 200967.6923646161\n",
      "Training step:  1228\n",
      "Loss: 263334.447430188\n",
      "Training step:  1229\n",
      "Loss: 200962.65610885422\n",
      "Training step:  1230\n",
      "Loss: 263329.64115575084\n",
      "Training step:  1231\n",
      "Loss: 200957.62993719903\n",
      "Training step:  1232\n",
      "Loss: 263324.84441127174\n",
      "Training step:  1233\n",
      "Loss: 200952.6138144326\n",
      "Training step:  1234\n",
      "Loss: 263320.0571638307\n",
      "Training step:  1235\n",
      "Loss: 200947.6077055514\n",
      "Training step:  1236\n",
      "Loss: 263315.27938071784\n",
      "Training step:  1237\n",
      "Loss: 200942.61157570695\n",
      "Training step:  1238\n",
      "Loss: 263310.5110293313\n",
      "Training step:  1239\n",
      "Loss: 200937.62539024086\n",
      "Training step:  1240\n",
      "Loss: 263305.75207726564\n",
      "Training step:  1241\n",
      "Loss: 200932.64911464835\n",
      "Training step:  1242\n",
      "Loss: 263301.0024922695\n",
      "Training step:  1243\n",
      "Loss: 200927.68271464523\n",
      "Training step:  1244\n",
      "Loss: 263296.2622422875\n",
      "Training step:  1245\n",
      "Loss: 200922.7261560703\n",
      "Training step:  1246\n",
      "Loss: 263291.5312953555\n",
      "Training step:  1247\n",
      "Loss: 200917.77940495947\n",
      "Training step:  1248\n",
      "Loss: 263286.8096197454\n",
      "Training step:  1249\n",
      "Loss: 200912.84242753565\n",
      "Training step:  1250\n",
      "Loss: 263282.0971838559\n",
      "Training step:  1251\n",
      "Loss: 200907.91519017037\n",
      "Training step:  1252\n",
      "Loss: 263277.393956266\n",
      "Training step:  1253\n",
      "Loss: 200902.9976594236\n",
      "Training step:  1254\n",
      "Loss: 263272.6999056852\n",
      "Training step:  1255\n",
      "Loss: 200898.08980199945\n",
      "Training step:  1256\n",
      "Loss: 263268.0150009986\n",
      "Training step:  1257\n",
      "Loss: 200893.19158482304\n",
      "Training step:  1258\n",
      "Loss: 263263.33921131585\n",
      "Training step:  1259\n",
      "Loss: 200888.30297494307\n",
      "Training step:  1260\n",
      "Loss: 263258.6725057743\n",
      "Training step:  1261\n",
      "Loss: 200883.42393957652\n",
      "Training step:  1262\n",
      "Loss: 263254.0148537874\n",
      "Training step:  1263\n",
      "Loss: 200878.55444615605\n",
      "Training step:  1264\n",
      "Loss: 263249.366224885\n",
      "Training step:  1265\n",
      "Loss: 200873.69446221297\n",
      "Training step:  1266\n",
      "Loss: 263244.7265887022\n",
      "Training step:  1267\n",
      "Loss: 200868.84395546938\n",
      "Training step:  1268\n",
      "Loss: 263240.09591508267\n",
      "Training step:  1269\n",
      "Loss: 200864.0028938017\n",
      "Training step:  1270\n",
      "Loss: 263235.4741739779\n",
      "Training step:  1271\n",
      "Loss: 200859.1712452589\n",
      "Training step:  1272\n",
      "Loss: 263230.86133555026\n",
      "Training step:  1273\n",
      "Loss: 200854.34897806548\n",
      "Training step:  1274\n",
      "Loss: 263226.25737008604\n",
      "Training step:  1275\n",
      "Loss: 200849.5360605627\n",
      "Training step:  1276\n",
      "Loss: 263221.66224796645\n",
      "Training step:  1277\n",
      "Loss: 200844.73246126084\n",
      "Training step:  1278\n",
      "Loss: 263217.0759397659\n",
      "Training step:  1279\n",
      "Loss: 200839.9381488304\n",
      "Training step:  1280\n",
      "Loss: 263212.4984162035\n",
      "Training step:  1281\n",
      "Loss: 200835.15309212302\n",
      "Training step:  1282\n",
      "Loss: 263207.9296481792\n",
      "Training step:  1283\n",
      "Loss: 200830.3772601314\n",
      "Training step:  1284\n",
      "Loss: 263203.3696066945\n",
      "Training step:  1285\n",
      "Loss: 200825.61062199276\n",
      "Training step:  1286\n",
      "Loss: 263198.8182629182\n",
      "Training step:  1287\n",
      "Loss: 200820.85314702426\n",
      "Training step:  1288\n",
      "Loss: 263194.2755881865\n",
      "Training step:  1289\n",
      "Loss: 200816.10480467926\n",
      "Training step:  1290\n",
      "Loss: 263189.7415539135\n",
      "Training step:  1291\n",
      "Loss: 200811.3655644952\n",
      "Training step:  1292\n",
      "Loss: 263185.2161315773\n",
      "Training step:  1293\n",
      "Loss: 200806.63539621816\n",
      "Training step:  1294\n",
      "Loss: 263180.69929298724\n",
      "Training step:  1295\n",
      "Loss: 200801.91426977934\n",
      "Training step:  1296\n",
      "Loss: 263176.1910099918\n",
      "Training step:  1297\n",
      "Loss: 200797.2021552088\n",
      "Training step:  1298\n",
      "Loss: 263171.6912546138\n",
      "Training step:  1299\n",
      "Loss: 200792.49902272696\n",
      "Training step:  1300\n",
      "Loss: 263167.19999900553\n",
      "Training step:  1301\n",
      "Loss: 200787.8048426426\n",
      "Training step:  1302\n",
      "Loss: 263162.71721540595\n",
      "Training step:  1303\n",
      "Loss: 200783.1195854463\n",
      "Training step:  1304\n",
      "Loss: 263158.24287625425\n",
      "Training step:  1305\n",
      "Loss: 200778.44322177116\n",
      "Training step:  1306\n",
      "Loss: 263153.7769540891\n",
      "Training step:  1307\n",
      "Loss: 200773.7757223634\n",
      "Training step:  1308\n",
      "Loss: 263149.31942156085\n",
      "Training step:  1309\n",
      "Loss: 200769.11705814218\n",
      "Training step:  1310\n",
      "Loss: 263144.8702515021\n",
      "Training step:  1311\n",
      "Loss: 200764.46720015124\n",
      "Training step:  1312\n",
      "Loss: 263140.4294168449\n",
      "Training step:  1313\n",
      "Loss: 200759.82611958619\n",
      "Training step:  1314\n",
      "Loss: 263135.9968906669\n",
      "Training step:  1315\n",
      "Loss: 200755.19378778414\n",
      "Training step:  1316\n",
      "Loss: 263131.5726461938\n",
      "Training step:  1317\n",
      "Loss: 200750.57017620275\n",
      "Training step:  1318\n",
      "Loss: 263127.1566567158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1319\n",
      "Loss: 200745.95525643625\n",
      "Training step:  1320\n",
      "Loss: 263122.74889569567\n",
      "Training step:  1321\n",
      "Loss: 200741.3490002182\n",
      "Training step:  1322\n",
      "Loss: 263118.34933669923\n",
      "Training step:  1323\n",
      "Loss: 200736.75137942762\n",
      "Training step:  1324\n",
      "Loss: 263113.9579534883\n",
      "Training step:  1325\n",
      "Loss: 200732.16236613132\n",
      "Training step:  1326\n",
      "Loss: 263109.574719984\n",
      "Training step:  1327\n",
      "Loss: 200727.58193248336\n",
      "Training step:  1328\n",
      "Loss: 263105.1996101167\n",
      "Training step:  1329\n",
      "Loss: 200723.0100507418\n",
      "Training step:  1330\n",
      "Loss: 263100.8325979508\n",
      "Training step:  1331\n",
      "Loss: 200718.44669329323\n",
      "Training step:  1332\n",
      "Loss: 263096.4736576538\n",
      "Training step:  1333\n",
      "Loss: 200713.89183266432\n",
      "Training step:  1334\n",
      "Loss: 263092.12276359415\n",
      "Training step:  1335\n",
      "Loss: 200709.34544156742\n",
      "Training step:  1336\n",
      "Loss: 263087.7798902454\n",
      "Training step:  1337\n",
      "Loss: 200704.80749276842\n",
      "Training step:  1338\n",
      "Loss: 263083.44501213974\n",
      "Training step:  1339\n",
      "Loss: 200700.27795922218\n",
      "Training step:  1340\n",
      "Loss: 263079.1181040379\n",
      "Training step:  1341\n",
      "Loss: 200695.7568139976\n",
      "Training step:  1342\n",
      "Loss: 263074.79914075916\n",
      "Training step:  1343\n",
      "Loss: 200691.24403029334\n",
      "Training step:  1344\n",
      "Loss: 263070.4880972691\n",
      "Training step:  1345\n",
      "Loss: 200686.73958143475\n",
      "Training step:  1346\n",
      "Loss: 263066.18494861276\n",
      "Training step:  1347\n",
      "Loss: 200682.24344083006\n",
      "Training step:  1348\n",
      "Loss: 263061.8896699399\n",
      "Training step:  1349\n",
      "Loss: 200677.75558207405\n",
      "Training step:  1350\n",
      "Loss: 263057.60223660496\n",
      "Training step:  1351\n",
      "Loss: 200673.27597885425\n",
      "Training step:  1352\n",
      "Loss: 263053.3226239569\n",
      "Training step:  1353\n",
      "Loss: 200668.8046049284\n",
      "Training step:  1354\n",
      "Loss: 263049.0508074582\n",
      "Training step:  1355\n",
      "Loss: 200664.34143425158\n",
      "Training step:  1356\n",
      "Loss: 263044.786762835\n",
      "Training step:  1357\n",
      "Loss: 200659.8864409092\n",
      "Training step:  1358\n",
      "Loss: 263040.5304658338\n",
      "Training step:  1359\n",
      "Loss: 200655.439599081\n",
      "Training step:  1360\n",
      "Loss: 263036.28189232753\n",
      "Training step:  1361\n",
      "Loss: 200651.00088305803\n",
      "Training step:  1362\n",
      "Loss: 263032.04101830744\n",
      "Training step:  1363\n",
      "Loss: 200646.57026729838\n",
      "Training step:  1364\n",
      "Loss: 263027.80781989783\n",
      "Training step:  1365\n",
      "Loss: 200642.14772630157\n",
      "Training step:  1366\n",
      "Loss: 263023.5822732025\n",
      "Training step:  1367\n",
      "Loss: 200637.73323469528\n",
      "Training step:  1368\n",
      "Loss: 263019.3643545604\n",
      "Training step:  1369\n",
      "Loss: 200633.32676728733\n",
      "Training step:  1370\n",
      "Loss: 263015.15404043434\n",
      "Training step:  1371\n",
      "Loss: 200628.92829896798\n",
      "Training step:  1372\n",
      "Loss: 263010.95130731096\n",
      "Training step:  1373\n",
      "Loss: 200624.53780470762\n",
      "Training step:  1374\n",
      "Loss: 263006.7561318086\n",
      "Training step:  1375\n",
      "Loss: 200620.15525964866\n",
      "Training step:  1376\n",
      "Loss: 263002.56849071325\n",
      "Training step:  1377\n",
      "Loss: 200615.7806390357\n",
      "Training step:  1378\n",
      "Loss: 262998.38836090465\n",
      "Training step:  1379\n",
      "Loss: 200611.41391823976\n",
      "Training step:  1380\n",
      "Loss: 262994.2157193342\n",
      "Training step:  1381\n",
      "Loss: 200607.05507269388\n",
      "Training step:  1382\n",
      "Loss: 262990.0505430299\n",
      "Training step:  1383\n",
      "Loss: 200602.7040779747\n",
      "Training step:  1384\n",
      "Loss: 262985.8928091996\n",
      "Training step:  1385\n",
      "Loss: 200598.3609097945\n",
      "Training step:  1386\n",
      "Loss: 262981.74249511166\n",
      "Training step:  1387\n",
      "Loss: 200594.025543915\n",
      "Training step:  1388\n",
      "Loss: 262977.5995781074\n",
      "Training step:  1389\n",
      "Loss: 200589.69795624938\n",
      "Training step:  1390\n",
      "Loss: 262973.4640356642\n",
      "Training step:  1391\n",
      "Loss: 200585.3781227873\n",
      "Training step:  1392\n",
      "Loss: 262969.3358453298\n",
      "Training step:  1393\n",
      "Loss: 200581.0660196588\n",
      "Training step:  1394\n",
      "Loss: 262965.21498480625\n",
      "Training step:  1395\n",
      "Loss: 200576.7616231096\n",
      "Training step:  1396\n",
      "Loss: 262961.10143189953\n",
      "Training step:  1397\n",
      "Loss: 200572.46490949977\n",
      "Training step:  1398\n",
      "Loss: 262956.9951645436\n",
      "Training step:  1399\n",
      "Loss: 200568.17585530752\n",
      "Training step:  1400\n",
      "Loss: 262952.8961607206\n",
      "Training step:  1401\n",
      "Loss: 200563.8944370584\n",
      "Training step:  1402\n",
      "Loss: 262948.80439845816\n",
      "Training step:  1403\n",
      "Loss: 200559.6206313736\n",
      "Training step:  1404\n",
      "Loss: 262944.71985590295\n",
      "Training step:  1405\n",
      "Loss: 200555.35441504288\n",
      "Training step:  1406\n",
      "Loss: 262940.64251139935\n",
      "Training step:  1407\n",
      "Loss: 200551.09576494724\n",
      "Training step:  1408\n",
      "Loss: 262936.5723433137\n",
      "Training step:  1409\n",
      "Loss: 200546.84465804772\n",
      "Training step:  1410\n",
      "Loss: 262932.5093300835\n",
      "Training step:  1411\n",
      "Loss: 200542.60107142877\n",
      "Training step:  1412\n",
      "Loss: 262928.45345035\n",
      "Training step:  1413\n",
      "Loss: 200538.36498228056\n",
      "Training step:  1414\n",
      "Loss: 262924.4046827201\n",
      "Training step:  1415\n",
      "Loss: 200534.13636786214\n",
      "Training step:  1416\n",
      "Loss: 262920.3630059851\n",
      "Training step:  1417\n",
      "Loss: 200529.91520557427\n",
      "Training step:  1418\n",
      "Loss: 262916.3283989734\n",
      "Training step:  1419\n",
      "Loss: 200525.70147288527\n",
      "Training step:  1420\n",
      "Loss: 262912.30084066023\n",
      "Training step:  1421\n",
      "Loss: 200521.49514739108\n",
      "Training step:  1422\n",
      "Loss: 262908.280310063\n",
      "Training step:  1423\n",
      "Loss: 200517.29620674686\n",
      "Training step:  1424\n",
      "Loss: 262904.2667863103\n",
      "Training step:  1425\n",
      "Loss: 200513.10462876793\n",
      "Training step:  1426\n",
      "Loss: 262900.2602486642\n",
      "Training step:  1427\n",
      "Loss: 200508.92039130713\n",
      "Training step:  1428\n",
      "Loss: 262896.2606763925\n",
      "Training step:  1429\n",
      "Loss: 200504.74347234447\n",
      "Training step:  1430\n",
      "Loss: 262892.2680489229\n",
      "Training step:  1431\n",
      "Loss: 200500.5738499522\n",
      "Training step:  1432\n",
      "Loss: 262888.28234573605\n",
      "Training step:  1433\n",
      "Loss: 200496.41150227078\n",
      "Training step:  1434\n",
      "Loss: 262884.3035463932\n",
      "Training step:  1435\n",
      "Loss: 200492.25640761573\n",
      "Training step:  1436\n",
      "Loss: 262880.3316306712\n",
      "Training step:  1437\n",
      "Loss: 200488.1085443637\n",
      "Training step:  1438\n",
      "Loss: 262876.3665783451\n",
      "Training step:  1439\n",
      "Loss: 200483.96789098924\n",
      "Training step:  1440\n",
      "Loss: 262872.4083692659\n",
      "Training step:  1441\n",
      "Loss: 200479.83442601914\n",
      "Training step:  1442\n",
      "Loss: 262868.4569833402\n",
      "Training step:  1443\n",
      "Loss: 200475.70812806452\n",
      "Training step:  1444\n",
      "Loss: 262864.51240054006\n",
      "Training step:  1445\n",
      "Loss: 200471.5889758533\n",
      "Training step:  1446\n",
      "Loss: 262860.5746010112\n",
      "Training step:  1447\n",
      "Loss: 200467.4769482414\n",
      "Training step:  1448\n",
      "Loss: 262856.6435649731\n",
      "Training step:  1449\n",
      "Loss: 200463.37202414006\n",
      "Training step:  1450\n",
      "Loss: 262852.7192727031\n",
      "Training step:  1451\n",
      "Loss: 200459.27418257634\n",
      "Training step:  1452\n",
      "Loss: 262848.8017045976\n",
      "Training step:  1453\n",
      "Loss: 200455.1834026569\n",
      "Training step:  1454\n",
      "Loss: 262844.8908411069\n",
      "Training step:  1455\n",
      "Loss: 200451.09966357308\n",
      "Training step:  1456\n",
      "Loss: 262840.98666277557\n",
      "Training step:  1457\n",
      "Loss: 200447.02294461508\n",
      "Training step:  1458\n",
      "Loss: 262837.08915024996\n",
      "Training step:  1459\n",
      "Loss: 200442.95322516919\n",
      "Training step:  1460\n",
      "Loss: 262833.19828422694\n",
      "Training step:  1461\n",
      "Loss: 200438.89048468982\n",
      "Training step:  1462\n",
      "Loss: 262829.314045528\n",
      "Training step:  1463\n",
      "Loss: 200434.83470274438\n",
      "Training step:  1464\n",
      "Loss: 262825.4364149947\n",
      "Training step:  1465\n",
      "Loss: 200430.78585893885\n",
      "Training step:  1466\n",
      "Loss: 262821.5653735692\n",
      "Training step:  1467\n",
      "Loss: 200426.74393301996\n",
      "Training step:  1468\n",
      "Loss: 262817.70090231975\n",
      "Training step:  1469\n",
      "Loss: 200422.7089047961\n",
      "Training step:  1470\n",
      "Loss: 262813.8429823306\n",
      "Training step:  1471\n",
      "Loss: 200418.68075414968\n",
      "Training step:  1472\n",
      "Loss: 262809.99159480876\n",
      "Training step:  1473\n",
      "Loss: 200414.65946110344\n",
      "Training step:  1474\n",
      "Loss: 262806.146721092\n",
      "Training step:  1475\n",
      "Loss: 200410.6450057358\n",
      "Training step:  1476\n",
      "Loss: 262802.3083425264\n",
      "Training step:  1477\n",
      "Loss: 200406.6373681941\n",
      "Training step:  1478\n",
      "Loss: 262798.47644052247\n",
      "Training step:  1479\n",
      "Loss: 200402.6365287202\n",
      "Training step:  1480\n",
      "Loss: 262794.650996632\n",
      "Training step:  1481\n",
      "Loss: 200398.64246763586\n",
      "Training step:  1482\n",
      "Loss: 262790.83199239813\n",
      "Training step:  1483\n",
      "Loss: 200394.65516532047\n",
      "Training step:  1484\n",
      "Loss: 262787.01940948865\n",
      "Training step:  1485\n",
      "Loss: 200390.67460228453\n",
      "Training step:  1486\n",
      "Loss: 262783.2132296636\n",
      "Training step:  1487\n",
      "Loss: 200386.7007590947\n",
      "Training step:  1488\n",
      "Loss: 262779.4134347702\n",
      "Training step:  1489\n",
      "Loss: 200382.73361644577\n",
      "Training step:  1490\n",
      "Loss: 262775.62000674487\n",
      "Training step:  1491\n",
      "Loss: 200378.7731550508\n",
      "Training step:  1492\n",
      "Loss: 262771.8329275075\n",
      "Training step:  1493\n",
      "Loss: 200374.81935572874\n",
      "Training step:  1494\n",
      "Loss: 262768.05217915867\n",
      "Training step:  1495\n",
      "Loss: 200370.8721993943\n",
      "Training step:  1496\n",
      "Loss: 262764.2777438037\n",
      "Training step:  1497\n",
      "Loss: 200366.9316669932\n",
      "Training step:  1498\n",
      "Loss: 262760.50960361\n",
      "Training step:  1499\n",
      "Loss: 200362.9977395979\n",
      "Training step:  1500\n",
      "Loss: 262756.74774089997\n",
      "Training step:  1501\n",
      "Loss: 200359.07039834262\n",
      "Training step:  1502\n",
      "Loss: 262752.9921379738\n",
      "Training step:  1503\n",
      "Loss: 200355.14962444102\n",
      "Training step:  1504\n",
      "Loss: 262749.24277731386\n",
      "Training step:  1505\n",
      "Loss: 200351.2353992307\n",
      "Training step:  1506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 262745.49964144285\n",
      "Training step:  1507\n",
      "Loss: 200347.32770406\n",
      "Training step:  1508\n",
      "Loss: 262741.76271287014\n",
      "Training step:  1509\n",
      "Loss: 200343.42652037047\n",
      "Training step:  1510\n",
      "Loss: 262738.0319742595\n",
      "Training step:  1511\n",
      "Loss: 200339.5318296979\n",
      "Training step:  1512\n",
      "Loss: 262734.30740831274\n",
      "Training step:  1513\n",
      "Loss: 200335.64361363178\n",
      "Training step:  1514\n",
      "Loss: 262730.588997809\n",
      "Training step:  1515\n",
      "Loss: 200331.76185387783\n",
      "Training step:  1516\n",
      "Loss: 262726.87672565476\n",
      "Training step:  1517\n",
      "Loss: 200327.8865322044\n",
      "Training step:  1518\n",
      "Loss: 262723.1705747568\n",
      "Training step:  1519\n",
      "Loss: 200324.01763040345\n",
      "Training step:  1520\n",
      "Loss: 262719.47052805393\n",
      "Training step:  1521\n",
      "Loss: 200320.1551304054\n",
      "Training step:  1522\n",
      "Loss: 262715.7765686986\n",
      "Training step:  1523\n",
      "Loss: 200316.29901421518\n",
      "Training step:  1524\n",
      "Loss: 262712.0886798112\n",
      "Training step:  1525\n",
      "Loss: 200312.4492638524\n",
      "Training step:  1526\n",
      "Loss: 262708.4068445222\n",
      "Training step:  1527\n",
      "Loss: 200308.60586144112\n",
      "Training step:  1528\n",
      "Loss: 262704.7310461668\n",
      "Training step:  1529\n",
      "Loss: 200304.76878922686\n",
      "Training step:  1530\n",
      "Loss: 262701.0612681221\n",
      "Training step:  1531\n",
      "Loss: 200300.93802947138\n",
      "Training step:  1532\n",
      "Loss: 262697.3974937236\n",
      "Training step:  1533\n",
      "Loss: 200297.1135644775\n",
      "Training step:  1534\n",
      "Loss: 262693.7397064315\n",
      "Training step:  1535\n",
      "Loss: 200293.29537669252\n",
      "Training step:  1536\n",
      "Loss: 262690.08788982825\n",
      "Training step:  1537\n",
      "Loss: 200289.48344861311\n",
      "Training step:  1538\n",
      "Loss: 262686.4420275342\n",
      "Training step:  1539\n",
      "Loss: 200285.67776281663\n",
      "Training step:  1540\n",
      "Loss: 262682.80210323684\n",
      "Training step:  1541\n",
      "Loss: 200281.87830193766\n",
      "Training step:  1542\n",
      "Loss: 262679.16810065706\n",
      "Training step:  1543\n",
      "Loss: 200278.08504863642\n",
      "Training step:  1544\n",
      "Loss: 262675.5400035308\n",
      "Training step:  1545\n",
      "Loss: 200274.2979856886\n",
      "Training step:  1546\n",
      "Loss: 262671.9177957993\n",
      "Training step:  1547\n",
      "Loss: 200270.51709598617\n",
      "Training step:  1548\n",
      "Loss: 262668.30146143516\n",
      "Training step:  1549\n",
      "Loss: 200266.74236244286\n",
      "Training step:  1550\n",
      "Loss: 262664.6909844283\n",
      "Training step:  1551\n",
      "Loss: 200262.97376803696\n",
      "Training step:  1552\n",
      "Loss: 262661.08634884696\n",
      "Training step:  1553\n",
      "Loss: 200259.21129581408\n",
      "Training step:  1554\n",
      "Loss: 262657.48753879097\n",
      "Training step:  1555\n",
      "Loss: 200255.45492887567\n",
      "Training step:  1556\n",
      "Loss: 262653.8945384475\n",
      "Training step:  1557\n",
      "Loss: 200251.7046504276\n",
      "Training step:  1558\n",
      "Loss: 262650.3073321215\n",
      "Training step:  1559\n",
      "Loss: 200247.9604437387\n",
      "Training step:  1560\n",
      "Loss: 262646.7259041012\n",
      "Training step:  1561\n",
      "Loss: 200244.22229208582\n",
      "Training step:  1562\n",
      "Loss: 262643.1502387159\n",
      "Training step:  1563\n",
      "Loss: 200240.49017887673\n",
      "Training step:  1564\n",
      "Loss: 262639.5803204919\n",
      "Training step:  1565\n",
      "Loss: 200236.7640876056\n",
      "Training step:  1566\n",
      "Loss: 262636.01613393216\n",
      "Training step:  1567\n",
      "Loss: 200233.04400175993\n",
      "Training step:  1568\n",
      "Loss: 262632.45766354963\n",
      "Training step:  1569\n",
      "Loss: 200229.32990491213\n",
      "Training step:  1570\n",
      "Loss: 262628.90489397786\n",
      "Training step:  1571\n",
      "Loss: 200225.62178070727\n",
      "Training step:  1572\n",
      "Loss: 262625.35780986416\n",
      "Training step:  1573\n",
      "Loss: 200221.91961287957\n",
      "Training step:  1574\n",
      "Loss: 262621.81639605283\n",
      "Training step:  1575\n",
      "Loss: 200218.22338524173\n",
      "Training step:  1576\n",
      "Loss: 262618.28063735383\n",
      "Training step:  1577\n",
      "Loss: 200214.5330816678\n",
      "Training step:  1578\n",
      "Loss: 262614.7505186732\n",
      "Training step:  1579\n",
      "Loss: 200210.8486860166\n",
      "Training step:  1580\n",
      "Loss: 262611.22602480993\n",
      "Training step:  1581\n",
      "Loss: 200207.17018223155\n",
      "Training step:  1582\n",
      "Loss: 262607.70714078605\n",
      "Training step:  1583\n",
      "Loss: 200203.49755439415\n",
      "Training step:  1584\n",
      "Loss: 262604.1938516885\n",
      "Training step:  1585\n",
      "Loss: 200199.83078659032\n",
      "Training step:  1586\n",
      "Loss: 262600.6861425786\n",
      "Training step:  1587\n",
      "Loss: 200196.16986295488\n",
      "Training step:  1588\n",
      "Loss: 262597.1839985867\n",
      "Training step:  1589\n",
      "Loss: 200192.51476773786\n",
      "Training step:  1590\n",
      "Loss: 262593.68740501645\n",
      "Training step:  1591\n",
      "Loss: 200188.86548524798\n",
      "Training step:  1592\n",
      "Loss: 262590.1963471255\n",
      "Training step:  1593\n",
      "Loss: 200185.22199983094\n",
      "Training step:  1594\n",
      "Loss: 262586.7108102664\n",
      "Training step:  1595\n",
      "Loss: 200181.58429587842\n",
      "Training step:  1596\n",
      "Loss: 262583.230779775\n",
      "Training step:  1597\n",
      "Loss: 200177.9523578612\n",
      "Training step:  1598\n",
      "Loss: 262579.7562411381\n",
      "Training step:  1599\n",
      "Loss: 200174.32617032417\n",
      "Training step:  1600\n",
      "Loss: 262576.28717986343\n",
      "Training step:  1601\n",
      "Loss: 200170.70571785027\n",
      "Training step:  1602\n",
      "Loss: 262572.8235814902\n",
      "Training step:  1603\n",
      "Loss: 200167.0909850894\n",
      "Training step:  1604\n",
      "Loss: 262569.36543165497\n",
      "Training step:  1605\n",
      "Loss: 200163.48195676942\n",
      "Training step:  1606\n",
      "Loss: 262565.91271603113\n",
      "Training step:  1607\n",
      "Loss: 200159.87861764754\n",
      "Training step:  1608\n",
      "Loss: 262562.4654203494\n",
      "Training step:  1609\n",
      "Loss: 200156.28095257666\n",
      "Training step:  1610\n",
      "Loss: 262559.02353040944\n",
      "Training step:  1611\n",
      "Loss: 200152.688946441\n",
      "Training step:  1612\n",
      "Loss: 262555.5870320425\n",
      "Training step:  1613\n",
      "Loss: 200149.10258416465\n",
      "Training step:  1614\n",
      "Loss: 262552.15591107047\n",
      "Training step:  1615\n",
      "Loss: 200145.52185072756\n",
      "Training step:  1616\n",
      "Loss: 262548.73015345796\n",
      "Training step:  1617\n",
      "Loss: 200141.9467312284\n",
      "Training step:  1618\n",
      "Loss: 262545.3097452409\n",
      "Training step:  1619\n",
      "Loss: 200138.37721079378\n",
      "Training step:  1620\n",
      "Loss: 262541.8946724825\n",
      "Training step:  1621\n",
      "Loss: 200134.81327459464\n",
      "Training step:  1622\n",
      "Loss: 262538.48492125067\n",
      "Training step:  1623\n",
      "Loss: 200131.25490786997\n",
      "Training step:  1624\n",
      "Loss: 262535.08047775575\n",
      "Training step:  1625\n",
      "Loss: 200127.7020959359\n",
      "Training step:  1626\n",
      "Loss: 262531.6813282121\n",
      "Training step:  1627\n",
      "Loss: 200124.15482411988\n",
      "Training step:  1628\n",
      "Loss: 262528.2874588452\n",
      "Training step:  1629\n",
      "Loss: 200120.61307782322\n",
      "Training step:  1630\n",
      "Loss: 262524.89885597513\n",
      "Training step:  1631\n",
      "Loss: 200117.07684247973\n",
      "Training step:  1632\n",
      "Loss: 262521.5155059078\n",
      "Training step:  1633\n",
      "Loss: 200113.5461036014\n",
      "Training step:  1634\n",
      "Loss: 262518.1373951139\n",
      "Training step:  1635\n",
      "Loss: 200110.02084679838\n",
      "Training step:  1636\n",
      "Loss: 262514.764510113\n",
      "Training step:  1637\n",
      "Loss: 200106.5010577273\n",
      "Training step:  1638\n",
      "Loss: 262511.3968374587\n",
      "Training step:  1639\n",
      "Loss: 200102.9867220432\n",
      "Training step:  1640\n",
      "Loss: 262508.03436362563\n",
      "Training step:  1641\n",
      "Loss: 200099.47782544186\n",
      "Training step:  1642\n",
      "Loss: 262504.6770752556\n",
      "Training step:  1643\n",
      "Loss: 200095.9743537326\n",
      "Training step:  1644\n",
      "Loss: 262501.3249590058\n",
      "Training step:  1645\n",
      "Loss: 200092.47629275257\n",
      "Training step:  1646\n",
      "Loss: 262497.97800164274\n",
      "Training step:  1647\n",
      "Loss: 200088.98362842636\n",
      "Training step:  1648\n",
      "Loss: 262494.63618993654\n",
      "Training step:  1649\n",
      "Loss: 200085.49634668237\n",
      "Training step:  1650\n",
      "Loss: 262491.2995106835\n",
      "Training step:  1651\n",
      "Loss: 200082.01443352102\n",
      "Training step:  1652\n",
      "Loss: 262487.96795075963\n",
      "Training step:  1653\n",
      "Loss: 200078.53787499815\n",
      "Training step:  1654\n",
      "Loss: 262484.6414970877\n",
      "Training step:  1655\n",
      "Loss: 200075.06665722834\n",
      "Training step:  1656\n",
      "Loss: 262481.3201366419\n",
      "Training step:  1657\n",
      "Loss: 200071.6007663647\n",
      "Training step:  1658\n",
      "Loss: 262478.0038564367\n",
      "Training step:  1659\n",
      "Loss: 200068.14018863687\n",
      "Training step:  1660\n",
      "Loss: 262474.69264357013\n",
      "Training step:  1661\n",
      "Loss: 200064.68491030578\n",
      "Training step:  1662\n",
      "Loss: 262471.3864851187\n",
      "Training step:  1663\n",
      "Loss: 200061.23491767727\n",
      "Training step:  1664\n",
      "Loss: 262468.08536827273\n",
      "Training step:  1665\n",
      "Loss: 200057.7901971304\n",
      "Training step:  1666\n",
      "Loss: 262464.78928023356\n",
      "Training step:  1667\n",
      "Loss: 200054.350735093\n",
      "Training step:  1668\n",
      "Loss: 262461.4982082906\n",
      "Training step:  1669\n",
      "Loss: 200050.91651802202\n",
      "Training step:  1670\n",
      "Loss: 262458.21213969187\n",
      "Training step:  1671\n",
      "Loss: 200047.48753239436\n",
      "Training step:  1672\n",
      "Loss: 262454.9310617396\n",
      "Training step:  1673\n",
      "Loss: 200044.0637648088\n",
      "Training step:  1674\n",
      "Loss: 262451.65496193786\n",
      "Training step:  1675\n",
      "Loss: 200040.64520191294\n",
      "Training step:  1676\n",
      "Loss: 262448.3838277072\n",
      "Training step:  1677\n",
      "Loss: 200037.2318303372\n",
      "Training step:  1678\n",
      "Loss: 262445.11764646653\n",
      "Training step:  1679\n",
      "Loss: 200033.82363678468\n",
      "Training step:  1680\n",
      "Loss: 262441.8564057848\n",
      "Training step:  1681\n",
      "Loss: 200030.4206080491\n",
      "Training step:  1682\n",
      "Loss: 262438.6000932598\n",
      "Training step:  1683\n",
      "Loss: 200027.02273093988\n",
      "Training step:  1684\n",
      "Loss: 262435.3486965064\n",
      "Training step:  1685\n",
      "Loss: 200023.62999233097\n",
      "Training step:  1686\n",
      "Loss: 262432.1022032304\n",
      "Training step:  1687\n",
      "Loss: 200020.24237914075\n",
      "Training step:  1688\n",
      "Loss: 262428.86060112464\n",
      "Training step:  1689\n",
      "Loss: 200016.8598783188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1690\n",
      "Loss: 262425.6238779446\n",
      "Training step:  1691\n",
      "Loss: 200013.4824768781\n",
      "Training step:  1692\n",
      "Loss: 262422.392021532\n",
      "Training step:  1693\n",
      "Loss: 200010.1101619036\n",
      "Training step:  1694\n",
      "Loss: 262419.1650197422\n",
      "Training step:  1695\n",
      "Loss: 200006.74292047686\n",
      "Training step:  1696\n",
      "Loss: 262415.9428604355\n",
      "Training step:  1697\n",
      "Loss: 200003.38073973806\n",
      "Training step:  1698\n",
      "Loss: 262412.72553154425\n",
      "Training step:  1699\n",
      "Loss: 200000.0236068916\n",
      "Training step:  1700\n",
      "Loss: 262409.51302106754\n",
      "Training step:  1701\n",
      "Loss: 199996.6715091903\n",
      "Training step:  1702\n",
      "Loss: 262406.305317035\n",
      "Training step:  1703\n",
      "Loss: 199993.32443392632\n",
      "Training step:  1704\n",
      "Loss: 262403.102407501\n",
      "Training step:  1705\n",
      "Loss: 199989.98236841185\n",
      "Training step:  1706\n",
      "Loss: 262399.9042805414\n",
      "Training step:  1707\n",
      "Loss: 199986.64530002646\n",
      "Training step:  1708\n",
      "Loss: 262396.71092432237\n",
      "Training step:  1709\n",
      "Loss: 199983.3132162311\n",
      "Training step:  1710\n",
      "Loss: 262393.5223271026\n",
      "Training step:  1711\n",
      "Loss: 199979.98610449609\n",
      "Training step:  1712\n",
      "Loss: 262390.3384770733\n",
      "Training step:  1713\n",
      "Loss: 199976.66395235562\n",
      "Training step:  1714\n",
      "Loss: 262387.1593625516\n",
      "Training step:  1715\n",
      "Loss: 199973.34674734232\n",
      "Training step:  1716\n",
      "Loss: 262383.9849718001\n",
      "Training step:  1717\n",
      "Loss: 199970.03447708263\n",
      "Training step:  1718\n",
      "Loss: 262380.81529323244\n",
      "Training step:  1719\n",
      "Loss: 199966.72712925292\n",
      "Training step:  1720\n",
      "Loss: 262377.65031529363\n",
      "Training step:  1721\n",
      "Loss: 199963.4246915716\n",
      "Training step:  1722\n",
      "Loss: 262374.49002641375\n",
      "Training step:  1723\n",
      "Loss: 199960.12715174694\n",
      "Training step:  1724\n",
      "Loss: 262371.33441503666\n",
      "Training step:  1725\n",
      "Loss: 199956.83449756904\n",
      "Training step:  1726\n",
      "Loss: 262368.18346971885\n",
      "Training step:  1727\n",
      "Loss: 199953.54671688814\n",
      "Training step:  1728\n",
      "Loss: 262365.0371790503\n",
      "Training step:  1729\n",
      "Loss: 199950.26379756787\n",
      "Training step:  1730\n",
      "Loss: 262361.8955315771\n",
      "Training step:  1731\n",
      "Loss: 199946.9857274917\n",
      "Training step:  1732\n",
      "Loss: 262358.7585159662\n",
      "Training step:  1733\n",
      "Loss: 199943.71249467955\n",
      "Training step:  1734\n",
      "Loss: 262355.62612099113\n",
      "Training step:  1735\n",
      "Loss: 199940.44408715243\n",
      "Training step:  1736\n",
      "Loss: 262352.4983353532\n",
      "Training step:  1737\n",
      "Loss: 199937.18049291061\n",
      "Training step:  1738\n",
      "Loss: 262349.37514775124\n",
      "Training step:  1739\n",
      "Loss: 199933.92170003877\n",
      "Training step:  1740\n",
      "Loss: 262346.2565470387\n",
      "Training step:  1741\n",
      "Loss: 199930.66769671382\n",
      "Training step:  1742\n",
      "Loss: 262343.14252211316\n",
      "Training step:  1743\n",
      "Loss: 199927.41847111538\n",
      "Training step:  1744\n",
      "Loss: 262340.0330618621\n",
      "Training step:  1745\n",
      "Loss: 199924.17401146304\n",
      "Training step:  1746\n",
      "Loss: 262336.9281552047\n",
      "Training step:  1747\n",
      "Loss: 199920.93430600103\n",
      "Training step:  1748\n",
      "Loss: 262333.8277910745\n",
      "Training step:  1749\n",
      "Loss: 199917.69934301646\n",
      "Training step:  1750\n",
      "Loss: 262330.7319584663\n",
      "Training step:  1751\n",
      "Loss: 199914.46911083677\n",
      "Training step:  1752\n",
      "Loss: 262327.6406464227\n",
      "Training step:  1753\n",
      "Loss: 199911.2435979091\n",
      "Training step:  1754\n",
      "Loss: 262324.55384414626\n",
      "Training step:  1755\n",
      "Loss: 199908.02279266357\n",
      "Training step:  1756\n",
      "Loss: 262321.47154068557\n",
      "Training step:  1757\n",
      "Loss: 199904.80668352958\n",
      "Training step:  1758\n",
      "Loss: 262318.3937251806\n",
      "Training step:  1759\n",
      "Loss: 199901.59525900634\n",
      "Training step:  1760\n",
      "Loss: 262315.32038681145\n",
      "Training step:  1761\n",
      "Loss: 199898.38850765696\n",
      "Training step:  1762\n",
      "Loss: 262312.25151486776\n",
      "Training step:  1763\n",
      "Loss: 199895.18641808347\n",
      "Training step:  1764\n",
      "Loss: 262309.18709860113\n",
      "Training step:  1765\n",
      "Loss: 199891.98897889673\n",
      "Training step:  1766\n",
      "Loss: 262306.1271273134\n",
      "Training step:  1767\n",
      "Loss: 199888.7961787754\n",
      "Training step:  1768\n",
      "Loss: 262303.0715903627\n",
      "Training step:  1769\n",
      "Loss: 199885.60800642206\n",
      "Training step:  1770\n",
      "Loss: 262300.02047713654\n",
      "Training step:  1771\n",
      "Loss: 199882.42445060192\n",
      "Training step:  1772\n",
      "Loss: 262296.9737770555\n",
      "Training step:  1773\n",
      "Loss: 199879.24550006248\n",
      "Training step:  1774\n",
      "Loss: 262293.9314795206\n",
      "Training step:  1775\n",
      "Loss: 199876.0711436443\n",
      "Training step:  1776\n",
      "Loss: 262290.89357407956\n",
      "Training step:  1777\n",
      "Loss: 199872.90137024724\n",
      "Training step:  1778\n",
      "Loss: 262287.8600503281\n",
      "Training step:  1779\n",
      "Loss: 199869.73616879113\n",
      "Training step:  1780\n",
      "Loss: 262284.83089778334\n",
      "Training step:  1781\n",
      "Loss: 199866.57552818244\n",
      "Training step:  1782\n",
      "Loss: 262281.8061060298\n",
      "Training step:  1783\n",
      "Loss: 199863.41943739058\n",
      "Training step:  1784\n",
      "Loss: 262278.78566467034\n",
      "Training step:  1785\n",
      "Loss: 199860.26788543497\n",
      "Training step:  1786\n",
      "Loss: 262275.7695634202\n",
      "Training step:  1787\n",
      "Loss: 199857.12086141144\n",
      "Training step:  1788\n",
      "Loss: 262272.75779202685\n",
      "Training step:  1789\n",
      "Loss: 199853.97835439764\n",
      "Training step:  1790\n",
      "Loss: 262269.7503401811\n",
      "Training step:  1791\n",
      "Loss: 199850.84035353636\n",
      "Training step:  1792\n",
      "Loss: 262266.7471977156\n",
      "Training step:  1793\n",
      "Loss: 199847.70684799805\n",
      "Training step:  1794\n",
      "Loss: 262263.74835440196\n",
      "Training step:  1795\n",
      "Loss: 199844.57782698423\n",
      "Training step:  1796\n",
      "Loss: 262260.7538001018\n",
      "Training step:  1797\n",
      "Loss: 199841.45327972743\n",
      "Training step:  1798\n",
      "Loss: 262257.7635246537\n",
      "Training step:  1799\n",
      "Loss: 199838.33319550354\n",
      "Training step:  1800\n",
      "Loss: 262254.7775180191\n",
      "Training step:  1801\n",
      "Loss: 199835.21756367703\n",
      "Training step:  1802\n",
      "Loss: 262251.79577018507\n",
      "Training step:  1803\n",
      "Loss: 199832.10637358803\n",
      "Training step:  1804\n",
      "Loss: 262248.8182711048\n",
      "Training step:  1805\n",
      "Loss: 199828.99961463537\n",
      "Training step:  1806\n",
      "Loss: 262245.8450108138\n",
      "Training step:  1807\n",
      "Loss: 199825.8972762301\n",
      "Training step:  1808\n",
      "Loss: 262242.87597933214\n",
      "Training step:  1809\n",
      "Loss: 199822.79934785538\n",
      "Training step:  1810\n",
      "Loss: 262239.91116679565\n",
      "Training step:  1811\n",
      "Loss: 199819.70581900488\n",
      "Training step:  1812\n",
      "Loss: 262236.9505632811\n",
      "Training step:  1813\n",
      "Loss: 199816.61667921575\n",
      "Training step:  1814\n",
      "Loss: 262233.99415897304\n",
      "Training step:  1815\n",
      "Loss: 199813.53191806003\n",
      "Training step:  1816\n",
      "Loss: 262231.04194402625\n",
      "Training step:  1817\n",
      "Loss: 199810.4515251432\n",
      "Training step:  1818\n",
      "Loss: 262228.09390869236\n",
      "Training step:  1819\n",
      "Loss: 199807.3754901207\n",
      "Training step:  1820\n",
      "Loss: 262225.15004320425\n",
      "Training step:  1821\n",
      "Loss: 199804.30380264844\n",
      "Training step:  1822\n",
      "Loss: 262222.21033783787\n",
      "Training step:  1823\n",
      "Loss: 199801.23645247534\n",
      "Training step:  1824\n",
      "Loss: 262219.27478298754\n",
      "Training step:  1825\n",
      "Loss: 199798.17342936184\n",
      "Training step:  1826\n",
      "Loss: 262216.343368968\n",
      "Training step:  1827\n",
      "Loss: 199795.11472307524\n",
      "Training step:  1828\n",
      "Loss: 262213.4160861586\n",
      "Training step:  1829\n",
      "Loss: 199792.06032341573\n",
      "Training step:  1830\n",
      "Loss: 262210.49292492424\n",
      "Training step:  1831\n",
      "Loss: 199789.01022021222\n",
      "Training step:  1832\n",
      "Loss: 262207.5738757048\n",
      "Training step:  1833\n",
      "Loss: 199785.96440340395\n",
      "Training step:  1834\n",
      "Loss: 262204.65892912325\n",
      "Training step:  1835\n",
      "Loss: 199782.92286295927\n",
      "Training step:  1836\n",
      "Loss: 262201.7480756471\n",
      "Training step:  1837\n",
      "Loss: 199779.88558877376\n",
      "Training step:  1838\n",
      "Loss: 262198.84130576043\n",
      "Training step:  1839\n",
      "Loss: 199776.8525708396\n",
      "Training step:  1840\n",
      "Loss: 262195.9386100573\n",
      "Training step:  1841\n",
      "Loss: 199773.82379917195\n",
      "Training step:  1842\n",
      "Loss: 262193.0399791225\n",
      "Training step:  1843\n",
      "Loss: 199770.79926383545\n",
      "Training step:  1844\n",
      "Loss: 262190.14540361444\n",
      "Training step:  1845\n",
      "Loss: 199767.77895492592\n",
      "Training step:  1846\n",
      "Loss: 262187.25487420487\n",
      "Training step:  1847\n",
      "Loss: 199764.76286255833\n",
      "Training step:  1848\n",
      "Loss: 262184.3683815695\n",
      "Training step:  1849\n",
      "Loss: 199761.75097688372\n",
      "Training step:  1850\n",
      "Loss: 262181.485916456\n",
      "Training step:  1851\n",
      "Loss: 199758.74328812904\n",
      "Training step:  1852\n",
      "Loss: 262178.6074696827\n",
      "Training step:  1853\n",
      "Loss: 199755.73978652013\n",
      "Training step:  1854\n",
      "Loss: 262175.7330320092\n",
      "Training step:  1855\n",
      "Loss: 199752.7404622745\n",
      "Training step:  1856\n",
      "Loss: 262172.86259419157\n",
      "Training step:  1857\n",
      "Loss: 199749.7453056841\n",
      "Training step:  1858\n",
      "Loss: 262169.9961471591\n",
      "Training step:  1859\n",
      "Loss: 199746.7543071081\n",
      "Training step:  1860\n",
      "Loss: 262167.1336817962\n",
      "Training step:  1861\n",
      "Loss: 199743.76745687643\n",
      "Training step:  1862\n",
      "Loss: 262164.2751889784\n",
      "Training step:  1863\n",
      "Loss: 199740.78474534766\n",
      "Training step:  1864\n",
      "Loss: 262161.42065960914\n",
      "Training step:  1865\n",
      "Loss: 199737.80616294467\n",
      "Training step:  1866\n",
      "Loss: 262158.57008469634\n",
      "Training step:  1867\n",
      "Loss: 199734.83170012446\n",
      "Training step:  1868\n",
      "Loss: 262155.7234552456\n",
      "Training step:  1869\n",
      "Loss: 199731.86134737314\n",
      "Training step:  1870\n",
      "Loss: 262152.8807622957\n",
      "Training step:  1871\n",
      "Loss: 199728.8950952229\n",
      "Training step:  1872\n",
      "Loss: 262150.041996959\n",
      "Training step:  1873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 199725.9329342257\n",
      "Training step:  1874\n",
      "Loss: 262147.20715028123\n",
      "Training step:  1875\n",
      "Loss: 199722.97485491476\n",
      "Training step:  1876\n",
      "Loss: 262144.37621334643\n",
      "Training step:  1877\n",
      "Loss: 199720.02084789585\n",
      "Training step:  1878\n",
      "Loss: 262141.54917730976\n",
      "Training step:  1879\n",
      "Loss: 199717.07090383442\n",
      "Training step:  1880\n",
      "Loss: 262138.72603341992\n",
      "Training step:  1881\n",
      "Loss: 199714.12501339798\n",
      "Training step:  1882\n",
      "Loss: 262135.90677281326\n",
      "Training step:  1883\n",
      "Loss: 199711.18316725537\n",
      "Training step:  1884\n",
      "Loss: 262133.09138672065\n",
      "Training step:  1885\n",
      "Loss: 199708.24535614907\n",
      "Training step:  1886\n",
      "Loss: 262130.2798664351\n",
      "Training step:  1887\n",
      "Loss: 199705.3115708509\n",
      "Training step:  1888\n",
      "Loss: 262127.47220324446\n",
      "Training step:  1889\n",
      "Loss: 199702.381802129\n",
      "Training step:  1890\n",
      "Loss: 262124.6683884309\n",
      "Training step:  1891\n",
      "Loss: 199699.45604081283\n",
      "Training step:  1892\n",
      "Loss: 262121.86841338032\n",
      "Training step:  1893\n",
      "Loss: 199696.5342777483\n",
      "Training step:  1894\n",
      "Loss: 262119.07226944246\n",
      "Training step:  1895\n",
      "Loss: 199693.61650382986\n",
      "Training step:  1896\n",
      "Loss: 262116.27994805892\n",
      "Training step:  1897\n",
      "Loss: 199690.70270995228\n",
      "Training step:  1898\n",
      "Loss: 262113.49144060718\n",
      "Training step:  1899\n",
      "Loss: 199687.7928870519\n",
      "Training step:  1900\n",
      "Loss: 262110.7067385626\n",
      "Training step:  1901\n",
      "Loss: 199684.88702608252\n",
      "Training step:  1902\n",
      "Loss: 262107.92583337968\n",
      "Training step:  1903\n",
      "Loss: 199681.9851180576\n",
      "Training step:  1904\n",
      "Loss: 262105.14871661266\n",
      "Training step:  1905\n",
      "Loss: 199679.0871540045\n",
      "Training step:  1906\n",
      "Loss: 262102.37537979125\n",
      "Training step:  1907\n",
      "Loss: 199676.19312499955\n",
      "Training step:  1908\n",
      "Loss: 262099.60581453395\n",
      "Training step:  1909\n",
      "Loss: 199673.30302214238\n",
      "Training step:  1910\n",
      "Loss: 262096.84001240853\n",
      "Training step:  1911\n",
      "Loss: 199670.416836518\n",
      "Training step:  1912\n",
      "Loss: 262094.0779650164\n",
      "Training step:  1913\n",
      "Loss: 199667.53455926923\n",
      "Training step:  1914\n",
      "Loss: 262091.31966400065\n",
      "Training step:  1915\n",
      "Loss: 199664.65618157698\n",
      "Training step:  1916\n",
      "Loss: 262088.56510106343\n",
      "Training step:  1917\n",
      "Loss: 199661.7816946335\n",
      "Training step:  1918\n",
      "Loss: 262085.81426785322\n",
      "Training step:  1919\n",
      "Loss: 199658.91108963662\n",
      "Training step:  1920\n",
      "Loss: 262083.0671560725\n",
      "Training step:  1921\n",
      "Loss: 199656.04435784032\n",
      "Training step:  1922\n",
      "Loss: 262080.3237574946\n",
      "Training step:  1923\n",
      "Loss: 199653.1814905686\n",
      "Training step:  1924\n",
      "Loss: 262077.58406395811\n",
      "Training step:  1925\n",
      "Loss: 199650.3224791433\n",
      "Training step:  1926\n",
      "Loss: 262074.84806726463\n",
      "Training step:  1927\n",
      "Loss: 199647.467314901\n",
      "Training step:  1928\n",
      "Loss: 262072.11575923432\n",
      "Training step:  1929\n",
      "Loss: 199644.61598920886\n",
      "Training step:  1930\n",
      "Loss: 262069.38713171674\n",
      "Training step:  1931\n",
      "Loss: 199641.76849344178\n",
      "Training step:  1932\n",
      "Loss: 262066.66217655744\n",
      "Training step:  1933\n",
      "Loss: 199638.92481902317\n",
      "Training step:  1934\n",
      "Loss: 262063.9408857101\n",
      "Training step:  1935\n",
      "Loss: 199636.0849574322\n",
      "Training step:  1936\n",
      "Loss: 262061.22325110444\n",
      "Training step:  1937\n",
      "Loss: 199633.24890013348\n",
      "Training step:  1938\n",
      "Loss: 262058.5092647132\n",
      "Training step:  1939\n",
      "Loss: 199630.41663865212\n",
      "Training step:  1940\n",
      "Loss: 262055.7989185099\n",
      "Training step:  1941\n",
      "Loss: 199627.58816449135\n",
      "Training step:  1942\n",
      "Loss: 262053.09220448288\n",
      "Training step:  1943\n",
      "Loss: 199624.76346921435\n",
      "Training step:  1944\n",
      "Loss: 262050.38911467206\n",
      "Training step:  1945\n",
      "Loss: 199621.94254441166\n",
      "Training step:  1946\n",
      "Loss: 262047.68964113755\n",
      "Training step:  1947\n",
      "Loss: 199619.12538168332\n",
      "Training step:  1948\n",
      "Loss: 262044.99377593925\n",
      "Training step:  1949\n",
      "Loss: 199616.31197266403\n",
      "Training step:  1950\n",
      "Loss: 262042.30151118853\n",
      "Training step:  1951\n",
      "Loss: 199613.50230903187\n",
      "Training step:  1952\n",
      "Loss: 262039.61283905938\n",
      "Training step:  1953\n",
      "Loss: 199610.6963825114\n",
      "Training step:  1954\n",
      "Loss: 262036.92775174434\n",
      "Training step:  1955\n",
      "Loss: 199607.89418480828\n",
      "Training step:  1956\n",
      "Loss: 262034.2462413728\n",
      "Training step:  1957\n",
      "Loss: 199605.09570765516\n",
      "Training step:  1958\n",
      "Loss: 262031.56830016966\n",
      "Training step:  1959\n",
      "Loss: 199602.30094283156\n",
      "Training step:  1960\n",
      "Loss: 262028.8939203618\n",
      "Training step:  1961\n",
      "Loss: 199599.5098821299\n",
      "Training step:  1962\n",
      "Loss: 262026.22309420526\n",
      "Training step:  1963\n",
      "Loss: 199596.72251737723\n",
      "Training step:  1964\n",
      "Loss: 262023.5558139777\n",
      "Training step:  1965\n",
      "Loss: 199593.93884041658\n",
      "Training step:  1966\n",
      "Loss: 262020.89207197697\n",
      "Training step:  1967\n",
      "Loss: 199591.15884310944\n",
      "Training step:  1968\n",
      "Loss: 262018.23186052204\n",
      "Training step:  1969\n",
      "Loss: 199588.3825173803\n",
      "Training step:  1970\n",
      "Loss: 262015.575172004\n",
      "Training step:  1971\n",
      "Loss: 199585.60985516803\n",
      "Training step:  1972\n",
      "Loss: 262012.92199880633\n",
      "Training step:  1973\n",
      "Loss: 199582.84084841117\n",
      "Training step:  1974\n",
      "Loss: 262010.2723333025\n",
      "Training step:  1975\n",
      "Loss: 199580.07548907673\n",
      "Training step:  1976\n",
      "Loss: 262007.62616790965\n",
      "Training step:  1977\n",
      "Loss: 199577.31376917483\n",
      "Training step:  1978\n",
      "Loss: 262004.98349509097\n",
      "Training step:  1979\n",
      "Loss: 199574.55568074025\n",
      "Training step:  1980\n",
      "Loss: 262002.34430733926\n",
      "Training step:  1981\n",
      "Loss: 199571.80121582886\n",
      "Training step:  1982\n",
      "Loss: 261999.70859710846\n",
      "Training step:  1983\n",
      "Loss: 199569.0503664797\n",
      "Training step:  1984\n",
      "Loss: 261997.07635689285\n",
      "Training step:  1985\n",
      "Loss: 199566.30312480696\n",
      "Training step:  1986\n",
      "Loss: 261994.4475792387\n",
      "Training step:  1987\n",
      "Loss: 199563.55948292528\n",
      "Training step:  1988\n",
      "Loss: 261991.82225670267\n",
      "Training step:  1989\n",
      "Loss: 199560.81943300072\n",
      "Training step:  1990\n",
      "Loss: 261989.20038191328\n",
      "Training step:  1991\n",
      "Loss: 199558.0829672352\n",
      "Training step:  1992\n",
      "Loss: 261986.58194749782\n",
      "Training step:  1993\n",
      "Loss: 199555.35007781122\n",
      "Training step:  1994\n",
      "Loss: 261983.96694603725\n",
      "Training step:  1995\n",
      "Loss: 199552.62075695835\n",
      "Training step:  1996\n",
      "Loss: 261981.3553702469\n",
      "Training step:  1997\n",
      "Loss: 199549.8949969325\n",
      "Training step:  1998\n",
      "Loss: 261978.74721274668\n",
      "Training step:  1999\n",
      "Loss: 199547.17278996418\n",
      "Loss_min: tensor(24857.3717, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_city_date_path = make_dir('wuhan','02-09')\n",
    "features=['I', 'cured','dead']\n",
    "I_init = float(data_wh['I'].iloc[0])\n",
    "R_init = float(data_wh['cured'].iloc[0])\n",
    "D_init = float(data_wh['dead'].iloc[0])\n",
    "N = 2870000.\n",
    "S,I,E,R,D = train(data_wh, model_city_date_path, N=N, I_init=I_init, R_init=R_init, D_init=D_init, features=features, max_epoches=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_city_date_path='models/wuhan/02-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  258   363   425   495   572   618   698  1590  1905  2261  2639  3215\n",
      "  4109  5142  6384  8351 10117 11618 13603 14982 16902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAGDCAYAAACiFo3zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZyO1f/H8dcZY9+3EYYoQiYGY/tVNGWZ7FsTJURpU0mbkmiXlKX6KlFKMkbRUNY0tiJLpJCsMQjZGYaZOb8/zj3NDINRM3PP8n4+Hvfjvq7Pda7rPhd9vz6PsxprLSIiIiKSdfl4uwIiIiIi8t8ooRMRERHJ4pTQiYiIiGRxSuhEREREsjgldCIiIiJZnBI6ERERkSxOCZ2IiIhIFufr7QqIiGQEY0x74OkULs0HWqQQ32etvcMYEwGUTOF6F+BBoFkK116z1s457/fzAN+nVDdr7U3GmA+BmilcftRauzal+0REEiihE5Gcoiww1Fr7XULAGFMIGA8ssta+kLSwMeZLz+E5a+1N510bAeQDqgO3WGtjk1xrA5RJ4fd9gJ3W2u4X+Z2SKfxOP6Bo6l9RRHIqdbmKiIiIZHFK6ERERESyOCV0IiIiIlmcEjoRkXRgjLnbGHPS85lz+TtEJNMz5mOMOYAxv50XfxRjNmPMBowZ7onlwZhPMOZXjPkFY25JUr6eJ74VY8ZgjPHE38KY3zFmPcbMwJhiqa2aEjoRkXRgrZ1srS3k+dzu7fqISJqYCIQkixgTDLQHamFtTWCE58r9AFh7A9AceBtjEvKusUBfoKrnk/DMBUAA1tYC/gCeS23FlNCJiIiIpIa1S4DD50UfAoZhbYynzAFP/HpgYZLYUSAIY8oCRbB2OdZa4DOgg6fcfBJnza8A/FNbNSV0IiIiIv/edcDNGPMTxizGmPqe+C9Ae4zxxZjKQD2gAlAeiEpyf5Qndr7eQKqHa2gdOhEREZF/zxcoDjQC6gPhGHMN8DFQA1gN/An8CMQCJoVn2GRnxgzylJ18JZUQEckp3jbGHElyngvYA9xjjLnpvLIJu0PcYIxZdN61a4H3PMcLjTFJ/8+4JPD2RX6/eQrPStgdonQK18qTMA5HRDKrKGC6p/t0JcbEA6Ww9iDwxD+ljPkR2AIcIXlXqj+wN0m5nkAb4DbPM1NFCZ2I5AjW2g+AD/7FfdUucbnrFTznDCnvIJFwvemV1EtEMo2vgVuBRRhzHZAH+BtjCgAGa09hTHMgFms3AmDMCYxpBPwE9ADe9cRDgGeBplgbfSWVMFeQ/ImIiIjkXMZMAW4BSgH7gSHAJFz3aiBwFngKa7/HmErAPCAe1xPQB2v/9DwnCDdjNj9unNyjWGsxZiuQFzjk+cUVWPtgqqqmhE5EREQka9MsVxEREZEsLseNoStVqpStVKmSt6shIiIicllr1qz521pb+nLlclxCV6lSJVavXu3taoiIiIhcljHmz9SUU5eriIiISCr07g1+fhAQkBi7804IDHSfSpXcd4I33oAqVaBaNZg3L/mz4uKgTh1o0yYxtnAh1K3rnnHTTbB1a+rrlm4JnTHmY2PMAZNkA1tjzFRjzDrPZ6cxZp0nXskYczrJtQ+S3FPPGPOrMWarMWaM8Wxga4wpYYxZYIzZ4vkunl7vIiIiItKrF8ydmzw2dSqsW+c+nTtDp04uvnEjhIXBhg3unocfdklcgtGjoUaN5M966CGYPNk966674NVXU1+39Gyhm8h5G9haa++01gZaawOBr4DpSS5vS7hmk0/RvdgGtgOBhdbaqri90gamz2uIiIiIQJMmUKJEyteshfBw6NbNnUdEQNeukDcvVK7sWupWrnTXoqLg22/hvvuSP8MYOH7cHR87BuXKpb5u6TaGzlq7xLg1WC7gaWULxS3Ed1HGs4GttXa55zxhA9s5QHvcWjAAnwKLcIvxXbFz584RFRXFmTNn/s3tkgr58uXD39+f3Llze7sqIiIiaW7pUihTBqpWded79kCjRonX/f1dDKB/fxg+HE6cSP6M8eOhVSvInx+KFIEVK1y3bWp4a1LEzcB+a+2WJLHKxpi1wHHgBWvtUi69gW0Za+0+AGvtPmOM38V+zBjTF9fKR8WKFS+4HhUVReHChalUqRKeHl1JQ9ZaDh06RFRUFJUrV/Z2dURERNLclCmJrXPgWuzOZwx8840bh1evHixalPz6yJEwezY0bAhvvQUDBqT+9701KaIbMCXJ+T6gorW2DjAA+MIYU4TUbGCbCtbacdbaIGttUOnSF878PXPmDCVLllQyl06MMZQsWVItoCIiki3FxsL06W6CRAJ/f9i9O/E8Ksp1of7wA8yc6SZQdO0K338P3bvDwYPwyy8umQP3rB9/TH0dMjyhM8b4Ap2AqQkxa22MtfaQ53gNsA24Dtcid7ENbPd7umQTumYP/Md6/Zfb5TL05ysiItnVd99B9eouiUvQrp2bFBETAzt2wJYt0KCB60KNioKdO931W2+Fzz+H4sXduLk//nD3L1hw4aSJS/FGC10z4Hdr7T9dqcaY0saYXJ7ja3CTH7Z7ulRPGGMaecbd9QAiPLfNBHp6jnsmiYuIiIikuW7doHFj2LzZJW8TJrh4WFjy7laAmjUhNBSuvx5CQuD99yFXros/29cXPvrIzZStXRsmTXLdrqmVbnu5mhQ2sLXWTjDGTARWWGuTLk3SGXgZiAXiPGVnea5dsIGttdYaY0oC4UBFYBdwh7X28OXqFRQUZM9fWHjTpk3USG0aPHw41K8PwcGJschIWLUKnnkmdc/Ioa7oz1lEREQwxqyx1gZdrlx6znLtdpF4rxRiX+GWMUmp/GogIIX4IeC2/1bLf6F+fZdyh4e7pC4yMvH8Xxo6dCgrVqzA19f9dcTGxtKoUaMUY0C6xocOHfqv30NERCQ7y8xtOjlu66/L6t/freh3KeXKQcuWULYs7NvnOrlfesl9UhIYCKNGXfKRYWFhFCtWDICjR48yatSoFGMXK5uWcREREblQOrTppBkldP9G8eIumdu1CypWdOciIiKSrQUHu+QtNNQtMrxkSWJy521K6M6XmlaqhJR88GAYOxaGDMkcf5siIiKSfoYPJ7h+fapVC2b6dLc9VzCRMNz7fa7eWocu60ravvryy4mpemSkt2smIiIi6al+fV5pvYIffoA6gZb5354lssNo1xfrZUrortSqVcnbVxPaX1et8m69REREJF19uiuYIacHUs1nMz8erEp4XBdCTTiReL+XTl2uVyqlJtXgYHW5ioiIZGMnT7oUoHARWJDvbvLt2Ubwo60I75iHVau8nwaohU5ERETkEqyF3r3h779hRq0hVDiwBu64A6ZMIZhIbw+fA9RClyn4+fnRo0cPfHxcfh0fH09ISEiKMSDd4yIiIpLonXdg2jR4s9kCbv3uFbedQ3h48nH1Xm6iS7edIjKr/7xThPxr+nMWEZGsZtEiaNYMOjQ/ybTI0phKV8P69ZAnjyuQzisLe32nCBEREZGsLCrKNcBVrWL55EAbTL68MGdOYjIHmWYcvcbQiYiIiJwnJsb1rJ45AzMavEHhnxfDJ59A5crerlqKlNCJiIiInOfxx2HlSpj40E9UnzQIHnsMOnb0drUuSgmdiIiIZG29e4OfHwQEXHhtxAgwxk1RBThyxCVmtWpBgwbw22+JZUeOhJo1OeIfQNMPuzHovv10GhcCJUq4rtaAAPdb585lzHtdASV0V2j48As3hYiMdHERERHxgl69YO7cC+O7d8OCBW7f9QSvvw6BgW5iw2efuaY4gD17YMwYfh63mrJ//0a50rG8tPBGiI93/8hv3gy//gqnT8P48RnyWldCkyKuUP36yWcoJ52x/G8NHTqUFStW4Ovr/jpiY2Np1KhRijEgS8SHDh367/9ARERErkSTJrBz54XxJ55wyVj79omxjRvhuefccfXq7r79+wGIOxvLvV1PU7Z0bhr5rCPXjm3w5ZduMF2CBg3cbIlMRgndefr3h3XrLl2mXDlo2RLKloV9+6BGDXjpJfdJSWAgjBp16WeGhYVRrFgxAI4ePcqoUaNSjF2sbGaMi4iIeM3MmVC+PNSunTxeuzZMnw433eQGyf35J0RFERdYjw8LP8UPmyuSt6AvuU8dg379kidz587BpEkwenTGvksqqMv1Xyhe3CVzu3a57+LFvV0jERER+Ud0NLz2Grz88oXXBg504+gCA+Hdd6FOHfD15bWnjlB9cwQRg9eQ2xcoWhTq1k1+78MPu9bAm2/OkNe4EmqhO09qGpcSulkHD4axY2HIkEyxBI2IiIgAbNsGO3Ykts5FRbnkbOVKuOoqt/wIuD29Klfmmw2V+XXUPG69rhJ3L+jl4oMHuwWD773XlX3pJTh4ED780CuvdDlK6K7Q+bt8BAdnml0/REREBOCGG+DAgcTzSpVg9WooVQqOHoUCBdziwOPHcyywCXc9WITONSryf/tnwh+HYOpU+PZbCPJs0DB+PMybBwsXgk/m7NzMnLXKxFatSp68BQe781WrvFsvERGRHKtbN2jc2M1E9feHCRMuXnbTJqhZE6pXJ3bWHEJ+H03evPDy0yfwOXwIihVzXbXx8dC3r7vnwQfdxInGjV1XbUpduV6mFrorlNJWbZlk1w8REZGcacqUS19POgO2cWPYsgVr4a47YeUWWPD5fir0u9Mla8uXQ758ye+PjU3zKqc1JXQiIiKS47zzDkybBm++Hset73Z0M1jDwy9M5rIIJXSZgJ+fHz169MDH0y8fHx9PSEhIijEgy8RFREQyQu/e8M03brOIhI0fhg6Fjz6C0qXd+euvQ6tWbp3hRx6BLVtc72q9dRNg+XKiP53GHf2rsm0b5MoFbdvCsGHu3pgY6NED1qyBkiXdELtKlbzxphdnrLXerkOGCgoKsqtXr04W27RpEzVq1PBSjXIO/TmLiEh6WLIEChVySVfShK5QIXjqqeRl58yB7t2hTBn4pM8yOj1VmT0Pvkr022P56Sc3hOrsWbjtNnj+ebj9dvjf/9zGEh98AGFhMGOGS+oygjFmjbU26HLlNCnCI6clthlNf74iIpJemjRx261eTkyMS/TOnYPp7++jwesdOJOrIDHDRlKgQOJ4+Dx53ConCRtCRERAz57uuEsXN9k1s/2zpoQOyJcvH4cOHVLSkU6stRw6dIh8WXRcgoiIZE3vvQe1arku2SNH3LatK1fCxPGxVB98B19Fh1CnQW7yFk3+79PRozBrlmulA7fNa4UK7tjX1605fOhQBr/MZWgMHeDv709UVBQHDx70dlWyrXz58uHv7+/taoiISA7x0ENubWBj3He7drBsGTz7LHRaO5gNPxzhWb85zJ9UMNl9sbFuFZTHHoNrrnGxlNp7jMmAl7gCSuiA3LlzU7lyZW9XQ0RERNJImTKJx40awRtvuBa3V2+aS1TbSXQsuobPphfm2muT39e3L1St6vZ2T+DvD7t3u+/YWDh2LHVdvBlJXa4iIiKS7ezb577//ttNlsifH6a8vZeTPR+hdb6FvDG2GDfemPyeF15wydr524C2aweffuqOv/wSbr0187XQaZariIiIZGndusGiRS55K1PGbbu6aBGsW+fWFI6Ohm8jYgl5M5hXf2rOG74vUPW6xDat+fPdzNYKFaB6dcib18X79YP77oMzZ+Cee2DtWtcyFxaW2B2b3lI7y1UJnYiIiGRLzz/vulrHj4c+2we5xeg+/xzuvtvbVUu11CZ0GkMnIiIi2c7XX7tk7v77oY//PLjvddfcloWSuSuhMXQiIiKS5Q0fDpGR7njzZjdurlo1qFTiuOsvDQiA0aO9W8l0pIROREREsrz69SE0FGbPhk6d3KSFgwctjee86AbRTZsGBQp4u5rpRl2uIiIikuUFB7vJCq1auQkORYvCl60+Ifjz0fDZZ262QzaWbi10xpiPjTEHjDG/JYkNNcbsMcas83xaJbn2nDFmqzFmszGmZZJ4iCe21RgzMEm8sjHmJ2PMFmPMVGNMnvR6FxEREcn8Fi1yyRzAY222Ezz5PrdNxD33eLVeGSE9u1wnAiEpxEdaawM9n9kAxpjrga5ATc89/zPG5DLG5ALeB24Hrge6ecoCvOl5VlXgCNAnHd9FRERE/o3evcHPz41hSzB4sNuTKzAQWrSAvXsTry1a5OI1a0LTponxuXPdoLgqVWDYsMR4nz5QuzZHilWi9qtdKJn3JC/0P8HYL4oQ6Xcn5JCNA9ItobPWLgEOp7J4eyDMWhtjrd0BbAUaeD5brbXbrbVngTCgvTHGALcCX3ru/xTokKYvICIiIv9dr14uGUvq6adh/Xq3UFybNvDyyy5+9Cg8/DDMnAkbNrhxbwBxcfDIIzBnDmzcCFOmuG+AkSNZ8eEvlDm5jSj8+fGW53hlXTvCfe8m9MC7RBZonWGv6k3emBTRzxiz3tMlW9wTKw/sTlImyhO7WLwkcNRaG3teXERERDKTJk0u3CerSJHE41OnErdd+OILN6OhYkV37ufnvleudC1z11wDefJA164QEQHArqNF6NABChfxoX3QXq5b+AEsWkRwvuWEj9jNqtg66fyCmUNGJ3RjgWuBQGAf8LYnntIGGvZfxFNkjOlrjFltjFl98ODBK6uxiIiIpL1Bg9zWDJMnJ7bQ/fEHHDkCt9wC9eq5yQwAe/a4sgn8/WHPHk6edNtyjTh8L/t9rqLyX8vdZqsA/fsTPKAOzzyToW/lNRma0Flr91tr46y18cBHuC5VcC1sSf6m8Af2XiL+N1DMGON7XvxivzvOWhtkrQ0qXbp02ryMiIiI/HuvveZ2vL/7bnjvPReLjYU1a+Dbb2HePHjlFZfkpbCrlcXQvTv8+iuUjpiAb6f2EBUFuXO7TVnHjk1cmC4HyNCEzhhTNslpRyBhBuxMoKsxJq8xpjJQFVgJrAKqema05sFNnJhp3X5lkUAXz/09gYiMeAcRERFJQ3fdBV995Y79/SEkBAoWhFKlXHftL7+4+O4kI7Ciopj3WzkiImDU23G0nNILPvrIdcfWresSwfBwtzBdDknq0nPZkinAcqCaMSbKGNMHGG6M+dUYsx4IBp4AsNZuAMKBjcBc4BFPS14s0A+YB2wCwj1lAZ4FBhhjtuLG1E1Ir3cRERGRNLRlS+LxzJmJa8S1bw9Ll7qWuuho+OknqFHDrRq8ZQvs2AFnz3J4bBhPLm7Hg/fF0m9eW5g0yc2Wbd8ebrrJPSs42CV1q1Zl/Pt5gbEpNGNmZ0FBQXb16tXeroaIiEjO0K2bW4rk77+hTBl46SW3ncPmzeDjA1dfDR98AOU9cxvfegs++cRdu+8+6N/fxWfPhv79OX0qjjf29+aHmwcyN38ncs+ZCVddBSVLQu3arqs16aSLLM4Ys8ZaG3TZckroREREJCvYuRMaNIBiReNZUb4LJRbPcAncgw96u2rpJrUJnbb+EhERkUzvxAlo2xbOnbXMKnoPJZZGwMSJ0LOnt6uWKSihExERkUwtLs7Nndi0yTK3yqNU+yXcLS4cGurtqmUaSuhEREQkUxs4EL75Bv5X/nWa7fjIzYpt187b1cpUlNCJiIhIpvXxxzBiBPQrPpmHDr8Gs2a5Ga2SjBI6ERERyZSWLIEHH7S0yL+MkWc9e7k2bertamVKSuhEREQk09m+HTp1iOMau4OpubvjO28uNGrk7WplWkroREREJFM5dgzatjhD/NHTfFPsLoot/Brq1PF2tTI1JXQiIiKSacTGQtdWx/ljW37mF7+PKks/gZo1vV2tTC9D93IVERGRnKV3b/Dzg4CAxNjgwVCrFgQGuvkNe/e6+KJFULBAPHN/LMJVuQ6y9J5x/yRzc+dCtWpQpQoMG5b4rLvvdvGAAPdb585l3LtlJkroREREJN306uWSsaSefhrWr4d166BNG3j5ZRefNTaKs+d86F/kY3ZvO8eLo0sCbh26RzxzIjZudEvQbdzo7rn7bvj9d/j1Vzh9GsaPz7h3y0yU0ImIiEi6adIESpRIHku61eqpU2AMRI5Yw6jwqyid6xBvrW/p9nj1WLnStcxdcw3kyQNdu0JEhLvWqpW73xi3LVhUVAa8VCakhE5EREQy3KBBUKECTJ4Mvaoso/PTlamQez+xhYtTr115br8dNmxwZffscWUT+Pu7WFLnzsGkSRASknHvkJkooRMREZEM99prsHs3dKq+gdZPVcfH14eI7wqya7cPv/wCjz4KHTq4stZeeL8xyc8ffti1Bt58c/rXPTNSQiciIiJeETvxcyK/OswhSjJ9Zm5qNylGoULuWqtWrtXt779di9zu3Yn3RUVBuXKJ5y+9BAcPwjvvZGz9MxMldCIiIpKhtmwBxo3jiXuPsoybqVcnnia3F+SvvxJb41auhPh4KFkS6td39+zYAWfPQlhY4lau48fDvHluooRPDs5qtA6diIiIpJtu3WDRtyf5O7oA/v4+vPQSzB6zheXr27CPclxTOZ6IWbkA+PJLGDsWfH0hf36XuBnjzt97D1q2dDNee/dOXJruwQfd/InGjd15p07w4oteelkvMjaljulsLCgoyK5evdrb1RAREck5IiMhNBTCw2H5cr4b9D0hzOX2hkf4+ofS5Mrl7QpmXsaYNdbaoMuVUwudiIiIpKvhq4Kp/9x8gtvcxOZof+5gBRXKnKNBayVzaSUH9zaLiIhIRqhfH0KH1iAi+jbaMgubNx/Hz+Xnppu8XbPsQwmdiIiIpKvgyjuZEtOZO/iSbaYK5uxZvhy0luBgb9cs+1BCJyIiIuknNhZat2bu2Vs5Rx7irQ+Pdj9C8Bst3Ng6SRNK6ERERCT9vPwyUzcG8DZPki8fDB4MY+dUIvK5+bBqlbdrl21oUoSIiIikj8WL2fDKdHr5/Iyvj9t/tUULCA6G0NA6hIfXQb2uaUMtdCIiIpL2Dh/m2F0P0TH3LHwL+PLFFy6ZA5fQhYergS4tqYVORERE0pa1xPe5n577hrHDpxLfzzYX7LEaHIwmRaQhJXQiIiKStsaNY9jX1YigHaPf4YJkTtKeulxFRERyot69wc8PAgISY9OmuT21fHzg/F2V1q93+2vVrAk33ABnzrj4oEFQoQIUKuTON2xg3qPf8CF92eAXzKOf1IFatWD27Ix5rxxKCZ2IiEhO1KsXzJ2bPBYQANOnQ5MmyeOxsdC9O3zwAWzYAIsWQe7c7lrbtrBypTs+c4adnZ/krthPebvYq1z7XChm7Vq3KevDD6f3G+Vo6nIVERHJiZo0gZ07k8dq1Ei57Pz5rpWtdm13XrJk4rVGjf45PP3E83Ta/DpxBQvTvGUu8sYcdxeOHYNy5dKu7nIBJXQiIiJyaX/8AcZAy5Zw8CB07QrPPJOsiI2L46EParGWuswKg6L1hrppre++C6dOwXffeafuOYS6XEVEROTSYmNh2TKYPNl9z5gBCxcmXt+7l9gzcXxKL4YMiqVNG2DKFNetGxXlxs/dcw/Ex3vrDbI9JXQiIiJyaf7+0LQplCoFBQpAq1bw88/uWlwcy9u9QQx5aNX0JC++7On8mzABQkPdcePGbhLF3397p/45gBI6ERERubSWLd0s1+ho11q3eDFcfz0A+198ny5rBmKAz2cUwichs6hYMbEVb9Mml9CVLu2V6ucESuhERERyom7dXMvZ5s2uBW7CBNeV6u8Py5dD69YukQMoXhwGDID69SEwEOrWhdatOffjKr5/fTkraUgBE03xG/xh6FB3z9tvw0cfuYkU3brBxIluHJ6kC2OtTZ8HG/Mx0AY4YK0N8MTeAtoCZ4FtwL3W2qPGmErAJmCz5/YV1toHPffUAyYC+YHZwOPWWmuMKQFMBSoBO4FQa+2Ry9UrKCjIrj5/bR0RERG5MsePM6DiNEYe68OkD07R/YGC3q5RtmSMWWOtDbpcufRsoZsIhJwXWwAEWGtrAX8AzyW5ts1aG+j5PJgkPhboC1T1fBKeORBYaK2tCiz0nIuIiEgGCGs9iZHH+vBol71K5jKBdEvorLVLgMPnxeZba2M9pysA/0s9wxhTFihirV1uXVPiZ0AHz+X2wKee40+TxEVERCQd/fbGLPos68WNFXcxYrLWl8sMvDmGrjcwJ8l5ZWPMWmPMYmNMwq5v5YGoJGWiPDGAMtbafQCeb7/0rrCIiEhOd2ztdjoNqkGR3GeY9kN58uTxdo0EvLSwsDFmEBALTPaE9gEVrbWHPGPmvjbG1ARSGj15xYP+jDF9cd22VKxY8d9VWkREJIeLP3OWHrfuZof9PyKnHKasfy5vV0k8MryFzhjTEzdZ4m5PNyrW2hhr7SHP8RrchInrcC1ySbtl/YG9nuP9ni7ZhK7ZAxf7TWvtOGttkLU2qLSmTIuIiPwrr7dYxMyjTXmnzwZu6lzG29WRJDI0oTPGhADPAu2stdFJ4qWNMbk8x9fgJj9s93SlnjDGNDLGGKAHEOG5bSbQ03PcM0lcRERELqN3b/Dzg4CAxNi0aVCzJvj4wPkLQox9bBODlzanaJ5oxv0UyJkzcOKEW8Uk4VOqFPTv78pPnOiWnUu4Nn58hr1ajpRuXa7GmCnALUApY0wUMAQ3qzUvsMDlZ/8sT9IEeNkYEwvEAQ9aaxMmVDxE4rIlc0gcdzcMCDfG9AF2AXek17uIiIhkN716Qb9+0KNHYiwgAKZPhwceSF52y4pDPPpuVarm3sm6PWU4bSB3bsiXD9atSyxXrx506pR4fued8N576foa4pFuCZ21tlsK4QkXKfsV8NVFrq0GAlKIHwJu+y91FBERyamaNIGdO5PHatS4sFz0KUvIrWfxIY45089QoFQBCqTwvC1b4MABuPnmFC5KutNOESIiIpIia+GhW39n++ky3FT1AA+/W4O6dWH48AvLTpniWuSSbgbx1VdQqxZ06QK7d2dcvXMiJXQiIiKSorEv7OGzlTVoXmodO875M3kyLFvmdghL2KY1QViY2+ErQdu2rgVw/Xpo1gx69kTSkRI6ERERucD61TH0f92P1nkX0OvVKjRtaihVCgoUgFat4OefE8v+8gvExroxdAlKloS8ed3x/ffDmjUZW/+cRgmdiIiIJHP2LDzbP4aK/MmksDzcHlqE9eshOtolbosXw/XXJ5afMiV56xzAvmKIgTcAACAASURBVH2JxzNnpjw+T9KOVxYWFhEREe/q1g0WLYK//wZ/f3jpJShRAh59FPbutVhbmKrljlC8Q1MABgyA+vXdGLlWraB168RnhYfD7NnJnz9mjEvkfH3dcydOzLBXy5GMZ23fHCMoKMiuPn9xHREREQHgiftOMGpCYSZfM5i7fn/RrU8iXmOMWWOtDbpcOXW5ioiI5FDDh0NkZOL5lMnxjJpQmBt9fuSu+b2UzGUhSuhERERyqPrbwgjteJbISPj1V7i3Zxy+nGXIzZFw7bXerp5cASV0IiIiOVRw1zKE21Du6HCOpjee41ycD2G+PWg+5P+8XTW5QkroREREMpuUNlo9fBiaN4eqVd33kSMu/vvv0LixWyNkxIjLPwfcCsCBgfDEE9ySfwVLj9fiyInc9GASnWd0h+Dg9H0/SXNK6ERERDKbXr1g7tzksWHD4Lbb3B5bt93mzsFNIR0zBp56KnXPAZg61W3Cum4dkX5dmUI3mjOfb/J1JrJgm7R+G8kASuhEREQymyZNXKKWVERE4nYLPXvC11+7Yz8/t55IShMYUnpOEmNHx1D116/YzHXM6zSO8Dz3/DOmTrIWJXQiIiJZwf79ULasOy5bFg4c+E+PO7L/LN8M+J7DlGDsY5sxX31J8NePE25DWRW2LQ0qLBlJCwuLiIjkMPZcLL3rrqNd/NcUq12JEqOHuAvBwQR/DcGrvgKe8Wod5coooRMREckKypRx+2mVLeu+/fz+3XPi4xlzYxiz9nbl8zwhFPxmffLrwcGaFJEFqctVREQkK2jXDj791B1/+im0b3/lz7CWlV2G8/SqUF7wn0iBRje4fb8ky1MLnYiISGaT0karAwdCaChMmAAVK8K0aa7sX39BUBAcPw4+PjBqFGzcCEWKXPCcU9cFcmfku5QrcpLnblqGadrNm28paUh7uYqIiOQA9sUhdHylDrN92rDsx1w0aGi8XSVJhdTu5aoWOhERkexu+HBGv3KMCDowckS8krlsSAmdiIhIdvbee6x89kue8fmR9m0sj/fX8PnsSAmdiIhIdvXxxxx5dDCh+TdTzi8Xn0w0GDXOZUtK6ERERLKjsDBsn/u4t/Qy9h4tzbJwQ/Hi3q6UpBe1u4qIiGQ3M2fCPfcw6poxRBz8P956y9CggbcrJelJCZ2IiEh2Mn8+3HEHP113D8/seoQOHeCxx7xdKUlvSuhERESyiyVLoEMHDldtyJ0nPsLf3/Dxx2jcXA6gMXQiIiLZwcqV0Lo1tuLV3Ou/gL3f52LZMjRuLodQC52IiEhW98sv0LIl+Pkx8s4VzJyXl7feQuPmchC10ImIiGRlmzZB8+ZQuDArRizj2dCidOyocXM5jRI6ERGRrGrbNmjWDHx8OPzl99x5R1n8/dG4uRxICZ2IiEhWtHs33HYbxMRgIxfRa1AV9u2DH36AYsW8XTnJaEroREREspq//nLJ3JEj8P33jFwQwKxZMHo01K/v7cqJN2hShIiISCY0ejQEBEDNmjBqlIvdeScE3hBLYOWjVNq6gEC/vaw4V49nn4Vbb4UpU1z5G26AM2cgOhpat4bq1V184EDvvpOkH7XQiYiIZDK//QYffeRWIsmTB0JCXGI2ddwx1zJnf+PJzn+Qp0pBQkPB39812n3xBdSuDYcOQe7cEBMDTz0FwcFw9qy7dc4cuP12b7+hpDW10ImIiGQymzZBo0ZQoAD4+kLTpjAjLAZatYL167FfTSd8RUVWrHCJXP/+UKeOS+YASpaEXLnc/cHBLpYnD9StC1FR3nsvST9K6ERERDKZgABYEnGYQ18vJToaZn8Tz+5xs2H5crjzTpYWbgXAokXw9ttgrZvV2rKlS9qGD7/wmUePwqxZrpVOsp90TeiMMR8bYw4YY35LEithjFlgjNni+S7uiRtjzBhjzFZjzHpjTN0k9/T0lN9ijOmZJF7PGPOr554xxmiStoiIZH01asCzvQ7QvEtRQhoeofa+ufhG7YRChaB3b0aNgr17oVMn6NcPYmNh2TKYPNl9z5gBCxcmPi82Frp1c2vTXXON115L0lF6t9BNBELOiw0EFlprqwILPecAtwNVPZ++wFhwCSAwBGgINACGJCSBnjJ9k9x3/m+JiIhkSX3eqs7P8/9myZaylNi9jqp5d0FEBPuvDyYiAsqXhwkTXMucv7/rli1VynWztmoFP/+c+Ky+faFqVdc1K9lTuiZ01tolwOHzwu2BTz3HnwIdksQ/s84KoJgxpizQElhgrT1srT0CLABCPNeKWGuXW2st8FmSZ4mIiGRpBw4AK1awK8aP6XSi26OliW8aTNu2rot1+vTE9eZatoT1692s1thYWLwYrr/eXXvhBTh2LHGmrGRP3pjlWsZauw/AWrvPGOPniZcHdicpF+WJXSoelUJcREQky+scfIhDGzuQ27Th/buWU3ziSEacCGXVqiqEhkJQUGLZ4sVhwAC3Bp0xroWudWs3AeK119yyJXU9A5n69YP77vPOO0n6yUzLlqQ0/s3+i/iFDzamL65rlooVK/7b+omIiGSMTZtYuqMe+J5zMxlC7uXHd2sx8LFKdG5ygLAwvwtu6d7dfZLy93eteZL9eWOW635Pdyme7wOeeBRQIUk5f2DvZeL+KcQvYK0dZ60NstYGlS5dOk1eQkREJF0cOQLt2zM87kkin5sPISEcOgRd36qHX4k4auXZrH1a5QLeSOhmAgkzVXsCEUniPTyzXRsBxzxds/OAFsaY4p7JEC2AeZ5rJ4wxjTyzW3skeZaIiEj6GDnSbbsQEOCmjp45A336uEXgatWCLl3g5ElXduJEKF0aAgPdZ/z4xOeEhLhBcG3aJMbi4twzd+6k/og7CR0bzMKF0LMn7NsHp+PzcvPzN2fo60rWkK5drsaYKcAtQCljTBRutuowINwY0wfYBdzhKT4baAVsBaKBewGstYeNMa8AqzzlXrbWJky0eAg3kzY/MMfzERERSR979sCYMbBxI+TPD6GhEBbmkrwiRVyZAQPgvfcS99m68053fr6nn3azGD78MDE2cCDMmwfjxhF8fwDhAdC2LZw65VYsmT49caFgkaTSNaGz1na7yKULljX0zFR95CLP+Rj4OIX4aiDgv9RRRETkisTGwunTbm+t6GgoVy4xmbPWXUtNn+htt7mVgRN8/jmMGAGPPAL33w+4BrtTp9zl/v2VzMnFaacIERGR1Cpf3m2OWrEilC0LRYtCixbu2r33wlVXwe+/w6OPJt7z1VeJXbG7d6f83NWr3dTTpk1dax+wcyd07uy28Hr2WfjgA4iMTN/Xk6xLCZ2IiEhqHTkCERGwY4fbquHUKdeyBvDJJy5WowZMnepibdu6zGz9emjWzA2GO19MDHTo4JLBadMgd26io13xEyfcY4cNg/Bw18OrpE5SooROREQktb77DipXdhMdcud2e2/9+GPi9Vy53Ji5r75y5yVLQt687vj++2HNmuTPO3vWtc4lJIqlS2OtK7ptm1tD7p57XNHgYJfUrVqFyAWU0ImIiKRWxYqwYoUbO2et2zC1Rg3YutVdt9atG1e9ujvfty/x3pkzXdkE1sLo0XD0qJsNW7s24HZ0+OILePVVeO655D8fHAzPPJN+rydZV2ZaWFhERCRza9jQjYWrWxd8faFOHbdR6q23wvHjLkmrXRvGjnXlx4xxiZyvL5Qo4RK3BFWqwPbt7toTT0CRInyfuyVPP+0a/p5/3itvKFmUsTlsCemgoCC7evVqb1dDRERysshIaN7c7dH19dfg48Off0K9elCmjGsELFzY25WUzMAYs8ZaG3S5cupyFRERyUg7dsAdd0C1am5ChY8P0dHQsaNbEeXrr5XMyZVTl6uIiEhGOXkS2rd3C8xFRECRIljrem3XrXPD76pW9XYlJStSQiciIpIR4uOhVy/YsAHmzHFj6HDzIiZPhldegdatvVtFybqU0ImIiGSE115zy5m8/fY/ixFHRrp1ijt00CQI+W80hk5ERCS9RUTAiy+6ReWeeAKAP/90CwVXrQqffgo++hdZ/gP95yMiIpKefvsNuneH+vXhww/BGE6fdkuTnD3rJkEkbAUr8m+py1VERCS9HD7sJkEUKgQzZkD+/FgLDzwAP//slqirVs3blZTsQAmdiIhIeoiNdduARUXBokVQvjwA774LkybBSy+5rV5F0oISOhERkfTwzDNu79ePP4bGjQGX1w0Y4BrtXnjBu9WT7CVVCZ0x5sXLFDlgrf0gDeojIiKS9X36KYwcCY89BvfeC8CuXW4SRJUq8NlnmgQhaSu1LXSNgK6Aucj1TwEldCIiIj/95AbJ3XorjBgB8M8kiDNnNAlC0kdqE7o4a+3xi100xuSsDWFFRERSsnev28OrXDkID4fcubEWHnwQ1qxxq5dUr+7tSkp2lNoG38slbEroREQk29u8GQIDEz9FisCoUfDLL9C4YTw3VImm7YHxHJ88C0qWBOC551wXa+nSMGiQa6VLql07CAjwwstItpLahC63MabIRT5FgVzpWUkREZHMoFo1t+fqunWuxa1AAdcgd999lmHF3+TX01Xp+EAZ3ppdE4CFC+HNN6FJE/jrLzcpInfuxOdNn+5WNBH5r1Lb5boC6H+RawaYkzbVERERyRoWLoRrr4Wrr4bNv56lSczzMGQIzfvUo2VL6NvXjZsrXNitN+fj80+jHQAnT8I778C4cW6yhMh/kdqEriGaFCEiIuIMH05Y5D1061YWvvuOgJiCzKwxkPb58zNtGuze7ZK5mBi3bWtoKBw8CF27utVMAAYPhiefdK18Iv9Vartc46y1x621x1L6oDF0IiKSg5wNbMDMeXm4w3wJoaF8XO4F3t/agnoTHub4cTh3Dlavhm7d4NdfYfJkWLbMbRaxcKHrst261XXXiqSF1LbQaVKEiIiIx5zTt1A38CBlHu8KuXNT3axj/jwguDAvvuha5l58EWrUAGuhVCl3X6tWbsuvQoXcGLxKldyGEgcOwC23uDF2Iv+GJkWIiIhcoSlToFvBWRAXB2fOcKDXMxAczKJF8OqrUKsWDBkCLVvC+vUQHe0St8WL4frr4aGH3AonO3e6lrvrrlMyJ//NlU6KuNgYurlpUx0REZHMLToaFnwbw4cnn3AD4J58kinvHGf0lNPsOpCfYsVc4ubjA8WLu62+6tcHY1wLXevW3n4DyY6MtTmrtzQoKMiuXr3a29UQEZGsavt2t3DcuXMwZw40a8aZeYtp0qYwm3LX4qfVvlx/vbcrKdmFMWaNtTbocuW0k5yIiEhqnTvnZjpY61YLbtYMa+HhqU1ZFVuXz7rMUjInXqGETkREJLVeeAFWrmR4l5+IvKobAGPHwiefQPfusCVA01bFO5TQiYiIpMb8+TB8OPTtS/3etQgNhTFj4PHHoWFDmDvXjZUT8QaNoRMREbmc/fuhdm23/sjKlVCgAF984Vrlihd3Ex6mTYPgYG9XVLIbjaETEZGc5+hR6NIFqld3i8AtX+62ZKhVCwID3bYNe/e6sseOQdu2LlGrWdP1myZ1/DiULw+PPAI9erjyYWFQoAD797tlSfLmhcOH4eGHlcyJdymhExGR7OPxxyEkBH7/HX75xSV1Tz/tFoNbtw7atIGXX3Zl33/fLQr3yy9uEbgnn4SzZxOfNXgwNG3q7ps/H0aOhIAAjh+H22+HXbsgXz5XbOxYiIz0yhuLAEroREQkuzh+HJYsgT593HmePFCsGBQpkljm1CnXPwru+8QJN2P15EkoUQJ8PcuzrlnjulmrVHGtfJ07wwMPcOYMtG/vcsB8+WD6dJcfhoe7/VqV1Im3pHZhYRERkcxt+3YoXRruvddlXPXqwejRULAgDBrklhkpWjQx6+rXD9q1g3LlXGI3dapbDTg+3rXW/e9/bj+uggXho4+IjTPcdZdrzOvaFfr2TexmDQ52Sd2qVep6Fe9QC52IiGQPsbFuo9SHHoK1a10iNmyYu/baa7B7N9x9N7z3novNm+fG1e3d67pV+/VzrXz/+5/rU331Vfj7b2jRAlusOA8+CDNmuBxxypQLE7fgYHjmmYx9ZZEEGZ7QGWOqGWPWJfkcN8b0N8YMNcbsSRJvleSe54wxW40xm40xLZPEQzyxrcaYgRn9LiIikon4+7tPw4buvEsXl+Aldddd8NVX7viTT6BTJ9f1WqUKVK7sxt4tX+6WJ5kyBfLnhwULWPJ/A5kwwTX0PfZYxr6WSGpkeEJnrd1srQ201gYC9YBoYIbn8siEa9ba2QDGmOuBrkBNIAT4nzEmlzEmF/A+cDtwPdDNU1ZERHKiq66CChVg82Z3vnChm/SwZUtimZkz3QxYgIoVXRlw4+U2b4ZrrnGzHM6ccd2t777Lulo9uGXFMB54AF55JUPfSCTVvD2G7jZgm7X2T5MwSPVC7YEwa20MsMMYsxVo4Lm21Vq7HcAYE+YpuzGd6ywiIpnVu++6btWzZ11y9skncN99Llnz8YGrr4YPPnBlBw+GXr3ghhvcxIg334RChaBZM9cy9/nn/DB0AWt/cI1977+fOJ9CJLPxdkLXFZiS5LyfMaYHsBp40lp7BCgPrEhSJsoTA9h9XrxhSj9ijOkL9AWoWLFi2tRcREQyn8BAOH/x+IQu1vOVK+eWI0nqscfchIqZM/lmbXk6fNKLW27rxbefQ65c6VJjkTThtUkRxpg8QDtgmic0FrgWCAT2AW8nFE3hdnuJ+IVBa8dZa4OstUGlS5f+T/UWEZFsauZM18L32GMsK96WO+5w+eGMGW4BYZHMzJstdLcDP1tr9wMkfAMYYz4CvvGcRgEVktznD3iW+b5oXEREJPX27HHLnQQG8muPt2jbzA2xmzMHChf2duVELs+by5Z0I0l3qzGmbJJrHYHfPMczga7GmLzGmMpAVWAlsAqoaoyp7Gnt6+opKyIiknpxcW7cXUwMO0Z8Rcu2eShY0PXGqlNHsgqvtNAZYwoAzYEHkoSHG2MCcd2mOxOuWWs3GGPCcZMdYoFHrLVxnuf0A+YBuYCPrbUbMuwlREQke3j9dVi8mP2jptD8gWs4cwaWLnXzJ0SyCmNtisPOsq2goCC7+vwBsyIikjMtWwZNm3Ks073csvUj/vjDsHAhNGrk7YqJOMaYNdbaoMuV8/YsVxEREe84fBjuuoszV1ej/V8f8NtvhlmzlMxJ1qStv0REJNs4etStGVe9OtSo4TZ9GDwYatVyM1ZbtHA7fWEtR3o8Tofd71LmwHoWL/Pl1VchJMQ9Z+RIqFkTAgKgWze3zrBIZqaETkREso3HH3dJ2e+/u+XkatSAp5+G9evddq1t2sDLLwMffMBr39ZiV/mGHD/ly6BBiUvS7dkDY8a45ex++83NmQgL8+priVyWulxFRCRbOH4cliyBiRPdeZ487pPUqVNgDh+CJ55gRv7tbN9zFYMHuyTv2mvdDmAAsbFw+jTkzg3R0W4NYpHMTC10IiKSLWzf7pYZufdeqFPH7fh16pS7NmiQ2+Z18qR4Xl7XjrdzD2T76XLUqgUvvQQrV8Kff0JUFJQvD0895dahK1sWihZ1XbUimZkSOhERyRZiY+Hnn+Ghh2DtWihYEIYNc9deew1274a7C33N/Vue4qmTQ2nf3iV+deq4DSLq1AFfXzhyBCIiYMcON97u1Cn4/HPvvpvI5ajLVUREsgV/f/dp6NnVu0uXxIQOgGnT8Fs1hwgm0KwZTJ2auKWXtVC5svvMm+e+ExYV7tQJfvwRunfP0NcRuSJqoRMRkWzhqqtct+rmze584UK4/nrYsgXYuZOl937Mg3xI8eIwfbobI3f2rCs7fjw0aQJFiriu1hUr3Ng5a91zatTw2muJpIoSOhERyRiVKsENN7j1Q4I866ROm+bWB/HxcdNKz7drFxQqBCNGuPPduyE42GVYNWvC6NHJir/7rtvFq1YtN6v1+edh4DPxVKnuyy2nviFvgVwsXmwoXBg2bXKPqF7d7dma8KiGDV3rXt26rrrx8dC3b/r9sYikBe0UISIiGaNSJZe0lSqVGNu0ySVzDzzgkrag8xbE79zZXW/Y0M1U2LfPferWhRMnoF49+Ppr1xR3EdsfeosbP+hOrhJF+XFtASpWTJ/XE0kP2ilCREQyv0v1ZX79NVxzjZvdkKBsWfcBKFzY3b9nz0UTur+mLaXFBx05m7cwS5cqmZPsS12uIiKSMYxx63/Uqwfjxl267KlT8OabMGTIxcvs3OmmsybMggCGt1pE5DtrATi29SAhdxUnCn+61d50qUY8kSxPLXQiIpIxfvjBrdB74AA0b+4GrzVpknLZIUPgiSfc+LmUnDzpumNHjXIzGTzqNytK6FMVmBSzljfe8uW32OoUIprOd+qfO8ne9F+4iIhkjITtFvz8oGNHt5rvxRK6n36CL7+EZ55xG7T6+EC+fNCvH5w755K5u+92a4okETygDh9H/0K752tyjtwU5gQz3t5O8IA66fxyIt6lhE5ERNLfqVNuumjhwu54/nx48cWLl1+6NPF46FDXUtevn1tHpE8fN3ZuwIALbovacprn3ypOHLkAQ/+b1hA8IDjNX0cks9EYOhERSX/798NNN0Ht2tCgAbRuDSEhMGOGWw14+XIXa9ny0s/54QeYNAm+/94tfxIYCLNnA7Bh6WEaBxxn2/GSFOYkg2+KZOwPN/wzpk4kO9OyJSIikuUtnrSLDr2K4hN/Dksuvnp7J8ED6hD5zlpCn6pA+Ijd6naVLCm1y5aohU5ERLK08KEbadGjDGXNX/Stu+afZA7cmLrwEbtZ9d0xL9dSJH2phU5ERLKsUfesYcDndbgx/89ELC1JiXqVvV0lkTSlhYVFRCTbio+zPNN0BW//0JjOJRfx+fpa5CtXwtvVEvEaJXQiIpKlxJw8R69aPxO2ozH9rpvHqLW3kKtAXm9XS8SrlNCJiEiWcfTPY3QM3MGiow1587b5PD2/BcbHeLtaIl6nhE5ERLKEqBVR3H5LNJtjrufz+xdz97gW3q6SSKahWa4iIpLpbZj6G41vNPwZcxWz3/yNu8c19XaVRDIVJXQiIpIhKlWCG25wawEHeebsTZsGNWu6nb2SLkCwYAHUq+fKVyt/koZdrybO+LLky4NEHqtLhQoX3+ZVJCdSQiciIhkmMhLWrUtM3gICYPr0C7d0LVUKZs2CwUFz2L43DzHkZ/lyQ2Dna2nb1m0DKyKJNIZORES8pkaNlON1asUx6taZDFjSnsbFf2eTrcFVtfwAaNQoAysokkWohU5ERCAuDurUgTZt3Pl770GVKmAM/P13Yjlr4bHH3LVateDnnxOvPfusa3ILCICpUy/4CWOgRQvXlTpu3MWrEn/iFE9Vm8UTSzrSscqvPDKmGnXrGfJqZRKRi1ILnYiIwOjRrrns+HF3fuONLrm75Zbk5ebMgS1b3Oenn+Chh9z3t9+65G7dOoiJgaZN4fbboUiRf2794QcoVw4OHIDmzaF69Qu7WmP+/ItedX8h7HAHHrl5PX3fq03HjjB/fvq+vkhWpxY6EZGcLirKJWT33ZcYq1PHzWI4X0QE9OjhmtsaNYKjR2HfPti40SVxvr5QsCDUrg1z5ya7tVw59+3nBx07XjgO7uSvOwiptoOwwy0Z1mMjz06uRZcu8NlncO21afvKItmNEjoRkZyuf38YPtxNNb2cPXugQoXEc39/F6td27XeRUe7LtrISNi9+59ip07BiROJx/Pnu57ZBDEHjnFfn3iWxQQx6eUdPDD6etq0gTfecI2FInJpSuhERHKyb75xTWb16qWuvLUXxhIGx7VqBf/3f9CtGzRu7FrrPPbvh5tucnlfgwbQujWEhMCMGXBV0dOs2FSE7bYytW+Ip/vgyrz3HmzdCq+84pY5CQx0XbUAzzzj8sjoaPc9dOh//2MQyeqMTel/nNlYUFCQXZ10sSMRkZzsuedg0iSXfJ0548bQdeoEn3/urleq5NYYKVXKnT/wgBtX162bO69WDRYtgrJlkz/3rruge3eX5F2MtSzpOYH2kzqTL088c77LQ+DNhdP4BUWyNmPMGmtt0OXKqYVORCQne+MNN4Zu504IC4Nbb01M5lLSrp0b1GYtrFgBRYu6ZC4uDg4dcmXWr3efFsm35hreahGR76x1JzExTGvyLrdN6kFuX8vy34oomRP5DzTLVURELjRmjBtX99dfbnmSVq1g/Hj3PXu2W7akQAH45BNX/tw5uPlmd1ykiEsKfZP/E1O/WVFCn6pAePQPrJ+4hv7b+uFLHB+9uJtKVWtn8AuKZC9e63I1xuwETgBxQKy1NsgYUwKYClQCdgKh1tojxhgDjAZaAdFAL2vtz57n9ARe8Dz2VWvtp5f6XXW5ioh4z/xHZ9LhvWacpgB5iCFi2O+EPKtkTuRiskqXa7C1NjBJRQcCC621VYGFnnOA24Gqnk9fYCyAJwEcAjQEGgBDjDHFM7D+IiKSGnFxbHnqQwa9V47TFID/b+/M42ys2z/+/poxllmMwWgYaxHZ93goY6cdTaQn8XgqUUmonlLSjpSWn7SISjQpWpQ2U0IyKtn3dRhjzGB2s31/f1znOGfGbMRsrvfrdb/OfX/v/b6PMx/XCkzs+puKOUW5QBS3oMvJTYDTwjYfuNlt/AMrrAX8jTFBQF/gB2ttnLX2BPAD0K+oL1pRFEXJGxt5mHnNZ9Dm5WFsL9cUP+KZ3O1n5qxu7oqpUxTlH1Gcgs4C3xtj/jDG3O0Yq2mtjQJwfAY6xmsDh9z2jXSM5TWeDWPM3caY9caY9TExMRf4NhRFUZS8OLlgGUMv/50R2x/h8hqn8LKnWfryHqau7E7YjEOETqijok5RLgDFmRTxL2vtEWNMIPCDMWZ7PtuaXMZsPuPZB6x9G3gbJIbufC5WURRFOQeSk1l9+5sM++JWIgnmuXExlNu+m069/QgZ3waAkPFtCOMvIn48Rcj4Yr5eRSnlFJugs9YecXweM8Ys+4wToAAAIABJREFUQWLgoo0xQdbaKIdL1VFGkkjArTQ5wcARx3j3HOM/X+RLVxRFUfIh44+/ea7fr0w9Pp56VU6y+mtLp641gGvP2jZkfBsVc4pyASgWl6sxxtsY4+ucB/oAm4EvgeGOzYYDXzjmvwTuNMLVwCmHS/Y7oI8xpqojGaKPY0xRFEUpaqzlwFNzCemQwJTjY7m9ZzQbDlajU9fyxX1lilLmKa4YuprAKmPM38A6YJm1djnwItDbGLML6O1YBvgG2AvsBt4B7gOw1sYBzwARjmmqY0xRFKX0k5oqfbJatYJmzeCpp2R82DDp0NC8OYwcKTXgALZvl5ZbFSrAjBnZj1W/PrRoIT202p9dASEzE9q0geuvl+V9+6BTJ2jUCG67DdLSZPzgQQgJkW1btpSSdAAL/u8U9Ssfo+HU4ayxXTDG8vCMWvj5XfjHoijK2WjrL0VRlJKKtdLJ3sdHRFvXrjBrFsTFQf/+ss3tt8M118Do0dLs9MABWLoUqlaFCRNcx8rZwisHM2fK6vh4ae8aGiodwIYMgXvvFU05ejTcfbeIudGjYetWqTO8+ZUfePD2GOam3k6n+kd58o2ajL3fsHfvxX9EilLWKS116BRFUZS8MEbEHIigS0+XsQED5NMYseBFRso2gYHQoQOUPzcXZ2QkLFsGo0bJsrWwYgUMHizLw4eLRnReUny8zJ+KSaNK0hHaDqzH+6lDePy/x/h152WsWm3OtHpVFKVoUEGnKIpSksnMFDdpYCD07i1+UCfp6fDhh9CvEOU3jZHequ3awdtvZ1s1bpx0+Srn+IsQGwv+/q7OXcHBcPiwzE+ZIl29gi9Lp2dIFluP1yDZuwYrlqfz7NuBlC8Pn3yCCjpFKWJU0CmKopRkPDxgwwYxo61bB5s3u9bdd5+4W509VPNj9Wr480/49lt4801YuRIQ92pgoOg8J7lF4hhHkaiFH1sG1ltP05iVpNiKVKoEG/ZXpXvfCgD8/ru0eG3e/HxvWFGU86E469ApiqIohcXfH7p3h+XLRS09/TTExMCcOYXbv1Yt+QwMhFtuEXF4zTWsXg1ffinJDamp4k4dNw5OnoSMDLHSRUY6do+N5dXJWSSmNCC1nDdvTz/JC//nT1aW6zSLFql1TlGKA7XQKYqilFRiYkRZAaSkwI8/QpMm8O678N13sHChy0+aH0lJkJDgmv/++zMmtBdeEMG2f7+IsR49YMECyWRdvFh2mT8f+jfaxf31vuRQSg18/Mvzx0Yvul7nT2oq1Kgh22VlwaefSiKFoihFi1roFEVRSipRUZKRkJkpaik0VOqKeHpCvXpSogQkHfXJJ+HoUSlJEh8vQu/VVyUV9fhxscqBmN1uv73AuLuXXhJh9sQTloZZu/l132m2MoJ/X3ecXbHVGXK7uGHnzXO5Y1eulHi7hg0v3iNRFCV3tGyJoiiKkit29x5m9/qMhw/cj1/FdOYtKE//gZWK+7IU5ZJCy5YoiqIohWbagJ8Jn/nXmeXj/xdG18bRjDkwie6tT7Jxv5+KOUUpwaigUxRFOR8OHZJAs6ZNpYvDrFmuda+/Lp0cmjWDSZNkbN06KT/SurVU6V2yxLX9rFkS09asmbhJi4EOvaoQOqEO4c+t4adeL3DlmB6ssZ25r/dOlv0RRM2axXJZiqIUEo2hUxRFOR88PeHll6FtW0k4aNdO6sRFR8MXX8DGjdKC69gx2b55c2nF4OkpsXGtWsENN0i7rnfeEcHn5SWxbdddJz23ipCQ8W34cOtirntiACl0xoNM3h63jf++clWRXoeiKOeHWugURVHOh6AgEXMAvr5iqTt8GGbPhkcfFTEHUiYEpDibs1Jvaqork2DbNrj6atf6a6/Nbr0rAuzRaD7r9iqj32tHCpUBw4Qua1TMKUopQgWdoijKP2X/fvjrL+nisHMn/PqrzF97LUREuLb7/Xdxq7ZoAW+9JQKueXNJD42NheRkKQh36FDRXHdWFpue+pSedXYweNU4jHdlqphTTO72M+/9dlW2mDpFUUo2KugURVH+CYmJMGiQxL75+UlZkBMnYO1amD5dSo04qwl06gRbtojIe+EFsdQ1bQqPPCLu2n79xBXrefGjYWJ/3cqY2ktoPXUgf9OKB/tsJSHZkyUz9jJ1ZXfCZhySmDoVdYpSKlBBpyiKcr6kp4uYGzZMasGBFGIbOFBcqh07Sj2448ez79e0KXh7u9p4/ec/0pZr5UoICDgTP5eaKodo1UoMe089JZsPGyY5F82bw8iRchkAP/8MVaq4ci+mTuXs4zTNon/D7TS65jLmHL2J+3rtYtdRP2p5HCNsxkFCxrcBJKYubMYhIn48dREfoKIoFwqtQ6coinI+WCtFfwMCsmemvvUWHDkiamrnTujZEw4eFLdsnTpifTtwQIoCb9wI1atL4kRgoGzXpw/89htUrYq10tjBx0dEW9eukhAbFwf9+8vpbr9d2rmOHi2CbsYM6c+a81KTkmDd67/zwJNV2JLRhHbV9jFvaVWad/UvqiemKMp5oHXoFEW5NMmrnMjEidI2q2VL6ZrgbKkFIqw6d3bFt6Wmyvjjj4sI8/E5+zyrV8OHH8KKFS6T2DffiMls714xnw0ZIn2zjIFVq8RE1rq1nP///k/EHIiV76qrJOv1zTehalVAdnOeOj1dJmNgwAD5dBoBIyPzfyT7f4/mzia/0/N/nUjEhwZBKbzxdQMVc4pShlALnaIoZYuoKJncy4ksXSqqp0cPsZA98ohs+9JLEvPWtq2Is1atJDnB3x88PCQOrl49cYEmJhbL7WRmyi3s3g1jxsglO0lPl7C8WbOgWzex0A0aJF7fWrVg6lOZLH3qL17+vjnlyKSKTxYJ1ocxY0y24yiKUnJRC52iKJcmeZUT6dPHlWxw9dUus9b334vVrlUrWa5WTcScc7ugoKK9/hx4eMCGDXK569a5wu4A7rtP3K3dusly27bizd2wAZrXiKZzZ8vz37dn8GWr2fXrMaISfImMNGcdR1GU0o8KOkVRyi7u5UTcmTvXFYS2c6f4Lvv2FUU0bVqRX2Zh8PeH7t1h+XJZfvppiImBmTNd2/j5wfY/k/lX7X3M+LAmHmSybOLPfHSkB7W7Nsj1OIqilA1U0CmKUjbJWU7EyXPPiaVu2DBZzsiQ+LYFC+RzyRL46afiueYcxMS4Qv1SUuDHHyUM8N134bvvYOFCSaIFaVAxtNshOlxbkb1RlXiizTJq1i5P/5e6E3Pc5HocRVHKDtr6S1GUskdu5URAEhS+/loEm7NTQ3CwFAB2JigMGCAlRHr2LPrrzkFUlCTSZmZCVpaUtLv+etGj9epJHoe1cJl/Cr+tsSRlBFHN4xQ16vnyg9d1LAqT28zrOIqilB1U0CmKUnSMHCmCKjDQFcT1999w771iUatfXyxlTovaCy/Ae+9JINlrr4lbFGQ7X18Z9/SUHqlOrJW6bk2bwvjxrvHlyyWj4JdfpM2Wk759xc2anCy9VH/5BR566GI+hULTsqV4jHOSkSGfy77M5KFR8Xy/sSrXlfuWmRMiafz8XVC+fKGOoyhK2UFdroqiFB133XV28NaoUfDii7Bpk5TzmD5dxrduhUWLpLPC8uWSAZCZ6dovPFyi/3NmredVTmTsWMl67d1bxu69V7avWlWEX4cOMt62LVx3naybNEkseMnJ8jllysV4KvkybZrcqjvz50OT+ilcf5MH5WKi+ab9k3y9uwmNp//3LDGnKMqlgZYtURSlaNm/X/x9Tgudnx+cOiW+wUOHxGK2datY5wAee0w++/YVQdW5s1jo1q93uUnLMOH3LCL0k4GELfGibVsYdVcai5eWpzJJPOM7g7FzWuA1ZKDLhawoSplCy5YoilI6aN4cvvxS5j/91NWY/vBhKerrJDhYxkDES58+UqDt7beL9nod5FW/eMoUqF07u3EQJKxv+HCpW9y0qUuv5tXey0nIkJrMt3dyw4AMatXMYPHS8gxgGfv6j2X8oYfwGjpIxZyiKBpDpyhKMTN3LjzwgLTKuvFGiWMDV0N7d5zCZfVqqZx77Ji4UJs0kYJsRYinJ7z8cvb6xb17y7qHHoIJE7Jv/+mncPq0eJaTk6UxxNChktywYkX29l79+0sJvNhYeOPHf/F6ekeSUuXnehTv8s6baXDfvCK9X0VRSjYq6BRFKV6aNJHiviA14ZYtk/ngYJe1DqSybq1aMu/8DAyUuLt164pc0AUFuWoOu9cvzgtjpJ9qRoaUDvHyEm9zbu29oqNh3B3HeecTX5IzKtCZCLaZ5txvZzG78sPc3tSbkIt/i4qilCLU5aooijBypAik5s1dY3n5D9PSYMQI8R+2aiU9p5z88YeMX3GFWN4KitM9dkw+s7Lg2WddyQo33ihJEadPw759sGuX+CaTksQkBjL//ffZr7kYyFm/+I03JLN05Eg4cULGBg8Gb28RgXXrigUvIEDWZWbK461e3ZIWfYLBt2Tw5oIqDM76lLmd5rDLuw2f+w5n6uQMwjyHEXpL2lmJEoqiXNqooFMURcgtAxXEf7hhg0wDBsjYO+/I56ZN8MMP8PDDIsgARo+WuLZdu2RyP+bQoZLUsGOHWODee0+q4zZuLJa6WrVEKIIElIWGim+yXz9pWu/hIearrl1FSHbsKBmp/fpdtMdSEDnrF48eDXv2yOMKCpJHA2JE9PCAI0dEn778MuzdK+vWfryXuqc2kZJi2HbEj9t8v2HP5PnMP9afmFa9CPO4nZClD8LUqYQsfZAwG0rEoj3Fds+KopQ81OWqKIpwzTViaioMW7e6Cu8GBko/qfXrJYkhPl5EG8Cdd8LSpa42WwsX5n68Bx/Mffzxx2Vyp2FDqV1XAsitfnHNmq71//2vq4Dvxx+L7ixfXh5Zl04ZzLl/G2t+zWJVQiuqcZwpLT4juXkHarS5gboTJV5w0uXvwdIHJQMDICSEkKUQEvEZMKnoblZRlBKNWugURcmf3PyHrVrBF19IQNi+feJmPXRIgsiCg137umemljHyql8cFeWaX7LE5Q2uW1eSH9L+2sK7PRey8MNMpn3Tgn3Jgbw4YCUH9sOk3wex5lBdmjR1y1qdNMkl5pyEhMi4oiiKA7XQKYqSN6NHw+TJErk/ebL4D+fOFXG3bRu0by9pml26SNpnfpmpZQxn/eIWLST+DeD558UIuWGD3Hb9+jBnDpCSwl3eX9MvrBU+8xqRTjNqVjzBjPF7aTqwCaNGBbHgBm3LpSjK+aOCTlGUvMnLf+jpCa+84lrXpQs0aiRdFyIjXePumalljK5dc9evzjBDALZtI3bKhzz9gR+vp44ilup0bRDJo8/6MmBoVYypCmhbLkVR/jkq6BRFyZuoKFdtDnf/YXKyqBlvb0mK8PSU5AWQGh5r10rK5wcfwP33F8+1FwXTpknLMHeX6Hffwfvvc3BvBjMjuvIOj5OMNzd2ieGRaZYu/wrO+3iKoijniQo6RVGEoUOl/Mjx4xL79vTTsnyW/xApNdK3L5QrJ2VNPvzQdZzZsyVjNiVFkiGcCRFFxKFDkotx9Khc3t13S85FXBzcdpvkfdSvD2FhYlB0EhEhxXw/+URKjBw4IIkOmZmS/HD//a6KKk6m7RlEh+ceJmQpInwnT2buYl/eZCIbaQnlyjHs1nQmToZmzWoU4VNQFOVSo8h7uRpj6gAfAJcBWcDb1tpZxpgpwH+BGMem/7PWfuPY5zHgP0Am8IC19jvHeD9gFuABvGutfbGg82svV0Up20RFyeTewWHpUpg3T+q+PfoovPii5He89JLsk5kpXR4qVpTwwMGDpdSetVChgpQmad4c1qxx8yCnpRE+ezuhj9QnLH0gXlkpTGA6a+lCxfKZ3HtfOR4ab6hbt7iehKIoZYHC9nItDgtdBvCwtfZPY4wv8Icx5gfHulestTPcNzbGXAUMAZoBtYAfjTGNHavfBHoDkUCEMeZLa+3WIrkLRVFKJHl1cPjiC1f94+HDoXt3l6B7/XUpPxIR4TqOswMZSG3jrCwLm7fAwu/gp59g5UraJZVjOE/Rh2/JoDwGy113wYwZHlSrVgQ3qyiK4qDIBZ21NgqIcswnGGO2AbXz2eUmYJG19jSwzxizG+joWLfbWrsXwBizyLGtCjpFUYDsHRyio11CLyjI1aDi8GEJD1yxIrugAzi06gDXDfFh91Efpld8klp9p5GFIbzOcN6vvYLP97clJc2T6uY4x211JlV6jRfvbAnVtDGXoihFS7HWoTPG1AfaAL87hsYaYzYaY+YaZ/qXiD23ho5EOsbyGs/tPHcbY9YbY9bHxMTktomiKGWMnB0c8mLcOLHUeXgAqSmwehWMGgUNGlCnW302Hq7O7hpdeNtrDA/12UKD2mn0OvQ+y4515K5+0bzpPRH8/Jg8Gd7zGk34zbPQvlyKohQ1xSbojDE+wGfAOGttPDAbuBxojVjwXnZumsvuNp/xswetfdta295a275GDQ1MVpSyTl4dHJxFf6OipFsDCQms/zWZIX3jqO91mMWfZHLfq41ZujAFWrcmYcYc5j57hCGN1rPxRF1m/XAVV7XwZNEiOcatl/3KU57PEbbEi6lTIWyJF6EmjPBF0cV274qiXJoUS5arMaY8IuYWWGs/B7DWRrutfwf42rEYCdRx2z0YOOKYz2tcUZRLFGvhP1dvpmn9Kowf7/qJuLH1QebftYdHn/Bk/pRUbko6BgF3sS8jQzIfrunKXSdmMmBwZap0+IDBb3nwzWRJ1r3iCqhWDRYtgl69XOeKuHwIYUuydeUibIkXERFDUKeroihFSXFkuRpgPhBnrR3nNh7kiK/DGPMQ0MlaO8QY0wz4GImbqwX8BDRCLHQ7gZ7AYSACuN1auyW/82uWq6KUbVatgm7doIXHFsrVrwsenjx/+Xt0+uFZQrMWcjArmLoc5NO2LxLQt4P0pO3Shb1RlRg4EI4cgZgYqFxZsl4DAqBSJRg7VkqgKIqiFCUlOcv1X8C/gU3GmA2Osf8BQ40xrRG36X7gHgBr7RZjTBiS7JABjLHWZgIYY8YC3yFlS+YWJOYURSleRo6Er78Wd+fmza7x11+XlrGennDddVKvNzZWyodEREhZuzfecG3/xx+uUncDBsCsWY4OY5mZdPXeiJ35MyxeDL/9Jia7nUCdOvx042diYuveHfx/IDFRNpvXH375RY7RqxeMGAE33yxCTlEUpTRQ5Ba64kYtdEqp5ORJCdTfvFlUx9y5YkK6916J/q9fHxYskOj/9HTZ9s8/ISNDquw+9lhx3wEAK1eCj49cklPQhYfDc8/BsmXi+Tx2TARfUpJkqG7eLJO7oOvYUUTc1R0yGXBtIg80/ZH+x+bLCU6dYhoT6VDrCCGBW6Qw8oMPEn7Tq0REwIQJ8OuvUpfu00/lPI0aiUD897+hTp3crlxRFKV4KKyFrlizXBWlTHDypJiSmjSRome//SZKoVkzaVXg/h+I9HQpgtaihWz7wguFO8eDD0K/frB9O/z9t+w7apRUyN20CW65BaZPl20//VQKp23aJKasOXOkfkcJ4JprxIXpzuzZUuy3QgVZDgyUT29v6ZdasaLbxhkZRH27gfj9sXR+7npMtQDuXHMvS987Ls8mNBQ++ogOn0wkNGku4XvrweTJhL+/n8E3pbNtm8TDde8On30mzTFWrYIdO+B//1MxpyhK6UVbfylll/r1pbKsh4f48tavl95PO3bI+pMnwd9fLDg//CCqIi1NKspOnw49ehTuPE6xtXix7J+cLMf9/HO4557s27qLreRk6X86dKhca17Ex4vlad48WfbykmnHDlFIIG0O+vaFZ54RC15SkljnUlJk2/zqdhQzO3eKxezxx0W8zZgh7VEBEcB7DsKfJ2HAZFi1isMJjQnmRdi9G4YOJbjmYA6v7go/up51SHg4YXYWt/IpXTeW55ukLNIzyzF/vqVHD8PUqZL9Wrly8dyzoijKhUYFnVJ8ZGZC+/bSC/Trr6Wy64QJIoratYP33hMh9vPPcNNN0KCB7DdwIDz5ZOHOER4O1au7lj/5xDX/8MNQpYrMV68OX30lfZ02bxZxdPhwwcfPS2z5++e+/fmIrb17oUYNCez6+295NrNmSS+qL7+UZ/Ppp9LEFMRa+MUXUj03ORleeeVss1hx8tZbkHQH4APIozixKZK1Az8moutDhN6Uyd6xr2B++RlWr4akwUB7aLof7rgDG3wLLO8GK7fL8X4F86fr8Lt3w1czLV81fJ+4v8vzxRdQtWo5xt+8l3/X/J56L+RoyKooilIGUJerUnzMmiWuQ4CsLHFFLlokgqpePZg/37Vtt25iSduwofBiLj+sle7sQ4fKcps2riadzZpBaqpY0grCXWy1aSNu0KSkvLcfPFh8iUFBULeuCNiCxFZGhsTDjR4tQWXe3uJqnTsX3nxTBF5CgqtX1bp1YpU8cgT27YOXX5brLCm0aiXiMzwcTp8mOPMAA78ZhQn7hI59/CkXdZjjj88UQX3XXXDffTBiJGzdCv/3fwSP6E3ksQpnDnfwoHi2H3lEvk6NGsH4r3uw72RVKlaUV+PhAf/6d0MVc4qilFlU0Clnk5kp4uT662V52DC48kqxCI0cKW4wEMtZlSrQurVMU6cW/hyRkRIFP2qULMfGShBVY0eb3t69Jcjpn2AM9Okjguftt7Ov+/VXqTTbqNHZ+332mdx/hQpnr8tJXmIrL85HbAUHy9SpkywPHiznbNIEvv9e4uSGDoXLL5f1H38sLuDy5SUg7V//yh7HlwcjR8rmzZu7xiZOlNO0bClheidPutZt3AidO4v+bdFCNDCIEbRlSxmfNCnHSY4eFfHp4yNWUB8fbt7+AitOd4H0dHYOfJS0akFUj97qyoTo0DGbbzQoSBafe06SGEaMEEPlK6/IY5o1Cz76SHJFli0T3RsWJuF12sBBUZSyigq60kJqqqT2tWolfymfekrGrZXgo8aNxTzx2msy/sUX8le1dWtxa65aVfhzuVvOQATd9u0S95WSAu++61p3vpazceOkNkU5x1ewenURik7hsXixy4UIkmjQqhX07w9bClmdZvVqET7ffiuWrJUrXesWLnRZ59zZskVMPXPmFO4ceYmtvDgfsXXZZRKt74z9++knib1zNiPNyoJnn5WMVxDL34oV8t1ISoK1a0WVFcBdd8Hy5dnHevcWXbVxo3zFnDkcGRlwxx3iPd2yRbR9+fKiyydOlEvc8udporfE8NOYz+VZN2jA0KBwOt/Tgh2nLiM48wDvZdzJyEGn2Dv4EZpnbWTIlsnMD6uMCZSOLvXrw/jx4tEOCpLEhT595HqeeEIeZ4MGYtiNiZFQyAceEONeWFiOgr9hZ/dqVRRFKStoDF1poUIF+SPt4yPCp2tXETfbtonw2b5dxJHzj3zPnnDjjWKl2rhRzBPbtxd8Hqfl7PHHYeZMGRswwLW+Y0fZ5p/gLETWrp0oAZDrXLQIHnpIXJ19+kj8HEDbtnDggNz7N99IgbBduwo+j9OFGhgo5qV16ySJICNDEhb++CP79pGRst0HH7isXQXhLrauvNIltvLCKbbuuEPi29auFXFbEK+/LsI6LQ0aNoT335frfPNNWT9woJiqAMaMkfnmzUXUjRgh4r4Arrnm7GTYPn1c81dfLTobxDDYsqVobIBqARYOHWLvRztoTD1q3Dgc/vyTXmmhfEZnetZZDVdfzcL7o+DqfRD/t5jXRo+G2bP5KGyNS305yMwU3f3VVzJt3iyCskkTEXk33CAWQs9cfsXOsgwih89xCkVRlLKDtfaSmtq1a2cvOAcPWtu9u7VNmlh71VXWvvqqjD/1lLW1alnbqpVMy5bJeFqatXfeaW3z5rLP88+f2/mSkqxt08batWut7dDB2l278t9+zRo5T2EYNMja9eutDQ+39rrrsq9LS5Pzrlwpy+Hh1gYEWNuypbX9+lm7eXPhzvHoo9bWrm1tvXrW1qxpbaVK1g4bln2b776z9tZbc9+/Xj1rY2LyP0diorXx8a75zp2t/fZbWf72W2uvuSb79idOyH0sXly4e3Dnr7+sbdfO2hYtrL3pJmvj4qz9/HO5Ry8vawMDre3TR7ZNSLB28GD5njRtau20aed+vovIvkdm22b1E7IPrlhh7Usv2euvt/bDD2XolZdS7R29j9o+jfbaNlX22Jd8n7EWbBz+tjaRdl/7wTZ9/CQ7sFOkvb5XcrbDvXT3brvC7yY5ruP4K/xusi/dvdsmJMijGzFCHhtY6+Eh/7xeftnanTuL4CEoiqKUIID1thD6ptgFVlFPF0XQHTli7R9/yHx8vLWNGlm7ZYsIuunTz95+wQJrb7tN5pOSRKDs21fweTIyRBh6e1s7aZKMBQRY++yzIij69cv+F+/zz6298kprq1YVUVcQX31l7ejRMp+boBs1ytoHH3QtnzolAsVaEatXXFHwOXLifp7oaPlMTbW2Rw9rf/pJlqOirM3Kkvnff7e2Th3Xcl7s2SMCrWVLEU/PPutaN3y4tbNnZ9/+mWesrVzZJb5btXJdTzEzYoS1NWpY26yZayw21tpeveSR9+olGtJaeSz332/t5ZeLvnR+La21dt482f6KK2Q+N/Z9vMY289iaTWzZ6tXts4P/tDe3O2CzRt9nbdu2drqZaOuz18ZQzSY1bG6vrr7T/nj/UmvXr7dffp5uO3a09uqrrR0/3tqbb85+jhV3L7TVq5w+c4pFi6z1qZRuOwQfthUqyK9SlSrWDhli7ccfu+5NURTlUkQFXVEKupzceKO133+ft6D7+GNrr7/e2vR0a48fFwEYG1v44584ISaLTZtE3M2YIeOffWZt165nb//LL9b27FnwcfOznE2ZItanzMy89y+M5Swn7oJuwgSxJDZubO0rr7i2ef11EWUtW1rbqZO1q1ef2zlKOb/8IsLMXdBNnGjtCy/I/AsvuPT9smWi67OyrP3tN2s7dpTx2FjDuTl8AAAapklEQVRrGzSQz7g4mc9NKO3bZ8VC5+9v7bXXWuvlZedVvMdezRqbRCVrfX2t7dnTLrx5kR3e46C1x45Za62dOjV3Y+OcOXKt7sTFWfvcc/L1qllTfoVAhOZDD4mGTEv7R49MURSlzKCCrrgE3b59YkE6dUoEXb16YioZMcL1FzQtTSx01auLVWjOnHM/z5QpIhavvNJl3cvKstbPL/ft69c/N7HlLrTeeUdclsnZXWfnZTlTzot9+7ILusaNxTBsrXw2bizzd98t/1/Iud3HH8s6Jzm3O3OetUdtM78DZ1TWt1VCbVP/w/bYzA/lPxAZGdZa+Sq3aSMG5vR0+f/C11/LMZyGzbg4MXT+8ouc67775J+CMXL4cuXks2dPa7dt06+OoihKbhRW0GmW64UkMREGDYJXX5VisaNHw549kgEaFCSFbOH8SlfExLhqRqSkwI8/SnT4zTdLkD1Id3Fn2Y/du+VPMkjWZVoaVKt2fvd1770QHS0R6O7lSRYvlsD7Vq0ktXDRIkeHdOViEx0tXymQT2cuzOHD2dtXBQfLWF7jZ8jMZGi7nXTubNkRH0SwieS9vmGMTXiRhPIB9J5/B63vaM69YzwAqFpVEhM6dJCvRNu2cN11rhyMWrUk+/TwYbj2Wrj9dsnhCAqCp5+WfJuAAJg8WWolR0XpV0dRFOWfoFmuF4r0dBFzw4ZJxiFInTMn//2vq65bXqUrGjbM+/hRUVJ4NzNTylSEhsrxunaVc77yimSBOkuKfPaZ/AUtXx4qVZLiYOfyF7N7d5lAskJzY+xYmS5hduyQbmJO9u4VvRsSIjo4MVFKbyxYIBo/NlYqm0RESJkQ94bzFwKnhnfHmLzHARH899zDwj/XS4mbPXvk+xNyK/8JD4fQjvBK2FkponfcIff+119S1u+WW6Q6zvHjsj4wUL6e3brJ1KqVZKSGh8vX11lWJCQk+7KiKIpy7qiguxBYC//5j9RuGz/eNR4V5TKjLFniqth6PqUrWraUv5w58feXMiM5eeQRmZSLypVXigEWRGvXri3CZvBg6Ul67bVS2Hb6dGmzWrGifG7eLNP5UrOm6+sVFeVqaB8cnL18X2SkWMuCg10VYpzj3TulwLjHpCRKYCAsWsS0+YF0GOpPSEgb2TAkhPDHvidi+ikmhbjK2q1aJSLut9/kKwxS6eW661wCrlGj3P8PERGRd404FXSKoijnSWH8smVpuigxdL/+KsFALVpkL1Fyxx1SmqRFC2tvuMEV9FTCS1co58d331nbpYvM+/q6YsIOHpTX7M7771s7Zkzhj50zhm7ChOxJEc7Eg6+/zp4U0aGDjMfGShhlXJy1cbFZtn5goo0NaiYBbffdJ4k29kxS65kM1CVLJCzz1lslwcLTU77qxljburW1Y8da+8kn1h4+XPh7URRFUQoPhYyhUwvdhaBr19x9Wu4Fed3x8ZFm6spF5eRJ6Sy2ebNYiubOlXrCX30lbU8vv1zq8/r7i0t0+nTXvhs3iieydevCn2/RIlfziebNpR3VTTfJq3a3mp0rQ4eKde34cbG0Pf00PPqouCnfe08Mvs6v04ABUnv5iiukPdb778u4M16tQ5t0iInhyeTHCWjlCUt+O9PlIjFR6lcPGybH8fFxuU+/+EJqSk+cKNa3Ll2k65uiKIpSMjA2NyFShmnfvr1dX4i+lkrpZ/hwER+jRklOSHKy5KP06CGxXE6P9EsvZd9v0yYRYufSzz4tTVybW7aIO3T7dskTiY2Vhh2vvSbzTubNk7DJCx1Dlyfp6ZKsM2UKFkPUhJfZ0H4UGzZ5nOnc5p5HU7GidJsLCZGYwPbtZUxRFEUpWowxf1hr2xe0nVrolGIjM1OEQu3a0g1sxQqYMEHEUbt2Yn3y9IRTpyTc8OBByc+YMMHV5Sov4uOldeu8ebLs5SVTXq2s3MmrzWt+fPutZHo682CaNJH2WAA7d+Ye5lgUZGTAzrANbHh0ERsOBbChxmo2ZLUgZqrHmW0aNhRL5L//LZ/JyZLrMnEizJ4tWlDFnKIoSslGBZ1SbMyaJXkk8fGSuDt8uLRCbdwYnnwS5s+XXJM335T2qF99JdVbrrxS3IJeXnkfe+9eqFFDhN/ff4tAnDULvL1d28ydmz1D1cknn4iL8VzIKQKPHZM8g6wsePZZyXj9J0ybJiVC3JMGwsMlkcDZtzQhQVzFGzbIPW/4I4NNf2eRmtkaaI2XZyYt6npwY2sRbq1aSa6Nu+s0PBxGjtQMVEVRlNKG1qFTspGaKrFSrVpBs2bw1FMyvmKFWKCaNxfh5axkMn26iIPWrWWdhwfExRV8nshIsVqNGiXLsbESv+Uso9e7t1TOAIl/S0gQd2BiosSD5daQ3Z2MDImBGz1akoO9veHFF13rn3tOjjFsWPb9fv9dYs+cCcmFITkZfvjBVa0GROA1biyWulq1slsU69eXZOh58yQmbuvWgs/RoYMIq/BweQ5hYVKCcMcOuPVWySj185NwzrFj4fOFqfhtWsOYrDf4sN8CNv2eTGKyB+vXS2WbsWPFHZ0zDi6/DFRFURSlBFOYzImyNBVJ66+LQEqKZCw6W5M++aSMv/669O2E7I0gTp6U7mLO7efOLdx5srJc7VnT0iSzcfVqa4ODrd2xQ8YnT7b23XfP3vfLL60NCSnceQYNsnb9eldDiqwsa+vWtTYiQtY/8IAkCFsr7XG7d7f2ssuk05mzI0F+REVJkw4nK1daO2CAzM+bJ31Gk5LO3m/cOGlLVRJISrL277+tXbzY2uefl+xVT09pmeVsl+VsmTVokLSj/WrOYXuo6xCbBfLy/vqruG9DURRF+QegWa5liwoVxErm4yMxTV27Qv/+UpP4+utdNYCdnI+bEsQa5uMj8+npMnl4nG09e+EFcYe6U9jYs6+/Fndku3au2mjGSJboQw/B6dMS6+a0wn33nVgAV6yQmre9e4t1yc8v73Ncdpl0RtixQ+79p5/keSxfLkkQv/wiljh3srIkW3TlyoLv4UJx+rTc065drmnnTvnM1skBqTlXq5bEEvbrB088AS1aOJ7D6dNyYw88Ly/rzTfhnnvk5SmKoihlHhV0F4BDh+DOO+HoUShXDu6+Gx58EKZMgXfekVgugOefl3IQ6eniavzzT3EN3nknPPZY/ufITWgZA23a5L39ubopnWRmitjavRvGjBEXbHq6ZGW2by+JBDnLcCQni1gqTNbm6tVS0uObb8TFGx8vSQ8ffSTFakESCnbulPn335cyHcZIOY4GDSSLtGPH/M/z+usiYtPSJPD//ffFdXn6tIhCkMSIt96S+ZUrxQWaX8OO3Cgovi09Hfbvzy7WnNOBA9kr3lSvLu7TXr3ks1EjEdJXXCHHCw2V8iOzZ8t9+fkhqvjee11tK155xVXQWlEURbk0KIwZryxNF8PleuSItX/8IfPx8dY2amTtli3WPvWUtdOnn739ggXW3nabzCcliWtw376Cz5ORITWLvb2tnTQp+7p69bK7XM/HTZmTEyfkGJs2WbtmjbVdu4rb9/HHpaisO4sWiYv3XHG6XK11NXVPTbW2Rw9rf/pJlu+9V56ltdYePWptrVrZ77W4cRbj/fBDKS78wAPiFu3YUdyhHh7ZXaRVqshzvP12ua+PPrJ23boztX1zP8fdC231KqfPFPxdscLa6n6pdkWju+WgDRtau3x5kdyvoiiKUnSgLteiIyjIZRDx9ZXMzZzuMneMkRZKGRmQkiJu0Pzch048PCSD8eRJaS+1eXPewfvn46bMib+/uHKXL5dSIblZz5y4F9U9X6ZPF3dsVpYkM/ToIeOTJ0vf0xYtRBK99JJYsgpDYbJDCyIjQ9prHTrkmg4ezL58/LiU/XBSsaJY0Nq0Eata48Yui1v16ufeiD6CDoTZUEJ4ELKuJeSbRwiL/4OIhI6E/O9/4n+tVOncDqooiqKUGVTQXWD275esyk6dxLX4xhvwwQfiqnz5ZahaVfp8fvGFiMDkZPGQBQQU/hzuQisvQXe+bsqYGChfXs6RkgI//igFeJ1lOJyhWo8/7trn1CmJSfvoo8Lfg5Pu3V3xf9OnZ+/W4KRWLVdNt3Olw55FhD4/kLAlXoSEOBrD35JG2G2fA0OwVu45P7F25Ii4od3x9ZUODXXqQFuPv6lznS/rYxvy5ZfSlnfmDeGY9eegGkGUbGKiPND4eNd06hSTOsSDRy0JmAwIgMhIQlq0IGTRnRIcqCiKolzSqKC7gCQmwqBBUpDfz0+sTJMni6iaPBkeflhqn61bJ9a2I0fgxAmxnPXqlX/sVl5CKy/q1pVEgG7dIDpawqsKExsWFSVlSTIzRV+EhoqGmDgxd+sZwJIlksTgXuOtJJCeDo171uHZBY9x8/Uv0S3Ek/AfM+matZpn1vXl7kZSPiU1Nft+FSqIUKtTRyx7znmngKtTx1Huw1o5yfeHCL/9HV7jEybfm8Dsd3248Z2ZhDzcVqoj5yLQcl1OSCjcjSUnww03wNKlErSpKIqiXPJo668LRHq6CJ++faXGWE7275f1mzdLosHVV7tcdCNHStZiaGjex9+48Wyh9eST0lJq2jRJyAgMlKSLd98VsXjXXSLQrBVr3R13XPDbPm+mDfiZDr2qEDLeldURPvMvIn48xaRvuue5X2qqCNS8J0t0VBbRxwwnTuYmdrII9jlF3erJ1PE9SR3vE9SpfJy6FWOoU/4odTyjqGGPYU6nyslSUuTTfXIfs5ZwuhNKGGGEEsLPZy2fwcdHlL6fnyhC53zO5bzWbdggX5bRoyUrQqv9KoqilHm09VcRYq2U8GjaNLuYi4pyxdYtWeJyj9atK7Ftd9whxpa1a8VNlx8tW4orNycPPCBTTv6Jm/KCBJ4VQIdeVQidUIcw/qLTPa1Z+sxGxkxrwMMD9/P2Ewc5eiRLxFmMB9Fx5Yk+VYHohMrEn869B5WfiaemOUbNrCiaEU0PoqnpmI5Rg5k8zHDms4BhfJAYSkjiz7KjMRLwVqmSfLpPlSrJVLVq9rEc20X81o2wK1YTstcXvoKQoUGEdY4mYt9CQsY5UlF9ff9ZCRFt4aAoiqLkg1roLgCrVolrs0ULlwfs+eelLtuGDaIZ6teHOXNE4CUmSueArVtFDI4YIS7NQlEEYmvaPXvosOhhQpY+iDPwLPzmWUQMeZlJcy4XE2FysrgIExMhIQGbkEjisWTiotOJO5ZB3PEs4mItcSfLEXfKg7iE8sQlehGXUpG41MrEpfkQlVaNWBsA5J4hUJW4M6JMpmPUrHCSmpUTqOmTRM0qqdSsmkZgtUwqVa3osmj5+p6ZD9/fgNDnWhLGbYQMr0v4h5GEmjDCFmQQ0qe8+LHPNUMhN8LDRWBdLOtZEbx3RVEUpeRRWAudCrpSRoFiy530dEmnzW9KTDwzbxOTSDqVwbc7G3LP6jt5Nut/XF7tFL8eb8IsxjG4wlf4Zx4nLt2XOALOmjIon+d1V+A01TxPElA+kYCKSQRUTCHA+zRbo/xZm9SSG6qt4d5bY6l5maFmbU8C61TAK8Anu0jz9j5n8XVOz+t8cYo5p4jLuawoiqIo54kKujy4WILufGPCcsVaEVmxsdIYNTb2zBS+3pfQBTdKCYvLDxK+K5hQPmFuvadpbTcQn+RBfLIn8Snlic+sTDx+Z02nqJLreAK+ZJG/W9CnfCoBlVMJ8D5NgG86AVUyCfC3BFSDgGrlCKjpSUBNLwJqVSAgqCIBNcsTEJB7RY3wmX8ROqEOo7tuZvaq5oTNOJTt+V0QisKypdYzRVEU5SKhgi4PLpagc4oTpyg5s/ziPkL+HUzW8ThSjpwg6cgpkqMTSDqWRNLxZJKOp5J8Mo2kk+kkncogOSGTpGRDUmYFkvAmmcok4X1mSqYyR00Qe2xDKpNMAr7k5bLMiXfFDPwqZ+Lnk4Wfr8WvClTxL4dfVQ/8Ajzwq1LOFYt/aAtfTN/BJ2kDGV1hLk8taEzVG7oW2DrsHz+viyHqFEVRFKWUooIuDy6myzV85l/c8HAj/Ewix2x1qnOcTDxIwpsUKhd8gBxU8srAu2Im3pUtlSuDt68H3lU88D59gn0Rx9mWdSWdPNbTd1g1/Fo2OCs50n3y8Sl86y+nWzLUhDH6AS9mv5YmFkGn2/ICcEEtmoqiKIpSRlFBlwcXO4ZuQGAE38Z0oGmFPXRsGEtl33J4+3ni7V+eyv5eeFeriHeNylSu4Y13QAW8fYyINW+ZnPOVKuVRYqwIxFb4PYsI/ST3Yrwhc4ZckHMoiqIoilIwl0zZEmNMP2AW4AG8a619sbiuJXzmX0Qcb8Dkbj8ze1Vzho+Kv+Duw/BF0ZKl6RBbISFehN4SRtiizy9Y/H3E5UMIW+LShyEhELbEi4iIIWiIv6IoiqKUPEq1hc4Y4wHsBHoDkUAEMNRauzWvfYo8hu4Cx4Rp/L2iKIqiXDpcKha6jsBua+1eAGPMIuAmIE9Bd7GI+PEUYTM4I95CxrchDIkJC8mlc8T5kptoc9aZVRRFURTl0qS0C7rawCG35UigU3FcSG6B/CHj21xQMacoiqIoipIbpb2zd271Os7yIRtj7jbGrDfGrI+JiSmCy1IURVEURSk6SrugiwTquC0HA0dybmStfdta295a275GjRpFdnGKoiiKoihFQWkXdBFAI2NMA2OMFzAE+LKYr0lRFEVRFKVIKdUxdNbaDGPMWOA7pGzJXGvtlmK+LEVRFEVRlCKlVAs6AGvtN8A3xX0diqIoiqIoxUVpd7kqiqIoiqJc8qigUxRFURRFKeWooFMURVEURSnlqKBTFEVRFEUp5aigUxRFURRFKeUYa89qrFCmMcbEAAeK+zouENWB48V9EUo29J2UPPSdnDv6zEoe+k5KHkX1TupZawvsinDJCbqyhDFmvbW2fXFfh+JC30nJQ9/JuaPPrOSh76TkUdLeibpcFUVRFEVRSjkq6BRFURRFUUo5KuhKN28X9wUoZ6HvpOSh7+Tc0WdW8tB3UvIoUe9EY+gURVEURVFKOWqhUxRFURRFKeWooLtAGGPqGGPCjTHbjDFbjDEPOsYDjDE/GGN2OT6rOsaHGWM2OqY1xphWbsfqZ4zZYYzZbYx5NJ9zDnccd5cxZrjb+HPGmEPGmMR89q1sjFlmjNnuuN4X3dZdY4z50xiTYYwZ/E+fTXFSxt7LXcaYGGPMBsc06p8+n+KgjL2TesaYnxzX9rMxJvifPp9czl8inld+zyGX/dsZYzY5zvOaMcY4xm917JtljCkx2YHnQxl7L1OMMYfdflsGXKjnVJSUsXfSyhjzm2PdV8YYvwIfgLVWpwswAUFAW8e8L7ATuAqYBjzqGH8UeMkx3wWo6pjvD/zumPcA9gANAS/gb+CqXM4XAOx1fFZ1zDuPd7XjehLzud7KQIhj3gv4FejvWK4PtAQ+AAYX97PV93LmvdwFvFHcz1TfSbZ38ikw3DHfA/iwrD6v/J5DLsdYB3QGDPCt2/NqClwJ/Ay0L+7vor6XM+9lCjChuJ+pvpNs7yQCuNYxPxJ4pqD7VwvdBcJaG2Wt/dMxnwBsA2oDNwHzHZvNB252bLPGWnvCMb4WcP7PviOw21q711qbBixyHCMnfYEfrLVxjuP8APRzHHuttTaqgOtNttaGO+bTgD+d12Ct3W+t3QhkneNjKHGUpfdSVihj7+Qq4CfHfHge5/9HlJTnVdjvpjEmCPCz1v5m5a/RB27Xts1au+MfPI4SQ1l6L2WFMvZOrgRWOuZ/AAYVdP8q6C4Cxpj6QBvgd6Cm8w+G4zMwl13+gyhzkC/fIbd1kY6xnBR2u8Jcrz9wA64/TGWSMvJeBjncA4uNMXXO57gliTLwTv7G9UN7C+BrjKl2Pscu5PnrUwKeVwG/GbUd+xR0njJDGXkvYx2/LXOdLsnSTBl4J5uBGx3ztwIF/t6roLvAGGN8gM+Acdba+EJsH4J8kR5xDuWyWW6pyIXdrqDzewILgdestXvPdf/SQhl5L18B9a21LYEfcf2Ps1RSRt7JBOBaY8xfwLXAYSDjXI9dyPOXiOdViN+MC/K8Swtl5L3MBi4HWgNRwMu5XnwpoYy8k5HAGGPMH4j7OC33q3ehgu4CYowpj3yJFlhrP3cMRzvMqk7z6jG37VsC7wI3WWtjHcORZFfiwcARY0wnt4DVG/PaLp9r83Dbf6rbqreBXdbaV8/nnksDZeW9WGtjrbWnHYvvAO0K+wxKGmXonRyx1g601rYBHneMnTqHR1EoStjzyvYccnlekWR3L+X7vEszZeW9WGujrbWZ1tos5Lel4/k+k+KmDL2T7dbaPtbadogo3FPgzdsSEMhYFiZEaX8AvJpjfDrZgzGnOebrAruBLjm290QCKxvgCsZslsv5AoB9SABmVcd8QI5t8gz0dqx/Fvnil8tj/TxKf1JEmXkvQJDb/C3A2uJ+vvpOqO4cA54Dppbl51XQb4bbMSKQhBNnoPeAHOt/pvQnRZSZ95Ljt+UhYFFxP199JwQ6Pss57mlkgfdf3C+grExAV8RUuhHY4JgGANUQ3/kux6fzZb8LnHDbdr3bsQYg2Tl7gMfzOedIx5dxNzDCbXwaovyzHJ9Tctk32HG929yuYZRjXQfHfklALLCluJ+vvhcL8AKwxfHjEg40Ke7nq++EwY7r3em4zgpl9Xnl9xxy2b89EgO0B3gDzhSxv8XxnE8D0cB3xf191PdiAT4ENjnu5UvcBF5pmsrYO3nQcf6dwIvO8fwm7RShKIqiKIpSytEYOkVRFEVRlFKOCjpFURRFUZRSjgo6RVEURVGUUo4KOkVRFEVRlFKOCjpFURRFUZRSjgo6RVEURVGUUo4KOkVRFEVRlFKOZ3FfgKIoSmnCGDMFqezu7NnqCazNbcxaO6Wor09RlEsTFXSKoijnzhBr7UkAY4w/MC6PMUVRlCJBXa6KoiiKoiilHBV0iqIoiqIopRwVdIqiKIqiKKUcFXSKoiiKoiilHBV0iqIoiqIopRwVdIqiKIqiKKUcLVuiKIpybhwDPjDGZDmWywHL8xhTFEUpEoy1trivQVEURVEURfkHqMtVURRFURSllKOCTlEURVEUpZSjgk5RFEVRFKWUo4JOURRFURSllKOCTlEURVEUpZTz/2xIPJh3JdY2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "差分序列次数为： 1\n",
      "0 0\n",
      "0 1\n",
      "1 0\n",
      "1 1\n",
      "BIC最小的p值和q值为：0、1\n",
      "0.1346784452062565\n",
      "差分序列次数为： 1\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "1 0\n",
      "1 1\n",
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n",
      "2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC最小的p值和q值为：0、1\n",
      "0.014087746624891973\n",
      "差分序列次数为： 1\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "1 0\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "BIC最小的p值和q值为：0、0\n",
      "0.003586248758575628\n",
      "{'beta': 0.1346784452062565, 'gamma_2': 0.014087746624891973, 'theta': 0.003586248758575628}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27494 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27721 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22686 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22686 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model_predict(model_city_date_path, data_wh, N_cur=param['N_model_1'],beta=param['beta_model_1'],gamma_2=param['gamma_2_model_1'],theta=param['theta_model_1'], city_name='武汉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'beta_model_2': 0.03808052845960208, 'gamma_2_model_2': 0.011726751251695009, 'N_model_2': 59170000.21805534, 'theta_model_2': 0.003805129170338665}\n",
    "# i=2\n",
    "# for k in list(param.keys()):\n",
    "#     old_key = k\n",
    "#     new_key = k.replace(f'_model_{i}','')\n",
    "#     param[new_key]=param.pop(old_key)\n",
    "# param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_city_data(data, N, date, cityname='深圳',max_epoches=2000):\n",
    "    city_pinyin = {'深圳':'shenzhen', '湖北':'hubei', '武汉':'wuhan', '全国':'china'}\n",
    "    pinyin = city_pinyin[cityname]\n",
    "    model_city_date_path = make_dir(pinyin,date)\n",
    "    features=['I', 'cured','dead']\n",
    "    I_init = float(data['I'].iloc[0])\n",
    "    R_init = float(data['cured'].iloc[0])\n",
    "    D_init = float(data['dead'].iloc[0])\n",
    "    N = N\n",
    "    S,I,E,R,D = train(data, model_city_date_path, N=N, I_init=I_init, R_init=R_init, D_init=D_init, features=features, max_epoches=max_epoches)\n",
    "    return model_city_date_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>suspected</th>\n",
       "      <th>dead</th>\n",
       "      <th>cured</th>\n",
       "      <th>close_contact</th>\n",
       "      <th>under_medical_observation</th>\n",
       "      <th>quit_medical_observation</th>\n",
       "      <th>time</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1070</td>\n",
       "      <td>331</td>\n",
       "      <td>739</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>1181</td>\n",
       "      <td>426</td>\n",
       "      <td>755</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2556</td>\n",
       "      <td>1693</td>\n",
       "      <td>863</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>549</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>3653</td>\n",
       "      <td>2776</td>\n",
       "      <td>877</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>5682</td>\n",
       "      <td>4711</td>\n",
       "      <td>971</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1052</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>7989</td>\n",
       "      <td>6904</td>\n",
       "      <td>1085</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1423</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>10394</td>\n",
       "      <td>9103</td>\n",
       "      <td>1291</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2714</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>16904</td>\n",
       "      <td>15559</td>\n",
       "      <td>1345</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>2567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3554</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>80</td>\n",
       "      <td>22095</td>\n",
       "      <td>20366</td>\n",
       "      <td>1729</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>3349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4586</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>90</td>\n",
       "      <td>28780</td>\n",
       "      <td>26632</td>\n",
       "      <td>2148</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>4334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5806</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>116</td>\n",
       "      <td>35144</td>\n",
       "      <td>32340</td>\n",
       "      <td>2804</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>5486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>7153</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>166</td>\n",
       "      <td>41075</td>\n",
       "      <td>36838</td>\n",
       "      <td>4237</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>6738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>9074</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>215</td>\n",
       "      <td>48571</td>\n",
       "      <td>43121</td>\n",
       "      <td>5450</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>11177</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>295</td>\n",
       "      <td>56088</td>\n",
       "      <td>48171</td>\n",
       "      <td>7917</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>10532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>13522</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>396</td>\n",
       "      <td>68988</td>\n",
       "      <td>58544</td>\n",
       "      <td>10444</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>12712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16678</td>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>520</td>\n",
       "      <td>81039</td>\n",
       "      <td>66764</td>\n",
       "      <td>14275</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>15679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>19665</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>633</td>\n",
       "      <td>90997</td>\n",
       "      <td>64127</td>\n",
       "      <td>26870</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>18483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>22112</td>\n",
       "      <td>0</td>\n",
       "      <td>618</td>\n",
       "      <td>817</td>\n",
       "      <td>101599</td>\n",
       "      <td>64057</td>\n",
       "      <td>37542</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>20677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>24953</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>1115</td>\n",
       "      <td>114044</td>\n",
       "      <td>67802</td>\n",
       "      <td>46242</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>23139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>27100</td>\n",
       "      <td>23638</td>\n",
       "      <td>780</td>\n",
       "      <td>1439</td>\n",
       "      <td>123827</td>\n",
       "      <td>70438</td>\n",
       "      <td>53389</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>24881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>29631</td>\n",
       "      <td>18438</td>\n",
       "      <td>871</td>\n",
       "      <td>1795</td>\n",
       "      <td>132555</td>\n",
       "      <td>73127</td>\n",
       "      <td>59428</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>26965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confirmed  suspected  dead  cured  close_contact  \\\n",
       "0         270          0     6     25           1070   \n",
       "1         375          0     9     28           1181   \n",
       "2         444          0    17     28           2556   \n",
       "3         549          0    24     31           3653   \n",
       "4         729          0    39     32           5682   \n",
       "5        1052          0    52     42           7989   \n",
       "6        1423          0    76     44          10394   \n",
       "7        2714          0   100     47          16904   \n",
       "8        3554          0   125     80          22095   \n",
       "9        4586          0   162     90          28780   \n",
       "10       5806          0   204    116          35144   \n",
       "11       7153          0   249    166          41075   \n",
       "12       9074          0   294    215          48571   \n",
       "13      11177          0   350    295          56088   \n",
       "14      13522          0   414    396          68988   \n",
       "15      16678          0   479    520          81039   \n",
       "16      19665          0   549    633          90997   \n",
       "17      22112          0   618    817         101599   \n",
       "18      24953          0   699   1115         114044   \n",
       "19      27100      23638   780   1439         123827   \n",
       "20      29631      18438   871   1795         132555   \n",
       "\n",
       "    under_medical_observation  quit_medical_observation       time      I  \n",
       "0                         331                       739 2020-01-20    239  \n",
       "1                         426                       755 2020-01-21    338  \n",
       "2                        1693                       863 2020-01-22    399  \n",
       "3                        2776                       877 2020-01-23    494  \n",
       "4                        4711                       971 2020-01-24    658  \n",
       "5                        6904                      1085 2020-01-25    958  \n",
       "6                        9103                      1291 2020-01-26   1303  \n",
       "7                       15559                      1345 2020-01-27   2567  \n",
       "8                       20366                      1729 2020-01-28   3349  \n",
       "9                       26632                      2148 2020-01-29   4334  \n",
       "10                      32340                      2804 2020-01-30   5486  \n",
       "11                      36838                      4237 2020-01-31   6738  \n",
       "12                      43121                      5450 2020-02-01   8565  \n",
       "13                      48171                      7917 2020-02-02  10532  \n",
       "14                      58544                     10444 2020-02-03  12712  \n",
       "15                      66764                     14275 2020-02-04  15679  \n",
       "16                      64127                     26870 2020-02-05  18483  \n",
       "17                      64057                     37542 2020-02-06  20677  \n",
       "18                      67802                     46242 2020-02-07  23139  \n",
       "19                      70438                     53389 2020-02-08  24881  \n",
       "20                      73127                     59428 2020-02-09  26965  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hubei = read_data('./ncov/data/hubei_截至0209_24时i.csv')\n",
    "data_hubei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'beta_model_2': 0.03808052845960208, 'gamma_2_model_2': 0.011726751251695009, 'N_model_2': 0, 'theta_model_2': 0.003805129170338665}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n",
      "Loss: 872839.330382037\n",
      "Training step:  1556\n",
      "Loss: 669415.1439158998\n",
      "Training step:  1557\n",
      "Loss: 872823.1480143704\n",
      "Training step:  1558\n",
      "Loss: 669398.6483449434\n",
      "Training step:  1559\n",
      "Loss: 872806.9988472472\n",
      "Training step:  1560\n",
      "Loss: 669382.186563009\n",
      "Training step:  1561\n",
      "Loss: 872790.8827756529\n",
      "Training step:  1562\n",
      "Loss: 669365.7584629584\n",
      "Training step:  1563\n",
      "Loss: 872774.7996951195\n",
      "Training step:  1564\n",
      "Loss: 669349.3639379631\n",
      "Training step:  1565\n",
      "Loss: 872758.7495012515\n",
      "Training step:  1566\n",
      "Loss: 669333.0028816931\n",
      "Training step:  1567\n",
      "Loss: 872742.7320904778\n",
      "Training step:  1568\n",
      "Loss: 669316.6751884097\n",
      "Training step:  1569\n",
      "Loss: 872726.7473596112\n",
      "Training step:  1570\n",
      "Loss: 669300.3807527468\n",
      "Training step:  1571\n",
      "Loss: 872710.7952058689\n",
      "Training step:  1572\n",
      "Loss: 669284.1194699481\n",
      "Training step:  1573\n",
      "Loss: 872694.8755271897\n",
      "Training step:  1574\n",
      "Loss: 669267.8912355811\n",
      "Training step:  1575\n",
      "Loss: 872678.9882214658\n",
      "Training step:  1576\n",
      "Loss: 669251.6959455821\n",
      "Training step:  1577\n",
      "Loss: 872663.1331872933\n",
      "Training step:  1578\n",
      "Loss: 669235.5334965546\n",
      "Training step:  1579\n",
      "Loss: 872647.310323899\n",
      "Training step:  1580\n",
      "Loss: 669219.4037855824\n",
      "Training step:  1581\n",
      "Loss: 872631.519530856\n",
      "Training step:  1582\n",
      "Loss: 669203.3067100262\n",
      "Training step:  1583\n",
      "Loss: 872615.7607079457\n",
      "Training step:  1584\n",
      "Loss: 669187.2421677051\n",
      "Training step:  1585\n",
      "Loss: 872600.0337555149\n",
      "Training step:  1586\n",
      "Loss: 669171.210056958\n",
      "Training step:  1587\n",
      "Loss: 872584.3385744245\n",
      "Training step:  1588\n",
      "Loss: 669155.2102765639\n",
      "Training step:  1589\n",
      "Loss: 872568.6750658937\n",
      "Training step:  1590\n",
      "Loss: 669139.2427257284\n",
      "Training step:  1591\n",
      "Loss: 872553.0431315859\n",
      "Training step:  1592\n",
      "Loss: 669123.3073040468\n",
      "Training step:  1593\n",
      "Loss: 872537.442673508\n",
      "Training step:  1594\n",
      "Loss: 669107.4039116162\n",
      "Training step:  1595\n",
      "Loss: 872521.8735942849\n",
      "Training step:  1596\n",
      "Loss: 669091.5324489922\n",
      "Training step:  1597\n",
      "Loss: 872506.3357968132\n",
      "Training step:  1598\n",
      "Loss: 669075.6928171804\n",
      "Training step:  1599\n",
      "Loss: 872490.82918474\n",
      "Training step:  1600\n",
      "Loss: 669059.884917653\n",
      "Training step:  1601\n",
      "Loss: 872475.3536617431\n",
      "Training step:  1602\n",
      "Loss: 669044.1086521379\n",
      "Training step:  1603\n",
      "Loss: 872459.9091319522\n",
      "Training step:  1604\n",
      "Loss: 669028.363922778\n",
      "Training step:  1605\n",
      "Loss: 872444.4954998562\n",
      "Training step:  1606\n",
      "Loss: 669012.6506323181\n",
      "Training step:  1607\n",
      "Loss: 872429.1126707066\n",
      "Training step:  1608\n",
      "Loss: 668996.9686838839\n",
      "Training step:  1609\n",
      "Loss: 872413.7605499866\n",
      "Training step:  1610\n",
      "Loss: 668981.3179810536\n",
      "Training step:  1611\n",
      "Loss: 872398.4390435881\n",
      "Training step:  1612\n",
      "Loss: 668965.6984276831\n",
      "Training step:  1613\n",
      "Loss: 872383.1480576715\n",
      "Training step:  1614\n",
      "Loss: 668950.1099281192\n",
      "Training step:  1615\n",
      "Loss: 872367.8874989976\n",
      "Training step:  1616\n",
      "Loss: 668934.5523871308\n",
      "Training step:  1617\n",
      "Loss: 872352.6572745015\n",
      "Training step:  1618\n",
      "Loss: 668919.0257097803\n",
      "Training step:  1619\n",
      "Loss: 872337.4572917272\n",
      "Training step:  1620\n",
      "Loss: 668903.5298017908\n",
      "Training step:  1621\n",
      "Loss: 872322.2874585823\n",
      "Training step:  1622\n",
      "Loss: 668888.0645689702\n",
      "Training step:  1623\n",
      "Loss: 872307.1476831882\n",
      "Training step:  1624\n",
      "Loss: 668872.6299178912\n",
      "Training step:  1625\n",
      "Loss: 872292.037874538\n",
      "Training step:  1626\n",
      "Loss: 668857.2257552523\n",
      "Training step:  1627\n",
      "Loss: 872276.957941335\n",
      "Training step:  1628\n",
      "Loss: 668841.8519881585\n",
      "Training step:  1629\n",
      "Loss: 872261.907793107\n",
      "Training step:  1630\n",
      "Loss: 668826.5085243068\n",
      "Training step:  1631\n",
      "Loss: 872246.8873398567\n",
      "Training step:  1632\n",
      "Loss: 668811.195271631\n",
      "Training step:  1633\n",
      "Loss: 872231.8964916349\n",
      "Training step:  1634\n",
      "Loss: 668795.9121385728\n",
      "Training step:  1635\n",
      "Loss: 872216.9351592304\n",
      "Training step:  1636\n",
      "Loss: 668780.6590338215\n",
      "Training step:  1637\n",
      "Loss: 872202.0032533862\n",
      "Training step:  1638\n",
      "Loss: 668765.4358664886\n",
      "Training step:  1639\n",
      "Loss: 872187.1006855635\n",
      "Training step:  1640\n",
      "Loss: 668750.2425461748\n",
      "Training step:  1641\n",
      "Loss: 872172.2273674828\n",
      "Training step:  1642\n",
      "Loss: 668735.0789827335\n",
      "Training step:  1643\n",
      "Loss: 872157.3832112056\n",
      "Training step:  1644\n",
      "Loss: 668719.945086482\n",
      "Training step:  1645\n",
      "Loss: 872142.5681292143\n",
      "Training step:  1646\n",
      "Loss: 668704.8407681352\n",
      "Training step:  1647\n",
      "Loss: 872127.7820344894\n",
      "Training step:  1648\n",
      "Loss: 668689.7659387473\n",
      "Training step:  1649\n",
      "Loss: 872113.0248400638\n",
      "Training step:  1650\n",
      "Loss: 668674.7205096689\n",
      "Training step:  1651\n",
      "Loss: 872098.2964595867\n",
      "Training step:  1652\n",
      "Loss: 668659.704392779\n",
      "Training step:  1653\n",
      "Loss: 872083.5968069925\n",
      "Training step:  1654\n",
      "Loss: 668644.7175002369\n",
      "Training step:  1655\n",
      "Loss: 872068.9257966161\n",
      "Training step:  1656\n",
      "Loss: 668629.7597446099\n",
      "Training step:  1657\n",
      "Loss: 872054.2833431497\n",
      "Training step:  1658\n",
      "Loss: 668614.8310387959\n",
      "Training step:  1659\n",
      "Loss: 872039.6693615522\n",
      "Training step:  1660\n",
      "Loss: 668599.9312960759\n",
      "Training step:  1661\n",
      "Loss: 872025.0837672215\n",
      "Training step:  1662\n",
      "Loss: 668585.060430037\n",
      "Training step:  1663\n",
      "Loss: 872010.5264758156\n",
      "Training step:  1664\n",
      "Loss: 668570.2183547453\n",
      "Training step:  1665\n",
      "Loss: 871995.9974035398\n",
      "Training step:  1666\n",
      "Loss: 668555.4049845493\n",
      "Training step:  1667\n",
      "Loss: 871981.4964667747\n",
      "Training step:  1668\n",
      "Loss: 668540.6202342333\n",
      "Training step:  1669\n",
      "Loss: 871967.023582458\n",
      "Training step:  1670\n",
      "Loss: 668525.8640188961\n",
      "Training step:  1671\n",
      "Loss: 871952.5786676536\n",
      "Training step:  1672\n",
      "Loss: 668511.1362539278\n",
      "Training step:  1673\n",
      "Loss: 871938.1616397811\n",
      "Training step:  1674\n",
      "Loss: 668496.4368550635\n",
      "Training step:  1675\n",
      "Loss: 871923.7724166327\n",
      "Training step:  1676\n",
      "Loss: 668481.7657384755\n",
      "Training step:  1677\n",
      "Loss: 871909.4109163864\n",
      "Training step:  1678\n",
      "Loss: 668467.1228206205\n",
      "Training step:  1679\n",
      "Loss: 871895.0770575446\n",
      "Training step:  1680\n",
      "Loss: 668452.508018414\n",
      "Training step:  1681\n",
      "Loss: 871880.7707591212\n",
      "Training step:  1682\n",
      "Loss: 668437.9212490515\n",
      "Training step:  1683\n",
      "Loss: 871866.4919402018\n",
      "Training step:  1684\n",
      "Loss: 668423.3624300207\n",
      "Training step:  1685\n",
      "Loss: 871852.240520284\n",
      "Training step:  1686\n",
      "Loss: 668408.8314791715\n",
      "Training step:  1687\n",
      "Loss: 871838.0164192125\n",
      "Training step:  1688\n",
      "Loss: 668394.3283147205\n",
      "Training step:  1689\n",
      "Loss: 871823.8195571615\n",
      "Training step:  1690\n",
      "Loss: 668379.8528551889\n",
      "Training step:  1691\n",
      "Loss: 871809.649854623\n",
      "Training step:  1692\n",
      "Loss: 668365.4050194395\n",
      "Training step:  1693\n",
      "Loss: 871795.507232377\n",
      "Training step:  1694\n",
      "Loss: 668350.9847266859\n",
      "Training step:  1695\n",
      "Loss: 871781.3916116358\n",
      "Training step:  1696\n",
      "Loss: 668336.5918964917\n",
      "Training step:  1697\n",
      "Loss: 871767.3029138959\n",
      "Training step:  1698\n",
      "Loss: 668322.226448741\n",
      "Training step:  1699\n",
      "Loss: 871753.2410609727\n",
      "Training step:  1700\n",
      "Loss: 668307.8883036327\n",
      "Training step:  1701\n",
      "Loss: 871739.205974944\n",
      "Training step:  1702\n",
      "Loss: 668293.5773816368\n",
      "Training step:  1703\n",
      "Loss: 871725.1975782074\n",
      "Training step:  1704\n",
      "Loss: 668279.2936036834\n",
      "Training step:  1705\n",
      "Loss: 871711.2157936404\n",
      "Training step:  1706\n",
      "Loss: 668265.0368909073\n",
      "Training step:  1707\n",
      "Loss: 871697.2605442116\n",
      "Training step:  1708\n",
      "Loss: 668250.8071648092\n",
      "Training step:  1709\n",
      "Loss: 871683.3317533518\n",
      "Training step:  1710\n",
      "Loss: 668236.6043472654\n",
      "Training step:  1711\n",
      "Loss: 871669.4293448365\n",
      "Training step:  1712\n",
      "Loss: 668222.4283603741\n",
      "Training step:  1713\n",
      "Loss: 871655.5532425822\n",
      "Training step:  1714\n",
      "Loss: 668208.2791265991\n",
      "Training step:  1715\n",
      "Loss: 871641.7033708933\n",
      "Training step:  1716\n",
      "Loss: 668194.1565686688\n",
      "Training step:  1717\n",
      "Loss: 871627.879654431\n",
      "Training step:  1718\n",
      "Loss: 668180.0606097276\n",
      "Training step:  1719\n",
      "Loss: 871614.0820181475\n",
      "Training step:  1720\n",
      "Loss: 668165.9911732137\n",
      "Training step:  1721\n",
      "Loss: 871600.3103874155\n",
      "Training step:  1722\n",
      "Loss: 668151.9481828619\n",
      "Training step:  1723\n",
      "Loss: 871586.564687689\n",
      "Training step:  1724\n",
      "Loss: 668137.9315626322\n",
      "Training step:  1725\n",
      "Loss: 871572.8448447577\n",
      "Training step:  1726\n",
      "Loss: 668123.9412368515\n",
      "Training step:  1727\n",
      "Loss: 871559.1507848596\n",
      "Training step:  1728\n",
      "Loss: 668109.9771302573\n",
      "Training step:  1729\n",
      "Loss: 871545.4824344933\n",
      "Training step:  1730\n",
      "Loss: 668096.0391676506\n",
      "Training step:  1731\n",
      "Loss: 871531.8397200704\n",
      "Training step:  1732\n",
      "Loss: 668082.127274224\n",
      "Training step:  1733\n",
      "Loss: 871518.2225688179\n",
      "Training step:  1734\n",
      "Loss: 668068.2413755694\n",
      "Training step:  1735\n",
      "Loss: 871504.6309078996\n",
      "Training step:  1736\n",
      "Loss: 668054.3813974387\n",
      "Training step:  1737\n",
      "Loss: 871491.0646649724\n",
      "Training step:  1738\n",
      "Loss: 668040.5472660947\n",
      "Training step:  1739\n",
      "Loss: 871477.5237681149\n",
      "Training step:  1740\n",
      "Loss: 668026.7389079452\n",
      "Training step:  1741\n",
      "Loss: 871464.0081454039\n",
      "Training step:  1742\n",
      "Loss: 668012.9562497602\n",
      "Training step:  1743\n",
      "Loss: 871450.5177254553\n",
      "Training step:  1744\n",
      "Loss: 667999.1992185251\n",
      "Training step:  1745\n",
      "Loss: 871437.0524368833\n",
      "Training step:  1746\n",
      "Loss: 667985.4677415558\n",
      "Training step:  1747\n",
      "Loss: 871423.6122088261\n",
      "Training step:  1748\n",
      "Loss: 667971.7617464447\n",
      "Training step:  1749\n",
      "Loss: 871410.1969705519\n",
      "Training step:  1750\n",
      "Loss: 667958.0811610722\n",
      "Training step:  1751\n",
      "Loss: 871396.8066516625\n",
      "Training step:  1752\n",
      "Loss: 667944.4259136167\n",
      "Training step:  1753\n",
      "Loss: 871383.4411820844\n",
      "Training step:  1754\n",
      "Loss: 667930.7959325582\n",
      "Training step:  1755\n",
      "Loss: 871370.1004920048\n",
      "Training step:  1756\n",
      "Loss: 667917.1911466927\n",
      "Training step:  1757\n",
      "Loss: 871356.7845119651\n",
      "Training step:  1758\n",
      "Loss: 667903.6114850091\n",
      "Training step:  1759\n",
      "Loss: 871343.4931724658\n",
      "Training step:  1760\n",
      "Loss: 667890.0568767755\n",
      "Training step:  1761\n",
      "Loss: 871330.2264046749\n",
      "Training step:  1762\n",
      "Loss: 667876.5272516832\n",
      "Training step:  1763\n",
      "Loss: 871316.9841398668\n",
      "Training step:  1764\n",
      "Loss: 667863.0225395533\n",
      "Training step:  1765\n",
      "Loss: 871303.7663095072\n",
      "Training step:  1766\n",
      "Loss: 667849.5426705098\n",
      "Training step:  1767\n",
      "Loss: 871290.572845375\n",
      "Training step:  1768\n",
      "Loss: 667836.0875749812\n",
      "Training step:  1769\n",
      "Loss: 871277.4036796344\n",
      "Training step:  1770\n",
      "Loss: 667822.6571837094\n",
      "Training step:  1771\n",
      "Loss: 871264.2587445815\n",
      "Training step:  1772\n",
      "Loss: 667809.251427592\n",
      "Training step:  1773\n",
      "Loss: 871251.1379728565\n",
      "Training step:  1774\n",
      "Loss: 667795.8702380513\n",
      "Training step:  1775\n",
      "Loss: 871238.0412975637\n",
      "Training step:  1776\n",
      "Loss: 667782.5135465417\n",
      "Training step:  1777\n",
      "Loss: 871224.9686516401\n",
      "Training step:  1778\n",
      "Loss: 667769.1812847871\n",
      "Training step:  1779\n",
      "Loss: 871211.9199684552\n",
      "Training step:  1780\n",
      "Loss: 667755.8733847913\n",
      "Training step:  1781\n",
      "Loss: 871198.8951815877\n",
      "Training step:  1782\n",
      "Loss: 667742.58977884\n",
      "Training step:  1783\n",
      "Loss: 871185.8942249706\n",
      "Training step:  1784\n",
      "Loss: 667729.3303995691\n",
      "Training step:  1785\n",
      "Loss: 871172.9170329185\n",
      "Training step:  1786\n",
      "Loss: 667716.0951799469\n",
      "Training step:  1787\n",
      "Loss: 871159.9635399979\n",
      "Training step:  1788\n",
      "Loss: 667702.8840529933\n",
      "Training step:  1789\n",
      "Loss: 871147.0336806561\n",
      "Training step:  1790\n",
      "Loss: 667689.696952009\n",
      "Training step:  1791\n",
      "Loss: 871134.1273898553\n",
      "Training step:  1792\n",
      "Loss: 667676.5338106451\n",
      "Training step:  1793\n",
      "Loss: 871121.2446028161\n",
      "Training step:  1794\n",
      "Loss: 667663.3945628207\n",
      "Training step:  1795\n",
      "Loss: 871108.3852550954\n",
      "Training step:  1796\n",
      "Loss: 667650.2791427297\n",
      "Training step:  1797\n",
      "Loss: 871095.5492824159\n",
      "Training step:  1798\n",
      "Loss: 667637.187484776\n",
      "Training step:  1799\n",
      "Loss: 871082.7366206842\n",
      "Training step:  1800\n",
      "Loss: 667624.1195234921\n",
      "Training step:  1801\n",
      "Loss: 871069.94720589\n",
      "Training step:  1802\n",
      "Loss: 667611.0751937819\n",
      "Training step:  1803\n",
      "Loss: 871057.1809746983\n",
      "Training step:  1804\n",
      "Loss: 667598.0544310007\n",
      "Training step:  1805\n",
      "Loss: 871044.4378639394\n",
      "Training step:  1806\n",
      "Loss: 667585.0571704445\n",
      "Training step:  1807\n",
      "Loss: 871031.7178103152\n",
      "Training step:  1808\n",
      "Loss: 667572.0833477089\n",
      "Training step:  1809\n",
      "Loss: 871019.0207509781\n",
      "Training step:  1810\n",
      "Loss: 667559.1328987487\n",
      "Training step:  1811\n",
      "Loss: 871006.3466234783\n",
      "Training step:  1812\n",
      "Loss: 667546.2057597416\n",
      "Training step:  1813\n",
      "Loss: 870993.6953654364\n",
      "Training step:  1814\n",
      "Loss: 667533.3018670649\n",
      "Training step:  1815\n",
      "Loss: 870981.0669147682\n",
      "Training step:  1816\n",
      "Loss: 667520.4211573836\n",
      "Training step:  1817\n",
      "Loss: 870968.4612095641\n",
      "Training step:  1818\n",
      "Loss: 667507.563567529\n",
      "Training step:  1819\n",
      "Loss: 870955.8781882096\n",
      "Training step:  1820\n",
      "Loss: 667494.7290346842\n",
      "Training step:  1821\n",
      "Loss: 870943.3177893731\n",
      "Training step:  1822\n",
      "Loss: 667481.9174962225\n",
      "Training step:  1823\n",
      "Loss: 870930.7799518551\n",
      "Training step:  1824\n",
      "Loss: 667469.1288896936\n",
      "Training step:  1825\n",
      "Loss: 870918.264614644\n",
      "Training step:  1826\n",
      "Loss: 667456.3631529588\n",
      "Training step:  1827\n",
      "Loss: 870905.7717172159\n",
      "Training step:  1828\n",
      "Loss: 667443.6202242225\n",
      "Training step:  1829\n",
      "Loss: 870893.3011991314\n",
      "Training step:  1830\n",
      "Loss: 667430.9000416984\n",
      "Training step:  1831\n",
      "Loss: 870880.8530000425\n",
      "Training step:  1832\n",
      "Loss: 667418.2025439788\n",
      "Training step:  1833\n",
      "Loss: 870868.4270599788\n",
      "Training step:  1834\n",
      "Loss: 667405.5276697263\n",
      "Training step:  1835\n",
      "Loss: 870856.0233189807\n",
      "Training step:  1836\n",
      "Loss: 667392.8753580672\n",
      "Training step:  1837\n",
      "Loss: 870843.6417178244\n",
      "Training step:  1838\n",
      "Loss: 667380.2455483468\n",
      "Training step:  1839\n",
      "Loss: 870831.2821971636\n",
      "Training step:  1840\n",
      "Loss: 667367.638179979\n",
      "Training step:  1841\n",
      "Loss: 870818.9446977043\n",
      "Training step:  1842\n",
      "Loss: 667355.0531925275\n",
      "Training step:  1843\n",
      "Loss: 870806.629160531\n",
      "Training step:  1844\n",
      "Loss: 667342.4905261064\n",
      "Training step:  1845\n",
      "Loss: 870794.3355272841\n",
      "Training step:  1846\n",
      "Loss: 667329.9501208861\n",
      "Training step:  1847\n",
      "Loss: 870782.06373937\n",
      "Training step:  1848\n",
      "Loss: 667317.4319172087\n",
      "Training step:  1849\n",
      "Loss: 870769.8137385703\n",
      "Training step:  1850\n",
      "Loss: 667304.9358556498\n",
      "Training step:  1851\n",
      "Loss: 870757.5854668324\n",
      "Training step:  1852\n",
      "Loss: 667292.4618770935\n",
      "Training step:  1853\n",
      "Loss: 870745.3788664916\n",
      "Training step:  1854\n",
      "Loss: 667280.0099226246\n",
      "Training step:  1855\n",
      "Loss: 870733.1938799472\n",
      "Training step:  1856\n",
      "Loss: 667267.5799334816\n",
      "Training step:  1857\n",
      "Loss: 870721.0304498578\n",
      "Training step:  1858\n",
      "Loss: 667255.1718512527\n",
      "Training step:  1859\n",
      "Loss: 870708.8885191855\n",
      "Training step:  1860\n",
      "Loss: 667242.7856176244\n",
      "Training step:  1861\n",
      "Loss: 870696.7680309477\n",
      "Training step:  1862\n",
      "Loss: 667230.421174544\n",
      "Training step:  1863\n",
      "Loss: 870684.6689284366\n",
      "Training step:  1864\n",
      "Loss: 667218.0784640937\n",
      "Training step:  1865\n",
      "Loss: 870672.591155039\n",
      "Training step:  1866\n",
      "Loss: 667205.757428719\n",
      "Training step:  1867\n",
      "Loss: 870660.5346546939\n",
      "Training step:  1868\n",
      "Loss: 667193.4580110434\n",
      "Training step:  1869\n",
      "Loss: 870648.4993712709\n",
      "Training step:  1870\n",
      "Loss: 667181.1801538935\n",
      "Training step:  1871\n",
      "Loss: 870636.4852489794\n",
      "Training step:  1872\n",
      "Loss: 667168.9238002861\n",
      "Training step:  1873\n",
      "Loss: 870624.4922321714\n",
      "Training step:  1874\n",
      "Loss: 667156.6888934723\n",
      "Training step:  1875\n",
      "Loss: 870612.520265326\n",
      "Training step:  1876\n",
      "Loss: 667144.4753767485\n",
      "Training step:  1877\n",
      "Loss: 870600.5692930379\n",
      "Training step:  1878\n",
      "Loss: 667132.2831938169\n",
      "Training step:  1879\n",
      "Loss: 870588.6392603868\n",
      "Training step:  1880\n",
      "Loss: 667120.1122884947\n",
      "Training step:  1881\n",
      "Loss: 870576.7301124557\n",
      "Training step:  1882\n",
      "Loss: 667107.9626049501\n",
      "Training step:  1883\n",
      "Loss: 870564.8417948382\n",
      "Training step:  1884\n",
      "Loss: 667095.834087434\n",
      "Training step:  1885\n",
      "Loss: 870552.9742529107\n",
      "Training step:  1886\n",
      "Loss: 667083.7266803973\n",
      "Training step:  1887\n",
      "Loss: 870541.1274325529\n",
      "Training step:  1888\n",
      "Loss: 667071.6403286237\n",
      "Training step:  1889\n",
      "Loss: 870529.3012797991\n",
      "Training step:  1890\n",
      "Loss: 667059.574976931\n",
      "Training step:  1891\n",
      "Loss: 870517.4957407012\n",
      "Training step:  1892\n",
      "Loss: 667047.5305704563\n",
      "Training step:  1893\n",
      "Loss: 870505.7107617578\n",
      "Training step:  1894\n",
      "Loss: 667035.5070545281\n",
      "Training step:  1895\n",
      "Loss: 870493.9462895173\n",
      "Training step:  1896\n",
      "Loss: 667023.5043745915\n",
      "Training step:  1897\n",
      "Loss: 870482.2022706608\n",
      "Training step:  1898\n",
      "Loss: 667011.5224763595\n",
      "Training step:  1899\n",
      "Loss: 870470.4786521931\n",
      "Training step:  1900\n",
      "Loss: 666999.561305693\n",
      "Training step:  1901\n",
      "Loss: 870458.7753811587\n",
      "Training step:  1902\n",
      "Loss: 666987.6208086535\n",
      "Training step:  1903\n",
      "Loss: 870447.0924048986\n",
      "Training step:  1904\n",
      "Loss: 666975.7009315443\n",
      "Training step:  1905\n",
      "Loss: 870435.4296709774\n",
      "Training step:  1906\n",
      "Loss: 666963.801620862\n",
      "Training step:  1907\n",
      "Loss: 870423.78712712\n",
      "Training step:  1908\n",
      "Loss: 666951.9228233562\n",
      "Training step:  1909\n",
      "Loss: 870412.1647214431\n",
      "Training step:  1910\n",
      "Loss: 666940.0644859617\n",
      "Training step:  1911\n",
      "Loss: 870400.5624019105\n",
      "Training step:  1912\n",
      "Loss: 666928.2265555911\n",
      "Training step:  1913\n",
      "Loss: 870388.9801167182\n",
      "Training step:  1914\n",
      "Loss: 666916.4089796253\n",
      "Training step:  1915\n",
      "Loss: 870377.4178145959\n",
      "Training step:  1916\n",
      "Loss: 666904.6117055364\n",
      "Training step:  1917\n",
      "Loss: 870365.8754440111\n",
      "Training step:  1918\n",
      "Loss: 666892.8346808315\n",
      "Training step:  1919\n",
      "Loss: 870354.3529538221\n",
      "Training step:  1920\n",
      "Loss: 666881.0778535157\n",
      "Training step:  1921\n",
      "Loss: 870342.8502932817\n",
      "Training step:  1922\n",
      "Loss: 666869.3411715946\n",
      "Training step:  1923\n",
      "Loss: 870331.3674114592\n",
      "Training step:  1924\n",
      "Loss: 666857.6245831784\n",
      "Training step:  1925\n",
      "Loss: 870319.9042576781\n",
      "Training step:  1926\n",
      "Loss: 666845.9280366701\n",
      "Training step:  1927\n",
      "Loss: 870308.46078155\n",
      "Training step:  1928\n",
      "Loss: 666834.251480695\n",
      "Training step:  1929\n",
      "Loss: 870297.036932876\n",
      "Training step:  1930\n",
      "Loss: 666822.5948639713\n",
      "Training step:  1931\n",
      "Loss: 870285.6326615257\n",
      "Training step:  1932\n",
      "Loss: 666810.9581355081\n",
      "Training step:  1933\n",
      "Loss: 870274.2479178295\n",
      "Training step:  1934\n",
      "Loss: 666799.3412445614\n",
      "Training step:  1935\n",
      "Loss: 870262.8826521311\n",
      "Training step:  1936\n",
      "Loss: 666787.7441403677\n",
      "Training step:  1937\n",
      "Loss: 870251.5368147668\n",
      "Training step:  1938\n",
      "Loss: 666776.1667724021\n",
      "Training step:  1939\n",
      "Loss: 870240.2103563822\n",
      "Training step:  1940\n",
      "Loss: 666764.6090903507\n",
      "Training step:  1941\n",
      "Loss: 870228.9032279002\n",
      "Training step:  1942\n",
      "Loss: 666753.071044154\n",
      "Training step:  1943\n",
      "Loss: 870217.6153803805\n",
      "Training step:  1944\n",
      "Loss: 666741.5525838545\n",
      "Training step:  1945\n",
      "Loss: 870206.3467650479\n",
      "Training step:  1946\n",
      "Loss: 666730.0536597107\n",
      "Training step:  1947\n",
      "Loss: 870195.0973332082\n",
      "Training step:  1948\n",
      "Loss: 666718.5742219965\n",
      "Training step:  1949\n",
      "Loss: 870183.8670362174\n",
      "Training step:  1950\n",
      "Loss: 666707.1142212619\n",
      "Training step:  1951\n",
      "Loss: 870172.6558258532\n",
      "Training step:  1952\n",
      "Loss: 666695.6736083494\n",
      "Training step:  1953\n",
      "Loss: 870161.4636541232\n",
      "Training step:  1954\n",
      "Loss: 666684.2523342478\n",
      "Training step:  1955\n",
      "Loss: 870150.2904731166\n",
      "Training step:  1956\n",
      "Loss: 666672.8503500365\n",
      "Training step:  1957\n",
      "Loss: 870139.1362350119\n",
      "Training step:  1958\n",
      "Loss: 666661.4676070189\n",
      "Training step:  1959\n",
      "Loss: 870128.0008922523\n",
      "Training step:  1960\n",
      "Loss: 666650.1040566411\n",
      "Training step:  1961\n",
      "Loss: 870116.8843973383\n",
      "Training step:  1962\n",
      "Loss: 666638.7596504502\n",
      "Training step:  1963\n",
      "Loss: 870105.7867028964\n",
      "Training step:  1964\n",
      "Loss: 666627.4343402738\n",
      "Training step:  1965\n",
      "Loss: 870094.7077619646\n",
      "Training step:  1966\n",
      "Loss: 666616.1280781502\n",
      "Training step:  1967\n",
      "Loss: 870083.6475276032\n",
      "Training step:  1968\n",
      "Loss: 666604.8408161865\n",
      "Training step:  1969\n",
      "Loss: 870072.6059530727\n",
      "Training step:  1970\n",
      "Loss: 666593.572506732\n",
      "Training step:  1971\n",
      "Loss: 870061.5829917614\n",
      "Training step:  1972\n",
      "Loss: 666582.3231021769\n",
      "Training step:  1973\n",
      "Loss: 870050.5785970526\n",
      "Training step:  1974\n",
      "Loss: 666571.0925551904\n",
      "Training step:  1975\n",
      "Loss: 870039.59272291\n",
      "Training step:  1976\n",
      "Loss: 666559.880818668\n",
      "Training step:  1977\n",
      "Loss: 870028.6253231337\n",
      "Training step:  1978\n",
      "Loss: 666548.6878454798\n",
      "Training step:  1979\n",
      "Loss: 870017.6763516332\n",
      "Training step:  1980\n",
      "Loss: 666537.5135887214\n",
      "Training step:  1981\n",
      "Loss: 870006.745762661\n",
      "Training step:  1982\n",
      "Loss: 666526.3580017928\n",
      "Training step:  1983\n",
      "Loss: 869995.8335106445\n",
      "Training step:  1984\n",
      "Loss: 666515.2210380883\n",
      "Training step:  1985\n",
      "Loss: 869984.9395500399\n",
      "Training step:  1986\n",
      "Loss: 666504.1026513778\n",
      "Training step:  1987\n",
      "Loss: 869974.0638357796\n",
      "Training step:  1988\n",
      "Loss: 666493.0027954315\n",
      "Training step:  1989\n",
      "Loss: 869963.2063225801\n",
      "Training step:  1990\n",
      "Loss: 666481.9214242423\n",
      "Training step:  1991\n",
      "Loss: 869952.3669655197\n",
      "Training step:  1992\n",
      "Loss: 666470.8584918511\n",
      "Training step:  1993\n",
      "Loss: 869941.5457195978\n",
      "Training step:  1994\n",
      "Loss: 666459.8139525368\n",
      "Training step:  1995\n",
      "Loss: 869930.7425401792\n",
      "Training step:  1996\n",
      "Loss: 666448.7877606794\n",
      "Training step:  1997\n",
      "Loss: 869919.9573825623\n",
      "Training step:  1998\n",
      "Loss: 666437.779870825\n",
      "Training step:  1999\n",
      "Loss: 869909.1902024563\n",
      "Loss_min: tensor(283867.6553, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_city_date_path = train_with_city_data(data_hubei,59170000.,'02-08','湖北')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  270   375   444   549   729  1052  1423  2714  3554  4586  5806  7153\n",
      "  9074 11177 13522 16678 19665 22112 24953 27100 29631]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"384.192812pt\" version=\"1.1\" viewBox=\"0 0 617.501562 384.192812\" width=\"617.501562pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 384.192812 \n",
       "L 617.501562 384.192812 \n",
       "L 617.501562 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 52.301563 348.9225 \n",
       "L 610.301563 348.9225 \n",
       "L 610.301563 22.7625 \n",
       "L 52.301563 22.7625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m3eda0fb42e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.028835\" xlink:href=\"#m3eda0fb42e\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2020-01-21 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.53125 1.5625 \n",
       "L 4.6875 1.5625 \n",
       "L 4.6875 7.8125 \n",
       "Q 7.03125 14.0625 11.125 19.328125 \n",
       "Q 15.234375 24.609375 23.046875 31.25 \n",
       "Q 28.90625 36.328125 31.4375 40.625 \n",
       "Q 33.984375 44.921875 33.984375 50 \n",
       "Q 33.984375 55.078125 31.828125 58.390625 \n",
       "Q 29.6875 61.71875 25 61.71875 \n",
       "Q 21.09375 61.71875 18.15625 58.203125 \n",
       "Q 15.234375 54.6875 15.234375 45.703125 \n",
       "L 6.25 45.703125 \n",
       "Q 6.640625 57.03125 11.515625 63.078125 \n",
       "Q 16.40625 69.140625 25.390625 69.140625 \n",
       "Q 33.984375 69.140625 38.671875 63.859375 \n",
       "Q 43.359375 58.59375 43.359375 49.609375 \n",
       "Q 43.359375 42.1875 39.0625 36.71875 \n",
       "Q 34.765625 31.25 28.515625 25.78125 \n",
       "Q 21.484375 19.53125 18.75 16.40625 \n",
       "Q 16.015625 13.28125 13.671875 8.984375 \n",
       "L 44.53125 8.984375 \n",
       "z\n",
       "\" id=\"SimHei-50\"/>\n",
       "       <path d=\"M 46.484375 35.15625 \n",
       "Q 46.484375 21.09375 41.40625 10.9375 \n",
       "Q 36.328125 0.78125 25 0.78125 \n",
       "Q 13.671875 0.78125 8.390625 10.9375 \n",
       "Q 3.125 21.09375 3.125 35.15625 \n",
       "Q 3.125 49.21875 8.390625 59.171875 \n",
       "Q 13.671875 69.140625 25 69.140625 \n",
       "Q 36.328125 69.140625 41.40625 59.171875 \n",
       "Q 46.484375 49.21875 46.484375 35.15625 \n",
       "z\n",
       "M 37.109375 35.15625 \n",
       "Q 37.109375 47.65625 34.171875 54.6875 \n",
       "Q 31.25 61.71875 25 61.71875 \n",
       "Q 18.75 61.71875 15.625 54.6875 \n",
       "Q 12.5 47.65625 12.5 35.15625 \n",
       "Q 12.5 22.65625 15.625 15.421875 \n",
       "Q 18.75 8.203125 25 8.203125 \n",
       "Q 31.25 8.203125 34.171875 15.421875 \n",
       "Q 37.109375 22.65625 37.109375 35.15625 \n",
       "z\n",
       "\" id=\"SimHei-48\"/>\n",
       "       <path d=\"M 46.875 32.8125 \n",
       "L 2.34375 32.8125 \n",
       "L 2.34375 39.0625 \n",
       "L 46.875 39.0625 \n",
       "z\n",
       "\" id=\"SimHei-45\"/>\n",
       "       <path d=\"M 30.46875 1.5625 \n",
       "L 21.484375 1.5625 \n",
       "L 21.484375 53.515625 \n",
       "L 9.765625 53.515625 \n",
       "L 9.765625 58.203125 \n",
       "Q 16.796875 58.203125 20.703125 60.9375 \n",
       "Q 24.609375 63.671875 25.78125 69.140625 \n",
       "L 30.46875 69.140625 \n",
       "z\n",
       "\" id=\"SimHei-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(78.028835 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"204.483381\" xlink:href=\"#m3eda0fb42e\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2020-01-25 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 25.78125 \n",
       "Q 44.140625 14.0625 38.46875 7.421875 \n",
       "Q 32.8125 0.78125 23.4375 0.78125 \n",
       "Q 15.234375 0.78125 9.953125 6.25 \n",
       "Q 4.6875 11.71875 4.296875 21.09375 \n",
       "L 13.28125 21.09375 \n",
       "Q 13.28125 15.234375 16.015625 11.71875 \n",
       "Q 18.75 8.203125 23.828125 8.203125 \n",
       "Q 28.90625 8.203125 31.828125 12.5 \n",
       "Q 34.765625 16.796875 34.765625 25.78125 \n",
       "Q 34.765625 33.59375 32.21875 37.296875 \n",
       "Q 29.6875 41.015625 25.390625 41.015625 \n",
       "Q 21.875 41.015625 19.328125 39.453125 \n",
       "Q 16.796875 37.890625 14.453125 33.984375 \n",
       "L 6.640625 33.984375 \n",
       "L 8.984375 68.359375 \n",
       "L 42.578125 68.359375 \n",
       "L 42.578125 60.9375 \n",
       "L 16.40625 60.9375 \n",
       "L 14.84375 42.96875 \n",
       "Q 17.1875 45.3125 19.921875 46.484375 \n",
       "Q 22.65625 47.65625 27.34375 47.65625 \n",
       "Q 34.765625 47.65625 39.453125 41.984375 \n",
       "Q 44.140625 36.328125 44.140625 25.78125 \n",
       "z\n",
       "\" id=\"SimHei-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(179.483381 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.937926\" xlink:href=\"#m3eda0fb42e\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2020-01-29 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 35.9375 \n",
       "Q 44.140625 19.921875 38.46875 10.34375 \n",
       "Q 32.8125 0.78125 22.265625 0.78125 \n",
       "Q 14.84375 0.78125 10.34375 6.25 \n",
       "Q 5.859375 11.71875 5.859375 18.359375 \n",
       "L 14.84375 18.359375 \n",
       "Q 14.84375 14.453125 16.984375 11.328125 \n",
       "Q 19.140625 8.203125 22.65625 8.203125 \n",
       "Q 28.515625 8.203125 31.4375 14.84375 \n",
       "Q 34.375 21.484375 35.15625 34.375 \n",
       "Q 33.203125 30.078125 29.6875 27.734375 \n",
       "Q 26.171875 25.390625 21.875 25.390625 \n",
       "Q 14.453125 25.390625 9.765625 30.859375 \n",
       "Q 5.078125 36.328125 5.078125 46.484375 \n",
       "Q 5.078125 56.640625 9.765625 62.890625 \n",
       "Q 14.453125 69.140625 23.828125 69.140625 \n",
       "Q 33.203125 69.140625 38.671875 61.328125 \n",
       "Q 44.140625 53.515625 44.140625 35.9375 \n",
       "z\n",
       "M 34.375 44.921875 \n",
       "Q 34.375 53.515625 31.4375 57.8125 \n",
       "Q 28.515625 62.109375 23.4375 62.109375 \n",
       "Q 19.921875 62.109375 17.1875 58.78125 \n",
       "Q 14.453125 55.46875 14.453125 46.484375 \n",
       "Q 14.453125 39.84375 16.59375 36.125 \n",
       "Q 18.75 32.421875 23.4375 32.421875 \n",
       "Q 28.515625 32.421875 31.4375 35.9375 \n",
       "Q 34.375 39.453125 34.375 44.921875 \n",
       "z\n",
       "\" id=\"SimHei-57\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(280.937926 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"382.028835\" xlink:href=\"#m3eda0fb42e\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2020-02-01 -->\n",
       "      <g transform=\"translate(357.028835 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"483.483381\" xlink:href=\"#m3eda0fb42e\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2020-02-05 -->\n",
       "      <g transform=\"translate(458.483381 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"584.937926\" xlink:href=\"#m3eda0fb42e\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2020-02-09 -->\n",
       "      <g transform=\"translate(559.937926 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- 日期 -->\n",
       "     <defs>\n",
       "      <path d=\"M 30.859375 69.921875 \n",
       "L 30.859375 43.359375 \n",
       "L 72.265625 43.359375 \n",
       "L 72.265625 69.921875 \n",
       "z\n",
       "M 30.859375 36.71875 \n",
       "L 30.859375 9.765625 \n",
       "L 72.265625 9.765625 \n",
       "L 72.265625 36.71875 \n",
       "z\n",
       "M 23.046875 76.5625 \n",
       "L 80.078125 76.5625 \n",
       "Q 79.6875 57.8125 79.6875 35.15625 \n",
       "Q 79.6875 12.5 80.078125 -6.25 \n",
       "L 72.265625 -6.25 \n",
       "L 72.265625 3.125 \n",
       "L 30.859375 3.125 \n",
       "L 30.859375 -8.203125 \n",
       "L 23.046875 -8.203125 \n",
       "Q 23.4375 9.375 23.4375 33 \n",
       "Q 23.4375 56.640625 23.046875 76.5625 \n",
       "z\n",
       "\" id=\"SimHei-26085\"/>\n",
       "      <path d=\"M 23.4375 60.9375 \n",
       "L 23.4375 52.34375 \n",
       "L 38.671875 52.34375 \n",
       "L 38.671875 60.9375 \n",
       "z\n",
       "M 18.359375 15.625 \n",
       "L 25.78125 10.9375 \n",
       "Q 23.4375 9.765625 19.328125 4.09375 \n",
       "Q 15.234375 -1.5625 11.71875 -5.859375 \n",
       "Q 7.8125 -3.125 5.078125 -1.5625 \n",
       "Q 8.59375 1.171875 12.296875 6.046875 \n",
       "Q 16.015625 10.9375 18.359375 15.625 \n",
       "z\n",
       "M 23.4375 46.484375 \n",
       "L 23.4375 38.28125 \n",
       "L 38.671875 38.28125 \n",
       "L 38.671875 46.484375 \n",
       "z\n",
       "M 23.4375 32.421875 \n",
       "L 23.4375 23.828125 \n",
       "L 38.671875 23.828125 \n",
       "L 38.671875 32.421875 \n",
       "z\n",
       "M 46.875 7.421875 \n",
       "Q 44.140625 4.6875 42.1875 1.5625 \n",
       "Q 37.109375 8.203125 32.8125 10.9375 \n",
       "Q 35.546875 13.671875 37.109375 16.40625 \n",
       "Q 42.96875 10.546875 46.875 7.421875 \n",
       "z\n",
       "M 8.203125 67.1875 \n",
       "Q 12.5 66.796875 16.40625 66.796875 \n",
       "Q 16.40625 74.21875 16.015625 79.6875 \n",
       "L 24.21875 79.6875 \n",
       "Q 23.4375 75 23.4375 66.796875 \n",
       "L 38.671875 66.796875 \n",
       "Q 38.671875 74.21875 38.28125 79.6875 \n",
       "L 46.484375 79.6875 \n",
       "Q 45.3125 75 45.703125 66.796875 \n",
       "Q 48.828125 66.796875 53.125 67.1875 \n",
       "L 53.125 60.546875 \n",
       "Q 49.21875 60.9375 45.703125 60.9375 \n",
       "L 45.703125 23.828125 \n",
       "Q 49.21875 23.828125 53.125 24.21875 \n",
       "L 53.125 17.578125 \n",
       "Q 47.265625 17.96875 42.1875 17.96875 \n",
       "L 17.1875 17.96875 \n",
       "Q 12.109375 17.96875 5.859375 17.578125 \n",
       "L 5.859375 24.21875 \n",
       "Q 11.71875 23.828125 16.40625 23.828125 \n",
       "L 16.40625 60.9375 \n",
       "Q 12.890625 60.9375 8.203125 60.546875 \n",
       "z\n",
       "M 76.953125 -9.765625 \n",
       "Q 76.953125 -5.46875 73.828125 -0.78125 \n",
       "Q 82.8125 -1.953125 82.03125 2.34375 \n",
       "L 82.03125 24.21875 \n",
       "L 64.453125 24.21875 \n",
       "Q 63.671875 14.84375 60.34375 6.25 \n",
       "Q 57.03125 -2.34375 50.78125 -9.765625 \n",
       "Q 48.046875 -6.25 43.75 -4.6875 \n",
       "Q 50.390625 1.953125 53.515625 9.375 \n",
       "Q 56.640625 16.796875 57.21875 24.21875 \n",
       "Q 57.8125 31.640625 57.8125 48.625 \n",
       "Q 57.8125 65.625 57.421875 75.78125 \n",
       "L 89.453125 75.78125 \n",
       "Q 89.0625 68.359375 89.0625 57.8125 \n",
       "L 89.0625 0.390625 \n",
       "Q 89.0625 -5.078125 85.9375 -7.03125 \n",
       "Q 82.8125 -8.984375 76.953125 -9.765625 \n",
       "z\n",
       "M 64.84375 69.921875 \n",
       "L 64.84375 52.34375 \n",
       "L 82.03125 52.34375 \n",
       "L 82.03125 69.921875 \n",
       "z\n",
       "M 64.84375 46.484375 \n",
       "L 64.84375 30.078125 \n",
       "L 82.03125 30.078125 \n",
       "L 82.03125 46.484375 \n",
       "z\n",
       "\" id=\"SimHei-26399\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(321.301562 375.70375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-26085\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-26399\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"mffe9b42913\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"336.683215\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(40.301563 340.101183)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"288.791192\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 5000 -->\n",
       "      <g transform=\"translate(25.301563 292.209161)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"240.899169\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 10000 -->\n",
       "      <g transform=\"translate(20.301563 244.317138)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"193.007147\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 15000 -->\n",
       "      <g transform=\"translate(20.301563 196.425115)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"145.115124\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 20000 -->\n",
       "      <g transform=\"translate(20.301563 148.533093)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"97.223101\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 25000 -->\n",
       "      <g transform=\"translate(20.301563 100.64107)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#mffe9b42913\" y=\"49.331079\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 30000 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 20.3125 \n",
       "Q 44.140625 11.328125 38.46875 6.046875 \n",
       "Q 32.8125 0.78125 24.21875 0.78125 \n",
       "Q 15.625 0.78125 9.953125 6.046875 \n",
       "Q 4.296875 11.328125 4.296875 22.265625 \n",
       "L 13.28125 22.265625 \n",
       "Q 13.28125 14.84375 16.203125 11.515625 \n",
       "Q 19.140625 8.203125 24.21875 8.203125 \n",
       "Q 29.296875 8.203125 32.03125 11.328125 \n",
       "Q 34.765625 14.453125 34.765625 21.09375 \n",
       "Q 34.765625 26.5625 31.828125 29.6875 \n",
       "Q 28.90625 32.8125 21.484375 32.8125 \n",
       "L 21.484375 39.453125 \n",
       "Q 27.734375 39.453125 30.65625 42.578125 \n",
       "Q 33.59375 45.703125 33.59375 51.953125 \n",
       "Q 33.59375 56.640625 31.4375 59.375 \n",
       "Q 29.296875 62.109375 24.609375 62.109375 \n",
       "Q 19.921875 62.109375 17.375 58.78125 \n",
       "Q 14.84375 55.46875 14.453125 49.21875 \n",
       "L 5.859375 49.21875 \n",
       "Q 6.640625 58.203125 11.515625 63.671875 \n",
       "Q 16.40625 69.140625 24.609375 69.140625 \n",
       "Q 33.203125 69.140625 37.890625 64.25 \n",
       "Q 42.578125 59.375 42.578125 52.34375 \n",
       "Q 42.578125 45.703125 40.234375 41.984375 \n",
       "Q 37.890625 38.28125 32.421875 36.328125 \n",
       "Q 37.890625 35.15625 41.015625 30.859375 \n",
       "Q 44.140625 26.5625 44.140625 20.3125 \n",
       "z\n",
       "\" id=\"SimHei-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.301563 52.749047)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-51\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- 人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 13.671875 -8.984375 \n",
       "Q 10.9375 -3.515625 6.25 -1.171875 \n",
       "Q 21.09375 5.46875 29.484375 15.8125 \n",
       "Q 37.890625 26.171875 41.59375 38.078125 \n",
       "Q 45.3125 50 45.5 60.15625 \n",
       "Q 45.703125 70.3125 44.921875 79.296875 \n",
       "Q 48.4375 78.90625 54.296875 78.515625 \n",
       "Q 53.125 74.21875 53.125 64.640625 \n",
       "Q 53.125 55.078125 53.3125 49.015625 \n",
       "Q 53.515625 42.96875 64.25 25 \n",
       "Q 75 7.03125 94.921875 -1.171875 \n",
       "Q 89.0625 -5.46875 87.890625 -8.984375 \n",
       "Q 61.328125 4.296875 49.609375 39.84375 \n",
       "Q 40.625 7.03125 13.671875 -8.984375 \n",
       "z\n",
       "\" id=\"SimHei-20154\"/>\n",
       "      <path d=\"M 10.9375 75.78125 \n",
       "Q 14.84375 76.953125 17.1875 78.515625 \n",
       "Q 20.3125 73.4375 23.046875 68.359375 \n",
       "Q 19.53125 66.796875 16.796875 65.234375 \n",
       "Q 14.453125 71.09375 10.9375 75.78125 \n",
       "z\n",
       "M 44.921875 78.515625 \n",
       "Q 49.21875 76.5625 53.125 75 \n",
       "Q 50.78125 73.4375 49.21875 70.703125 \n",
       "Q 47.65625 67.96875 45.703125 64.453125 \n",
       "Q 42.578125 66.015625 39.453125 66.796875 \n",
       "Q 42.578125 71.875 44.921875 78.515625 \n",
       "z\n",
       "M 38.28125 49.609375 \n",
       "Q 41.796875 51.171875 44.140625 53.515625 \n",
       "Q 48.828125 46.875 51.953125 41.40625 \n",
       "Q 48.4375 39.84375 45.3125 37.5 \n",
       "Q 42.1875 44.921875 38.28125 49.609375 \n",
       "z\n",
       "M 8.203125 61.71875 \n",
       "Q 14.453125 61.328125 28.125 61.328125 \n",
       "Q 28.125 72.65625 27.734375 80.859375 \n",
       "L 35.546875 80.859375 \n",
       "Q 35.15625 72.65625 35.15625 61.328125 \n",
       "Q 48.046875 61.328125 53.90625 61.71875 \n",
       "L 53.90625 54.6875 \n",
       "Q 48.046875 55.078125 35.15625 55.078125 \n",
       "Q 35.15625 46.09375 35.546875 39.453125 \n",
       "L 27.734375 39.453125 \n",
       "Q 28.125 45.3125 28.125 51.953125 \n",
       "Q 26.171875 48.046875 21.671875 43.546875 \n",
       "Q 17.1875 39.0625 11.71875 35.9375 \n",
       "Q 10.15625 39.453125 6.640625 41.796875 \n",
       "Q 10.15625 42.96875 15.421875 46.875 \n",
       "Q 20.703125 50.78125 23.046875 55.078125 \n",
       "Q 14.84375 55.078125 8.203125 54.6875 \n",
       "z\n",
       "M 26.953125 24.21875 \n",
       "Q 25 20.3125 22.65625 16.40625 \n",
       "Q 27.34375 15.234375 35.15625 13.28125 \n",
       "Q 37.890625 16.796875 40.234375 24.21875 \n",
       "z\n",
       "M 24.21875 38.28125 \n",
       "Q 28.515625 36.71875 32.8125 35.546875 \n",
       "Q 31.25 33.984375 29.296875 30.46875 \n",
       "L 44.53125 30.46875 \n",
       "L 48.828125 30.46875 \n",
       "Q 46.484375 20.3125 42.1875 11.328125 \n",
       "Q 48.828125 9.375 52.734375 8.203125 \n",
       "Q 49.609375 3.90625 48.046875 0.390625 \n",
       "Q 44.53125 2.734375 37.5 5.46875 \n",
       "Q 28.125 -3.90625 9.375 -10.15625 \n",
       "Q 7.8125 -6.25 4.6875 -3.90625 \n",
       "Q 21.484375 0 31.25 8.203125 \n",
       "Q 20.3125 10.9375 13.28125 12.890625 \n",
       "Q 15.625 16.015625 19.53125 24.21875 \n",
       "Q 13.28125 24.21875 4.6875 23.828125 \n",
       "L 4.6875 30.859375 \n",
       "Q 12.109375 30.46875 21.875 30.46875 \n",
       "Q 23.046875 33.59375 24.21875 38.28125 \n",
       "z\n",
       "M 63.671875 80.46875 \n",
       "Q 68.359375 78.515625 73.4375 77.734375 \n",
       "Q 71.484375 75.390625 70.5 72.265625 \n",
       "Q 69.53125 69.140625 67.96875 63.28125 \n",
       "L 85.546875 63.28125 \n",
       "Q 89.0625 63.28125 94.53125 63.671875 \n",
       "L 94.53125 56.640625 \n",
       "Q 90.234375 57.03125 87.5 57.03125 \n",
       "Q 87.109375 48.828125 85.546875 35.34375 \n",
       "Q 83.984375 21.875 78.125 11.71875 \n",
       "Q 82.03125 6.25 87.109375 2.734375 \n",
       "Q 92.1875 -0.78125 96.09375 -2.34375 \n",
       "Q 90.625 -5.859375 89.0625 -9.375 \n",
       "Q 82.421875 -4.6875 79.296875 -1.359375 \n",
       "Q 76.171875 1.953125 73.4375 5.859375 \n",
       "Q 68.75 1.171875 64.640625 -1.953125 \n",
       "Q 60.546875 -5.078125 51.5625 -10.15625 \n",
       "Q 49.609375 -6.640625 45.3125 -3.90625 \n",
       "Q 52.734375 -1.171875 58.984375 3.125 \n",
       "Q 65.234375 7.421875 69.53125 12.109375 \n",
       "Q 65.234375 20.703125 62.890625 29.09375 \n",
       "Q 60.546875 37.5 60.15625 41.015625 \n",
       "Q 59.375 38.28125 58.203125 34.765625 \n",
       "Q 54.6875 36.328125 50.390625 37.890625 \n",
       "Q 55.078125 46.484375 58.984375 58.59375 \n",
       "Q 62.890625 70.703125 63.671875 80.46875 \n",
       "z\n",
       "M 66.40625 57.03125 \n",
       "Q 64.84375 53.125 64.0625 50.578125 \n",
       "Q 63.28125 48.046875 66.984375 36.71875 \n",
       "Q 70.703125 25.390625 74.21875 19.140625 \n",
       "Q 77.734375 28.515625 79.09375 38.671875 \n",
       "Q 80.46875 48.828125 80.46875 57.03125 \n",
       "z\n",
       "\" id=\"SimHei-25968\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(15.0125 195.8425)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#pc9db4454a7)\" d=\"M 77.665199 334.097045 \n",
       "L 103.028835 333.091313 \n",
       "L 128.392472 332.430403 \n",
       "L 153.756108 331.424671 \n",
       "L 179.119744 329.700558 \n",
       "L 204.483381 326.606733 \n",
       "L 229.847017 323.053145 \n",
       "L 255.210653 310.687425 \n",
       "L 280.57429 302.641565 \n",
       "L 305.937926 292.756651 \n",
       "L 331.301562 281.070998 \n",
       "L 356.665199 268.168887 \n",
       "L 382.028835 249.768772 \n",
       "L 407.392472 229.625387 \n",
       "L 432.756108 207.164029 \n",
       "L 458.119744 176.934584 \n",
       "L 483.483381 148.323889 \n",
       "L 508.847017 124.885534 \n",
       "L 534.210653 97.673286 \n",
       "L 559.57429 77.108452 \n",
       "L 584.937926 52.86551 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    <defs>\n",
       "     <path d=\"M -3 3 \n",
       "L 3 -3 \n",
       "M -3 -3 \n",
       "L 3 3 \n",
       "\" id=\"m1b1c190031\" style=\"stroke:#ff0000;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pc9db4454a7)\">\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"77.665199\" xlink:href=\"#m1b1c190031\" y=\"334.097045\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"103.028835\" xlink:href=\"#m1b1c190031\" y=\"333.091313\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"128.392472\" xlink:href=\"#m1b1c190031\" y=\"332.430403\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"153.756108\" xlink:href=\"#m1b1c190031\" y=\"331.424671\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"179.119744\" xlink:href=\"#m1b1c190031\" y=\"329.700558\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"204.483381\" xlink:href=\"#m1b1c190031\" y=\"326.606733\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"229.847017\" xlink:href=\"#m1b1c190031\" y=\"323.053145\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"255.210653\" xlink:href=\"#m1b1c190031\" y=\"310.687425\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"280.57429\" xlink:href=\"#m1b1c190031\" y=\"302.641565\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"305.937926\" xlink:href=\"#m1b1c190031\" y=\"292.756651\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"331.301562\" xlink:href=\"#m1b1c190031\" y=\"281.070998\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"356.665199\" xlink:href=\"#m1b1c190031\" y=\"268.168887\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"382.028835\" xlink:href=\"#m1b1c190031\" y=\"249.768772\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"407.392472\" xlink:href=\"#m1b1c190031\" y=\"229.625387\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"432.756108\" xlink:href=\"#m1b1c190031\" y=\"207.164029\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"458.119744\" xlink:href=\"#m1b1c190031\" y=\"176.934584\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"483.483381\" xlink:href=\"#m1b1c190031\" y=\"148.323889\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"508.847017\" xlink:href=\"#m1b1c190031\" y=\"124.885534\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"534.210653\" xlink:href=\"#m1b1c190031\" y=\"97.673286\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"559.57429\" xlink:href=\"#m1b1c190031\" y=\"77.108452\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"584.937926\" xlink:href=\"#m1b1c190031\" y=\"52.86551\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#pc9db4454a7)\" d=\"M 77.665199 334.097045 \n",
       "L 103.028835 333.464871 \n",
       "L 128.392472 332.574079 \n",
       "L 153.756108 331.348043 \n",
       "L 179.119744 329.662244 \n",
       "L 204.483381 327.334692 \n",
       "L 229.847017 324.125926 \n",
       "L 255.210653 319.700703 \n",
       "L 280.57429 313.627995 \n",
       "L 305.937926 305.37141 \n",
       "L 331.301562 294.346667 \n",
       "L 356.665199 279.969481 \n",
       "L 382.028835 261.741778 \n",
       "L 407.392472 239.529457 \n",
       "L 432.756108 213.648608 \n",
       "L 458.119744 184.626043 \n",
       "L 483.483381 154.319971 \n",
       "L 508.847017 125.019631 \n",
       "L 534.210653 96.169477 \n",
       "L 559.57429 68.018546 \n",
       "L 584.937926 37.587955 \n",
       "\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    <defs>\n",
       "     <path d=\"M -3 3 \n",
       "L 3 -3 \n",
       "M -3 -3 \n",
       "L 3 3 \n",
       "\" id=\"m6398f9ed21\" style=\"stroke:#0000ff;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pc9db4454a7)\">\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"77.665199\" xlink:href=\"#m6398f9ed21\" y=\"334.097045\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"103.028835\" xlink:href=\"#m6398f9ed21\" y=\"333.464871\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"128.392472\" xlink:href=\"#m6398f9ed21\" y=\"332.574079\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"153.756108\" xlink:href=\"#m6398f9ed21\" y=\"331.348043\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"179.119744\" xlink:href=\"#m6398f9ed21\" y=\"329.662244\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"204.483381\" xlink:href=\"#m6398f9ed21\" y=\"327.334692\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"229.847017\" xlink:href=\"#m6398f9ed21\" y=\"324.125926\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"255.210653\" xlink:href=\"#m6398f9ed21\" y=\"319.700703\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"280.57429\" xlink:href=\"#m6398f9ed21\" y=\"313.627995\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"305.937926\" xlink:href=\"#m6398f9ed21\" y=\"305.37141\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"331.301562\" xlink:href=\"#m6398f9ed21\" y=\"294.346667\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"356.665199\" xlink:href=\"#m6398f9ed21\" y=\"279.969481\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"382.028835\" xlink:href=\"#m6398f9ed21\" y=\"261.741778\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"407.392472\" xlink:href=\"#m6398f9ed21\" y=\"239.529457\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"432.756108\" xlink:href=\"#m6398f9ed21\" y=\"213.648608\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"458.119744\" xlink:href=\"#m6398f9ed21\" y=\"184.626043\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"483.483381\" xlink:href=\"#m6398f9ed21\" y=\"154.319971\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"508.847017\" xlink:href=\"#m6398f9ed21\" y=\"125.019631\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"534.210653\" xlink:href=\"#m6398f9ed21\" y=\"96.169477\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"559.57429\" xlink:href=\"#m6398f9ed21\" y=\"68.018546\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"584.937926\" xlink:href=\"#m6398f9ed21\" y=\"37.587955\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 52.301563 348.9225 \n",
       "L 52.301563 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 610.301563 348.9225 \n",
       "L 610.301563 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 52.301562 348.9225 \n",
       "L 610.301562 348.9225 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 52.301562 22.7625 \n",
       "L 610.301562 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_16\">\n",
       "    <!-- 270 -->\n",
       "    <defs>\n",
       "     <path d=\"M 43.359375 60.15625 \n",
       "L 25 1.5625 \n",
       "L 16.015625 1.5625 \n",
       "L 34.765625 60.9375 \n",
       "L 6.25 60.9375 \n",
       "L 6.25 68.359375 \n",
       "L 43.359375 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-55\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(72.665199 329.097045)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- 336 -->\n",
       "    <defs>\n",
       "     <path d=\"M 44.53125 24.21875 \n",
       "Q 44.53125 13.28125 39.84375 7.03125 \n",
       "Q 35.15625 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.9375 8.59375 \n",
       "Q 5.46875 16.40625 5.46875 33.984375 \n",
       "Q 5.46875 50 11.125 59.5625 \n",
       "Q 16.796875 69.140625 27.34375 69.140625 \n",
       "Q 34.765625 69.140625 39.25 63.671875 \n",
       "Q 43.75 58.203125 43.75 51.5625 \n",
       "L 34.765625 51.5625 \n",
       "Q 34.765625 55.46875 32.609375 58.59375 \n",
       "Q 30.46875 61.71875 26.953125 61.71875 \n",
       "Q 21.09375 61.71875 17.96875 55.65625 \n",
       "Q 14.84375 49.609375 14.453125 37.109375 \n",
       "Q 17.1875 42.1875 20.3125 44.140625 \n",
       "Q 23.4375 46.09375 27.734375 46.09375 \n",
       "Q 35.15625 46.09375 39.84375 40.234375 \n",
       "Q 44.53125 34.375 44.53125 24.21875 \n",
       "z\n",
       "M 35.15625 24.21875 \n",
       "Q 35.15625 31.25 32.8125 35.15625 \n",
       "Q 30.46875 39.0625 26.171875 39.0625 \n",
       "Q 21.09375 39.0625 18.15625 35.15625 \n",
       "Q 15.234375 31.25 15.234375 25.78125 \n",
       "Q 15.234375 17.1875 18.15625 12.5 \n",
       "Q 21.09375 7.8125 26.171875 7.8125 \n",
       "Q 29.6875 7.8125 32.421875 11.328125 \n",
       "Q 35.15625 14.84375 35.15625 24.21875 \n",
       "z\n",
       "\" id=\"SimHei-54\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(98.028835 328.464871)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_18\">\n",
       "    <!-- 429 -->\n",
       "    <defs>\n",
       "     <path d=\"M 46.484375 18.75 \n",
       "L 38.28125 18.75 \n",
       "L 38.28125 1.5625 \n",
       "L 29.296875 1.5625 \n",
       "L 29.296875 18.75 \n",
       "L 3.125 18.75 \n",
       "L 3.125 26.171875 \n",
       "L 29.296875 69.140625 \n",
       "L 38.28125 69.140625 \n",
       "L 38.28125 26.171875 \n",
       "L 46.484375 26.171875 \n",
       "z\n",
       "M 29.296875 26.171875 \n",
       "L 29.296875 55.078125 \n",
       "L 11.71875 26.171875 \n",
       "z\n",
       "\" id=\"SimHei-52\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(123.392472 327.574079)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_19\">\n",
       "    <!-- 557 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(148.756108 326.348043)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_20\">\n",
       "    <!-- 733 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(174.119744 324.662244)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_21\">\n",
       "    <!-- 976 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(199.483381 322.334692)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_22\">\n",
       "    <!-- 1311 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(224.847017 319.125926)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_23\">\n",
       "    <!-- 1773 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(250.210653 314.700703)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_24\">\n",
       "    <!-- 2407 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(275.57429 308.627995)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_25\">\n",
       "    <!-- 3269 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(300.937926 300.37141)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_26\">\n",
       "    <!-- 4420 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(326.301562 289.346667)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_27\">\n",
       "    <!-- 5921 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(351.665199 274.969481)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_28\">\n",
       "    <!-- 7824 -->\n",
       "    <defs>\n",
       "     <path d=\"M 44.921875 20.703125 \n",
       "Q 44.921875 10.9375 39.453125 5.859375 \n",
       "Q 33.984375 0.78125 24.609375 0.78125 \n",
       "Q 15.234375 0.78125 9.765625 5.859375 \n",
       "Q 4.296875 10.9375 4.296875 20.703125 \n",
       "Q 4.296875 25.78125 7.421875 29.875 \n",
       "Q 10.546875 33.984375 16.015625 35.9375 \n",
       "Q 11.328125 37.890625 8.78125 41.40625 \n",
       "Q 6.25 44.921875 6.25 50.390625 \n",
       "Q 6.25 58.984375 11.71875 64.0625 \n",
       "Q 17.1875 69.140625 24.609375 69.140625 \n",
       "Q 32.03125 69.140625 37.5 64.0625 \n",
       "Q 42.96875 58.984375 42.96875 50.390625 \n",
       "Q 42.96875 44.921875 40.421875 41.40625 \n",
       "Q 37.890625 37.890625 33.203125 35.9375 \n",
       "Q 38.671875 33.984375 41.796875 29.875 \n",
       "Q 44.921875 25.78125 44.921875 20.703125 \n",
       "z\n",
       "M 34.375 50.390625 \n",
       "Q 34.375 56.640625 31.640625 59.375 \n",
       "Q 28.90625 62.109375 24.609375 62.109375 \n",
       "Q 20.3125 62.109375 17.578125 59.375 \n",
       "Q 14.84375 56.640625 14.84375 50.390625 \n",
       "Q 14.84375 44.140625 17.765625 41.59375 \n",
       "Q 20.703125 39.0625 24.609375 39.0625 \n",
       "Q 28.515625 39.0625 31.4375 41.59375 \n",
       "Q 34.375 44.140625 34.375 50.390625 \n",
       "z\n",
       "M 35.9375 20.703125 \n",
       "Q 35.9375 26.171875 33 29.296875 \n",
       "Q 30.078125 32.421875 24.609375 32.421875 \n",
       "Q 19.140625 32.421875 16.203125 29.296875 \n",
       "Q 13.28125 26.171875 13.28125 20.703125 \n",
       "Q 13.28125 14.453125 16.40625 11.125 \n",
       "Q 19.53125 7.8125 24.609375 7.8125 \n",
       "Q 29.6875 7.8125 32.8125 11.125 \n",
       "Q 35.9375 14.453125 35.9375 20.703125 \n",
       "z\n",
       "\" id=\"SimHei-56\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(377.028835 256.741778)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_29\">\n",
       "    <!-- 10143 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(402.392472 234.529457)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_30\">\n",
       "    <!-- 12845 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(427.756108 208.648608)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_31\">\n",
       "    <!-- 15875 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(453.119744 179.626043)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_32\">\n",
       "    <!-- 19039 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(478.483381 149.319971)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_33\">\n",
       "    <!-- 22098 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(503.847017 120.019631)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-56\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_34\">\n",
       "    <!-- 25110 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(529.210653 91.169477)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_35\">\n",
       "    <!-- 28049 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(554.57429 63.018546)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_36\">\n",
       "    <!-- 31226 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(579.937926 32.587955)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_37\">\n",
       "    <!-- 270 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(72.665199 314.097045)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_38\">\n",
       "    <!-- 375 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(98.028835 313.091313)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_39\">\n",
       "    <!-- 444 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(123.392472 312.430403)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_40\">\n",
       "    <!-- 549 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(148.756108 311.424671)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_41\">\n",
       "    <!-- 729 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(174.119744 309.700558)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_42\">\n",
       "    <!-- 1052 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(199.483381 306.606733)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_43\">\n",
       "    <!-- 1423 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(224.847017 303.053145)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_44\">\n",
       "    <!-- 2714 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(250.210653 290.687425)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_45\">\n",
       "    <!-- 3554 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(275.57429 282.641565)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_46\">\n",
       "    <!-- 4586 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(300.937926 272.756651)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_47\">\n",
       "    <!-- 5806 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(326.301562 261.070998)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_48\">\n",
       "    <!-- 7153 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(351.665199 248.168887)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_49\">\n",
       "    <!-- 9074 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(377.028835 229.768772)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_50\">\n",
       "    <!-- 11177 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(402.392472 209.625387)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_51\">\n",
       "    <!-- 13522 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(427.756108 187.164029)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_52\">\n",
       "    <!-- 16678 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(453.119744 156.934584)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-56\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_53\">\n",
       "    <!-- 19665 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(478.483381 128.323889)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_54\">\n",
       "    <!-- 22112 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(503.847017 104.885534)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_55\">\n",
       "    <!-- 24953 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(529.210653 77.673286)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_56\">\n",
       "    <!-- 27100 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(554.57429 57.108452)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_57\">\n",
       "    <!-- 29631 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(579.937926 32.86551)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_58\">\n",
       "    <!-- 疫情状况-湖北 -->\n",
       "    <defs>\n",
       "     <path d=\"M 5.859375 61.71875 \n",
       "Q 9.375 62.5 13.28125 62.890625 \n",
       "Q 14.84375 53.125 15.234375 42.1875 \n",
       "Q 11.328125 41.796875 7.8125 41.40625 \n",
       "Q 7.421875 52.34375 5.859375 61.71875 \n",
       "z\n",
       "M 50 79.6875 \n",
       "Q 55.078125 80.859375 58.59375 82.03125 \n",
       "Q 60.546875 76.171875 61.71875 70.703125 \n",
       "L 78.90625 70.703125 \n",
       "Q 85.546875 70.703125 93.75 71.09375 \n",
       "L 93.75 64.453125 \n",
       "Q 85.9375 64.84375 78.90625 64.84375 \n",
       "L 28.125 64.84375 \n",
       "Q 27.734375 58.203125 27.921875 48.828125 \n",
       "Q 28.125 39.453125 27.34375 29.09375 \n",
       "Q 26.5625 18.75 23.828125 8.59375 \n",
       "Q 21.09375 -1.5625 15.234375 -9.765625 \n",
       "Q 11.71875 -7.421875 7.03125 -5.46875 \n",
       "Q 10.546875 -1.171875 13.28125 3.125 \n",
       "Q 16.015625 7.421875 17.96875 14.0625 \n",
       "Q 19.921875 20.703125 20.703125 30.078125 \n",
       "Q 11.71875 25 7.03125 21.09375 \n",
       "Q 5.859375 25.78125 3.90625 30.078125 \n",
       "Q 8.59375 32.03125 12.5 33.78125 \n",
       "Q 16.40625 35.546875 21.09375 37.5 \n",
       "L 21.09375 53.515625 \n",
       "Q 21.09375 65.625 20.703125 70.703125 \n",
       "L 52.734375 70.703125 \n",
       "Q 51.953125 75 50 79.6875 \n",
       "z\n",
       "M 44.140625 56.25 \n",
       "L 76.953125 56.25 \n",
       "Q 76.5625 53.515625 76.5625 48.046875 \n",
       "L 76.5625 43.359375 \n",
       "Q 76.5625 39.453125 80.078125 39.640625 \n",
       "Q 83.59375 39.84375 89.453125 40.625 \n",
       "Q 87.890625 36.328125 88.671875 33.59375 \n",
       "Q 76.5625 33.203125 73.046875 34.5625 \n",
       "Q 69.53125 35.9375 69.53125 40.234375 \n",
       "L 69.53125 50.390625 \n",
       "L 51.953125 50.390625 \n",
       "Q 52.734375 41.015625 50 36.71875 \n",
       "Q 47.265625 32.421875 40.625 28.90625 \n",
       "Q 38.671875 32.8125 33.59375 35.546875 \n",
       "Q 44.53125 37.890625 44.53125 44.328125 \n",
       "Q 44.53125 50.78125 44.140625 56.25 \n",
       "z\n",
       "M 35.15625 28.125 \n",
       "Q 41.796875 27.734375 49.609375 27.734375 \n",
       "L 85.15625 27.734375 \n",
       "Q 82.03125 22.65625 78.125 16.40625 \n",
       "Q 74.21875 10.15625 66.796875 3.125 \n",
       "Q 73.046875 0.390625 78.703125 -0.78125 \n",
       "Q 84.375 -1.953125 94.140625 -1.953125 \n",
       "Q 90.234375 -5.859375 90.234375 -10.546875 \n",
       "Q 81.25 -9.375 73.828125 -7.03125 \n",
       "Q 66.40625 -4.6875 60.546875 -0.78125 \n",
       "Q 47.265625 -7.8125 32.03125 -10.15625 \n",
       "Q 31.25 -7.03125 26.5625 -2.34375 \n",
       "Q 35.9375 -1.953125 41.59375 -0.78125 \n",
       "Q 47.265625 0.390625 54.6875 3.515625 \n",
       "Q 48.828125 9.375 42.578125 22.265625 \n",
       "Q 45.703125 22.265625 49.609375 22.65625 \n",
       "Q 53.125 15.625 55.265625 12.890625 \n",
       "Q 57.421875 10.15625 60.546875 7.421875 \n",
       "Q 67.96875 13.28125 73.4375 21.875 \n",
       "L 49.609375 21.875 \n",
       "Q 42.1875 21.875 35.15625 21.484375 \n",
       "z\n",
       "\" id=\"SimHei-30123\"/>\n",
       "     <path d=\"M 37.5 50 \n",
       "Q 33.984375 49.609375 31.25 48.046875 \n",
       "Q 30.078125 53.125 28.125 61.71875 \n",
       "Q 30.859375 62.109375 34.375 63.28125 \n",
       "Q 36.328125 54.6875 37.5 50 \n",
       "z\n",
       "M 18.75 81.25 \n",
       "L 26.5625 81.25 \n",
       "Q 26.171875 74.609375 26.171875 68.359375 \n",
       "L 26.171875 6.25 \n",
       "Q 26.171875 -1.953125 26.5625 -9.765625 \n",
       "L 18.75 -9.765625 \n",
       "Q 19.140625 -1.953125 19.140625 6.25 \n",
       "L 19.140625 67.1875 \n",
       "Q 19.140625 75 18.75 81.25 \n",
       "z\n",
       "M 55.078125 44.140625 \n",
       "Q 44.53125 44.140625 39.84375 43.75 \n",
       "L 39.84375 50 \n",
       "Q 46.484375 49.609375 54.6875 49.609375 \n",
       "L 62.109375 49.609375 \n",
       "L 62.109375 56.25 \n",
       "L 55.078125 56.25 \n",
       "Q 48.046875 56.25 42.96875 55.859375 \n",
       "L 42.96875 62.109375 \n",
       "Q 48.046875 61.71875 55.078125 61.71875 \n",
       "L 62.109375 61.71875 \n",
       "L 62.109375 67.578125 \n",
       "L 54.296875 67.578125 \n",
       "Q 47.65625 67.578125 41.40625 67.1875 \n",
       "L 41.40625 73.4375 \n",
       "Q 48.046875 73.046875 54.296875 73.046875 \n",
       "L 62.109375 73.046875 \n",
       "Q 62.109375 77.34375 61.71875 81.25 \n",
       "L 69.53125 81.25 \n",
       "Q 69.140625 77.34375 69.140625 73.046875 \n",
       "L 79.6875 73.046875 \n",
       "Q 86.328125 73.046875 92.1875 73.4375 \n",
       "L 92.1875 67.1875 \n",
       "Q 86.328125 67.578125 79.6875 67.578125 \n",
       "L 69.140625 67.578125 \n",
       "L 69.140625 61.71875 \n",
       "L 76.5625 61.71875 \n",
       "Q 82.421875 61.71875 89.453125 62.109375 \n",
       "L 89.453125 55.859375 \n",
       "Q 82.03125 56.25 76.5625 56.25 \n",
       "L 69.140625 56.25 \n",
       "L 69.140625 49.609375 \n",
       "L 80.46875 49.609375 \n",
       "Q 89.84375 49.609375 95.3125 50 \n",
       "L 95.3125 43.75 \n",
       "Q 89.84375 44.140625 80.078125 44.140625 \n",
       "z\n",
       "M 44.53125 -10.15625 \n",
       "Q 44.921875 -1.171875 44.921875 5.46875 \n",
       "L 44.921875 22.65625 \n",
       "Q 44.921875 31.640625 44.53125 39.0625 \n",
       "L 86.71875 39.0625 \n",
       "Q 86.328125 32.421875 86.328125 26.5625 \n",
       "L 86.328125 -2.734375 \n",
       "Q 86.328125 -7.03125 83.203125 -8.203125 \n",
       "Q 80.078125 -9.375 75.390625 -10.15625 \n",
       "Q 75 -6.640625 72.65625 -2.734375 \n",
       "Q 78.125 -2.734375 78.90625 -1.5625 \n",
       "Q 79.6875 -0.390625 79.6875 7.421875 \n",
       "L 51.953125 7.421875 \n",
       "L 51.953125 -10.15625 \n",
       "z\n",
       "M 51.953125 33.59375 \n",
       "L 51.953125 26.171875 \n",
       "L 79.296875 26.171875 \n",
       "L 79.296875 33.59375 \n",
       "z\n",
       "M 51.953125 20.703125 \n",
       "L 51.953125 12.890625 \n",
       "L 79.296875 12.890625 \n",
       "L 79.296875 20.703125 \n",
       "z\n",
       "M 9.375 61.71875 \n",
       "Q 12.890625 60.9375 16.40625 60.546875 \n",
       "Q 15.625 57.03125 12.109375 35.15625 \n",
       "Q 8.59375 36.328125 5.078125 36.71875 \n",
       "Q 7.03125 42.578125 9.375 61.71875 \n",
       "z\n",
       "\" id=\"SimHei-24773\"/>\n",
       "     <path d=\"M 43.75 -8.59375 \n",
       "Q 40.234375 -5.078125 35.9375 -3.125 \n",
       "Q 42.578125 1.5625 47.265625 8.390625 \n",
       "Q 51.953125 15.234375 54.6875 21.671875 \n",
       "Q 57.421875 28.125 58.59375 34.171875 \n",
       "Q 59.765625 40.234375 60.15625 44.921875 \n",
       "L 51.171875 44.921875 \n",
       "Q 45.3125 44.921875 39.84375 44.53125 \n",
       "L 39.84375 51.5625 \n",
       "Q 45.3125 51.171875 50.78125 51.171875 \n",
       "L 60.9375 51.171875 \n",
       "Q 60.9375 61.71875 60.734375 67.765625 \n",
       "Q 60.546875 73.828125 60.15625 78.515625 \n",
       "Q 64.84375 78.515625 69.53125 78.515625 \n",
       "Q 68.359375 73.4375 68.15625 68.359375 \n",
       "Q 67.96875 63.28125 67.96875 51.171875 \n",
       "L 83.984375 51.171875 \n",
       "Q 87.890625 51.171875 93.359375 51.5625 \n",
       "L 93.359375 44.53125 \n",
       "Q 87.890625 44.921875 83.984375 44.921875 \n",
       "L 68.359375 44.921875 \n",
       "Q 70.3125 32.8125 73.4375 25 \n",
       "Q 76.5625 17.1875 80.46875 12.6875 \n",
       "Q 84.375 8.203125 88.46875 5.65625 \n",
       "Q 92.578125 3.125 96.09375 1.171875 \n",
       "Q 90.625 -1.171875 87.890625 -7.03125 \n",
       "Q 82.03125 -1.953125 78.3125 2.734375 \n",
       "Q 74.609375 7.421875 72.0625 12.109375 \n",
       "Q 69.53125 16.796875 67.765625 21.484375 \n",
       "Q 66.015625 26.171875 64.84375 31.25 \n",
       "Q 62.890625 22.265625 60.15625 16.015625 \n",
       "Q 57.421875 9.765625 54.296875 4.875 \n",
       "Q 51.171875 0 43.75 -8.59375 \n",
       "z\n",
       "M 90.234375 62.5 \n",
       "Q 86.71875 60.15625 83.984375 57.8125 \n",
       "Q 81.640625 61.328125 79.484375 64.25 \n",
       "Q 77.34375 67.1875 74.609375 70.3125 \n",
       "Q 77.734375 72.65625 80.46875 74.609375 \n",
       "Q 83.59375 71.484375 85.734375 68.546875 \n",
       "Q 87.890625 65.625 90.234375 62.5 \n",
       "z\n",
       "M 7.03125 60.15625 \n",
       "Q 9.765625 62.109375 13.28125 64.0625 \n",
       "Q 15.625 60.546875 18.359375 56.640625 \n",
       "Q 21.09375 52.734375 23.4375 48.828125 \n",
       "Q 19.53125 46.484375 17.1875 44.140625 \n",
       "Q 14.84375 48.828125 12.6875 52.140625 \n",
       "Q 10.546875 55.46875 7.03125 60.15625 \n",
       "z\n",
       "M 12.109375 12.109375 \n",
       "Q 7.8125 16.015625 5.078125 18.359375 \n",
       "Q 9.765625 21.875 14.84375 26.75 \n",
       "Q 19.921875 31.640625 26.953125 40.234375 \n",
       "L 26.953125 30.078125 \n",
       "Q 24.21875 26.953125 19.140625 21.09375 \n",
       "Q 14.0625 15.234375 12.109375 12.109375 \n",
       "z\n",
       "M 26.5625 78.515625 \n",
       "L 34.765625 78.515625 \n",
       "Q 34.375 72.65625 34.375 64.453125 \n",
       "L 34.375 12.5 \n",
       "Q 34.375 1.953125 34.765625 -8.203125 \n",
       "L 26.5625 -8.203125 \n",
       "Q 26.953125 2.34375 26.953125 12.5 \n",
       "L 26.953125 64.453125 \n",
       "Q 26.953125 72.65625 26.5625 78.515625 \n",
       "z\n",
       "\" id=\"SimHei-29366\"/>\n",
       "     <path d=\"M 7.421875 66.015625 \n",
       "Q 11.328125 69.140625 13.671875 72.65625 \n",
       "Q 15.625 69.921875 20.109375 65.625 \n",
       "Q 24.609375 61.328125 28.90625 56.25 \n",
       "Q 25 53.515625 21.875 50.390625 \n",
       "Q 18.359375 55.078125 7.421875 66.015625 \n",
       "z\n",
       "M 22.265625 41.40625 \n",
       "Q 25.390625 36.71875 28.125 34.765625 \n",
       "Q 25 26.953125 20.703125 17.1875 \n",
       "Q 16.40625 7.421875 14.0625 1.5625 \n",
       "Q 10.15625 6.25 7.03125 8.59375 \n",
       "Q 12.5 17.1875 15.625 23.828125 \n",
       "Q 18.75 30.46875 22.265625 41.40625 \n",
       "z\n",
       "M 36.71875 73.4375 \n",
       "L 84.375 73.4375 \n",
       "Q 83.59375 67.578125 83.59375 55.265625 \n",
       "Q 83.59375 42.96875 84.375 35.546875 \n",
       "L 70.3125 35.546875 \n",
       "L 70.3125 7.421875 \n",
       "Q 70.3125 2.34375 73.046875 1.953125 \n",
       "Q 75.78125 1.5625 79.296875 1.75 \n",
       "Q 82.8125 1.953125 83.59375 4.484375 \n",
       "Q 84.375 7.03125 84.765625 15.234375 \n",
       "Q 89.453125 11.328125 94.140625 10.546875 \n",
       "Q 91.40625 -1.953125 88.078125 -3.515625 \n",
       "Q 84.765625 -5.078125 77.921875 -5.265625 \n",
       "Q 71.09375 -5.46875 67.1875 -4.484375 \n",
       "Q 63.28125 -3.515625 63.28125 4.296875 \n",
       "L 63.28125 35.546875 \n",
       "L 53.90625 35.546875 \n",
       "Q 54.296875 1.5625 28.90625 -10.15625 \n",
       "Q 26.953125 -5.46875 21.875 -2.34375 \n",
       "Q 47.265625 3.90625 46.484375 35.546875 \n",
       "L 36.71875 35.546875 \n",
       "Q 37.109375 42.96875 37.109375 55.46875 \n",
       "Q 37.109375 67.96875 36.71875 73.4375 \n",
       "z\n",
       "M 44.921875 67.1875 \n",
       "L 44.921875 41.796875 \n",
       "L 75.78125 41.796875 \n",
       "L 75.78125 67.1875 \n",
       "z\n",
       "\" id=\"SimHei-20917\"/>\n",
       "     <path d=\"M 10.15625 71.484375 \n",
       "Q 12.5 74.609375 14.453125 77.34375 \n",
       "Q 17.96875 74.609375 21.484375 72.0625 \n",
       "Q 25 69.53125 28.90625 66.796875 \n",
       "Q 25.78125 63.671875 23.828125 60.9375 \n",
       "Q 19.921875 64.453125 16.984375 66.796875 \n",
       "Q 14.0625 69.140625 10.15625 71.484375 \n",
       "z\n",
       "M 5.859375 48.046875 \n",
       "Q 8.203125 50.78125 9.765625 53.90625 \n",
       "Q 14.0625 51.171875 17.1875 49.21875 \n",
       "Q 20.3125 47.265625 26.171875 43.359375 \n",
       "Q 23.4375 40.234375 21.875 37.109375 \n",
       "Q 17.1875 40.625 14.0625 42.765625 \n",
       "Q 10.9375 44.921875 5.859375 48.046875 \n",
       "z\n",
       "M 20.3125 28.90625 \n",
       "Q 23.046875 25.390625 26.171875 23.828125 \n",
       "Q 22.65625 16.40625 20.5 11.328125 \n",
       "Q 18.359375 6.25 16.40625 1.953125 \n",
       "Q 14.453125 -2.34375 12.890625 -7.03125 \n",
       "Q 8.59375 -4.296875 5.078125 -3.125 \n",
       "Q 9.375 3.125 13.671875 12.5 \n",
       "Q 17.96875 21.875 20.3125 28.90625 \n",
       "z\n",
       "M 37.5 32.421875 \n",
       "L 37.5 17.578125 \n",
       "L 49.21875 17.578125 \n",
       "L 49.21875 32.421875 \n",
       "z\n",
       "M 70.703125 69.140625 \n",
       "L 70.703125 51.953125 \n",
       "L 84.375 51.953125 \n",
       "L 84.375 69.140625 \n",
       "z\n",
       "M 70.703125 46.09375 \n",
       "Q 70.3125 33.984375 70.3125 29.6875 \n",
       "L 84.375 29.6875 \n",
       "L 84.375 46.09375 \n",
       "z\n",
       "M 55.859375 38.28125 \n",
       "Q 55.46875 32.421875 55.46875 24.015625 \n",
       "Q 55.46875 15.625 55.859375 5.859375 \n",
       "L 49.21875 5.859375 \n",
       "L 49.21875 11.71875 \n",
       "L 37.5 11.71875 \n",
       "L 37.5 1.953125 \n",
       "L 30.859375 1.953125 \n",
       "Q 31.25 7.03125 31.25 19.53125 \n",
       "Q 31.25 32.03125 30.859375 38.28125 \n",
       "L 40.625 38.28125 \n",
       "L 40.625 53.515625 \n",
       "Q 32.03125 53.515625 27.734375 53.125 \n",
       "L 27.734375 59.765625 \n",
       "Q 32.03125 59.375 40.625 59.375 \n",
       "L 40.625 68.75 \n",
       "Q 40.625 73.4375 40.234375 80.078125 \n",
       "L 47.265625 80.078125 \n",
       "Q 46.875 74.21875 46.875 68.75 \n",
       "L 46.875 59.375 \n",
       "Q 54.6875 59.375 59.375 59.765625 \n",
       "L 59.375 53.125 \n",
       "Q 54.296875 53.515625 46.875 53.515625 \n",
       "L 46.875 38.28125 \n",
       "z\n",
       "M 64.0625 75 \n",
       "L 91.015625 75 \n",
       "Q 90.625 66.796875 90.625 61.328125 \n",
       "L 90.625 2.734375 \n",
       "Q 89.84375 -3.90625 86.328125 -5.65625 \n",
       "Q 82.8125 -7.421875 76.5625 -8.203125 \n",
       "Q 75.390625 -4.296875 73.4375 -0.390625 \n",
       "Q 79.6875 -0.78125 81.828125 -0.1875 \n",
       "Q 83.984375 0.390625 84.375 5.078125 \n",
       "L 84.375 23.828125 \n",
       "L 69.921875 23.828125 \n",
       "Q 69.140625 17.1875 66.984375 10.734375 \n",
       "Q 64.84375 4.296875 61.125 -0.96875 \n",
       "Q 57.421875 -6.25 53.90625 -10.15625 \n",
       "Q 51.171875 -7.8125 46.09375 -5.859375 \n",
       "Q 52.734375 -1.5625 56.640625 4.484375 \n",
       "Q 60.546875 10.546875 62.109375 17.96875 \n",
       "Q 63.671875 25.390625 64.0625 35.34375 \n",
       "Q 64.453125 45.3125 64.453125 56.4375 \n",
       "Q 64.453125 67.578125 64.0625 75 \n",
       "z\n",
       "\" id=\"SimHei-28246\"/>\n",
       "     <path d=\"M 9.765625 50.78125 \n",
       "Q 16.015625 50.390625 20.703125 50.390625 \n",
       "L 33.984375 50.390625 \n",
       "L 33.984375 69.140625 \n",
       "Q 33.984375 72.65625 33.59375 77.734375 \n",
       "L 42.1875 77.734375 \n",
       "Q 41.40625 72.65625 41.40625 69.140625 \n",
       "L 41.40625 4.6875 \n",
       "Q 41.40625 0.390625 41.796875 -5.859375 \n",
       "L 33.59375 -5.859375 \n",
       "Q 33.984375 0.390625 33.984375 7.421875 \n",
       "Q 26.171875 5.46875 19.71875 3.3125 \n",
       "Q 13.28125 1.171875 10.15625 -0.78125 \n",
       "Q 8.203125 3.90625 5.46875 8.984375 \n",
       "Q 10.546875 9.375 19.71875 11.328125 \n",
       "Q 28.90625 13.28125 33.984375 14.84375 \n",
       "L 33.984375 43.359375 \n",
       "L 20.703125 43.359375 \n",
       "Q 16.015625 43.359375 9.765625 42.96875 \n",
       "z\n",
       "M 55.46875 77.734375 \n",
       "L 63.671875 77.734375 \n",
       "Q 63.28125 73.4375 63.28125 69.921875 \n",
       "L 63.28125 44.140625 \n",
       "Q 73.828125 48.4375 85.9375 58.59375 \n",
       "Q 88.671875 54.296875 92.96875 50 \n",
       "Q 88.28125 49.21875 79.09375 44.53125 \n",
       "Q 69.921875 39.84375 63.28125 37.109375 \n",
       "L 63.28125 7.8125 \n",
       "Q 63.28125 1.953125 69.140625 1.953125 \n",
       "L 78.515625 1.953125 \n",
       "Q 83.203125 1.953125 84.375 3.90625 \n",
       "Q 85.546875 5.859375 86.71875 13.28125 \n",
       "Q 90.234375 9.375 95.703125 8.59375 \n",
       "Q 92.578125 0.390625 90.234375 -2.34375 \n",
       "Q 87.890625 -5.078125 83.203125 -5.078125 \n",
       "L 65.234375 -5.078125 \n",
       "Q 55.859375 -5.078125 55.859375 4.6875 \n",
       "L 55.859375 69.921875 \n",
       "Q 55.859375 72.65625 55.46875 77.734375 \n",
       "z\n",
       "\" id=\"SimHei-21271\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(292.301562 16.7625)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#SimHei-30123\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-24773\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-29366\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-20917\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-45\"/>\n",
       "     <use x=\"450\" xlink:href=\"#SimHei-28246\"/>\n",
       "     <use x=\"550\" xlink:href=\"#SimHei-21271\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 59.301563 59.35625 \n",
       "L 181.301562 59.35625 \n",
       "Q 183.301562 59.35625 183.301562 57.35625 \n",
       "L 183.301562 29.7625 \n",
       "Q 183.301562 27.7625 181.301562 27.7625 \n",
       "L 59.301563 27.7625 \n",
       "Q 57.301563 27.7625 57.301563 29.7625 \n",
       "L 57.301563 57.35625 \n",
       "Q 57.301563 59.35625 59.301563 59.35625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\">\n",
       "     <path d=\"M 61.301563 36.270312 \n",
       "L 81.301563 36.270312 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <g>\n",
       "      <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"71.301563\" xlink:href=\"#m1b1c190031\" y=\"36.270312\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_59\">\n",
       "     <!-- 累计确诊人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 16.015625 77.734375 \n",
       "L 86.71875 77.734375 \n",
       "Q 86.328125 71.875 86.328125 62.109375 \n",
       "Q 86.328125 52.34375 86.71875 46.09375 \n",
       "L 73.046875 46.09375 \n",
       "Q 76.171875 43.359375 80.46875 40.234375 \n",
       "Q 75.390625 39.0625 67.1875 35.34375 \n",
       "Q 58.984375 31.640625 52.34375 28.703125 \n",
       "Q 45.703125 25.78125 38.671875 22.65625 \n",
       "Q 60.546875 23.828125 72.65625 24.21875 \n",
       "Q 69.140625 26.5625 64.84375 28.515625 \n",
       "Q 67.96875 30.859375 70.703125 33.203125 \n",
       "Q 80.078125 27.734375 91.796875 20.703125 \n",
       "Q 89.0625 17.96875 85.9375 14.84375 \n",
       "Q 82.8125 17.578125 78.90625 19.921875 \n",
       "Q 66.40625 19.140625 55.46875 18.359375 \n",
       "L 55.46875 0.78125 \n",
       "Q 55.46875 -4.6875 51.359375 -6.25 \n",
       "Q 47.265625 -7.8125 41.015625 -8.984375 \n",
       "Q 40.234375 -4.6875 38.28125 0 \n",
       "Q 45.3125 0 46.875 0.578125 \n",
       "Q 48.4375 1.171875 48.4375 4.296875 \n",
       "L 48.4375 17.96875 \n",
       "Q 37.890625 17.1875 32.21875 16.59375 \n",
       "Q 26.5625 16.015625 15.625 13.671875 \n",
       "Q 14.453125 17.578125 12.890625 21.875 \n",
       "Q 21.484375 22.65625 27.921875 24.609375 \n",
       "Q 34.375 26.5625 49.609375 33.984375 \n",
       "Q 45.3125 33.203125 37.890625 32.609375 \n",
       "Q 30.46875 32.03125 21.484375 29.6875 \n",
       "Q 20.703125 33.984375 18.75 37.109375 \n",
       "Q 23.4375 37.5 29.484375 40.03125 \n",
       "Q 35.546875 42.578125 39.84375 46.09375 \n",
       "L 16.015625 46.09375 \n",
       "Q 16.40625 52.734375 16.40625 62.296875 \n",
       "Q 16.40625 71.875 16.015625 77.734375 \n",
       "z\n",
       "M 23.4375 72.65625 \n",
       "L 23.4375 64.0625 \n",
       "L 47.265625 64.0625 \n",
       "L 47.265625 72.65625 \n",
       "z\n",
       "M 23.4375 58.984375 \n",
       "L 23.4375 51.171875 \n",
       "L 47.265625 51.171875 \n",
       "L 47.265625 58.984375 \n",
       "z\n",
       "M 54.296875 72.65625 \n",
       "L 54.296875 64.0625 \n",
       "L 79.296875 64.0625 \n",
       "L 79.296875 72.65625 \n",
       "z\n",
       "M 54.296875 58.984375 \n",
       "L 54.296875 51.171875 \n",
       "L 79.296875 51.171875 \n",
       "L 79.296875 58.984375 \n",
       "z\n",
       "M 37.890625 37.890625 \n",
       "Q 48.828125 38.28125 58.984375 38.671875 \n",
       "Q 66.40625 42.1875 71.484375 46.09375 \n",
       "L 51.5625 46.09375 \n",
       "Q 46.875 42.96875 37.890625 37.890625 \n",
       "z\n",
       "M 32.421875 13.671875 \n",
       "Q 34.765625 10.9375 39.453125 7.8125 \n",
       "Q 35.15625 6.25 29.484375 2.53125 \n",
       "Q 23.828125 -1.171875 16.796875 -5.859375 \n",
       "Q 13.671875 -2.734375 9.765625 -0.390625 \n",
       "Q 15.625 1.953125 21.484375 5.65625 \n",
       "Q 27.34375 9.375 32.421875 13.671875 \n",
       "z\n",
       "M 62.890625 8.203125 \n",
       "Q 66.015625 11.328125 67.96875 14.0625 \n",
       "Q 73.046875 11.71875 78.703125 9.171875 \n",
       "Q 84.375 6.640625 91.796875 3.125 \n",
       "Q 89.0625 -0.390625 87.109375 -3.90625 \n",
       "Q 80.46875 0.390625 74.609375 3.125 \n",
       "Q 68.75 5.859375 62.890625 8.203125 \n",
       "z\n",
       "\" id=\"SimHei-32047\"/>\n",
       "      <path d=\"M 15.234375 72.265625 \n",
       "Q 17.96875 74.21875 22.265625 76.5625 \n",
       "Q 23.828125 73.828125 32.421875 61.328125 \n",
       "Q 28.90625 59.375 25 57.03125 \n",
       "Q 23.046875 60.546875 15.234375 72.265625 \n",
       "z\n",
       "M 5.46875 47.65625 \n",
       "Q 11.328125 47.265625 13.28125 47.265625 \n",
       "L 27.34375 47.265625 \n",
       "Q 26.953125 40.234375 26.953125 32.421875 \n",
       "L 26.953125 7.8125 \n",
       "Q 32.8125 14.453125 37.5 19.921875 \n",
       "Q 38.671875 16.015625 41.40625 13.28125 \n",
       "Q 37.890625 8.984375 32.609375 3.515625 \n",
       "Q 27.34375 -1.953125 23.4375 -7.8125 \n",
       "Q 19.53125 -4.296875 16.015625 -2.34375 \n",
       "Q 19.53125 2.34375 19.53125 8.203125 \n",
       "L 19.53125 40.625 \n",
       "Q 10.15625 40.625 5.46875 39.84375 \n",
       "z\n",
       "M 37.109375 47.65625 \n",
       "Q 42.96875 47.265625 48.828125 47.265625 \n",
       "L 63.28125 47.265625 \n",
       "L 63.28125 67.96875 \n",
       "Q 63.28125 72.65625 62.890625 76.953125 \n",
       "L 71.09375 76.953125 \n",
       "Q 70.703125 71.875 70.703125 67.96875 \n",
       "L 70.703125 47.265625 \n",
       "L 85.546875 47.265625 \n",
       "Q 89.0625 47.265625 94.53125 47.65625 \n",
       "L 94.53125 40.234375 \n",
       "Q 88.671875 40.625 85.9375 40.625 \n",
       "L 70.703125 40.625 \n",
       "L 70.703125 3.125 \n",
       "Q 70.703125 -3.125 71.09375 -9.765625 \n",
       "L 62.890625 -9.765625 \n",
       "Q 63.28125 -3.125 63.28125 2.734375 \n",
       "L 63.28125 40.625 \n",
       "L 49.21875 40.625 \n",
       "Q 42.96875 40.625 37.109375 40.234375 \n",
       "z\n",
       "\" id=\"SimHei-35745\"/>\n",
       "      <path d=\"M 21.484375 39.84375 \n",
       "L 21.484375 14.84375 \n",
       "L 32.03125 14.84375 \n",
       "L 32.03125 39.84375 \n",
       "z\n",
       "M 10.15625 25 \n",
       "Q 7.8125 28.125 3.515625 30.46875 \n",
       "Q 8.984375 35.546875 13.671875 43.9375 \n",
       "Q 18.359375 52.34375 20.703125 65.234375 \n",
       "Q 13.28125 65.234375 8.59375 64.84375 \n",
       "L 8.59375 71.09375 \n",
       "Q 14.0625 70.703125 19.140625 70.703125 \n",
       "L 29.296875 70.703125 \n",
       "Q 35.9375 70.703125 40.625 71.09375 \n",
       "L 40.625 64.84375 \n",
       "Q 35.9375 65.234375 27.734375 65.234375 \n",
       "Q 25.390625 54.6875 22.265625 45.3125 \n",
       "L 38.671875 45.3125 \n",
       "Q 38.28125 38.671875 38.28125 32.8125 \n",
       "L 38.28125 16.40625 \n",
       "Q 38.28125 10.15625 38.671875 1.953125 \n",
       "L 32.03125 1.953125 \n",
       "L 32.03125 9.375 \n",
       "L 21.484375 9.375 \n",
       "L 21.484375 -4.6875 \n",
       "L 14.84375 -4.6875 \n",
       "Q 15.234375 3.515625 15.234375 9.375 \n",
       "L 15.234375 33.203125 \n",
       "Q 12.890625 29.296875 10.15625 25 \n",
       "z\n",
       "M 70.3125 30.859375 \n",
       "L 70.3125 20.3125 \n",
       "L 83.203125 20.3125 \n",
       "L 83.203125 30.859375 \n",
       "z\n",
       "M 78.515625 -10.546875 \n",
       "Q 78.125 -6.640625 75.390625 -3.125 \n",
       "Q 80.078125 -3.125 81.640625 -2.53125 \n",
       "Q 83.203125 -1.953125 83.203125 1.953125 \n",
       "L 83.203125 14.84375 \n",
       "L 70.3125 14.84375 \n",
       "L 70.3125 -6.25 \n",
       "L 64.0625 -6.25 \n",
       "L 64.0625 14.84375 \n",
       "L 53.515625 14.84375 \n",
       "Q 53.125 9.765625 50.78125 3.703125 \n",
       "Q 48.4375 -2.34375 42.578125 -9.375 \n",
       "Q 39.84375 -5.46875 35.546875 -4.6875 \n",
       "Q 40.234375 -0.390625 42.765625 4.484375 \n",
       "Q 45.3125 9.375 46.09375 15.625 \n",
       "Q 46.875 21.875 47.0625 33.78125 \n",
       "Q 47.265625 45.703125 46.875 53.125 \n",
       "L 64.84375 53.125 \n",
       "Q 68.359375 59.375 70.703125 65.234375 \n",
       "L 55.46875 65.234375 \n",
       "Q 52.34375 60.15625 44.921875 50.390625 \n",
       "Q 41.796875 53.125 38.28125 54.296875 \n",
       "Q 45.703125 61.71875 49.21875 68.15625 \n",
       "Q 52.734375 74.609375 55.46875 82.03125 \n",
       "Q 59.765625 80.078125 64.0625 78.90625 \n",
       "Q 62.109375 77.734375 58.59375 70.703125 \n",
       "L 81.25 70.703125 \n",
       "Q 74.609375 58.59375 72.65625 53.125 \n",
       "L 89.84375 53.125 \n",
       "Q 89.453125 46.09375 89.453125 37.890625 \n",
       "L 89.453125 -0.78125 \n",
       "Q 89.84375 -5.46875 87.5 -7.21875 \n",
       "Q 85.15625 -8.984375 78.515625 -10.546875 \n",
       "z\n",
       "M 53.515625 47.65625 \n",
       "L 53.515625 36.328125 \n",
       "L 64.0625 36.328125 \n",
       "L 64.0625 47.65625 \n",
       "z\n",
       "M 53.515625 30.859375 \n",
       "L 53.515625 20.3125 \n",
       "L 64.0625 20.3125 \n",
       "L 64.0625 30.859375 \n",
       "z\n",
       "M 70.3125 47.65625 \n",
       "L 70.3125 36.328125 \n",
       "L 83.203125 36.328125 \n",
       "L 83.203125 47.65625 \n",
       "z\n",
       "\" id=\"SimHei-30830\"/>\n",
       "      <path d=\"M 12.5 71.484375 \n",
       "Q 15.234375 73.828125 18.75 76.171875 \n",
       "Q 22.265625 72.265625 29.6875 62.890625 \n",
       "Q 26.171875 60.546875 23.4375 57.8125 \n",
       "Q 16.796875 66.796875 12.5 71.484375 \n",
       "z\n",
       "M 26.171875 12.5 \n",
       "Q 30.078125 17.1875 32.421875 20.3125 \n",
       "Q 34.765625 16.796875 37.5 12.890625 \n",
       "Q 33.203125 8.203125 29.296875 3.90625 \n",
       "Q 25.390625 -0.390625 21.09375 -6.640625 \n",
       "Q 17.578125 -3.90625 14.0625 -1.171875 \n",
       "Q 16.015625 1.171875 17.1875 3.125 \n",
       "Q 18.359375 5.078125 18.359375 8.203125 \n",
       "L 18.359375 42.1875 \n",
       "L 15.234375 42.1875 \n",
       "Q 10.15625 42.1875 4.6875 41.796875 \n",
       "L 4.6875 48.828125 \n",
       "Q 9.765625 48.4375 15.234375 48.4375 \n",
       "L 26.5625 48.4375 \n",
       "Q 26.171875 41.40625 26.171875 33.59375 \n",
       "z\n",
       "M 37.5 38.28125 \n",
       "Q 35.15625 40.234375 29.296875 43.75 \n",
       "Q 34.765625 46.875 39.25 50.78125 \n",
       "Q 43.75 54.6875 47.0625 59.375 \n",
       "Q 50.390625 64.0625 52.734375 69.328125 \n",
       "Q 55.078125 74.609375 56.640625 80.46875 \n",
       "Q 61.328125 78.90625 67.1875 77.34375 \n",
       "L 66.015625 73.828125 \n",
       "Q 69.53125 63.28125 76.953125 58.390625 \n",
       "Q 84.375 53.515625 93.75 50.390625 \n",
       "Q 91.796875 48.046875 87.890625 41.40625 \n",
       "Q 76.171875 47.265625 69.71875 55.265625 \n",
       "Q 63.28125 63.28125 60.9375 69.140625 \n",
       "Q 57.421875 62.5 52.921875 55.265625 \n",
       "Q 48.4375 48.046875 37.5 38.28125 \n",
       "z\n",
       "M 62.5 52.34375 \n",
       "Q 65.234375 49.609375 69.140625 46.484375 \n",
       "Q 63.28125 40.234375 57.21875 34.765625 \n",
       "Q 51.171875 29.296875 44.53125 24.609375 \n",
       "Q 41.40625 28.125 38.671875 31.25 \n",
       "Q 44.53125 33.984375 50.96875 39.25 \n",
       "Q 57.421875 44.53125 62.5 52.34375 \n",
       "z\n",
       "M 48.046875 7.421875 \n",
       "Q 45.703125 10.9375 42.578125 14.453125 \n",
       "Q 52.734375 17.96875 61.328125 25.578125 \n",
       "Q 69.921875 33.203125 73.4375 40.625 \n",
       "Q 77.34375 37.109375 80.859375 33.984375 \n",
       "Q 76.5625 29.6875 71.484375 24.015625 \n",
       "Q 66.40625 18.359375 59.5625 14.0625 \n",
       "Q 52.734375 9.765625 48.046875 7.421875 \n",
       "z\n",
       "M 43.359375 -10.9375 \n",
       "Q 40.625 -6.640625 38.28125 -3.125 \n",
       "Q 45.703125 -1.953125 52.734375 0.78125 \n",
       "Q 59.765625 3.515625 65.625 7.421875 \n",
       "Q 71.484375 11.328125 76.171875 16.015625 \n",
       "Q 80.859375 20.703125 84.765625 25.78125 \n",
       "Q 87.5 21.484375 92.1875 18.359375 \n",
       "Q 88.28125 16.015625 84.5625 12.6875 \n",
       "Q 80.859375 9.375 76.171875 5.265625 \n",
       "Q 71.484375 1.171875 62.6875 -3.125 \n",
       "Q 53.90625 -7.421875 43.359375 -10.9375 \n",
       "z\n",
       "\" id=\"SimHei-35786\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(89.301563 39.770312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-32047\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-35745\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-30830\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-35786\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 61.301563 50.567187 \n",
       "L 81.301563 50.567187 \n",
       "\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <g>\n",
       "      <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"71.301563\" xlink:href=\"#m6398f9ed21\" y=\"50.567187\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_60\">\n",
       "     <!-- 预测的累计确诊人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 44.921875 75.390625 \n",
       "Q 51.953125 75 57.8125 75 \n",
       "L 79.6875 75 \n",
       "Q 85.15625 75 91.015625 75.390625 \n",
       "L 91.015625 68.75 \n",
       "Q 85.15625 69.140625 79.6875 69.140625 \n",
       "L 69.53125 69.140625 \n",
       "Q 68.359375 63.28125 67.1875 56.640625 \n",
       "L 87.890625 56.640625 \n",
       "Q 87.5 50.78125 87.5 44.140625 \n",
       "L 87.5 27.34375 \n",
       "Q 87.5 21.484375 87.890625 14.453125 \n",
       "L 80.078125 14.453125 \n",
       "L 80.078125 50.78125 \n",
       "L 55.46875 50.78125 \n",
       "L 55.46875 13.671875 \n",
       "L 48.046875 13.671875 \n",
       "Q 48.4375 22.65625 48.4375 28.125 \n",
       "L 48.4375 43.75 \n",
       "Q 48.4375 50.390625 48.046875 56.640625 \n",
       "L 60.15625 56.640625 \n",
       "Q 61.71875 64.84375 62.109375 69.140625 \n",
       "L 57.8125 69.140625 \n",
       "Q 51.5625 69.140625 44.921875 68.75 \n",
       "z\n",
       "M 64.84375 45.3125 \n",
       "Q 68.75 45.3125 72.65625 45.3125 \n",
       "Q 71.875 37.109375 71.484375 31.25 \n",
       "Q 71.09375 25.390625 69.140625 16.203125 \n",
       "Q 67.1875 7.03125 61.328125 0.96875 \n",
       "Q 55.46875 -5.078125 46.09375 -10.9375 \n",
       "Q 42.1875 -7.8125 38.28125 -5.46875 \n",
       "Q 48.046875 -1.953125 53.515625 3.125 \n",
       "Q 58.984375 8.203125 61.328125 14.453125 \n",
       "Q 63.671875 20.703125 64.25 28.515625 \n",
       "Q 64.84375 36.328125 64.84375 45.3125 \n",
       "z\n",
       "M 69.921875 6.640625 \n",
       "Q 72.265625 9.375 75 11.71875 \n",
       "Q 78.515625 9.765625 83.59375 5.859375 \n",
       "Q 88.671875 1.953125 93.359375 -2.734375 \n",
       "Q 90.234375 -5.859375 87.890625 -9.375 \n",
       "Q 82.8125 -3.90625 78.90625 -0.390625 \n",
       "Q 75 3.125 69.921875 6.640625 \n",
       "z\n",
       "M 31.640625 50.78125 \n",
       "Q 28.125 48.4375 25.78125 46.09375 \n",
       "Q 21.484375 52.34375 14.0625 58.203125 \n",
       "Q 16.40625 60.546875 19.140625 62.5 \n",
       "Q 21.484375 60.546875 23.828125 58.59375 \n",
       "Q 28.515625 64.84375 30.859375 68.359375 \n",
       "L 23.046875 68.359375 \n",
       "Q 17.1875 68.359375 10.15625 67.96875 \n",
       "L 10.15625 74.609375 \n",
       "Q 17.1875 74.21875 22.65625 74.21875 \n",
       "L 40.625 74.21875 \n",
       "L 40.625 68.75 \n",
       "Q 34.765625 62.5 28.125 53.90625 \n",
       "z\n",
       "M 43.75 44.53125 \n",
       "Q 41.796875 36.71875 40.625 30.46875 \n",
       "Q 36.328125 31.25 33.203125 31.640625 \n",
       "Q 34.375 35.546875 35.15625 38.671875 \n",
       "L 27.734375 38.671875 \n",
       "L 27.734375 2.734375 \n",
       "Q 27.34375 -3.90625 22.84375 -5.46875 \n",
       "Q 18.359375 -7.03125 12.109375 -7.03125 \n",
       "Q 11.71875 -2.734375 10.546875 1.5625 \n",
       "Q 17.578125 0.390625 19.140625 1.359375 \n",
       "Q 20.703125 2.34375 20.703125 6.25 \n",
       "L 20.703125 38.671875 \n",
       "L 16.40625 38.671875 \n",
       "Q 11.328125 38.671875 6.25 38.28125 \n",
       "L 6.25 44.921875 \n",
       "Q 11.328125 44.53125 16.015625 44.53125 \n",
       "z\n",
       "\" id=\"SimHei-39044\"/>\n",
       "      <path d=\"M 25.390625 67.96875 \n",
       "Q 23.046875 66.015625 20.703125 62.5 \n",
       "Q 14.84375 67.96875 7.8125 72.265625 \n",
       "Q 10.15625 74.21875 12.5 77.34375 \n",
       "Q 19.921875 72.65625 25.390625 67.96875 \n",
       "z\n",
       "M 4.6875 45.3125 \n",
       "Q 6.640625 48.4375 8.203125 51.5625 \n",
       "Q 16.40625 48.046875 23.4375 44.140625 \n",
       "Q 21.09375 40.625 19.921875 37.5 \n",
       "Q 13.671875 42.1875 4.6875 45.3125 \n",
       "z\n",
       "M 17.96875 27.34375 \n",
       "Q 21.09375 24.609375 24.609375 22.65625 \n",
       "Q 21.09375 13.671875 18.546875 4.875 \n",
       "Q 16.015625 -3.90625 14.84375 -8.59375 \n",
       "Q 10.546875 -5.46875 5.859375 -3.90625 \n",
       "Q 9.375 0.78125 12.890625 9.953125 \n",
       "Q 16.40625 19.140625 17.96875 27.34375 \n",
       "z\n",
       "M 28.515625 72.265625 \n",
       "L 60.546875 72.265625 \n",
       "Q 60.15625 65.625 60.15625 60.546875 \n",
       "L 60.15625 32.8125 \n",
       "Q 60.15625 25.78125 60.546875 19.140625 \n",
       "L 53.90625 19.140625 \n",
       "L 53.90625 66.015625 \n",
       "L 35.15625 66.015625 \n",
       "L 35.15625 18.75 \n",
       "L 28.515625 18.75 \n",
       "Q 28.90625 27.34375 28.90625 33.59375 \n",
       "L 28.90625 59.765625 \n",
       "Q 28.90625 66.015625 28.515625 72.265625 \n",
       "z\n",
       "M 41.40625 59.375 \n",
       "Q 44.921875 58.59375 49.609375 58.203125 \n",
       "Q 48.4375 54.296875 48.046875 39.84375 \n",
       "Q 47.65625 25.390625 45.890625 18.15625 \n",
       "Q 44.140625 10.9375 40.03125 4.296875 \n",
       "Q 35.9375 -2.34375 30.46875 -8.203125 \n",
       "Q 27.734375 -4.296875 23.4375 -2.34375 \n",
       "Q 31.25 3.125 35.15625 9.5625 \n",
       "Q 39.0625 16.015625 40.421875 24.21875 \n",
       "Q 41.796875 32.421875 41.796875 41.796875 \n",
       "Q 41.796875 51.171875 41.40625 59.375 \n",
       "z\n",
       "M 48.4375 10.546875 \n",
       "Q 51.171875 12.5 53.90625 14.84375 \n",
       "Q 62.109375 6.25 65.625 1.171875 \n",
       "Q 62.5 -0.78125 59.765625 -3.125 \n",
       "Q 54.6875 4.296875 48.4375 10.546875 \n",
       "z\n",
       "M 68.359375 67.1875 \n",
       "L 75.390625 67.1875 \n",
       "Q 75 62.890625 75 56.640625 \n",
       "L 75 27.34375 \n",
       "Q 75 21.875 75.390625 14.453125 \n",
       "L 68.359375 14.453125 \n",
       "Q 68.75 22.265625 68.75 27.34375 \n",
       "L 68.75 56.25 \n",
       "Q 68.75 62.890625 68.359375 67.1875 \n",
       "z\n",
       "M 83.203125 77.34375 \n",
       "L 90.234375 77.34375 \n",
       "Q 89.84375 71.09375 89.84375 66.796875 \n",
       "L 89.84375 2.34375 \n",
       "Q 89.84375 -4.6875 87.296875 -6.046875 \n",
       "Q 84.765625 -7.421875 78.125 -8.984375 \n",
       "Q 77.34375 -4.6875 74.21875 -0.78125 \n",
       "Q 80.078125 -0.78125 81.828125 -0.390625 \n",
       "Q 83.59375 0 83.59375 3.90625 \n",
       "L 83.59375 66.796875 \n",
       "Q 83.59375 71.09375 83.203125 77.34375 \n",
       "z\n",
       "\" id=\"SimHei-27979\"/>\n",
       "      <path d=\"M 23.828125 79.6875 \n",
       "Q 28.90625 78.515625 34.375 76.953125 \n",
       "Q 32.8125 74.609375 31.640625 70.109375 \n",
       "Q 30.46875 65.625 29.6875 62.109375 \n",
       "L 46.484375 62.109375 \n",
       "Q 46.09375 55.078125 46.09375 45.3125 \n",
       "L 46.09375 10.9375 \n",
       "Q 46.09375 4.6875 46.484375 -3.515625 \n",
       "L 39.0625 -3.515625 \n",
       "L 39.0625 4.6875 \n",
       "L 18.75 4.6875 \n",
       "L 18.75 -4.296875 \n",
       "L 11.328125 -4.296875 \n",
       "Q 11.71875 5.46875 11.71875 10.15625 \n",
       "L 11.71875 44.921875 \n",
       "Q 11.71875 55.078125 11.328125 62.109375 \n",
       "L 22.265625 62.109375 \n",
       "Q 22.65625 66.015625 23.046875 69.71875 \n",
       "Q 23.4375 73.4375 23.828125 79.6875 \n",
       "z\n",
       "M 18.75 55.078125 \n",
       "L 18.75 37.890625 \n",
       "L 39.0625 37.890625 \n",
       "L 39.0625 55.078125 \n",
       "z\n",
       "M 18.75 30.46875 \n",
       "L 18.75 12.109375 \n",
       "L 39.0625 12.109375 \n",
       "L 39.0625 30.46875 \n",
       "z\n",
       "M 91.40625 61.328125 \n",
       "Q 90.625 53.90625 90.234375 46.875 \n",
       "L 87.5 2.734375 \n",
       "Q 86.328125 -4.296875 80.46875 -6.25 \n",
       "Q 74.609375 -8.203125 67.96875 -8.59375 \n",
       "Q 67.96875 -4.296875 65.234375 0.390625 \n",
       "Q 71.875 0 75.78125 0.578125 \n",
       "Q 79.6875 1.171875 80.46875 5.46875 \n",
       "L 83.59375 54.296875 \n",
       "L 62.890625 54.296875 \n",
       "Q 59.765625 47.65625 55.46875 39.453125 \n",
       "Q 52.34375 41.796875 48.828125 43.359375 \n",
       "Q 51.171875 46.875 54.09375 53.125 \n",
       "Q 57.03125 59.375 59.171875 66.59375 \n",
       "Q 61.328125 73.828125 62.109375 78.515625 \n",
       "Q 67.1875 76.171875 71.875 75 \n",
       "Q 69.921875 71.875 68.359375 68.546875 \n",
       "Q 66.796875 65.234375 65.625 61.328125 \n",
       "z\n",
       "M 57.03125 35.9375 \n",
       "Q 59.765625 37.5 63.671875 39.84375 \n",
       "Q 65.625 36.328125 67.578125 32.03125 \n",
       "Q 69.53125 27.734375 71.875 21.484375 \n",
       "Q 68.75 20.3125 64.84375 17.96875 \n",
       "Q 63.671875 22.265625 61.515625 27.34375 \n",
       "Q 59.375 32.421875 57.03125 35.9375 \n",
       "z\n",
       "\" id=\"SimHei-30340\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(89.301563 54.067187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-39044\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-27979\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-30340\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-32047\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-35745\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-30830\"/>\n",
       "      <use x=\"600\" xlink:href=\"#SimHei-35786\"/>\n",
       "      <use x=\"700\" xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"800\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc9db4454a7\">\n",
       "   <rect height=\"326.16\" width=\"558\" x=\"52.301563\" y=\"22.7625\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "差分序列次数为： 0\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "1 0\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "1 1\n",
      "1 2\n",
      "2 0\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "2 1\n",
      "2 2\n",
      "BIC最小的p值和q值为：2、0\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "0.13103449841960682\n",
      "差分序列次数为： 3\n",
      "0 0\n",
      "0 1\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "0 2\n",
      "1 0\n",
      "1 1\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:695: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  invmacoefs = -np.log((1-macoefs)/(1+macoefs))\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:243: RuntimeWarning: invalid value encountered in add\n",
      "  **kwargs)).imag/2./hess[i, j]\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  **kwargs)).imag/2./hess[i, j]\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:668: RuntimeWarning: invalid value encountered in exp\n",
      "  newparams = ((1-np.exp(-params))/(1+np.exp(-params))).copy()\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:669: RuntimeWarning: invalid value encountered in exp\n",
      "  tmp = ((1-np.exp(-params))/(1+np.exp(-params))).copy()\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "1 2\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "2 0\n",
      "2 1\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "2 2\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:693: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp[kiter] = (macoefs[kiter]-b *macoefs[j-kiter-1])/(1-b**2)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "BIC最小的p值和q值为：1、2\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "0.012078601550385126\n",
      "差分序列次数为： 5\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "1 0\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/kalmanf/kalmanfilter.py:221: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  Z_mat, R_mat, T_mat)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "1 1\n",
      "1 2\n",
      "2 0\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "2 1\n",
      "2 2\n",
      "BIC最小的p值和q值为：0、1\n",
      "0.03061169699093932\n",
      "{'beta': 0.13103449841960682, 'gamma_2': 0.02005237437535854, 'theta': -0.01893450618997193}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"384.192812pt\" version=\"1.1\" viewBox=\"0 0 617.501562 384.192812\" width=\"617.501562pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 384.192812 \n",
       "L 617.501562 384.192812 \n",
       "L 617.501562 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 52.301563 348.9225 \n",
       "L 610.301563 348.9225 \n",
       "L 610.301563 22.7625 \n",
       "L 52.301563 22.7625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mce12e6361b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.956108\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2020-01-21 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.53125 1.5625 \n",
       "L 4.6875 1.5625 \n",
       "L 4.6875 7.8125 \n",
       "Q 7.03125 14.0625 11.125 19.328125 \n",
       "Q 15.234375 24.609375 23.046875 31.25 \n",
       "Q 28.90625 36.328125 31.4375 40.625 \n",
       "Q 33.984375 44.921875 33.984375 50 \n",
       "Q 33.984375 55.078125 31.828125 58.390625 \n",
       "Q 29.6875 61.71875 25 61.71875 \n",
       "Q 21.09375 61.71875 18.15625 58.203125 \n",
       "Q 15.234375 54.6875 15.234375 45.703125 \n",
       "L 6.25 45.703125 \n",
       "Q 6.640625 57.03125 11.515625 63.078125 \n",
       "Q 16.40625 69.140625 25.390625 69.140625 \n",
       "Q 33.984375 69.140625 38.671875 63.859375 \n",
       "Q 43.359375 58.59375 43.359375 49.609375 \n",
       "Q 43.359375 42.1875 39.0625 36.71875 \n",
       "Q 34.765625 31.25 28.515625 25.78125 \n",
       "Q 21.484375 19.53125 18.75 16.40625 \n",
       "Q 16.015625 13.28125 13.671875 8.984375 \n",
       "L 44.53125 8.984375 \n",
       "z\n",
       "\" id=\"SimHei-50\"/>\n",
       "       <path d=\"M 46.484375 35.15625 \n",
       "Q 46.484375 21.09375 41.40625 10.9375 \n",
       "Q 36.328125 0.78125 25 0.78125 \n",
       "Q 13.671875 0.78125 8.390625 10.9375 \n",
       "Q 3.125 21.09375 3.125 35.15625 \n",
       "Q 3.125 49.21875 8.390625 59.171875 \n",
       "Q 13.671875 69.140625 25 69.140625 \n",
       "Q 36.328125 69.140625 41.40625 59.171875 \n",
       "Q 46.484375 49.21875 46.484375 35.15625 \n",
       "z\n",
       "M 37.109375 35.15625 \n",
       "Q 37.109375 47.65625 34.171875 54.6875 \n",
       "Q 31.25 61.71875 25 61.71875 \n",
       "Q 18.75 61.71875 15.625 54.6875 \n",
       "Q 12.5 47.65625 12.5 35.15625 \n",
       "Q 12.5 22.65625 15.625 15.421875 \n",
       "Q 18.75 8.203125 25 8.203125 \n",
       "Q 31.25 8.203125 34.171875 15.421875 \n",
       "Q 37.109375 22.65625 37.109375 35.15625 \n",
       "z\n",
       "\" id=\"SimHei-48\"/>\n",
       "       <path d=\"M 46.875 32.8125 \n",
       "L 2.34375 32.8125 \n",
       "L 2.34375 39.0625 \n",
       "L 46.875 39.0625 \n",
       "z\n",
       "\" id=\"SimHei-45\"/>\n",
       "       <path d=\"M 30.46875 1.5625 \n",
       "L 21.484375 1.5625 \n",
       "L 21.484375 53.515625 \n",
       "L 9.765625 53.515625 \n",
       "L 9.765625 58.203125 \n",
       "Q 16.796875 58.203125 20.703125 60.9375 \n",
       "Q 24.609375 63.671875 25.78125 69.140625 \n",
       "L 30.46875 69.140625 \n",
       "z\n",
       "\" id=\"SimHei-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(72.956108 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"179.119744\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2020-01-25 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 25.78125 \n",
       "Q 44.140625 14.0625 38.46875 7.421875 \n",
       "Q 32.8125 0.78125 23.4375 0.78125 \n",
       "Q 15.234375 0.78125 9.953125 6.25 \n",
       "Q 4.6875 11.71875 4.296875 21.09375 \n",
       "L 13.28125 21.09375 \n",
       "Q 13.28125 15.234375 16.015625 11.71875 \n",
       "Q 18.75 8.203125 23.828125 8.203125 \n",
       "Q 28.90625 8.203125 31.828125 12.5 \n",
       "Q 34.765625 16.796875 34.765625 25.78125 \n",
       "Q 34.765625 33.59375 32.21875 37.296875 \n",
       "Q 29.6875 41.015625 25.390625 41.015625 \n",
       "Q 21.875 41.015625 19.328125 39.453125 \n",
       "Q 16.796875 37.890625 14.453125 33.984375 \n",
       "L 6.640625 33.984375 \n",
       "L 8.984375 68.359375 \n",
       "L 42.578125 68.359375 \n",
       "L 42.578125 60.9375 \n",
       "L 16.40625 60.9375 \n",
       "L 14.84375 42.96875 \n",
       "Q 17.1875 45.3125 19.921875 46.484375 \n",
       "Q 22.65625 47.65625 27.34375 47.65625 \n",
       "Q 34.765625 47.65625 39.453125 41.984375 \n",
       "Q 44.140625 36.328125 44.140625 25.78125 \n",
       "z\n",
       "\" id=\"SimHei-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(154.119744 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.283381\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2020-01-29 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 35.9375 \n",
       "Q 44.140625 19.921875 38.46875 10.34375 \n",
       "Q 32.8125 0.78125 22.265625 0.78125 \n",
       "Q 14.84375 0.78125 10.34375 6.25 \n",
       "Q 5.859375 11.71875 5.859375 18.359375 \n",
       "L 14.84375 18.359375 \n",
       "Q 14.84375 14.453125 16.984375 11.328125 \n",
       "Q 19.140625 8.203125 22.65625 8.203125 \n",
       "Q 28.515625 8.203125 31.4375 14.84375 \n",
       "Q 34.375 21.484375 35.15625 34.375 \n",
       "Q 33.203125 30.078125 29.6875 27.734375 \n",
       "Q 26.171875 25.390625 21.875 25.390625 \n",
       "Q 14.453125 25.390625 9.765625 30.859375 \n",
       "Q 5.078125 36.328125 5.078125 46.484375 \n",
       "Q 5.078125 56.640625 9.765625 62.890625 \n",
       "Q 14.453125 69.140625 23.828125 69.140625 \n",
       "Q 33.203125 69.140625 38.671875 61.328125 \n",
       "Q 44.140625 53.515625 44.140625 35.9375 \n",
       "z\n",
       "M 34.375 44.921875 \n",
       "Q 34.375 53.515625 31.4375 57.8125 \n",
       "Q 28.515625 62.109375 23.4375 62.109375 \n",
       "Q 19.921875 62.109375 17.1875 58.78125 \n",
       "Q 14.453125 55.46875 14.453125 46.484375 \n",
       "Q 14.453125 39.84375 16.59375 36.125 \n",
       "Q 18.75 32.421875 23.4375 32.421875 \n",
       "Q 28.515625 32.421875 31.4375 35.9375 \n",
       "Q 34.375 39.453125 34.375 44.921875 \n",
       "z\n",
       "\" id=\"SimHei-57\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(235.283381 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"321.156108\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2020-02-01 -->\n",
       "      <g transform=\"translate(296.156108 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"402.319744\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2020-02-05 -->\n",
       "      <g transform=\"translate(377.319744 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"483.483381\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2020-02-09 -->\n",
       "      <g transform=\"translate(458.483381 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"564.647017\" xlink:href=\"#mce12e6361b\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2020-02-13 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 20.3125 \n",
       "Q 44.140625 11.328125 38.46875 6.046875 \n",
       "Q 32.8125 0.78125 24.21875 0.78125 \n",
       "Q 15.625 0.78125 9.953125 6.046875 \n",
       "Q 4.296875 11.328125 4.296875 22.265625 \n",
       "L 13.28125 22.265625 \n",
       "Q 13.28125 14.84375 16.203125 11.515625 \n",
       "Q 19.140625 8.203125 24.21875 8.203125 \n",
       "Q 29.296875 8.203125 32.03125 11.328125 \n",
       "Q 34.765625 14.453125 34.765625 21.09375 \n",
       "Q 34.765625 26.5625 31.828125 29.6875 \n",
       "Q 28.90625 32.8125 21.484375 32.8125 \n",
       "L 21.484375 39.453125 \n",
       "Q 27.734375 39.453125 30.65625 42.578125 \n",
       "Q 33.59375 45.703125 33.59375 51.953125 \n",
       "Q 33.59375 56.640625 31.4375 59.375 \n",
       "Q 29.296875 62.109375 24.609375 62.109375 \n",
       "Q 19.921875 62.109375 17.375 58.78125 \n",
       "Q 14.84375 55.46875 14.453125 49.21875 \n",
       "L 5.859375 49.21875 \n",
       "Q 6.640625 58.203125 11.515625 63.671875 \n",
       "Q 16.40625 69.140625 24.609375 69.140625 \n",
       "Q 33.203125 69.140625 37.890625 64.25 \n",
       "Q 42.578125 59.375 42.578125 52.34375 \n",
       "Q 42.578125 45.703125 40.234375 41.984375 \n",
       "Q 37.890625 38.28125 32.421875 36.328125 \n",
       "Q 37.890625 35.15625 41.015625 30.859375 \n",
       "Q 44.140625 26.5625 44.140625 20.3125 \n",
       "z\n",
       "\" id=\"SimHei-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(539.647017 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- 日期 -->\n",
       "     <defs>\n",
       "      <path d=\"M 30.859375 69.921875 \n",
       "L 30.859375 43.359375 \n",
       "L 72.265625 43.359375 \n",
       "L 72.265625 69.921875 \n",
       "z\n",
       "M 30.859375 36.71875 \n",
       "L 30.859375 9.765625 \n",
       "L 72.265625 9.765625 \n",
       "L 72.265625 36.71875 \n",
       "z\n",
       "M 23.046875 76.5625 \n",
       "L 80.078125 76.5625 \n",
       "Q 79.6875 57.8125 79.6875 35.15625 \n",
       "Q 79.6875 12.5 80.078125 -6.25 \n",
       "L 72.265625 -6.25 \n",
       "L 72.265625 3.125 \n",
       "L 30.859375 3.125 \n",
       "L 30.859375 -8.203125 \n",
       "L 23.046875 -8.203125 \n",
       "Q 23.4375 9.375 23.4375 33 \n",
       "Q 23.4375 56.640625 23.046875 76.5625 \n",
       "z\n",
       "\" id=\"SimHei-26085\"/>\n",
       "      <path d=\"M 23.4375 60.9375 \n",
       "L 23.4375 52.34375 \n",
       "L 38.671875 52.34375 \n",
       "L 38.671875 60.9375 \n",
       "z\n",
       "M 18.359375 15.625 \n",
       "L 25.78125 10.9375 \n",
       "Q 23.4375 9.765625 19.328125 4.09375 \n",
       "Q 15.234375 -1.5625 11.71875 -5.859375 \n",
       "Q 7.8125 -3.125 5.078125 -1.5625 \n",
       "Q 8.59375 1.171875 12.296875 6.046875 \n",
       "Q 16.015625 10.9375 18.359375 15.625 \n",
       "z\n",
       "M 23.4375 46.484375 \n",
       "L 23.4375 38.28125 \n",
       "L 38.671875 38.28125 \n",
       "L 38.671875 46.484375 \n",
       "z\n",
       "M 23.4375 32.421875 \n",
       "L 23.4375 23.828125 \n",
       "L 38.671875 23.828125 \n",
       "L 38.671875 32.421875 \n",
       "z\n",
       "M 46.875 7.421875 \n",
       "Q 44.140625 4.6875 42.1875 1.5625 \n",
       "Q 37.109375 8.203125 32.8125 10.9375 \n",
       "Q 35.546875 13.671875 37.109375 16.40625 \n",
       "Q 42.96875 10.546875 46.875 7.421875 \n",
       "z\n",
       "M 8.203125 67.1875 \n",
       "Q 12.5 66.796875 16.40625 66.796875 \n",
       "Q 16.40625 74.21875 16.015625 79.6875 \n",
       "L 24.21875 79.6875 \n",
       "Q 23.4375 75 23.4375 66.796875 \n",
       "L 38.671875 66.796875 \n",
       "Q 38.671875 74.21875 38.28125 79.6875 \n",
       "L 46.484375 79.6875 \n",
       "Q 45.3125 75 45.703125 66.796875 \n",
       "Q 48.828125 66.796875 53.125 67.1875 \n",
       "L 53.125 60.546875 \n",
       "Q 49.21875 60.9375 45.703125 60.9375 \n",
       "L 45.703125 23.828125 \n",
       "Q 49.21875 23.828125 53.125 24.21875 \n",
       "L 53.125 17.578125 \n",
       "Q 47.265625 17.96875 42.1875 17.96875 \n",
       "L 17.1875 17.96875 \n",
       "Q 12.109375 17.96875 5.859375 17.578125 \n",
       "L 5.859375 24.21875 \n",
       "Q 11.71875 23.828125 16.40625 23.828125 \n",
       "L 16.40625 60.9375 \n",
       "Q 12.890625 60.9375 8.203125 60.546875 \n",
       "z\n",
       "M 76.953125 -9.765625 \n",
       "Q 76.953125 -5.46875 73.828125 -0.78125 \n",
       "Q 82.8125 -1.953125 82.03125 2.34375 \n",
       "L 82.03125 24.21875 \n",
       "L 64.453125 24.21875 \n",
       "Q 63.671875 14.84375 60.34375 6.25 \n",
       "Q 57.03125 -2.34375 50.78125 -9.765625 \n",
       "Q 48.046875 -6.25 43.75 -4.6875 \n",
       "Q 50.390625 1.953125 53.515625 9.375 \n",
       "Q 56.640625 16.796875 57.21875 24.21875 \n",
       "Q 57.8125 31.640625 57.8125 48.625 \n",
       "Q 57.8125 65.625 57.421875 75.78125 \n",
       "L 89.453125 75.78125 \n",
       "Q 89.0625 68.359375 89.0625 57.8125 \n",
       "L 89.0625 0.390625 \n",
       "Q 89.0625 -5.078125 85.9375 -7.03125 \n",
       "Q 82.8125 -8.984375 76.953125 -9.765625 \n",
       "z\n",
       "M 64.84375 69.921875 \n",
       "L 64.84375 52.34375 \n",
       "L 82.03125 52.34375 \n",
       "L 82.03125 69.921875 \n",
       "z\n",
       "M 64.84375 46.484375 \n",
       "L 64.84375 30.078125 \n",
       "L 82.03125 30.078125 \n",
       "L 82.03125 46.484375 \n",
       "z\n",
       "\" id=\"SimHei-26399\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(321.301562 375.70375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-26085\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-26399\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"ma4ffb0fad1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#ma4ffb0fad1\" y=\"335.56769\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(40.301563 338.985658)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#ma4ffb0fad1\" y=\"281.099388\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 10000 -->\n",
       "      <g transform=\"translate(20.301563 284.517357)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#ma4ffb0fad1\" y=\"226.631087\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20000 -->\n",
       "      <g transform=\"translate(20.301563 230.049056)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#ma4ffb0fad1\" y=\"172.162786\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 30000 -->\n",
       "      <g transform=\"translate(20.301563 175.580755)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-51\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#ma4ffb0fad1\" y=\"117.694485\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 40000 -->\n",
       "      <defs>\n",
       "       <path d=\"M 46.484375 18.75 \n",
       "L 38.28125 18.75 \n",
       "L 38.28125 1.5625 \n",
       "L 29.296875 1.5625 \n",
       "L 29.296875 18.75 \n",
       "L 3.125 18.75 \n",
       "L 3.125 26.171875 \n",
       "L 29.296875 69.140625 \n",
       "L 38.28125 69.140625 \n",
       "L 38.28125 26.171875 \n",
       "L 46.484375 26.171875 \n",
       "z\n",
       "M 29.296875 26.171875 \n",
       "L 29.296875 55.078125 \n",
       "L 11.71875 26.171875 \n",
       "z\n",
       "\" id=\"SimHei-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.301563 121.112454)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.301563\" xlink:href=\"#ma4ffb0fad1\" y=\"63.226184\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 50000 -->\n",
       "      <g transform=\"translate(20.301563 66.644153)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- 人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 13.671875 -8.984375 \n",
       "Q 10.9375 -3.515625 6.25 -1.171875 \n",
       "Q 21.09375 5.46875 29.484375 15.8125 \n",
       "Q 37.890625 26.171875 41.59375 38.078125 \n",
       "Q 45.3125 50 45.5 60.15625 \n",
       "Q 45.703125 70.3125 44.921875 79.296875 \n",
       "Q 48.4375 78.90625 54.296875 78.515625 \n",
       "Q 53.125 74.21875 53.125 64.640625 \n",
       "Q 53.125 55.078125 53.3125 49.015625 \n",
       "Q 53.515625 42.96875 64.25 25 \n",
       "Q 75 7.03125 94.921875 -1.171875 \n",
       "Q 89.0625 -5.46875 87.890625 -8.984375 \n",
       "Q 61.328125 4.296875 49.609375 39.84375 \n",
       "Q 40.625 7.03125 13.671875 -8.984375 \n",
       "z\n",
       "\" id=\"SimHei-20154\"/>\n",
       "      <path d=\"M 10.9375 75.78125 \n",
       "Q 14.84375 76.953125 17.1875 78.515625 \n",
       "Q 20.3125 73.4375 23.046875 68.359375 \n",
       "Q 19.53125 66.796875 16.796875 65.234375 \n",
       "Q 14.453125 71.09375 10.9375 75.78125 \n",
       "z\n",
       "M 44.921875 78.515625 \n",
       "Q 49.21875 76.5625 53.125 75 \n",
       "Q 50.78125 73.4375 49.21875 70.703125 \n",
       "Q 47.65625 67.96875 45.703125 64.453125 \n",
       "Q 42.578125 66.015625 39.453125 66.796875 \n",
       "Q 42.578125 71.875 44.921875 78.515625 \n",
       "z\n",
       "M 38.28125 49.609375 \n",
       "Q 41.796875 51.171875 44.140625 53.515625 \n",
       "Q 48.828125 46.875 51.953125 41.40625 \n",
       "Q 48.4375 39.84375 45.3125 37.5 \n",
       "Q 42.1875 44.921875 38.28125 49.609375 \n",
       "z\n",
       "M 8.203125 61.71875 \n",
       "Q 14.453125 61.328125 28.125 61.328125 \n",
       "Q 28.125 72.65625 27.734375 80.859375 \n",
       "L 35.546875 80.859375 \n",
       "Q 35.15625 72.65625 35.15625 61.328125 \n",
       "Q 48.046875 61.328125 53.90625 61.71875 \n",
       "L 53.90625 54.6875 \n",
       "Q 48.046875 55.078125 35.15625 55.078125 \n",
       "Q 35.15625 46.09375 35.546875 39.453125 \n",
       "L 27.734375 39.453125 \n",
       "Q 28.125 45.3125 28.125 51.953125 \n",
       "Q 26.171875 48.046875 21.671875 43.546875 \n",
       "Q 17.1875 39.0625 11.71875 35.9375 \n",
       "Q 10.15625 39.453125 6.640625 41.796875 \n",
       "Q 10.15625 42.96875 15.421875 46.875 \n",
       "Q 20.703125 50.78125 23.046875 55.078125 \n",
       "Q 14.84375 55.078125 8.203125 54.6875 \n",
       "z\n",
       "M 26.953125 24.21875 \n",
       "Q 25 20.3125 22.65625 16.40625 \n",
       "Q 27.34375 15.234375 35.15625 13.28125 \n",
       "Q 37.890625 16.796875 40.234375 24.21875 \n",
       "z\n",
       "M 24.21875 38.28125 \n",
       "Q 28.515625 36.71875 32.8125 35.546875 \n",
       "Q 31.25 33.984375 29.296875 30.46875 \n",
       "L 44.53125 30.46875 \n",
       "L 48.828125 30.46875 \n",
       "Q 46.484375 20.3125 42.1875 11.328125 \n",
       "Q 48.828125 9.375 52.734375 8.203125 \n",
       "Q 49.609375 3.90625 48.046875 0.390625 \n",
       "Q 44.53125 2.734375 37.5 5.46875 \n",
       "Q 28.125 -3.90625 9.375 -10.15625 \n",
       "Q 7.8125 -6.25 4.6875 -3.90625 \n",
       "Q 21.484375 0 31.25 8.203125 \n",
       "Q 20.3125 10.9375 13.28125 12.890625 \n",
       "Q 15.625 16.015625 19.53125 24.21875 \n",
       "Q 13.28125 24.21875 4.6875 23.828125 \n",
       "L 4.6875 30.859375 \n",
       "Q 12.109375 30.46875 21.875 30.46875 \n",
       "Q 23.046875 33.59375 24.21875 38.28125 \n",
       "z\n",
       "M 63.671875 80.46875 \n",
       "Q 68.359375 78.515625 73.4375 77.734375 \n",
       "Q 71.484375 75.390625 70.5 72.265625 \n",
       "Q 69.53125 69.140625 67.96875 63.28125 \n",
       "L 85.546875 63.28125 \n",
       "Q 89.0625 63.28125 94.53125 63.671875 \n",
       "L 94.53125 56.640625 \n",
       "Q 90.234375 57.03125 87.5 57.03125 \n",
       "Q 87.109375 48.828125 85.546875 35.34375 \n",
       "Q 83.984375 21.875 78.125 11.71875 \n",
       "Q 82.03125 6.25 87.109375 2.734375 \n",
       "Q 92.1875 -0.78125 96.09375 -2.34375 \n",
       "Q 90.625 -5.859375 89.0625 -9.375 \n",
       "Q 82.421875 -4.6875 79.296875 -1.359375 \n",
       "Q 76.171875 1.953125 73.4375 5.859375 \n",
       "Q 68.75 1.171875 64.640625 -1.953125 \n",
       "Q 60.546875 -5.078125 51.5625 -10.15625 \n",
       "Q 49.609375 -6.640625 45.3125 -3.90625 \n",
       "Q 52.734375 -1.171875 58.984375 3.125 \n",
       "Q 65.234375 7.421875 69.53125 12.109375 \n",
       "Q 65.234375 20.703125 62.890625 29.09375 \n",
       "Q 60.546875 37.5 60.15625 41.015625 \n",
       "Q 59.375 38.28125 58.203125 34.765625 \n",
       "Q 54.6875 36.328125 50.390625 37.890625 \n",
       "Q 55.078125 46.484375 58.984375 58.59375 \n",
       "Q 62.890625 70.703125 63.671875 80.46875 \n",
       "z\n",
       "M 66.40625 57.03125 \n",
       "Q 64.84375 53.125 64.0625 50.578125 \n",
       "Q 63.28125 48.046875 66.984375 36.71875 \n",
       "Q 70.703125 25.390625 74.21875 19.140625 \n",
       "Q 77.734375 28.515625 79.09375 38.671875 \n",
       "Q 80.46875 48.828125 80.46875 57.03125 \n",
       "z\n",
       "\" id=\"SimHei-25968\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(15.0125 195.8425)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#pf5e80461ab)\" d=\"M 77.665199 334.097045 \n",
       "L 97.956108 333.525128 \n",
       "L 118.247017 333.149297 \n",
       "L 138.537926 332.57738 \n",
       "L 158.828835 331.59695 \n",
       "L 179.119744 329.837624 \n",
       "L 199.410653 327.81685 \n",
       "L 219.701562 320.784993 \n",
       "L 239.992472 316.209655 \n",
       "L 260.283381 310.588527 \n",
       "L 280.57429 303.943394 \n",
       "L 300.865199 296.606514 \n",
       "L 321.156108 286.143153 \n",
       "L 341.447017 274.688469 \n",
       "L 361.737926 261.915653 \n",
       "L 382.028835 244.725457 \n",
       "L 402.319744 228.455775 \n",
       "L 422.610653 215.127382 \n",
       "L 442.901562 199.652938 \n",
       "L 463.192472 187.958593 \n",
       "L 483.483381 174.172666 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    <defs>\n",
       "     <path d=\"M -3 3 \n",
       "L 3 -3 \n",
       "M -3 -3 \n",
       "L 3 3 \n",
       "\" id=\"m6741c9f375\" style=\"stroke:#ff0000;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pf5e80461ab)\">\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"77.665199\" xlink:href=\"#m6741c9f375\" y=\"334.097045\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"97.956108\" xlink:href=\"#m6741c9f375\" y=\"333.525128\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"118.247017\" xlink:href=\"#m6741c9f375\" y=\"333.149297\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"138.537926\" xlink:href=\"#m6741c9f375\" y=\"332.57738\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"158.828835\" xlink:href=\"#m6741c9f375\" y=\"331.59695\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"179.119744\" xlink:href=\"#m6741c9f375\" y=\"329.837624\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"199.410653\" xlink:href=\"#m6741c9f375\" y=\"327.81685\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"219.701562\" xlink:href=\"#m6741c9f375\" y=\"320.784993\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"239.992472\" xlink:href=\"#m6741c9f375\" y=\"316.209655\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"260.283381\" xlink:href=\"#m6741c9f375\" y=\"310.588527\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"280.57429\" xlink:href=\"#m6741c9f375\" y=\"303.943394\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"300.865199\" xlink:href=\"#m6741c9f375\" y=\"296.606514\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"321.156108\" xlink:href=\"#m6741c9f375\" y=\"286.143153\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"341.447017\" xlink:href=\"#m6741c9f375\" y=\"274.688469\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"361.737926\" xlink:href=\"#m6741c9f375\" y=\"261.915653\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"382.028835\" xlink:href=\"#m6741c9f375\" y=\"244.725457\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"402.319744\" xlink:href=\"#m6741c9f375\" y=\"228.455775\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"422.610653\" xlink:href=\"#m6741c9f375\" y=\"215.127382\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"442.901562\" xlink:href=\"#m6741c9f375\" y=\"199.652938\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"463.192472\" xlink:href=\"#m6741c9f375\" y=\"187.958593\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"483.483381\" xlink:href=\"#m6741c9f375\" y=\"174.172666\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#pf5e80461ab)\" d=\"M 77.665199 334.097045 \n",
       "L 97.956108 333.737555 \n",
       "L 118.247017 333.230999 \n",
       "L 138.537926 332.533805 \n",
       "L 158.828835 331.575163 \n",
       "L 179.119744 330.251583 \n",
       "L 199.410653 328.426895 \n",
       "L 219.701562 325.91046 \n",
       "L 239.992472 322.45717 \n",
       "L 260.283381 317.762002 \n",
       "L 280.57429 311.4927 \n",
       "L 300.865199 303.317008 \n",
       "L 321.156108 292.951691 \n",
       "L 341.447017 280.320492 \n",
       "L 361.737926 265.603157 \n",
       "L 382.028835 249.099262 \n",
       "L 402.319744 231.865491 \n",
       "L 422.610653 215.203638 \n",
       "L 442.901562 198.797785 \n",
       "L 463.192472 182.789552 \n",
       "L 483.483381 165.484972 \n",
       "L 503.77429 145.740213 \n",
       "L 524.065199 123.435444 \n",
       "L 544.356108 98.227514 \n",
       "L 564.647017 69.756933 \n",
       "L 584.937926 37.587955 \n",
       "\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    <defs>\n",
       "     <path d=\"M -3 3 \n",
       "L 3 -3 \n",
       "M -3 -3 \n",
       "L 3 3 \n",
       "\" id=\"m9bad646ad8\" style=\"stroke:#0000ff;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pf5e80461ab)\">\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"77.665199\" xlink:href=\"#m9bad646ad8\" y=\"334.097045\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"97.956108\" xlink:href=\"#m9bad646ad8\" y=\"333.737555\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"118.247017\" xlink:href=\"#m9bad646ad8\" y=\"333.230999\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"138.537926\" xlink:href=\"#m9bad646ad8\" y=\"332.533805\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"158.828835\" xlink:href=\"#m9bad646ad8\" y=\"331.575163\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"179.119744\" xlink:href=\"#m9bad646ad8\" y=\"330.251583\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"199.410653\" xlink:href=\"#m9bad646ad8\" y=\"328.426895\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"219.701562\" xlink:href=\"#m9bad646ad8\" y=\"325.91046\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"239.992472\" xlink:href=\"#m9bad646ad8\" y=\"322.45717\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"260.283381\" xlink:href=\"#m9bad646ad8\" y=\"317.762002\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"280.57429\" xlink:href=\"#m9bad646ad8\" y=\"311.4927\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"300.865199\" xlink:href=\"#m9bad646ad8\" y=\"303.317008\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"321.156108\" xlink:href=\"#m9bad646ad8\" y=\"292.951691\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"341.447017\" xlink:href=\"#m9bad646ad8\" y=\"280.320492\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"361.737926\" xlink:href=\"#m9bad646ad8\" y=\"265.603157\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"382.028835\" xlink:href=\"#m9bad646ad8\" y=\"249.099262\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"402.319744\" xlink:href=\"#m9bad646ad8\" y=\"231.865491\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"422.610653\" xlink:href=\"#m9bad646ad8\" y=\"215.203638\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"442.901562\" xlink:href=\"#m9bad646ad8\" y=\"198.797785\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"463.192472\" xlink:href=\"#m9bad646ad8\" y=\"182.789552\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"483.483381\" xlink:href=\"#m9bad646ad8\" y=\"165.484972\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"503.77429\" xlink:href=\"#m9bad646ad8\" y=\"145.740213\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"524.065199\" xlink:href=\"#m9bad646ad8\" y=\"123.435444\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"544.356108\" xlink:href=\"#m9bad646ad8\" y=\"98.227514\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"564.647017\" xlink:href=\"#m9bad646ad8\" y=\"69.756933\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"584.937926\" xlink:href=\"#m9bad646ad8\" y=\"37.587955\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 52.301563 348.9225 \n",
       "L 52.301563 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 610.301563 348.9225 \n",
       "L 610.301563 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 52.301562 348.9225 \n",
       "L 610.301562 348.9225 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 52.301562 22.7625 \n",
       "L 610.301562 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_16\">\n",
       "    <!-- 270 -->\n",
       "    <defs>\n",
       "     <path d=\"M 43.359375 60.15625 \n",
       "L 25 1.5625 \n",
       "L 16.015625 1.5625 \n",
       "L 34.765625 60.9375 \n",
       "L 6.25 60.9375 \n",
       "L 6.25 68.359375 \n",
       "L 43.359375 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-55\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(72.665199 329.097045)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- 336 -->\n",
       "    <defs>\n",
       "     <path d=\"M 44.53125 24.21875 \n",
       "Q 44.53125 13.28125 39.84375 7.03125 \n",
       "Q 35.15625 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.9375 8.59375 \n",
       "Q 5.46875 16.40625 5.46875 33.984375 \n",
       "Q 5.46875 50 11.125 59.5625 \n",
       "Q 16.796875 69.140625 27.34375 69.140625 \n",
       "Q 34.765625 69.140625 39.25 63.671875 \n",
       "Q 43.75 58.203125 43.75 51.5625 \n",
       "L 34.765625 51.5625 \n",
       "Q 34.765625 55.46875 32.609375 58.59375 \n",
       "Q 30.46875 61.71875 26.953125 61.71875 \n",
       "Q 21.09375 61.71875 17.96875 55.65625 \n",
       "Q 14.84375 49.609375 14.453125 37.109375 \n",
       "Q 17.1875 42.1875 20.3125 44.140625 \n",
       "Q 23.4375 46.09375 27.734375 46.09375 \n",
       "Q 35.15625 46.09375 39.84375 40.234375 \n",
       "Q 44.53125 34.375 44.53125 24.21875 \n",
       "z\n",
       "M 35.15625 24.21875 \n",
       "Q 35.15625 31.25 32.8125 35.15625 \n",
       "Q 30.46875 39.0625 26.171875 39.0625 \n",
       "Q 21.09375 39.0625 18.15625 35.15625 \n",
       "Q 15.234375 31.25 15.234375 25.78125 \n",
       "Q 15.234375 17.1875 18.15625 12.5 \n",
       "Q 21.09375 7.8125 26.171875 7.8125 \n",
       "Q 29.6875 7.8125 32.421875 11.328125 \n",
       "Q 35.15625 14.84375 35.15625 24.21875 \n",
       "z\n",
       "\" id=\"SimHei-54\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(92.956108 328.737555)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_18\">\n",
       "    <!-- 429 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(113.247017 328.230999)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_19\">\n",
       "    <!-- 557 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(133.537926 327.533805)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_20\">\n",
       "    <!-- 733 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(153.828835 326.575163)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_21\">\n",
       "    <!-- 976 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(174.119744 325.251583)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_22\">\n",
       "    <!-- 1311 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(194.410653 323.426895)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_23\">\n",
       "    <!-- 1773 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(214.701562 320.91046)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_24\">\n",
       "    <!-- 2407 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(234.992472 317.45717)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_25\">\n",
       "    <!-- 3269 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(255.283381 312.762002)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_26\">\n",
       "    <!-- 4420 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(275.57429 306.4927)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_27\">\n",
       "    <!-- 5921 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(295.865199 298.317008)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_28\">\n",
       "    <!-- 7824 -->\n",
       "    <defs>\n",
       "     <path d=\"M 44.921875 20.703125 \n",
       "Q 44.921875 10.9375 39.453125 5.859375 \n",
       "Q 33.984375 0.78125 24.609375 0.78125 \n",
       "Q 15.234375 0.78125 9.765625 5.859375 \n",
       "Q 4.296875 10.9375 4.296875 20.703125 \n",
       "Q 4.296875 25.78125 7.421875 29.875 \n",
       "Q 10.546875 33.984375 16.015625 35.9375 \n",
       "Q 11.328125 37.890625 8.78125 41.40625 \n",
       "Q 6.25 44.921875 6.25 50.390625 \n",
       "Q 6.25 58.984375 11.71875 64.0625 \n",
       "Q 17.1875 69.140625 24.609375 69.140625 \n",
       "Q 32.03125 69.140625 37.5 64.0625 \n",
       "Q 42.96875 58.984375 42.96875 50.390625 \n",
       "Q 42.96875 44.921875 40.421875 41.40625 \n",
       "Q 37.890625 37.890625 33.203125 35.9375 \n",
       "Q 38.671875 33.984375 41.796875 29.875 \n",
       "Q 44.921875 25.78125 44.921875 20.703125 \n",
       "z\n",
       "M 34.375 50.390625 \n",
       "Q 34.375 56.640625 31.640625 59.375 \n",
       "Q 28.90625 62.109375 24.609375 62.109375 \n",
       "Q 20.3125 62.109375 17.578125 59.375 \n",
       "Q 14.84375 56.640625 14.84375 50.390625 \n",
       "Q 14.84375 44.140625 17.765625 41.59375 \n",
       "Q 20.703125 39.0625 24.609375 39.0625 \n",
       "Q 28.515625 39.0625 31.4375 41.59375 \n",
       "Q 34.375 44.140625 34.375 50.390625 \n",
       "z\n",
       "M 35.9375 20.703125 \n",
       "Q 35.9375 26.171875 33 29.296875 \n",
       "Q 30.078125 32.421875 24.609375 32.421875 \n",
       "Q 19.140625 32.421875 16.203125 29.296875 \n",
       "Q 13.28125 26.171875 13.28125 20.703125 \n",
       "Q 13.28125 14.453125 16.40625 11.125 \n",
       "Q 19.53125 7.8125 24.609375 7.8125 \n",
       "Q 29.6875 7.8125 32.8125 11.125 \n",
       "Q 35.9375 14.453125 35.9375 20.703125 \n",
       "z\n",
       "\" id=\"SimHei-56\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(316.156108 287.951691)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_29\">\n",
       "    <!-- 10143 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(336.447017 275.320492)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_30\">\n",
       "    <!-- 12845 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(356.737926 260.603157)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_31\">\n",
       "    <!-- 15875 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(377.028835 244.099262)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_32\">\n",
       "    <!-- 19039 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(397.319744 226.865491)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_33\">\n",
       "    <!-- 22098 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(417.610653 210.203638)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-56\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_34\">\n",
       "    <!-- 25110 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(437.901562 193.797785)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_35\">\n",
       "    <!-- 28049 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(458.192472 177.789552)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_36\">\n",
       "    <!-- 31226 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(478.483381 160.484972)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_37\">\n",
       "    <!-- 34851 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(498.77429 140.740213)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_38\">\n",
       "    <!-- 38946 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(519.065199 118.435444)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_39\">\n",
       "    <!-- 43574 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(539.356108 93.227514)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_40\">\n",
       "    <!-- 48801 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(559.647017 64.756933)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_41\">\n",
       "    <!-- 54707 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(579.937926 32.587955)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_42\">\n",
       "    <!-- 270 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(72.665199 314.097045)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_43\">\n",
       "    <!-- 375 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(92.956108 313.525128)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_44\">\n",
       "    <!-- 444 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(113.247017 313.149297)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_45\">\n",
       "    <!-- 549 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(133.537926 312.57738)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_46\">\n",
       "    <!-- 729 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(153.828835 311.59695)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_47\">\n",
       "    <!-- 1052 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(174.119744 309.837624)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_48\">\n",
       "    <!-- 1423 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(194.410653 307.81685)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_49\">\n",
       "    <!-- 2714 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(214.701562 300.784993)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_50\">\n",
       "    <!-- 3554 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(234.992472 296.209655)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_51\">\n",
       "    <!-- 4586 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(255.283381 290.588527)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_52\">\n",
       "    <!-- 5806 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(275.57429 283.943394)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_53\">\n",
       "    <!-- 7153 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(295.865199 276.606514)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_54\">\n",
       "    <!-- 9074 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(316.156108 266.143153)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_55\">\n",
       "    <!-- 11177 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(336.447017 254.688469)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-55\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_56\">\n",
       "    <!-- 13522 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(356.737926 241.915653)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_57\">\n",
       "    <!-- 16678 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(377.028835 224.725457)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-56\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_58\">\n",
       "    <!-- 19665 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(397.319744 208.455775)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-53\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_59\">\n",
       "    <!-- 22112 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(417.610653 195.127382)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-50\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_60\">\n",
       "    <!-- 24953 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(437.901562 179.652938)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-51\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_61\">\n",
       "    <!-- 27100 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(458.192472 167.958593)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_62\">\n",
       "    <!-- 29631 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(478.483381 154.172666)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-49\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_63\">\n",
       "    <!-- 疫情状况-湖北 -->\n",
       "    <defs>\n",
       "     <path d=\"M 5.859375 61.71875 \n",
       "Q 9.375 62.5 13.28125 62.890625 \n",
       "Q 14.84375 53.125 15.234375 42.1875 \n",
       "Q 11.328125 41.796875 7.8125 41.40625 \n",
       "Q 7.421875 52.34375 5.859375 61.71875 \n",
       "z\n",
       "M 50 79.6875 \n",
       "Q 55.078125 80.859375 58.59375 82.03125 \n",
       "Q 60.546875 76.171875 61.71875 70.703125 \n",
       "L 78.90625 70.703125 \n",
       "Q 85.546875 70.703125 93.75 71.09375 \n",
       "L 93.75 64.453125 \n",
       "Q 85.9375 64.84375 78.90625 64.84375 \n",
       "L 28.125 64.84375 \n",
       "Q 27.734375 58.203125 27.921875 48.828125 \n",
       "Q 28.125 39.453125 27.34375 29.09375 \n",
       "Q 26.5625 18.75 23.828125 8.59375 \n",
       "Q 21.09375 -1.5625 15.234375 -9.765625 \n",
       "Q 11.71875 -7.421875 7.03125 -5.46875 \n",
       "Q 10.546875 -1.171875 13.28125 3.125 \n",
       "Q 16.015625 7.421875 17.96875 14.0625 \n",
       "Q 19.921875 20.703125 20.703125 30.078125 \n",
       "Q 11.71875 25 7.03125 21.09375 \n",
       "Q 5.859375 25.78125 3.90625 30.078125 \n",
       "Q 8.59375 32.03125 12.5 33.78125 \n",
       "Q 16.40625 35.546875 21.09375 37.5 \n",
       "L 21.09375 53.515625 \n",
       "Q 21.09375 65.625 20.703125 70.703125 \n",
       "L 52.734375 70.703125 \n",
       "Q 51.953125 75 50 79.6875 \n",
       "z\n",
       "M 44.140625 56.25 \n",
       "L 76.953125 56.25 \n",
       "Q 76.5625 53.515625 76.5625 48.046875 \n",
       "L 76.5625 43.359375 \n",
       "Q 76.5625 39.453125 80.078125 39.640625 \n",
       "Q 83.59375 39.84375 89.453125 40.625 \n",
       "Q 87.890625 36.328125 88.671875 33.59375 \n",
       "Q 76.5625 33.203125 73.046875 34.5625 \n",
       "Q 69.53125 35.9375 69.53125 40.234375 \n",
       "L 69.53125 50.390625 \n",
       "L 51.953125 50.390625 \n",
       "Q 52.734375 41.015625 50 36.71875 \n",
       "Q 47.265625 32.421875 40.625 28.90625 \n",
       "Q 38.671875 32.8125 33.59375 35.546875 \n",
       "Q 44.53125 37.890625 44.53125 44.328125 \n",
       "Q 44.53125 50.78125 44.140625 56.25 \n",
       "z\n",
       "M 35.15625 28.125 \n",
       "Q 41.796875 27.734375 49.609375 27.734375 \n",
       "L 85.15625 27.734375 \n",
       "Q 82.03125 22.65625 78.125 16.40625 \n",
       "Q 74.21875 10.15625 66.796875 3.125 \n",
       "Q 73.046875 0.390625 78.703125 -0.78125 \n",
       "Q 84.375 -1.953125 94.140625 -1.953125 \n",
       "Q 90.234375 -5.859375 90.234375 -10.546875 \n",
       "Q 81.25 -9.375 73.828125 -7.03125 \n",
       "Q 66.40625 -4.6875 60.546875 -0.78125 \n",
       "Q 47.265625 -7.8125 32.03125 -10.15625 \n",
       "Q 31.25 -7.03125 26.5625 -2.34375 \n",
       "Q 35.9375 -1.953125 41.59375 -0.78125 \n",
       "Q 47.265625 0.390625 54.6875 3.515625 \n",
       "Q 48.828125 9.375 42.578125 22.265625 \n",
       "Q 45.703125 22.265625 49.609375 22.65625 \n",
       "Q 53.125 15.625 55.265625 12.890625 \n",
       "Q 57.421875 10.15625 60.546875 7.421875 \n",
       "Q 67.96875 13.28125 73.4375 21.875 \n",
       "L 49.609375 21.875 \n",
       "Q 42.1875 21.875 35.15625 21.484375 \n",
       "z\n",
       "\" id=\"SimHei-30123\"/>\n",
       "     <path d=\"M 37.5 50 \n",
       "Q 33.984375 49.609375 31.25 48.046875 \n",
       "Q 30.078125 53.125 28.125 61.71875 \n",
       "Q 30.859375 62.109375 34.375 63.28125 \n",
       "Q 36.328125 54.6875 37.5 50 \n",
       "z\n",
       "M 18.75 81.25 \n",
       "L 26.5625 81.25 \n",
       "Q 26.171875 74.609375 26.171875 68.359375 \n",
       "L 26.171875 6.25 \n",
       "Q 26.171875 -1.953125 26.5625 -9.765625 \n",
       "L 18.75 -9.765625 \n",
       "Q 19.140625 -1.953125 19.140625 6.25 \n",
       "L 19.140625 67.1875 \n",
       "Q 19.140625 75 18.75 81.25 \n",
       "z\n",
       "M 55.078125 44.140625 \n",
       "Q 44.53125 44.140625 39.84375 43.75 \n",
       "L 39.84375 50 \n",
       "Q 46.484375 49.609375 54.6875 49.609375 \n",
       "L 62.109375 49.609375 \n",
       "L 62.109375 56.25 \n",
       "L 55.078125 56.25 \n",
       "Q 48.046875 56.25 42.96875 55.859375 \n",
       "L 42.96875 62.109375 \n",
       "Q 48.046875 61.71875 55.078125 61.71875 \n",
       "L 62.109375 61.71875 \n",
       "L 62.109375 67.578125 \n",
       "L 54.296875 67.578125 \n",
       "Q 47.65625 67.578125 41.40625 67.1875 \n",
       "L 41.40625 73.4375 \n",
       "Q 48.046875 73.046875 54.296875 73.046875 \n",
       "L 62.109375 73.046875 \n",
       "Q 62.109375 77.34375 61.71875 81.25 \n",
       "L 69.53125 81.25 \n",
       "Q 69.140625 77.34375 69.140625 73.046875 \n",
       "L 79.6875 73.046875 \n",
       "Q 86.328125 73.046875 92.1875 73.4375 \n",
       "L 92.1875 67.1875 \n",
       "Q 86.328125 67.578125 79.6875 67.578125 \n",
       "L 69.140625 67.578125 \n",
       "L 69.140625 61.71875 \n",
       "L 76.5625 61.71875 \n",
       "Q 82.421875 61.71875 89.453125 62.109375 \n",
       "L 89.453125 55.859375 \n",
       "Q 82.03125 56.25 76.5625 56.25 \n",
       "L 69.140625 56.25 \n",
       "L 69.140625 49.609375 \n",
       "L 80.46875 49.609375 \n",
       "Q 89.84375 49.609375 95.3125 50 \n",
       "L 95.3125 43.75 \n",
       "Q 89.84375 44.140625 80.078125 44.140625 \n",
       "z\n",
       "M 44.53125 -10.15625 \n",
       "Q 44.921875 -1.171875 44.921875 5.46875 \n",
       "L 44.921875 22.65625 \n",
       "Q 44.921875 31.640625 44.53125 39.0625 \n",
       "L 86.71875 39.0625 \n",
       "Q 86.328125 32.421875 86.328125 26.5625 \n",
       "L 86.328125 -2.734375 \n",
       "Q 86.328125 -7.03125 83.203125 -8.203125 \n",
       "Q 80.078125 -9.375 75.390625 -10.15625 \n",
       "Q 75 -6.640625 72.65625 -2.734375 \n",
       "Q 78.125 -2.734375 78.90625 -1.5625 \n",
       "Q 79.6875 -0.390625 79.6875 7.421875 \n",
       "L 51.953125 7.421875 \n",
       "L 51.953125 -10.15625 \n",
       "z\n",
       "M 51.953125 33.59375 \n",
       "L 51.953125 26.171875 \n",
       "L 79.296875 26.171875 \n",
       "L 79.296875 33.59375 \n",
       "z\n",
       "M 51.953125 20.703125 \n",
       "L 51.953125 12.890625 \n",
       "L 79.296875 12.890625 \n",
       "L 79.296875 20.703125 \n",
       "z\n",
       "M 9.375 61.71875 \n",
       "Q 12.890625 60.9375 16.40625 60.546875 \n",
       "Q 15.625 57.03125 12.109375 35.15625 \n",
       "Q 8.59375 36.328125 5.078125 36.71875 \n",
       "Q 7.03125 42.578125 9.375 61.71875 \n",
       "z\n",
       "\" id=\"SimHei-24773\"/>\n",
       "     <path d=\"M 43.75 -8.59375 \n",
       "Q 40.234375 -5.078125 35.9375 -3.125 \n",
       "Q 42.578125 1.5625 47.265625 8.390625 \n",
       "Q 51.953125 15.234375 54.6875 21.671875 \n",
       "Q 57.421875 28.125 58.59375 34.171875 \n",
       "Q 59.765625 40.234375 60.15625 44.921875 \n",
       "L 51.171875 44.921875 \n",
       "Q 45.3125 44.921875 39.84375 44.53125 \n",
       "L 39.84375 51.5625 \n",
       "Q 45.3125 51.171875 50.78125 51.171875 \n",
       "L 60.9375 51.171875 \n",
       "Q 60.9375 61.71875 60.734375 67.765625 \n",
       "Q 60.546875 73.828125 60.15625 78.515625 \n",
       "Q 64.84375 78.515625 69.53125 78.515625 \n",
       "Q 68.359375 73.4375 68.15625 68.359375 \n",
       "Q 67.96875 63.28125 67.96875 51.171875 \n",
       "L 83.984375 51.171875 \n",
       "Q 87.890625 51.171875 93.359375 51.5625 \n",
       "L 93.359375 44.53125 \n",
       "Q 87.890625 44.921875 83.984375 44.921875 \n",
       "L 68.359375 44.921875 \n",
       "Q 70.3125 32.8125 73.4375 25 \n",
       "Q 76.5625 17.1875 80.46875 12.6875 \n",
       "Q 84.375 8.203125 88.46875 5.65625 \n",
       "Q 92.578125 3.125 96.09375 1.171875 \n",
       "Q 90.625 -1.171875 87.890625 -7.03125 \n",
       "Q 82.03125 -1.953125 78.3125 2.734375 \n",
       "Q 74.609375 7.421875 72.0625 12.109375 \n",
       "Q 69.53125 16.796875 67.765625 21.484375 \n",
       "Q 66.015625 26.171875 64.84375 31.25 \n",
       "Q 62.890625 22.265625 60.15625 16.015625 \n",
       "Q 57.421875 9.765625 54.296875 4.875 \n",
       "Q 51.171875 0 43.75 -8.59375 \n",
       "z\n",
       "M 90.234375 62.5 \n",
       "Q 86.71875 60.15625 83.984375 57.8125 \n",
       "Q 81.640625 61.328125 79.484375 64.25 \n",
       "Q 77.34375 67.1875 74.609375 70.3125 \n",
       "Q 77.734375 72.65625 80.46875 74.609375 \n",
       "Q 83.59375 71.484375 85.734375 68.546875 \n",
       "Q 87.890625 65.625 90.234375 62.5 \n",
       "z\n",
       "M 7.03125 60.15625 \n",
       "Q 9.765625 62.109375 13.28125 64.0625 \n",
       "Q 15.625 60.546875 18.359375 56.640625 \n",
       "Q 21.09375 52.734375 23.4375 48.828125 \n",
       "Q 19.53125 46.484375 17.1875 44.140625 \n",
       "Q 14.84375 48.828125 12.6875 52.140625 \n",
       "Q 10.546875 55.46875 7.03125 60.15625 \n",
       "z\n",
       "M 12.109375 12.109375 \n",
       "Q 7.8125 16.015625 5.078125 18.359375 \n",
       "Q 9.765625 21.875 14.84375 26.75 \n",
       "Q 19.921875 31.640625 26.953125 40.234375 \n",
       "L 26.953125 30.078125 \n",
       "Q 24.21875 26.953125 19.140625 21.09375 \n",
       "Q 14.0625 15.234375 12.109375 12.109375 \n",
       "z\n",
       "M 26.5625 78.515625 \n",
       "L 34.765625 78.515625 \n",
       "Q 34.375 72.65625 34.375 64.453125 \n",
       "L 34.375 12.5 \n",
       "Q 34.375 1.953125 34.765625 -8.203125 \n",
       "L 26.5625 -8.203125 \n",
       "Q 26.953125 2.34375 26.953125 12.5 \n",
       "L 26.953125 64.453125 \n",
       "Q 26.953125 72.65625 26.5625 78.515625 \n",
       "z\n",
       "\" id=\"SimHei-29366\"/>\n",
       "     <path d=\"M 7.421875 66.015625 \n",
       "Q 11.328125 69.140625 13.671875 72.65625 \n",
       "Q 15.625 69.921875 20.109375 65.625 \n",
       "Q 24.609375 61.328125 28.90625 56.25 \n",
       "Q 25 53.515625 21.875 50.390625 \n",
       "Q 18.359375 55.078125 7.421875 66.015625 \n",
       "z\n",
       "M 22.265625 41.40625 \n",
       "Q 25.390625 36.71875 28.125 34.765625 \n",
       "Q 25 26.953125 20.703125 17.1875 \n",
       "Q 16.40625 7.421875 14.0625 1.5625 \n",
       "Q 10.15625 6.25 7.03125 8.59375 \n",
       "Q 12.5 17.1875 15.625 23.828125 \n",
       "Q 18.75 30.46875 22.265625 41.40625 \n",
       "z\n",
       "M 36.71875 73.4375 \n",
       "L 84.375 73.4375 \n",
       "Q 83.59375 67.578125 83.59375 55.265625 \n",
       "Q 83.59375 42.96875 84.375 35.546875 \n",
       "L 70.3125 35.546875 \n",
       "L 70.3125 7.421875 \n",
       "Q 70.3125 2.34375 73.046875 1.953125 \n",
       "Q 75.78125 1.5625 79.296875 1.75 \n",
       "Q 82.8125 1.953125 83.59375 4.484375 \n",
       "Q 84.375 7.03125 84.765625 15.234375 \n",
       "Q 89.453125 11.328125 94.140625 10.546875 \n",
       "Q 91.40625 -1.953125 88.078125 -3.515625 \n",
       "Q 84.765625 -5.078125 77.921875 -5.265625 \n",
       "Q 71.09375 -5.46875 67.1875 -4.484375 \n",
       "Q 63.28125 -3.515625 63.28125 4.296875 \n",
       "L 63.28125 35.546875 \n",
       "L 53.90625 35.546875 \n",
       "Q 54.296875 1.5625 28.90625 -10.15625 \n",
       "Q 26.953125 -5.46875 21.875 -2.34375 \n",
       "Q 47.265625 3.90625 46.484375 35.546875 \n",
       "L 36.71875 35.546875 \n",
       "Q 37.109375 42.96875 37.109375 55.46875 \n",
       "Q 37.109375 67.96875 36.71875 73.4375 \n",
       "z\n",
       "M 44.921875 67.1875 \n",
       "L 44.921875 41.796875 \n",
       "L 75.78125 41.796875 \n",
       "L 75.78125 67.1875 \n",
       "z\n",
       "\" id=\"SimHei-20917\"/>\n",
       "     <path d=\"M 10.15625 71.484375 \n",
       "Q 12.5 74.609375 14.453125 77.34375 \n",
       "Q 17.96875 74.609375 21.484375 72.0625 \n",
       "Q 25 69.53125 28.90625 66.796875 \n",
       "Q 25.78125 63.671875 23.828125 60.9375 \n",
       "Q 19.921875 64.453125 16.984375 66.796875 \n",
       "Q 14.0625 69.140625 10.15625 71.484375 \n",
       "z\n",
       "M 5.859375 48.046875 \n",
       "Q 8.203125 50.78125 9.765625 53.90625 \n",
       "Q 14.0625 51.171875 17.1875 49.21875 \n",
       "Q 20.3125 47.265625 26.171875 43.359375 \n",
       "Q 23.4375 40.234375 21.875 37.109375 \n",
       "Q 17.1875 40.625 14.0625 42.765625 \n",
       "Q 10.9375 44.921875 5.859375 48.046875 \n",
       "z\n",
       "M 20.3125 28.90625 \n",
       "Q 23.046875 25.390625 26.171875 23.828125 \n",
       "Q 22.65625 16.40625 20.5 11.328125 \n",
       "Q 18.359375 6.25 16.40625 1.953125 \n",
       "Q 14.453125 -2.34375 12.890625 -7.03125 \n",
       "Q 8.59375 -4.296875 5.078125 -3.125 \n",
       "Q 9.375 3.125 13.671875 12.5 \n",
       "Q 17.96875 21.875 20.3125 28.90625 \n",
       "z\n",
       "M 37.5 32.421875 \n",
       "L 37.5 17.578125 \n",
       "L 49.21875 17.578125 \n",
       "L 49.21875 32.421875 \n",
       "z\n",
       "M 70.703125 69.140625 \n",
       "L 70.703125 51.953125 \n",
       "L 84.375 51.953125 \n",
       "L 84.375 69.140625 \n",
       "z\n",
       "M 70.703125 46.09375 \n",
       "Q 70.3125 33.984375 70.3125 29.6875 \n",
       "L 84.375 29.6875 \n",
       "L 84.375 46.09375 \n",
       "z\n",
       "M 55.859375 38.28125 \n",
       "Q 55.46875 32.421875 55.46875 24.015625 \n",
       "Q 55.46875 15.625 55.859375 5.859375 \n",
       "L 49.21875 5.859375 \n",
       "L 49.21875 11.71875 \n",
       "L 37.5 11.71875 \n",
       "L 37.5 1.953125 \n",
       "L 30.859375 1.953125 \n",
       "Q 31.25 7.03125 31.25 19.53125 \n",
       "Q 31.25 32.03125 30.859375 38.28125 \n",
       "L 40.625 38.28125 \n",
       "L 40.625 53.515625 \n",
       "Q 32.03125 53.515625 27.734375 53.125 \n",
       "L 27.734375 59.765625 \n",
       "Q 32.03125 59.375 40.625 59.375 \n",
       "L 40.625 68.75 \n",
       "Q 40.625 73.4375 40.234375 80.078125 \n",
       "L 47.265625 80.078125 \n",
       "Q 46.875 74.21875 46.875 68.75 \n",
       "L 46.875 59.375 \n",
       "Q 54.6875 59.375 59.375 59.765625 \n",
       "L 59.375 53.125 \n",
       "Q 54.296875 53.515625 46.875 53.515625 \n",
       "L 46.875 38.28125 \n",
       "z\n",
       "M 64.0625 75 \n",
       "L 91.015625 75 \n",
       "Q 90.625 66.796875 90.625 61.328125 \n",
       "L 90.625 2.734375 \n",
       "Q 89.84375 -3.90625 86.328125 -5.65625 \n",
       "Q 82.8125 -7.421875 76.5625 -8.203125 \n",
       "Q 75.390625 -4.296875 73.4375 -0.390625 \n",
       "Q 79.6875 -0.78125 81.828125 -0.1875 \n",
       "Q 83.984375 0.390625 84.375 5.078125 \n",
       "L 84.375 23.828125 \n",
       "L 69.921875 23.828125 \n",
       "Q 69.140625 17.1875 66.984375 10.734375 \n",
       "Q 64.84375 4.296875 61.125 -0.96875 \n",
       "Q 57.421875 -6.25 53.90625 -10.15625 \n",
       "Q 51.171875 -7.8125 46.09375 -5.859375 \n",
       "Q 52.734375 -1.5625 56.640625 4.484375 \n",
       "Q 60.546875 10.546875 62.109375 17.96875 \n",
       "Q 63.671875 25.390625 64.0625 35.34375 \n",
       "Q 64.453125 45.3125 64.453125 56.4375 \n",
       "Q 64.453125 67.578125 64.0625 75 \n",
       "z\n",
       "\" id=\"SimHei-28246\"/>\n",
       "     <path d=\"M 9.765625 50.78125 \n",
       "Q 16.015625 50.390625 20.703125 50.390625 \n",
       "L 33.984375 50.390625 \n",
       "L 33.984375 69.140625 \n",
       "Q 33.984375 72.65625 33.59375 77.734375 \n",
       "L 42.1875 77.734375 \n",
       "Q 41.40625 72.65625 41.40625 69.140625 \n",
       "L 41.40625 4.6875 \n",
       "Q 41.40625 0.390625 41.796875 -5.859375 \n",
       "L 33.59375 -5.859375 \n",
       "Q 33.984375 0.390625 33.984375 7.421875 \n",
       "Q 26.171875 5.46875 19.71875 3.3125 \n",
       "Q 13.28125 1.171875 10.15625 -0.78125 \n",
       "Q 8.203125 3.90625 5.46875 8.984375 \n",
       "Q 10.546875 9.375 19.71875 11.328125 \n",
       "Q 28.90625 13.28125 33.984375 14.84375 \n",
       "L 33.984375 43.359375 \n",
       "L 20.703125 43.359375 \n",
       "Q 16.015625 43.359375 9.765625 42.96875 \n",
       "z\n",
       "M 55.46875 77.734375 \n",
       "L 63.671875 77.734375 \n",
       "Q 63.28125 73.4375 63.28125 69.921875 \n",
       "L 63.28125 44.140625 \n",
       "Q 73.828125 48.4375 85.9375 58.59375 \n",
       "Q 88.671875 54.296875 92.96875 50 \n",
       "Q 88.28125 49.21875 79.09375 44.53125 \n",
       "Q 69.921875 39.84375 63.28125 37.109375 \n",
       "L 63.28125 7.8125 \n",
       "Q 63.28125 1.953125 69.140625 1.953125 \n",
       "L 78.515625 1.953125 \n",
       "Q 83.203125 1.953125 84.375 3.90625 \n",
       "Q 85.546875 5.859375 86.71875 13.28125 \n",
       "Q 90.234375 9.375 95.703125 8.59375 \n",
       "Q 92.578125 0.390625 90.234375 -2.34375 \n",
       "Q 87.890625 -5.078125 83.203125 -5.078125 \n",
       "L 65.234375 -5.078125 \n",
       "Q 55.859375 -5.078125 55.859375 4.6875 \n",
       "L 55.859375 69.921875 \n",
       "Q 55.859375 72.65625 55.46875 77.734375 \n",
       "z\n",
       "\" id=\"SimHei-21271\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(292.301562 16.7625)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#SimHei-30123\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-24773\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-29366\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-20917\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-45\"/>\n",
       "     <use x=\"450\" xlink:href=\"#SimHei-28246\"/>\n",
       "     <use x=\"550\" xlink:href=\"#SimHei-21271\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 59.301563 59.35625 \n",
       "L 181.301562 59.35625 \n",
       "Q 183.301562 59.35625 183.301562 57.35625 \n",
       "L 183.301562 29.7625 \n",
       "Q 183.301562 27.7625 181.301562 27.7625 \n",
       "L 59.301563 27.7625 \n",
       "Q 57.301563 27.7625 57.301563 29.7625 \n",
       "L 57.301563 57.35625 \n",
       "Q 57.301563 59.35625 59.301563 59.35625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\">\n",
       "     <path d=\"M 61.301563 36.270312 \n",
       "L 81.301563 36.270312 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <g>\n",
       "      <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"71.301563\" xlink:href=\"#m6741c9f375\" y=\"36.270312\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_64\">\n",
       "     <!-- 累计确诊人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 16.015625 77.734375 \n",
       "L 86.71875 77.734375 \n",
       "Q 86.328125 71.875 86.328125 62.109375 \n",
       "Q 86.328125 52.34375 86.71875 46.09375 \n",
       "L 73.046875 46.09375 \n",
       "Q 76.171875 43.359375 80.46875 40.234375 \n",
       "Q 75.390625 39.0625 67.1875 35.34375 \n",
       "Q 58.984375 31.640625 52.34375 28.703125 \n",
       "Q 45.703125 25.78125 38.671875 22.65625 \n",
       "Q 60.546875 23.828125 72.65625 24.21875 \n",
       "Q 69.140625 26.5625 64.84375 28.515625 \n",
       "Q 67.96875 30.859375 70.703125 33.203125 \n",
       "Q 80.078125 27.734375 91.796875 20.703125 \n",
       "Q 89.0625 17.96875 85.9375 14.84375 \n",
       "Q 82.8125 17.578125 78.90625 19.921875 \n",
       "Q 66.40625 19.140625 55.46875 18.359375 \n",
       "L 55.46875 0.78125 \n",
       "Q 55.46875 -4.6875 51.359375 -6.25 \n",
       "Q 47.265625 -7.8125 41.015625 -8.984375 \n",
       "Q 40.234375 -4.6875 38.28125 0 \n",
       "Q 45.3125 0 46.875 0.578125 \n",
       "Q 48.4375 1.171875 48.4375 4.296875 \n",
       "L 48.4375 17.96875 \n",
       "Q 37.890625 17.1875 32.21875 16.59375 \n",
       "Q 26.5625 16.015625 15.625 13.671875 \n",
       "Q 14.453125 17.578125 12.890625 21.875 \n",
       "Q 21.484375 22.65625 27.921875 24.609375 \n",
       "Q 34.375 26.5625 49.609375 33.984375 \n",
       "Q 45.3125 33.203125 37.890625 32.609375 \n",
       "Q 30.46875 32.03125 21.484375 29.6875 \n",
       "Q 20.703125 33.984375 18.75 37.109375 \n",
       "Q 23.4375 37.5 29.484375 40.03125 \n",
       "Q 35.546875 42.578125 39.84375 46.09375 \n",
       "L 16.015625 46.09375 \n",
       "Q 16.40625 52.734375 16.40625 62.296875 \n",
       "Q 16.40625 71.875 16.015625 77.734375 \n",
       "z\n",
       "M 23.4375 72.65625 \n",
       "L 23.4375 64.0625 \n",
       "L 47.265625 64.0625 \n",
       "L 47.265625 72.65625 \n",
       "z\n",
       "M 23.4375 58.984375 \n",
       "L 23.4375 51.171875 \n",
       "L 47.265625 51.171875 \n",
       "L 47.265625 58.984375 \n",
       "z\n",
       "M 54.296875 72.65625 \n",
       "L 54.296875 64.0625 \n",
       "L 79.296875 64.0625 \n",
       "L 79.296875 72.65625 \n",
       "z\n",
       "M 54.296875 58.984375 \n",
       "L 54.296875 51.171875 \n",
       "L 79.296875 51.171875 \n",
       "L 79.296875 58.984375 \n",
       "z\n",
       "M 37.890625 37.890625 \n",
       "Q 48.828125 38.28125 58.984375 38.671875 \n",
       "Q 66.40625 42.1875 71.484375 46.09375 \n",
       "L 51.5625 46.09375 \n",
       "Q 46.875 42.96875 37.890625 37.890625 \n",
       "z\n",
       "M 32.421875 13.671875 \n",
       "Q 34.765625 10.9375 39.453125 7.8125 \n",
       "Q 35.15625 6.25 29.484375 2.53125 \n",
       "Q 23.828125 -1.171875 16.796875 -5.859375 \n",
       "Q 13.671875 -2.734375 9.765625 -0.390625 \n",
       "Q 15.625 1.953125 21.484375 5.65625 \n",
       "Q 27.34375 9.375 32.421875 13.671875 \n",
       "z\n",
       "M 62.890625 8.203125 \n",
       "Q 66.015625 11.328125 67.96875 14.0625 \n",
       "Q 73.046875 11.71875 78.703125 9.171875 \n",
       "Q 84.375 6.640625 91.796875 3.125 \n",
       "Q 89.0625 -0.390625 87.109375 -3.90625 \n",
       "Q 80.46875 0.390625 74.609375 3.125 \n",
       "Q 68.75 5.859375 62.890625 8.203125 \n",
       "z\n",
       "\" id=\"SimHei-32047\"/>\n",
       "      <path d=\"M 15.234375 72.265625 \n",
       "Q 17.96875 74.21875 22.265625 76.5625 \n",
       "Q 23.828125 73.828125 32.421875 61.328125 \n",
       "Q 28.90625 59.375 25 57.03125 \n",
       "Q 23.046875 60.546875 15.234375 72.265625 \n",
       "z\n",
       "M 5.46875 47.65625 \n",
       "Q 11.328125 47.265625 13.28125 47.265625 \n",
       "L 27.34375 47.265625 \n",
       "Q 26.953125 40.234375 26.953125 32.421875 \n",
       "L 26.953125 7.8125 \n",
       "Q 32.8125 14.453125 37.5 19.921875 \n",
       "Q 38.671875 16.015625 41.40625 13.28125 \n",
       "Q 37.890625 8.984375 32.609375 3.515625 \n",
       "Q 27.34375 -1.953125 23.4375 -7.8125 \n",
       "Q 19.53125 -4.296875 16.015625 -2.34375 \n",
       "Q 19.53125 2.34375 19.53125 8.203125 \n",
       "L 19.53125 40.625 \n",
       "Q 10.15625 40.625 5.46875 39.84375 \n",
       "z\n",
       "M 37.109375 47.65625 \n",
       "Q 42.96875 47.265625 48.828125 47.265625 \n",
       "L 63.28125 47.265625 \n",
       "L 63.28125 67.96875 \n",
       "Q 63.28125 72.65625 62.890625 76.953125 \n",
       "L 71.09375 76.953125 \n",
       "Q 70.703125 71.875 70.703125 67.96875 \n",
       "L 70.703125 47.265625 \n",
       "L 85.546875 47.265625 \n",
       "Q 89.0625 47.265625 94.53125 47.65625 \n",
       "L 94.53125 40.234375 \n",
       "Q 88.671875 40.625 85.9375 40.625 \n",
       "L 70.703125 40.625 \n",
       "L 70.703125 3.125 \n",
       "Q 70.703125 -3.125 71.09375 -9.765625 \n",
       "L 62.890625 -9.765625 \n",
       "Q 63.28125 -3.125 63.28125 2.734375 \n",
       "L 63.28125 40.625 \n",
       "L 49.21875 40.625 \n",
       "Q 42.96875 40.625 37.109375 40.234375 \n",
       "z\n",
       "\" id=\"SimHei-35745\"/>\n",
       "      <path d=\"M 21.484375 39.84375 \n",
       "L 21.484375 14.84375 \n",
       "L 32.03125 14.84375 \n",
       "L 32.03125 39.84375 \n",
       "z\n",
       "M 10.15625 25 \n",
       "Q 7.8125 28.125 3.515625 30.46875 \n",
       "Q 8.984375 35.546875 13.671875 43.9375 \n",
       "Q 18.359375 52.34375 20.703125 65.234375 \n",
       "Q 13.28125 65.234375 8.59375 64.84375 \n",
       "L 8.59375 71.09375 \n",
       "Q 14.0625 70.703125 19.140625 70.703125 \n",
       "L 29.296875 70.703125 \n",
       "Q 35.9375 70.703125 40.625 71.09375 \n",
       "L 40.625 64.84375 \n",
       "Q 35.9375 65.234375 27.734375 65.234375 \n",
       "Q 25.390625 54.6875 22.265625 45.3125 \n",
       "L 38.671875 45.3125 \n",
       "Q 38.28125 38.671875 38.28125 32.8125 \n",
       "L 38.28125 16.40625 \n",
       "Q 38.28125 10.15625 38.671875 1.953125 \n",
       "L 32.03125 1.953125 \n",
       "L 32.03125 9.375 \n",
       "L 21.484375 9.375 \n",
       "L 21.484375 -4.6875 \n",
       "L 14.84375 -4.6875 \n",
       "Q 15.234375 3.515625 15.234375 9.375 \n",
       "L 15.234375 33.203125 \n",
       "Q 12.890625 29.296875 10.15625 25 \n",
       "z\n",
       "M 70.3125 30.859375 \n",
       "L 70.3125 20.3125 \n",
       "L 83.203125 20.3125 \n",
       "L 83.203125 30.859375 \n",
       "z\n",
       "M 78.515625 -10.546875 \n",
       "Q 78.125 -6.640625 75.390625 -3.125 \n",
       "Q 80.078125 -3.125 81.640625 -2.53125 \n",
       "Q 83.203125 -1.953125 83.203125 1.953125 \n",
       "L 83.203125 14.84375 \n",
       "L 70.3125 14.84375 \n",
       "L 70.3125 -6.25 \n",
       "L 64.0625 -6.25 \n",
       "L 64.0625 14.84375 \n",
       "L 53.515625 14.84375 \n",
       "Q 53.125 9.765625 50.78125 3.703125 \n",
       "Q 48.4375 -2.34375 42.578125 -9.375 \n",
       "Q 39.84375 -5.46875 35.546875 -4.6875 \n",
       "Q 40.234375 -0.390625 42.765625 4.484375 \n",
       "Q 45.3125 9.375 46.09375 15.625 \n",
       "Q 46.875 21.875 47.0625 33.78125 \n",
       "Q 47.265625 45.703125 46.875 53.125 \n",
       "L 64.84375 53.125 \n",
       "Q 68.359375 59.375 70.703125 65.234375 \n",
       "L 55.46875 65.234375 \n",
       "Q 52.34375 60.15625 44.921875 50.390625 \n",
       "Q 41.796875 53.125 38.28125 54.296875 \n",
       "Q 45.703125 61.71875 49.21875 68.15625 \n",
       "Q 52.734375 74.609375 55.46875 82.03125 \n",
       "Q 59.765625 80.078125 64.0625 78.90625 \n",
       "Q 62.109375 77.734375 58.59375 70.703125 \n",
       "L 81.25 70.703125 \n",
       "Q 74.609375 58.59375 72.65625 53.125 \n",
       "L 89.84375 53.125 \n",
       "Q 89.453125 46.09375 89.453125 37.890625 \n",
       "L 89.453125 -0.78125 \n",
       "Q 89.84375 -5.46875 87.5 -7.21875 \n",
       "Q 85.15625 -8.984375 78.515625 -10.546875 \n",
       "z\n",
       "M 53.515625 47.65625 \n",
       "L 53.515625 36.328125 \n",
       "L 64.0625 36.328125 \n",
       "L 64.0625 47.65625 \n",
       "z\n",
       "M 53.515625 30.859375 \n",
       "L 53.515625 20.3125 \n",
       "L 64.0625 20.3125 \n",
       "L 64.0625 30.859375 \n",
       "z\n",
       "M 70.3125 47.65625 \n",
       "L 70.3125 36.328125 \n",
       "L 83.203125 36.328125 \n",
       "L 83.203125 47.65625 \n",
       "z\n",
       "\" id=\"SimHei-30830\"/>\n",
       "      <path d=\"M 12.5 71.484375 \n",
       "Q 15.234375 73.828125 18.75 76.171875 \n",
       "Q 22.265625 72.265625 29.6875 62.890625 \n",
       "Q 26.171875 60.546875 23.4375 57.8125 \n",
       "Q 16.796875 66.796875 12.5 71.484375 \n",
       "z\n",
       "M 26.171875 12.5 \n",
       "Q 30.078125 17.1875 32.421875 20.3125 \n",
       "Q 34.765625 16.796875 37.5 12.890625 \n",
       "Q 33.203125 8.203125 29.296875 3.90625 \n",
       "Q 25.390625 -0.390625 21.09375 -6.640625 \n",
       "Q 17.578125 -3.90625 14.0625 -1.171875 \n",
       "Q 16.015625 1.171875 17.1875 3.125 \n",
       "Q 18.359375 5.078125 18.359375 8.203125 \n",
       "L 18.359375 42.1875 \n",
       "L 15.234375 42.1875 \n",
       "Q 10.15625 42.1875 4.6875 41.796875 \n",
       "L 4.6875 48.828125 \n",
       "Q 9.765625 48.4375 15.234375 48.4375 \n",
       "L 26.5625 48.4375 \n",
       "Q 26.171875 41.40625 26.171875 33.59375 \n",
       "z\n",
       "M 37.5 38.28125 \n",
       "Q 35.15625 40.234375 29.296875 43.75 \n",
       "Q 34.765625 46.875 39.25 50.78125 \n",
       "Q 43.75 54.6875 47.0625 59.375 \n",
       "Q 50.390625 64.0625 52.734375 69.328125 \n",
       "Q 55.078125 74.609375 56.640625 80.46875 \n",
       "Q 61.328125 78.90625 67.1875 77.34375 \n",
       "L 66.015625 73.828125 \n",
       "Q 69.53125 63.28125 76.953125 58.390625 \n",
       "Q 84.375 53.515625 93.75 50.390625 \n",
       "Q 91.796875 48.046875 87.890625 41.40625 \n",
       "Q 76.171875 47.265625 69.71875 55.265625 \n",
       "Q 63.28125 63.28125 60.9375 69.140625 \n",
       "Q 57.421875 62.5 52.921875 55.265625 \n",
       "Q 48.4375 48.046875 37.5 38.28125 \n",
       "z\n",
       "M 62.5 52.34375 \n",
       "Q 65.234375 49.609375 69.140625 46.484375 \n",
       "Q 63.28125 40.234375 57.21875 34.765625 \n",
       "Q 51.171875 29.296875 44.53125 24.609375 \n",
       "Q 41.40625 28.125 38.671875 31.25 \n",
       "Q 44.53125 33.984375 50.96875 39.25 \n",
       "Q 57.421875 44.53125 62.5 52.34375 \n",
       "z\n",
       "M 48.046875 7.421875 \n",
       "Q 45.703125 10.9375 42.578125 14.453125 \n",
       "Q 52.734375 17.96875 61.328125 25.578125 \n",
       "Q 69.921875 33.203125 73.4375 40.625 \n",
       "Q 77.34375 37.109375 80.859375 33.984375 \n",
       "Q 76.5625 29.6875 71.484375 24.015625 \n",
       "Q 66.40625 18.359375 59.5625 14.0625 \n",
       "Q 52.734375 9.765625 48.046875 7.421875 \n",
       "z\n",
       "M 43.359375 -10.9375 \n",
       "Q 40.625 -6.640625 38.28125 -3.125 \n",
       "Q 45.703125 -1.953125 52.734375 0.78125 \n",
       "Q 59.765625 3.515625 65.625 7.421875 \n",
       "Q 71.484375 11.328125 76.171875 16.015625 \n",
       "Q 80.859375 20.703125 84.765625 25.78125 \n",
       "Q 87.5 21.484375 92.1875 18.359375 \n",
       "Q 88.28125 16.015625 84.5625 12.6875 \n",
       "Q 80.859375 9.375 76.171875 5.265625 \n",
       "Q 71.484375 1.171875 62.6875 -3.125 \n",
       "Q 53.90625 -7.421875 43.359375 -10.9375 \n",
       "z\n",
       "\" id=\"SimHei-35786\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(89.301563 39.770312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-32047\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-35745\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-30830\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-35786\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 61.301563 50.567187 \n",
       "L 81.301563 50.567187 \n",
       "\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <g>\n",
       "      <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"71.301563\" xlink:href=\"#m9bad646ad8\" y=\"50.567187\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_65\">\n",
       "     <!-- 预测的累计确诊人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 44.921875 75.390625 \n",
       "Q 51.953125 75 57.8125 75 \n",
       "L 79.6875 75 \n",
       "Q 85.15625 75 91.015625 75.390625 \n",
       "L 91.015625 68.75 \n",
       "Q 85.15625 69.140625 79.6875 69.140625 \n",
       "L 69.53125 69.140625 \n",
       "Q 68.359375 63.28125 67.1875 56.640625 \n",
       "L 87.890625 56.640625 \n",
       "Q 87.5 50.78125 87.5 44.140625 \n",
       "L 87.5 27.34375 \n",
       "Q 87.5 21.484375 87.890625 14.453125 \n",
       "L 80.078125 14.453125 \n",
       "L 80.078125 50.78125 \n",
       "L 55.46875 50.78125 \n",
       "L 55.46875 13.671875 \n",
       "L 48.046875 13.671875 \n",
       "Q 48.4375 22.65625 48.4375 28.125 \n",
       "L 48.4375 43.75 \n",
       "Q 48.4375 50.390625 48.046875 56.640625 \n",
       "L 60.15625 56.640625 \n",
       "Q 61.71875 64.84375 62.109375 69.140625 \n",
       "L 57.8125 69.140625 \n",
       "Q 51.5625 69.140625 44.921875 68.75 \n",
       "z\n",
       "M 64.84375 45.3125 \n",
       "Q 68.75 45.3125 72.65625 45.3125 \n",
       "Q 71.875 37.109375 71.484375 31.25 \n",
       "Q 71.09375 25.390625 69.140625 16.203125 \n",
       "Q 67.1875 7.03125 61.328125 0.96875 \n",
       "Q 55.46875 -5.078125 46.09375 -10.9375 \n",
       "Q 42.1875 -7.8125 38.28125 -5.46875 \n",
       "Q 48.046875 -1.953125 53.515625 3.125 \n",
       "Q 58.984375 8.203125 61.328125 14.453125 \n",
       "Q 63.671875 20.703125 64.25 28.515625 \n",
       "Q 64.84375 36.328125 64.84375 45.3125 \n",
       "z\n",
       "M 69.921875 6.640625 \n",
       "Q 72.265625 9.375 75 11.71875 \n",
       "Q 78.515625 9.765625 83.59375 5.859375 \n",
       "Q 88.671875 1.953125 93.359375 -2.734375 \n",
       "Q 90.234375 -5.859375 87.890625 -9.375 \n",
       "Q 82.8125 -3.90625 78.90625 -0.390625 \n",
       "Q 75 3.125 69.921875 6.640625 \n",
       "z\n",
       "M 31.640625 50.78125 \n",
       "Q 28.125 48.4375 25.78125 46.09375 \n",
       "Q 21.484375 52.34375 14.0625 58.203125 \n",
       "Q 16.40625 60.546875 19.140625 62.5 \n",
       "Q 21.484375 60.546875 23.828125 58.59375 \n",
       "Q 28.515625 64.84375 30.859375 68.359375 \n",
       "L 23.046875 68.359375 \n",
       "Q 17.1875 68.359375 10.15625 67.96875 \n",
       "L 10.15625 74.609375 \n",
       "Q 17.1875 74.21875 22.65625 74.21875 \n",
       "L 40.625 74.21875 \n",
       "L 40.625 68.75 \n",
       "Q 34.765625 62.5 28.125 53.90625 \n",
       "z\n",
       "M 43.75 44.53125 \n",
       "Q 41.796875 36.71875 40.625 30.46875 \n",
       "Q 36.328125 31.25 33.203125 31.640625 \n",
       "Q 34.375 35.546875 35.15625 38.671875 \n",
       "L 27.734375 38.671875 \n",
       "L 27.734375 2.734375 \n",
       "Q 27.34375 -3.90625 22.84375 -5.46875 \n",
       "Q 18.359375 -7.03125 12.109375 -7.03125 \n",
       "Q 11.71875 -2.734375 10.546875 1.5625 \n",
       "Q 17.578125 0.390625 19.140625 1.359375 \n",
       "Q 20.703125 2.34375 20.703125 6.25 \n",
       "L 20.703125 38.671875 \n",
       "L 16.40625 38.671875 \n",
       "Q 11.328125 38.671875 6.25 38.28125 \n",
       "L 6.25 44.921875 \n",
       "Q 11.328125 44.53125 16.015625 44.53125 \n",
       "z\n",
       "\" id=\"SimHei-39044\"/>\n",
       "      <path d=\"M 25.390625 67.96875 \n",
       "Q 23.046875 66.015625 20.703125 62.5 \n",
       "Q 14.84375 67.96875 7.8125 72.265625 \n",
       "Q 10.15625 74.21875 12.5 77.34375 \n",
       "Q 19.921875 72.65625 25.390625 67.96875 \n",
       "z\n",
       "M 4.6875 45.3125 \n",
       "Q 6.640625 48.4375 8.203125 51.5625 \n",
       "Q 16.40625 48.046875 23.4375 44.140625 \n",
       "Q 21.09375 40.625 19.921875 37.5 \n",
       "Q 13.671875 42.1875 4.6875 45.3125 \n",
       "z\n",
       "M 17.96875 27.34375 \n",
       "Q 21.09375 24.609375 24.609375 22.65625 \n",
       "Q 21.09375 13.671875 18.546875 4.875 \n",
       "Q 16.015625 -3.90625 14.84375 -8.59375 \n",
       "Q 10.546875 -5.46875 5.859375 -3.90625 \n",
       "Q 9.375 0.78125 12.890625 9.953125 \n",
       "Q 16.40625 19.140625 17.96875 27.34375 \n",
       "z\n",
       "M 28.515625 72.265625 \n",
       "L 60.546875 72.265625 \n",
       "Q 60.15625 65.625 60.15625 60.546875 \n",
       "L 60.15625 32.8125 \n",
       "Q 60.15625 25.78125 60.546875 19.140625 \n",
       "L 53.90625 19.140625 \n",
       "L 53.90625 66.015625 \n",
       "L 35.15625 66.015625 \n",
       "L 35.15625 18.75 \n",
       "L 28.515625 18.75 \n",
       "Q 28.90625 27.34375 28.90625 33.59375 \n",
       "L 28.90625 59.765625 \n",
       "Q 28.90625 66.015625 28.515625 72.265625 \n",
       "z\n",
       "M 41.40625 59.375 \n",
       "Q 44.921875 58.59375 49.609375 58.203125 \n",
       "Q 48.4375 54.296875 48.046875 39.84375 \n",
       "Q 47.65625 25.390625 45.890625 18.15625 \n",
       "Q 44.140625 10.9375 40.03125 4.296875 \n",
       "Q 35.9375 -2.34375 30.46875 -8.203125 \n",
       "Q 27.734375 -4.296875 23.4375 -2.34375 \n",
       "Q 31.25 3.125 35.15625 9.5625 \n",
       "Q 39.0625 16.015625 40.421875 24.21875 \n",
       "Q 41.796875 32.421875 41.796875 41.796875 \n",
       "Q 41.796875 51.171875 41.40625 59.375 \n",
       "z\n",
       "M 48.4375 10.546875 \n",
       "Q 51.171875 12.5 53.90625 14.84375 \n",
       "Q 62.109375 6.25 65.625 1.171875 \n",
       "Q 62.5 -0.78125 59.765625 -3.125 \n",
       "Q 54.6875 4.296875 48.4375 10.546875 \n",
       "z\n",
       "M 68.359375 67.1875 \n",
       "L 75.390625 67.1875 \n",
       "Q 75 62.890625 75 56.640625 \n",
       "L 75 27.34375 \n",
       "Q 75 21.875 75.390625 14.453125 \n",
       "L 68.359375 14.453125 \n",
       "Q 68.75 22.265625 68.75 27.34375 \n",
       "L 68.75 56.25 \n",
       "Q 68.75 62.890625 68.359375 67.1875 \n",
       "z\n",
       "M 83.203125 77.34375 \n",
       "L 90.234375 77.34375 \n",
       "Q 89.84375 71.09375 89.84375 66.796875 \n",
       "L 89.84375 2.34375 \n",
       "Q 89.84375 -4.6875 87.296875 -6.046875 \n",
       "Q 84.765625 -7.421875 78.125 -8.984375 \n",
       "Q 77.34375 -4.6875 74.21875 -0.78125 \n",
       "Q 80.078125 -0.78125 81.828125 -0.390625 \n",
       "Q 83.59375 0 83.59375 3.90625 \n",
       "L 83.59375 66.796875 \n",
       "Q 83.59375 71.09375 83.203125 77.34375 \n",
       "z\n",
       "\" id=\"SimHei-27979\"/>\n",
       "      <path d=\"M 23.828125 79.6875 \n",
       "Q 28.90625 78.515625 34.375 76.953125 \n",
       "Q 32.8125 74.609375 31.640625 70.109375 \n",
       "Q 30.46875 65.625 29.6875 62.109375 \n",
       "L 46.484375 62.109375 \n",
       "Q 46.09375 55.078125 46.09375 45.3125 \n",
       "L 46.09375 10.9375 \n",
       "Q 46.09375 4.6875 46.484375 -3.515625 \n",
       "L 39.0625 -3.515625 \n",
       "L 39.0625 4.6875 \n",
       "L 18.75 4.6875 \n",
       "L 18.75 -4.296875 \n",
       "L 11.328125 -4.296875 \n",
       "Q 11.71875 5.46875 11.71875 10.15625 \n",
       "L 11.71875 44.921875 \n",
       "Q 11.71875 55.078125 11.328125 62.109375 \n",
       "L 22.265625 62.109375 \n",
       "Q 22.65625 66.015625 23.046875 69.71875 \n",
       "Q 23.4375 73.4375 23.828125 79.6875 \n",
       "z\n",
       "M 18.75 55.078125 \n",
       "L 18.75 37.890625 \n",
       "L 39.0625 37.890625 \n",
       "L 39.0625 55.078125 \n",
       "z\n",
       "M 18.75 30.46875 \n",
       "L 18.75 12.109375 \n",
       "L 39.0625 12.109375 \n",
       "L 39.0625 30.46875 \n",
       "z\n",
       "M 91.40625 61.328125 \n",
       "Q 90.625 53.90625 90.234375 46.875 \n",
       "L 87.5 2.734375 \n",
       "Q 86.328125 -4.296875 80.46875 -6.25 \n",
       "Q 74.609375 -8.203125 67.96875 -8.59375 \n",
       "Q 67.96875 -4.296875 65.234375 0.390625 \n",
       "Q 71.875 0 75.78125 0.578125 \n",
       "Q 79.6875 1.171875 80.46875 5.46875 \n",
       "L 83.59375 54.296875 \n",
       "L 62.890625 54.296875 \n",
       "Q 59.765625 47.65625 55.46875 39.453125 \n",
       "Q 52.34375 41.796875 48.828125 43.359375 \n",
       "Q 51.171875 46.875 54.09375 53.125 \n",
       "Q 57.03125 59.375 59.171875 66.59375 \n",
       "Q 61.328125 73.828125 62.109375 78.515625 \n",
       "Q 67.1875 76.171875 71.875 75 \n",
       "Q 69.921875 71.875 68.359375 68.546875 \n",
       "Q 66.796875 65.234375 65.625 61.328125 \n",
       "z\n",
       "M 57.03125 35.9375 \n",
       "Q 59.765625 37.5 63.671875 39.84375 \n",
       "Q 65.625 36.328125 67.578125 32.03125 \n",
       "Q 69.53125 27.734375 71.875 21.484375 \n",
       "Q 68.75 20.3125 64.84375 17.96875 \n",
       "Q 63.671875 22.265625 61.515625 27.34375 \n",
       "Q 59.375 32.421875 57.03125 35.9375 \n",
       "z\n",
       "\" id=\"SimHei-30340\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(89.301563 54.067187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-39044\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-27979\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-30340\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-32047\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-35745\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-30830\"/>\n",
       "      <use x=\"600\" xlink:href=\"#SimHei-35786\"/>\n",
       "      <use x=\"700\" xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"800\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pf5e80461ab\">\n",
       "   <rect height=\"326.16\" width=\"558\" x=\"52.301563\" y=\"22.7625\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"384.192812pt\" version=\"1.1\" viewBox=\"0 0 612.501562 384.192812\" width=\"612.501562pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 384.192812 \n",
       "L 612.501562 384.192812 \n",
       "L 612.501562 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 47.301563 348.9225 \n",
       "L 605.301563 348.9225 \n",
       "L 605.301563 22.7625 \n",
       "L 47.301563 22.7625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"me179914916\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"72.665199\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2020-01-21 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.53125 1.5625 \n",
       "L 4.6875 1.5625 \n",
       "L 4.6875 7.8125 \n",
       "Q 7.03125 14.0625 11.125 19.328125 \n",
       "Q 15.234375 24.609375 23.046875 31.25 \n",
       "Q 28.90625 36.328125 31.4375 40.625 \n",
       "Q 33.984375 44.921875 33.984375 50 \n",
       "Q 33.984375 55.078125 31.828125 58.390625 \n",
       "Q 29.6875 61.71875 25 61.71875 \n",
       "Q 21.09375 61.71875 18.15625 58.203125 \n",
       "Q 15.234375 54.6875 15.234375 45.703125 \n",
       "L 6.25 45.703125 \n",
       "Q 6.640625 57.03125 11.515625 63.078125 \n",
       "Q 16.40625 69.140625 25.390625 69.140625 \n",
       "Q 33.984375 69.140625 38.671875 63.859375 \n",
       "Q 43.359375 58.59375 43.359375 49.609375 \n",
       "Q 43.359375 42.1875 39.0625 36.71875 \n",
       "Q 34.765625 31.25 28.515625 25.78125 \n",
       "Q 21.484375 19.53125 18.75 16.40625 \n",
       "Q 16.015625 13.28125 13.671875 8.984375 \n",
       "L 44.53125 8.984375 \n",
       "z\n",
       "\" id=\"SimHei-50\"/>\n",
       "       <path d=\"M 46.484375 35.15625 \n",
       "Q 46.484375 21.09375 41.40625 10.9375 \n",
       "Q 36.328125 0.78125 25 0.78125 \n",
       "Q 13.671875 0.78125 8.390625 10.9375 \n",
       "Q 3.125 21.09375 3.125 35.15625 \n",
       "Q 3.125 49.21875 8.390625 59.171875 \n",
       "Q 13.671875 69.140625 25 69.140625 \n",
       "Q 36.328125 69.140625 41.40625 59.171875 \n",
       "Q 46.484375 49.21875 46.484375 35.15625 \n",
       "z\n",
       "M 37.109375 35.15625 \n",
       "Q 37.109375 47.65625 34.171875 54.6875 \n",
       "Q 31.25 61.71875 25 61.71875 \n",
       "Q 18.75 61.71875 15.625 54.6875 \n",
       "Q 12.5 47.65625 12.5 35.15625 \n",
       "Q 12.5 22.65625 15.625 15.421875 \n",
       "Q 18.75 8.203125 25 8.203125 \n",
       "Q 31.25 8.203125 34.171875 15.421875 \n",
       "Q 37.109375 22.65625 37.109375 35.15625 \n",
       "z\n",
       "\" id=\"SimHei-48\"/>\n",
       "       <path d=\"M 46.875 32.8125 \n",
       "L 2.34375 32.8125 \n",
       "L 2.34375 39.0625 \n",
       "L 46.875 39.0625 \n",
       "z\n",
       "\" id=\"SimHei-45\"/>\n",
       "       <path d=\"M 30.46875 1.5625 \n",
       "L 21.484375 1.5625 \n",
       "L 21.484375 53.515625 \n",
       "L 9.765625 53.515625 \n",
       "L 9.765625 58.203125 \n",
       "Q 16.796875 58.203125 20.703125 60.9375 \n",
       "Q 24.609375 63.671875 25.78125 69.140625 \n",
       "L 30.46875 69.140625 \n",
       "z\n",
       "\" id=\"SimHei-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(47.665199 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"157.210653\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2020-01-25 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 25.78125 \n",
       "Q 44.140625 14.0625 38.46875 7.421875 \n",
       "Q 32.8125 0.78125 23.4375 0.78125 \n",
       "Q 15.234375 0.78125 9.953125 6.25 \n",
       "Q 4.6875 11.71875 4.296875 21.09375 \n",
       "L 13.28125 21.09375 \n",
       "Q 13.28125 15.234375 16.015625 11.71875 \n",
       "Q 18.75 8.203125 23.828125 8.203125 \n",
       "Q 28.90625 8.203125 31.828125 12.5 \n",
       "Q 34.765625 16.796875 34.765625 25.78125 \n",
       "Q 34.765625 33.59375 32.21875 37.296875 \n",
       "Q 29.6875 41.015625 25.390625 41.015625 \n",
       "Q 21.875 41.015625 19.328125 39.453125 \n",
       "Q 16.796875 37.890625 14.453125 33.984375 \n",
       "L 6.640625 33.984375 \n",
       "L 8.984375 68.359375 \n",
       "L 42.578125 68.359375 \n",
       "L 42.578125 60.9375 \n",
       "L 16.40625 60.9375 \n",
       "L 14.84375 42.96875 \n",
       "Q 17.1875 45.3125 19.921875 46.484375 \n",
       "Q 22.65625 47.65625 27.34375 47.65625 \n",
       "Q 34.765625 47.65625 39.453125 41.984375 \n",
       "Q 44.140625 36.328125 44.140625 25.78125 \n",
       "z\n",
       "\" id=\"SimHei-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(132.210653 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.756108\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2020-01-29 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 35.9375 \n",
       "Q 44.140625 19.921875 38.46875 10.34375 \n",
       "Q 32.8125 0.78125 22.265625 0.78125 \n",
       "Q 14.84375 0.78125 10.34375 6.25 \n",
       "Q 5.859375 11.71875 5.859375 18.359375 \n",
       "L 14.84375 18.359375 \n",
       "Q 14.84375 14.453125 16.984375 11.328125 \n",
       "Q 19.140625 8.203125 22.65625 8.203125 \n",
       "Q 28.515625 8.203125 31.4375 14.84375 \n",
       "Q 34.375 21.484375 35.15625 34.375 \n",
       "Q 33.203125 30.078125 29.6875 27.734375 \n",
       "Q 26.171875 25.390625 21.875 25.390625 \n",
       "Q 14.453125 25.390625 9.765625 30.859375 \n",
       "Q 5.078125 36.328125 5.078125 46.484375 \n",
       "Q 5.078125 56.640625 9.765625 62.890625 \n",
       "Q 14.453125 69.140625 23.828125 69.140625 \n",
       "Q 33.203125 69.140625 38.671875 61.328125 \n",
       "Q 44.140625 53.515625 44.140625 35.9375 \n",
       "z\n",
       "M 34.375 44.921875 \n",
       "Q 34.375 53.515625 31.4375 57.8125 \n",
       "Q 28.515625 62.109375 23.4375 62.109375 \n",
       "Q 19.921875 62.109375 17.1875 58.78125 \n",
       "Q 14.453125 55.46875 14.453125 46.484375 \n",
       "Q 14.453125 39.84375 16.59375 36.125 \n",
       "Q 18.75 32.421875 23.4375 32.421875 \n",
       "Q 28.515625 32.421875 31.4375 35.9375 \n",
       "Q 34.375 39.453125 34.375 44.921875 \n",
       "z\n",
       "\" id=\"SimHei-57\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(216.756108 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.165199\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2020-02-01 -->\n",
       "      <g transform=\"translate(280.165199 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"389.710653\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2020-02-05 -->\n",
       "      <g transform=\"translate(364.710653 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"474.256108\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2020-02-09 -->\n",
       "      <g transform=\"translate(449.256108 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"558.801563\" xlink:href=\"#me179914916\" y=\"348.9225\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2020-02-13 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.140625 20.3125 \n",
       "Q 44.140625 11.328125 38.46875 6.046875 \n",
       "Q 32.8125 0.78125 24.21875 0.78125 \n",
       "Q 15.625 0.78125 9.953125 6.046875 \n",
       "Q 4.296875 11.328125 4.296875 22.265625 \n",
       "L 13.28125 22.265625 \n",
       "Q 13.28125 14.84375 16.203125 11.515625 \n",
       "Q 19.140625 8.203125 24.21875 8.203125 \n",
       "Q 29.296875 8.203125 32.03125 11.328125 \n",
       "Q 34.765625 14.453125 34.765625 21.09375 \n",
       "Q 34.765625 26.5625 31.828125 29.6875 \n",
       "Q 28.90625 32.8125 21.484375 32.8125 \n",
       "L 21.484375 39.453125 \n",
       "Q 27.734375 39.453125 30.65625 42.578125 \n",
       "Q 33.59375 45.703125 33.59375 51.953125 \n",
       "Q 33.59375 56.640625 31.4375 59.375 \n",
       "Q 29.296875 62.109375 24.609375 62.109375 \n",
       "Q 19.921875 62.109375 17.375 58.78125 \n",
       "Q 14.84375 55.46875 14.453125 49.21875 \n",
       "L 5.859375 49.21875 \n",
       "Q 6.640625 58.203125 11.515625 63.671875 \n",
       "Q 16.40625 69.140625 24.609375 69.140625 \n",
       "Q 33.203125 69.140625 37.890625 64.25 \n",
       "Q 42.578125 59.375 42.578125 52.34375 \n",
       "Q 42.578125 45.703125 40.234375 41.984375 \n",
       "Q 37.890625 38.28125 32.421875 36.328125 \n",
       "Q 37.890625 35.15625 41.015625 30.859375 \n",
       "Q 44.140625 26.5625 44.140625 20.3125 \n",
       "z\n",
       "\" id=\"SimHei-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(533.801563 362.758437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"200\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"300\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"350\" xlink:href=\"#SimHei-45\"/>\n",
       "       <use x=\"400\" xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"450\" xlink:href=\"#SimHei-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- 日期 -->\n",
       "     <defs>\n",
       "      <path d=\"M 30.859375 69.921875 \n",
       "L 30.859375 43.359375 \n",
       "L 72.265625 43.359375 \n",
       "L 72.265625 69.921875 \n",
       "z\n",
       "M 30.859375 36.71875 \n",
       "L 30.859375 9.765625 \n",
       "L 72.265625 9.765625 \n",
       "L 72.265625 36.71875 \n",
       "z\n",
       "M 23.046875 76.5625 \n",
       "L 80.078125 76.5625 \n",
       "Q 79.6875 57.8125 79.6875 35.15625 \n",
       "Q 79.6875 12.5 80.078125 -6.25 \n",
       "L 72.265625 -6.25 \n",
       "L 72.265625 3.125 \n",
       "L 30.859375 3.125 \n",
       "L 30.859375 -8.203125 \n",
       "L 23.046875 -8.203125 \n",
       "Q 23.4375 9.375 23.4375 33 \n",
       "Q 23.4375 56.640625 23.046875 76.5625 \n",
       "z\n",
       "\" id=\"SimHei-26085\"/>\n",
       "      <path d=\"M 23.4375 60.9375 \n",
       "L 23.4375 52.34375 \n",
       "L 38.671875 52.34375 \n",
       "L 38.671875 60.9375 \n",
       "z\n",
       "M 18.359375 15.625 \n",
       "L 25.78125 10.9375 \n",
       "Q 23.4375 9.765625 19.328125 4.09375 \n",
       "Q 15.234375 -1.5625 11.71875 -5.859375 \n",
       "Q 7.8125 -3.125 5.078125 -1.5625 \n",
       "Q 8.59375 1.171875 12.296875 6.046875 \n",
       "Q 16.015625 10.9375 18.359375 15.625 \n",
       "z\n",
       "M 23.4375 46.484375 \n",
       "L 23.4375 38.28125 \n",
       "L 38.671875 38.28125 \n",
       "L 38.671875 46.484375 \n",
       "z\n",
       "M 23.4375 32.421875 \n",
       "L 23.4375 23.828125 \n",
       "L 38.671875 23.828125 \n",
       "L 38.671875 32.421875 \n",
       "z\n",
       "M 46.875 7.421875 \n",
       "Q 44.140625 4.6875 42.1875 1.5625 \n",
       "Q 37.109375 8.203125 32.8125 10.9375 \n",
       "Q 35.546875 13.671875 37.109375 16.40625 \n",
       "Q 42.96875 10.546875 46.875 7.421875 \n",
       "z\n",
       "M 8.203125 67.1875 \n",
       "Q 12.5 66.796875 16.40625 66.796875 \n",
       "Q 16.40625 74.21875 16.015625 79.6875 \n",
       "L 24.21875 79.6875 \n",
       "Q 23.4375 75 23.4375 66.796875 \n",
       "L 38.671875 66.796875 \n",
       "Q 38.671875 74.21875 38.28125 79.6875 \n",
       "L 46.484375 79.6875 \n",
       "Q 45.3125 75 45.703125 66.796875 \n",
       "Q 48.828125 66.796875 53.125 67.1875 \n",
       "L 53.125 60.546875 \n",
       "Q 49.21875 60.9375 45.703125 60.9375 \n",
       "L 45.703125 23.828125 \n",
       "Q 49.21875 23.828125 53.125 24.21875 \n",
       "L 53.125 17.578125 \n",
       "Q 47.265625 17.96875 42.1875 17.96875 \n",
       "L 17.1875 17.96875 \n",
       "Q 12.109375 17.96875 5.859375 17.578125 \n",
       "L 5.859375 24.21875 \n",
       "Q 11.71875 23.828125 16.40625 23.828125 \n",
       "L 16.40625 60.9375 \n",
       "Q 12.890625 60.9375 8.203125 60.546875 \n",
       "z\n",
       "M 76.953125 -9.765625 \n",
       "Q 76.953125 -5.46875 73.828125 -0.78125 \n",
       "Q 82.8125 -1.953125 82.03125 2.34375 \n",
       "L 82.03125 24.21875 \n",
       "L 64.453125 24.21875 \n",
       "Q 63.671875 14.84375 60.34375 6.25 \n",
       "Q 57.03125 -2.34375 50.78125 -9.765625 \n",
       "Q 48.046875 -6.25 43.75 -4.6875 \n",
       "Q 50.390625 1.953125 53.515625 9.375 \n",
       "Q 56.640625 16.796875 57.21875 24.21875 \n",
       "Q 57.8125 31.640625 57.8125 48.625 \n",
       "Q 57.8125 65.625 57.421875 75.78125 \n",
       "L 89.453125 75.78125 \n",
       "Q 89.0625 68.359375 89.0625 57.8125 \n",
       "L 89.0625 0.390625 \n",
       "Q 89.0625 -5.078125 85.9375 -7.03125 \n",
       "Q 82.8125 -8.984375 76.953125 -9.765625 \n",
       "z\n",
       "M 64.84375 69.921875 \n",
       "L 64.84375 52.34375 \n",
       "L 82.03125 52.34375 \n",
       "L 82.03125 69.921875 \n",
       "z\n",
       "M 64.84375 46.484375 \n",
       "L 64.84375 30.078125 \n",
       "L 82.03125 30.078125 \n",
       "L 82.03125 46.484375 \n",
       "z\n",
       "\" id=\"SimHei-26399\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(316.301562 375.70375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-26085\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-26399\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m9ae5264c4b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"337.448004\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(35.301563 340.865973)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"286.6759\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(20.301563 290.093869)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"235.903795\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 2000 -->\n",
       "      <g transform=\"translate(20.301563 239.321764)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"185.131691\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 3000 -->\n",
       "      <g transform=\"translate(20.301563 188.549659)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-51\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"134.359586\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 4000 -->\n",
       "      <defs>\n",
       "       <path d=\"M 46.484375 18.75 \n",
       "L 38.28125 18.75 \n",
       "L 38.28125 1.5625 \n",
       "L 29.296875 1.5625 \n",
       "L 29.296875 18.75 \n",
       "L 3.125 18.75 \n",
       "L 3.125 26.171875 \n",
       "L 29.296875 69.140625 \n",
       "L 38.28125 69.140625 \n",
       "L 38.28125 26.171875 \n",
       "L 46.484375 26.171875 \n",
       "z\n",
       "M 29.296875 26.171875 \n",
       "L 29.296875 55.078125 \n",
       "L 11.71875 26.171875 \n",
       "z\n",
       "\" id=\"SimHei-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.301563 137.777555)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"83.587481\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 5000 -->\n",
       "      <g transform=\"translate(20.301563 87.00545)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.301563\" xlink:href=\"#m9ae5264c4b\" y=\"32.815377\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 6000 -->\n",
       "      <defs>\n",
       "       <path d=\"M 44.53125 24.21875 \n",
       "Q 44.53125 13.28125 39.84375 7.03125 \n",
       "Q 35.15625 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.9375 8.59375 \n",
       "Q 5.46875 16.40625 5.46875 33.984375 \n",
       "Q 5.46875 50 11.125 59.5625 \n",
       "Q 16.796875 69.140625 27.34375 69.140625 \n",
       "Q 34.765625 69.140625 39.25 63.671875 \n",
       "Q 43.75 58.203125 43.75 51.5625 \n",
       "L 34.765625 51.5625 \n",
       "Q 34.765625 55.46875 32.609375 58.59375 \n",
       "Q 30.46875 61.71875 26.953125 61.71875 \n",
       "Q 21.09375 61.71875 17.96875 55.65625 \n",
       "Q 14.84375 49.609375 14.453125 37.109375 \n",
       "Q 17.1875 42.1875 20.3125 44.140625 \n",
       "Q 23.4375 46.09375 27.734375 46.09375 \n",
       "Q 35.15625 46.09375 39.84375 40.234375 \n",
       "Q 44.53125 34.375 44.53125 24.21875 \n",
       "z\n",
       "M 35.15625 24.21875 \n",
       "Q 35.15625 31.25 32.8125 35.15625 \n",
       "Q 30.46875 39.0625 26.171875 39.0625 \n",
       "Q 21.09375 39.0625 18.15625 35.15625 \n",
       "Q 15.234375 31.25 15.234375 25.78125 \n",
       "Q 15.234375 17.1875 18.15625 12.5 \n",
       "Q 21.09375 7.8125 26.171875 7.8125 \n",
       "Q 29.6875 7.8125 32.421875 11.328125 \n",
       "Q 35.15625 14.84375 35.15625 24.21875 \n",
       "z\n",
       "\" id=\"SimHei-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.301563 36.233345)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-54\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- 人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 13.671875 -8.984375 \n",
       "Q 10.9375 -3.515625 6.25 -1.171875 \n",
       "Q 21.09375 5.46875 29.484375 15.8125 \n",
       "Q 37.890625 26.171875 41.59375 38.078125 \n",
       "Q 45.3125 50 45.5 60.15625 \n",
       "Q 45.703125 70.3125 44.921875 79.296875 \n",
       "Q 48.4375 78.90625 54.296875 78.515625 \n",
       "Q 53.125 74.21875 53.125 64.640625 \n",
       "Q 53.125 55.078125 53.3125 49.015625 \n",
       "Q 53.515625 42.96875 64.25 25 \n",
       "Q 75 7.03125 94.921875 -1.171875 \n",
       "Q 89.0625 -5.46875 87.890625 -8.984375 \n",
       "Q 61.328125 4.296875 49.609375 39.84375 \n",
       "Q 40.625 7.03125 13.671875 -8.984375 \n",
       "z\n",
       "\" id=\"SimHei-20154\"/>\n",
       "      <path d=\"M 10.9375 75.78125 \n",
       "Q 14.84375 76.953125 17.1875 78.515625 \n",
       "Q 20.3125 73.4375 23.046875 68.359375 \n",
       "Q 19.53125 66.796875 16.796875 65.234375 \n",
       "Q 14.453125 71.09375 10.9375 75.78125 \n",
       "z\n",
       "M 44.921875 78.515625 \n",
       "Q 49.21875 76.5625 53.125 75 \n",
       "Q 50.78125 73.4375 49.21875 70.703125 \n",
       "Q 47.65625 67.96875 45.703125 64.453125 \n",
       "Q 42.578125 66.015625 39.453125 66.796875 \n",
       "Q 42.578125 71.875 44.921875 78.515625 \n",
       "z\n",
       "M 38.28125 49.609375 \n",
       "Q 41.796875 51.171875 44.140625 53.515625 \n",
       "Q 48.828125 46.875 51.953125 41.40625 \n",
       "Q 48.4375 39.84375 45.3125 37.5 \n",
       "Q 42.1875 44.921875 38.28125 49.609375 \n",
       "z\n",
       "M 8.203125 61.71875 \n",
       "Q 14.453125 61.328125 28.125 61.328125 \n",
       "Q 28.125 72.65625 27.734375 80.859375 \n",
       "L 35.546875 80.859375 \n",
       "Q 35.15625 72.65625 35.15625 61.328125 \n",
       "Q 48.046875 61.328125 53.90625 61.71875 \n",
       "L 53.90625 54.6875 \n",
       "Q 48.046875 55.078125 35.15625 55.078125 \n",
       "Q 35.15625 46.09375 35.546875 39.453125 \n",
       "L 27.734375 39.453125 \n",
       "Q 28.125 45.3125 28.125 51.953125 \n",
       "Q 26.171875 48.046875 21.671875 43.546875 \n",
       "Q 17.1875 39.0625 11.71875 35.9375 \n",
       "Q 10.15625 39.453125 6.640625 41.796875 \n",
       "Q 10.15625 42.96875 15.421875 46.875 \n",
       "Q 20.703125 50.78125 23.046875 55.078125 \n",
       "Q 14.84375 55.078125 8.203125 54.6875 \n",
       "z\n",
       "M 26.953125 24.21875 \n",
       "Q 25 20.3125 22.65625 16.40625 \n",
       "Q 27.34375 15.234375 35.15625 13.28125 \n",
       "Q 37.890625 16.796875 40.234375 24.21875 \n",
       "z\n",
       "M 24.21875 38.28125 \n",
       "Q 28.515625 36.71875 32.8125 35.546875 \n",
       "Q 31.25 33.984375 29.296875 30.46875 \n",
       "L 44.53125 30.46875 \n",
       "L 48.828125 30.46875 \n",
       "Q 46.484375 20.3125 42.1875 11.328125 \n",
       "Q 48.828125 9.375 52.734375 8.203125 \n",
       "Q 49.609375 3.90625 48.046875 0.390625 \n",
       "Q 44.53125 2.734375 37.5 5.46875 \n",
       "Q 28.125 -3.90625 9.375 -10.15625 \n",
       "Q 7.8125 -6.25 4.6875 -3.90625 \n",
       "Q 21.484375 0 31.25 8.203125 \n",
       "Q 20.3125 10.9375 13.28125 12.890625 \n",
       "Q 15.625 16.015625 19.53125 24.21875 \n",
       "Q 13.28125 24.21875 4.6875 23.828125 \n",
       "L 4.6875 30.859375 \n",
       "Q 12.109375 30.46875 21.875 30.46875 \n",
       "Q 23.046875 33.59375 24.21875 38.28125 \n",
       "z\n",
       "M 63.671875 80.46875 \n",
       "Q 68.359375 78.515625 73.4375 77.734375 \n",
       "Q 71.484375 75.390625 70.5 72.265625 \n",
       "Q 69.53125 69.140625 67.96875 63.28125 \n",
       "L 85.546875 63.28125 \n",
       "Q 89.0625 63.28125 94.53125 63.671875 \n",
       "L 94.53125 56.640625 \n",
       "Q 90.234375 57.03125 87.5 57.03125 \n",
       "Q 87.109375 48.828125 85.546875 35.34375 \n",
       "Q 83.984375 21.875 78.125 11.71875 \n",
       "Q 82.03125 6.25 87.109375 2.734375 \n",
       "Q 92.1875 -0.78125 96.09375 -2.34375 \n",
       "Q 90.625 -5.859375 89.0625 -9.375 \n",
       "Q 82.421875 -4.6875 79.296875 -1.359375 \n",
       "Q 76.171875 1.953125 73.4375 5.859375 \n",
       "Q 68.75 1.171875 64.640625 -1.953125 \n",
       "Q 60.546875 -5.078125 51.5625 -10.15625 \n",
       "Q 49.609375 -6.640625 45.3125 -3.90625 \n",
       "Q 52.734375 -1.171875 58.984375 3.125 \n",
       "Q 65.234375 7.421875 69.53125 12.109375 \n",
       "Q 65.234375 20.703125 62.890625 29.09375 \n",
       "Q 60.546875 37.5 60.15625 41.015625 \n",
       "Q 59.375 38.28125 58.203125 34.765625 \n",
       "Q 54.6875 36.328125 50.390625 37.890625 \n",
       "Q 55.078125 46.484375 58.984375 58.59375 \n",
       "Q 62.890625 70.703125 63.671875 80.46875 \n",
       "z\n",
       "M 66.40625 57.03125 \n",
       "Q 64.84375 53.125 64.0625 50.578125 \n",
       "Q 63.28125 48.046875 66.984375 36.71875 \n",
       "Q 70.703125 25.390625 74.21875 19.140625 \n",
       "Q 77.734375 28.515625 79.09375 38.671875 \n",
       "Q 80.46875 48.828125 80.46875 57.03125 \n",
       "z\n",
       "\" id=\"SimHei-25968\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(15.0125 195.8425)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#pb25375afca)\" d=\"M 72.665199 332.116933 \n",
       "L 93.801562 333.944729 \n",
       "L 114.937926 332.116933 \n",
       "L 136.07429 328.309026 \n",
       "L 157.210653 321.048615 \n",
       "L 178.347017 318.611554 \n",
       "L 199.483381 271.901217 \n",
       "L 220.619744 294.799436 \n",
       "L 241.756108 285.051192 \n",
       "L 262.892472 275.506037 \n",
       "L 284.028835 269.057979 \n",
       "L 305.165199 239.914791 \n",
       "L 326.301562 230.674268 \n",
       "L 347.437926 218.387419 \n",
       "L 368.57429 177.211242 \n",
       "L 389.710653 185.791728 \n",
       "L 410.847017 213.208664 \n",
       "L 431.983381 193.204455 \n",
       "L 453.119744 228.440296 \n",
       "L 474.256108 208.943808 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    <defs>\n",
       "     <path d=\"M -3 3 \n",
       "L 3 -3 \n",
       "M -3 -3 \n",
       "L 3 3 \n",
       "\" id=\"m82bc647565\" style=\"stroke:#ff0000;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pb25375afca)\">\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"72.665199\" xlink:href=\"#m82bc647565\" y=\"332.116933\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"93.801562\" xlink:href=\"#m82bc647565\" y=\"333.944729\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"114.937926\" xlink:href=\"#m82bc647565\" y=\"332.116933\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"136.07429\" xlink:href=\"#m82bc647565\" y=\"328.309026\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"157.210653\" xlink:href=\"#m82bc647565\" y=\"321.048615\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"178.347017\" xlink:href=\"#m82bc647565\" y=\"318.611554\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"199.483381\" xlink:href=\"#m82bc647565\" y=\"271.901217\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"220.619744\" xlink:href=\"#m82bc647565\" y=\"294.799436\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"241.756108\" xlink:href=\"#m82bc647565\" y=\"285.051192\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"262.892472\" xlink:href=\"#m82bc647565\" y=\"275.506037\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"284.028835\" xlink:href=\"#m82bc647565\" y=\"269.057979\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"305.165199\" xlink:href=\"#m82bc647565\" y=\"239.914791\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"326.301562\" xlink:href=\"#m82bc647565\" y=\"230.674268\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"347.437926\" xlink:href=\"#m82bc647565\" y=\"218.387419\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"368.57429\" xlink:href=\"#m82bc647565\" y=\"177.211242\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"389.710653\" xlink:href=\"#m82bc647565\" y=\"185.791728\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"410.847017\" xlink:href=\"#m82bc647565\" y=\"213.208664\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"431.983381\" xlink:href=\"#m82bc647565\" y=\"193.204455\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"453.119744\" xlink:href=\"#m82bc647565\" y=\"228.440296\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"474.256108\" xlink:href=\"#m82bc647565\" y=\"208.943808\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#pb25375afca)\" d=\"M 72.665199 334.097045 \n",
       "L 93.801562 332.726199 \n",
       "L 114.937926 330.949175 \n",
       "L 136.07429 328.512114 \n",
       "L 157.210653 325.110383 \n",
       "L 178.347017 320.439349 \n",
       "L 199.483381 313.991292 \n",
       "L 220.619744 305.25849 \n",
       "L 241.756108 293.68245 \n",
       "L 262.892472 279.009312 \n",
       "L 284.028835 261.239075 \n",
       "L 305.165199 240.828689 \n",
       "L 326.301562 219.707494 \n",
       "L 347.437926 200.261778 \n",
       "L 368.57429 183.608527 \n",
       "L 389.710653 176.805065 \n",
       "L 410.847017 182.136136 \n",
       "L 431.983381 184.522425 \n",
       "L 453.119744 188.228789 \n",
       "L 474.256108 176.145028 \n",
       "L 495.392472 153.399125 \n",
       "L 516.528835 129.536236 \n",
       "L 537.665199 102.474704 \n",
       "L 558.801563 72.062214 \n",
       "L 579.937926 37.587955 \n",
       "\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    <defs>\n",
       "     <path d=\"M -3 3 \n",
       "L 3 -3 \n",
       "M -3 -3 \n",
       "L 3 3 \n",
       "\" id=\"m35e814b78a\" style=\"stroke:#0000ff;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pb25375afca)\">\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"72.665199\" xlink:href=\"#m35e814b78a\" y=\"334.097045\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"93.801562\" xlink:href=\"#m35e814b78a\" y=\"332.726199\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"114.937926\" xlink:href=\"#m35e814b78a\" y=\"330.949175\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"136.07429\" xlink:href=\"#m35e814b78a\" y=\"328.512114\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"157.210653\" xlink:href=\"#m35e814b78a\" y=\"325.110383\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"178.347017\" xlink:href=\"#m35e814b78a\" y=\"320.439349\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"199.483381\" xlink:href=\"#m35e814b78a\" y=\"313.991292\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"220.619744\" xlink:href=\"#m35e814b78a\" y=\"305.25849\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"241.756108\" xlink:href=\"#m35e814b78a\" y=\"293.68245\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"262.892472\" xlink:href=\"#m35e814b78a\" y=\"279.009312\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"284.028835\" xlink:href=\"#m35e814b78a\" y=\"261.239075\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"305.165199\" xlink:href=\"#m35e814b78a\" y=\"240.828689\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"326.301562\" xlink:href=\"#m35e814b78a\" y=\"219.707494\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"347.437926\" xlink:href=\"#m35e814b78a\" y=\"200.261778\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"368.57429\" xlink:href=\"#m35e814b78a\" y=\"183.608527\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"389.710653\" xlink:href=\"#m35e814b78a\" y=\"176.805065\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"410.847017\" xlink:href=\"#m35e814b78a\" y=\"182.136136\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"431.983381\" xlink:href=\"#m35e814b78a\" y=\"184.522425\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"453.119744\" xlink:href=\"#m35e814b78a\" y=\"188.228789\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"474.256108\" xlink:href=\"#m35e814b78a\" y=\"176.145028\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"495.392472\" xlink:href=\"#m35e814b78a\" y=\"153.399125\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"516.528835\" xlink:href=\"#m35e814b78a\" y=\"129.536236\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"537.665199\" xlink:href=\"#m35e814b78a\" y=\"102.474704\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"558.801563\" xlink:href=\"#m35e814b78a\" y=\"72.062214\"/>\n",
       "     <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"579.937926\" xlink:href=\"#m35e814b78a\" y=\"37.587955\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 47.301563 348.9225 \n",
       "L 47.301563 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 605.301563 348.9225 \n",
       "L 605.301563 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 47.301562 348.9225 \n",
       "L 605.301562 348.9225 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 47.301562 22.7625 \n",
       "L 605.301562 22.7625 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- 66.0 -->\n",
       "    <defs>\n",
       "     <path d=\"M 17.1875 1.5625 \n",
       "L 8.203125 1.5625 \n",
       "L 8.203125 10.15625 \n",
       "L 17.1875 10.15625 \n",
       "z\n",
       "\" id=\"SimHei-46\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(67.665199 329.097045)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_18\">\n",
       "    <!-- 93.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(88.801562 327.726199)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_19\">\n",
       "    <!-- 128.0 -->\n",
       "    <defs>\n",
       "     <path d=\"M 44.921875 20.703125 \n",
       "Q 44.921875 10.9375 39.453125 5.859375 \n",
       "Q 33.984375 0.78125 24.609375 0.78125 \n",
       "Q 15.234375 0.78125 9.765625 5.859375 \n",
       "Q 4.296875 10.9375 4.296875 20.703125 \n",
       "Q 4.296875 25.78125 7.421875 29.875 \n",
       "Q 10.546875 33.984375 16.015625 35.9375 \n",
       "Q 11.328125 37.890625 8.78125 41.40625 \n",
       "Q 6.25 44.921875 6.25 50.390625 \n",
       "Q 6.25 58.984375 11.71875 64.0625 \n",
       "Q 17.1875 69.140625 24.609375 69.140625 \n",
       "Q 32.03125 69.140625 37.5 64.0625 \n",
       "Q 42.96875 58.984375 42.96875 50.390625 \n",
       "Q 42.96875 44.921875 40.421875 41.40625 \n",
       "Q 37.890625 37.890625 33.203125 35.9375 \n",
       "Q 38.671875 33.984375 41.796875 29.875 \n",
       "Q 44.921875 25.78125 44.921875 20.703125 \n",
       "z\n",
       "M 34.375 50.390625 \n",
       "Q 34.375 56.640625 31.640625 59.375 \n",
       "Q 28.90625 62.109375 24.609375 62.109375 \n",
       "Q 20.3125 62.109375 17.578125 59.375 \n",
       "Q 14.84375 56.640625 14.84375 50.390625 \n",
       "Q 14.84375 44.140625 17.765625 41.59375 \n",
       "Q 20.703125 39.0625 24.609375 39.0625 \n",
       "Q 28.515625 39.0625 31.4375 41.59375 \n",
       "Q 34.375 44.140625 34.375 50.390625 \n",
       "z\n",
       "M 35.9375 20.703125 \n",
       "Q 35.9375 26.171875 33 29.296875 \n",
       "Q 30.078125 32.421875 24.609375 32.421875 \n",
       "Q 19.140625 32.421875 16.203125 29.296875 \n",
       "Q 13.28125 26.171875 13.28125 20.703125 \n",
       "Q 13.28125 14.453125 16.40625 11.125 \n",
       "Q 19.53125 7.8125 24.609375 7.8125 \n",
       "Q 29.6875 7.8125 32.8125 11.125 \n",
       "Q 35.9375 14.453125 35.9375 20.703125 \n",
       "z\n",
       "\" id=\"SimHei-56\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(109.937926 325.949175)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_20\">\n",
       "    <!-- 176.0 -->\n",
       "    <defs>\n",
       "     <path d=\"M 43.359375 60.15625 \n",
       "L 25 1.5625 \n",
       "L 16.015625 1.5625 \n",
       "L 34.765625 60.9375 \n",
       "L 6.25 60.9375 \n",
       "L 6.25 68.359375 \n",
       "L 43.359375 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-55\"/>\n",
       "    </defs>\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(131.07429 323.512114)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_21\">\n",
       "    <!-- 243.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(152.210653 320.110383)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_22\">\n",
       "    <!-- 335.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(173.347017 315.439349)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_23\">\n",
       "    <!-- 462.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(194.483381 308.991292)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_24\">\n",
       "    <!-- 634.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(215.619744 300.25849)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_25\">\n",
       "    <!-- 862.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(236.756108 288.68245)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_26\">\n",
       "    <!-- 1151.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(257.892472 274.009312)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_27\">\n",
       "    <!-- 1501.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(279.028835 256.239075)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_28\">\n",
       "    <!-- 1903.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(300.165199 235.828689)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_29\">\n",
       "    <!-- 2319.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(321.301562 214.707494)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_30\">\n",
       "    <!-- 2702.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(342.437926 195.261778)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_31\">\n",
       "    <!-- 3030.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(363.57429 178.608527)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_32\">\n",
       "    <!-- 3164.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(384.710653 171.805065)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_33\">\n",
       "    <!-- 3059.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(405.847017 177.136136)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_34\">\n",
       "    <!-- 3012.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(426.983381 179.522425)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_35\">\n",
       "    <!-- 2939.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(448.119744 183.228789)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_36\">\n",
       "    <!-- 3177.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(469.256108 171.145028)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_37\">\n",
       "    <!-- 3625.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(490.392472 148.399125)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_38\">\n",
       "    <!-- 4095.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(511.528835 124.536236)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_39\">\n",
       "    <!-- 4628.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(532.665199 97.474704)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_40\">\n",
       "    <!-- 5227.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(553.801563 67.062214)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_41\">\n",
       "    <!-- 5906.0 -->\n",
       "    <g style=\"fill:#0000ff;\" transform=\"translate(574.937926 32.587955)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_42\">\n",
       "    <!-- 105.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(67.665199 312.116933)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_43\">\n",
       "    <!-- 69.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(88.801562 313.944729)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_44\">\n",
       "    <!-- 105.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(109.937926 312.116933)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_45\">\n",
       "    <!-- 180.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(131.07429 308.309026)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_46\">\n",
       "    <!-- 323.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(152.210653 301.048615)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_47\">\n",
       "    <!-- 371.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(173.347017 298.611554)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_48\">\n",
       "    <!-- 1291.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(194.483381 251.901217)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_49\">\n",
       "    <!-- 840.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(215.619744 274.799436)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_50\">\n",
       "    <!-- 1032.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(236.756108 265.051192)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_51\">\n",
       "    <!-- 1220.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(257.892472 255.506037)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_52\">\n",
       "    <!-- 1347.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(279.028835 249.057979)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_53\">\n",
       "    <!-- 1921.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(300.165199 219.914791)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_54\">\n",
       "    <!-- 2103.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(321.301562 210.674268)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_55\">\n",
       "    <!-- 2345.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(342.437926 198.387419)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_56\">\n",
       "    <!-- 3156.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(363.57429 157.211242)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-54\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_57\">\n",
       "    <!-- 2987.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(384.710653 165.791728)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-57\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_58\">\n",
       "    <!-- 2447.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(405.847017 193.208664)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_59\">\n",
       "    <!-- 2841.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(426.983381 173.204455)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-56\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_60\">\n",
       "    <!-- 2147.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(448.119744 208.440296)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-52\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-55\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_61\">\n",
       "    <!-- 2531.0 -->\n",
       "    <g style=\"fill:#ff0000;\" transform=\"translate(469.256108 188.943808)scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#SimHei-50\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-51\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-49\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-46\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-48\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_62\">\n",
       "    <!-- 疫情状况-湖北 -->\n",
       "    <defs>\n",
       "     <path d=\"M 5.859375 61.71875 \n",
       "Q 9.375 62.5 13.28125 62.890625 \n",
       "Q 14.84375 53.125 15.234375 42.1875 \n",
       "Q 11.328125 41.796875 7.8125 41.40625 \n",
       "Q 7.421875 52.34375 5.859375 61.71875 \n",
       "z\n",
       "M 50 79.6875 \n",
       "Q 55.078125 80.859375 58.59375 82.03125 \n",
       "Q 60.546875 76.171875 61.71875 70.703125 \n",
       "L 78.90625 70.703125 \n",
       "Q 85.546875 70.703125 93.75 71.09375 \n",
       "L 93.75 64.453125 \n",
       "Q 85.9375 64.84375 78.90625 64.84375 \n",
       "L 28.125 64.84375 \n",
       "Q 27.734375 58.203125 27.921875 48.828125 \n",
       "Q 28.125 39.453125 27.34375 29.09375 \n",
       "Q 26.5625 18.75 23.828125 8.59375 \n",
       "Q 21.09375 -1.5625 15.234375 -9.765625 \n",
       "Q 11.71875 -7.421875 7.03125 -5.46875 \n",
       "Q 10.546875 -1.171875 13.28125 3.125 \n",
       "Q 16.015625 7.421875 17.96875 14.0625 \n",
       "Q 19.921875 20.703125 20.703125 30.078125 \n",
       "Q 11.71875 25 7.03125 21.09375 \n",
       "Q 5.859375 25.78125 3.90625 30.078125 \n",
       "Q 8.59375 32.03125 12.5 33.78125 \n",
       "Q 16.40625 35.546875 21.09375 37.5 \n",
       "L 21.09375 53.515625 \n",
       "Q 21.09375 65.625 20.703125 70.703125 \n",
       "L 52.734375 70.703125 \n",
       "Q 51.953125 75 50 79.6875 \n",
       "z\n",
       "M 44.140625 56.25 \n",
       "L 76.953125 56.25 \n",
       "Q 76.5625 53.515625 76.5625 48.046875 \n",
       "L 76.5625 43.359375 \n",
       "Q 76.5625 39.453125 80.078125 39.640625 \n",
       "Q 83.59375 39.84375 89.453125 40.625 \n",
       "Q 87.890625 36.328125 88.671875 33.59375 \n",
       "Q 76.5625 33.203125 73.046875 34.5625 \n",
       "Q 69.53125 35.9375 69.53125 40.234375 \n",
       "L 69.53125 50.390625 \n",
       "L 51.953125 50.390625 \n",
       "Q 52.734375 41.015625 50 36.71875 \n",
       "Q 47.265625 32.421875 40.625 28.90625 \n",
       "Q 38.671875 32.8125 33.59375 35.546875 \n",
       "Q 44.53125 37.890625 44.53125 44.328125 \n",
       "Q 44.53125 50.78125 44.140625 56.25 \n",
       "z\n",
       "M 35.15625 28.125 \n",
       "Q 41.796875 27.734375 49.609375 27.734375 \n",
       "L 85.15625 27.734375 \n",
       "Q 82.03125 22.65625 78.125 16.40625 \n",
       "Q 74.21875 10.15625 66.796875 3.125 \n",
       "Q 73.046875 0.390625 78.703125 -0.78125 \n",
       "Q 84.375 -1.953125 94.140625 -1.953125 \n",
       "Q 90.234375 -5.859375 90.234375 -10.546875 \n",
       "Q 81.25 -9.375 73.828125 -7.03125 \n",
       "Q 66.40625 -4.6875 60.546875 -0.78125 \n",
       "Q 47.265625 -7.8125 32.03125 -10.15625 \n",
       "Q 31.25 -7.03125 26.5625 -2.34375 \n",
       "Q 35.9375 -1.953125 41.59375 -0.78125 \n",
       "Q 47.265625 0.390625 54.6875 3.515625 \n",
       "Q 48.828125 9.375 42.578125 22.265625 \n",
       "Q 45.703125 22.265625 49.609375 22.65625 \n",
       "Q 53.125 15.625 55.265625 12.890625 \n",
       "Q 57.421875 10.15625 60.546875 7.421875 \n",
       "Q 67.96875 13.28125 73.4375 21.875 \n",
       "L 49.609375 21.875 \n",
       "Q 42.1875 21.875 35.15625 21.484375 \n",
       "z\n",
       "\" id=\"SimHei-30123\"/>\n",
       "     <path d=\"M 37.5 50 \n",
       "Q 33.984375 49.609375 31.25 48.046875 \n",
       "Q 30.078125 53.125 28.125 61.71875 \n",
       "Q 30.859375 62.109375 34.375 63.28125 \n",
       "Q 36.328125 54.6875 37.5 50 \n",
       "z\n",
       "M 18.75 81.25 \n",
       "L 26.5625 81.25 \n",
       "Q 26.171875 74.609375 26.171875 68.359375 \n",
       "L 26.171875 6.25 \n",
       "Q 26.171875 -1.953125 26.5625 -9.765625 \n",
       "L 18.75 -9.765625 \n",
       "Q 19.140625 -1.953125 19.140625 6.25 \n",
       "L 19.140625 67.1875 \n",
       "Q 19.140625 75 18.75 81.25 \n",
       "z\n",
       "M 55.078125 44.140625 \n",
       "Q 44.53125 44.140625 39.84375 43.75 \n",
       "L 39.84375 50 \n",
       "Q 46.484375 49.609375 54.6875 49.609375 \n",
       "L 62.109375 49.609375 \n",
       "L 62.109375 56.25 \n",
       "L 55.078125 56.25 \n",
       "Q 48.046875 56.25 42.96875 55.859375 \n",
       "L 42.96875 62.109375 \n",
       "Q 48.046875 61.71875 55.078125 61.71875 \n",
       "L 62.109375 61.71875 \n",
       "L 62.109375 67.578125 \n",
       "L 54.296875 67.578125 \n",
       "Q 47.65625 67.578125 41.40625 67.1875 \n",
       "L 41.40625 73.4375 \n",
       "Q 48.046875 73.046875 54.296875 73.046875 \n",
       "L 62.109375 73.046875 \n",
       "Q 62.109375 77.34375 61.71875 81.25 \n",
       "L 69.53125 81.25 \n",
       "Q 69.140625 77.34375 69.140625 73.046875 \n",
       "L 79.6875 73.046875 \n",
       "Q 86.328125 73.046875 92.1875 73.4375 \n",
       "L 92.1875 67.1875 \n",
       "Q 86.328125 67.578125 79.6875 67.578125 \n",
       "L 69.140625 67.578125 \n",
       "L 69.140625 61.71875 \n",
       "L 76.5625 61.71875 \n",
       "Q 82.421875 61.71875 89.453125 62.109375 \n",
       "L 89.453125 55.859375 \n",
       "Q 82.03125 56.25 76.5625 56.25 \n",
       "L 69.140625 56.25 \n",
       "L 69.140625 49.609375 \n",
       "L 80.46875 49.609375 \n",
       "Q 89.84375 49.609375 95.3125 50 \n",
       "L 95.3125 43.75 \n",
       "Q 89.84375 44.140625 80.078125 44.140625 \n",
       "z\n",
       "M 44.53125 -10.15625 \n",
       "Q 44.921875 -1.171875 44.921875 5.46875 \n",
       "L 44.921875 22.65625 \n",
       "Q 44.921875 31.640625 44.53125 39.0625 \n",
       "L 86.71875 39.0625 \n",
       "Q 86.328125 32.421875 86.328125 26.5625 \n",
       "L 86.328125 -2.734375 \n",
       "Q 86.328125 -7.03125 83.203125 -8.203125 \n",
       "Q 80.078125 -9.375 75.390625 -10.15625 \n",
       "Q 75 -6.640625 72.65625 -2.734375 \n",
       "Q 78.125 -2.734375 78.90625 -1.5625 \n",
       "Q 79.6875 -0.390625 79.6875 7.421875 \n",
       "L 51.953125 7.421875 \n",
       "L 51.953125 -10.15625 \n",
       "z\n",
       "M 51.953125 33.59375 \n",
       "L 51.953125 26.171875 \n",
       "L 79.296875 26.171875 \n",
       "L 79.296875 33.59375 \n",
       "z\n",
       "M 51.953125 20.703125 \n",
       "L 51.953125 12.890625 \n",
       "L 79.296875 12.890625 \n",
       "L 79.296875 20.703125 \n",
       "z\n",
       "M 9.375 61.71875 \n",
       "Q 12.890625 60.9375 16.40625 60.546875 \n",
       "Q 15.625 57.03125 12.109375 35.15625 \n",
       "Q 8.59375 36.328125 5.078125 36.71875 \n",
       "Q 7.03125 42.578125 9.375 61.71875 \n",
       "z\n",
       "\" id=\"SimHei-24773\"/>\n",
       "     <path d=\"M 43.75 -8.59375 \n",
       "Q 40.234375 -5.078125 35.9375 -3.125 \n",
       "Q 42.578125 1.5625 47.265625 8.390625 \n",
       "Q 51.953125 15.234375 54.6875 21.671875 \n",
       "Q 57.421875 28.125 58.59375 34.171875 \n",
       "Q 59.765625 40.234375 60.15625 44.921875 \n",
       "L 51.171875 44.921875 \n",
       "Q 45.3125 44.921875 39.84375 44.53125 \n",
       "L 39.84375 51.5625 \n",
       "Q 45.3125 51.171875 50.78125 51.171875 \n",
       "L 60.9375 51.171875 \n",
       "Q 60.9375 61.71875 60.734375 67.765625 \n",
       "Q 60.546875 73.828125 60.15625 78.515625 \n",
       "Q 64.84375 78.515625 69.53125 78.515625 \n",
       "Q 68.359375 73.4375 68.15625 68.359375 \n",
       "Q 67.96875 63.28125 67.96875 51.171875 \n",
       "L 83.984375 51.171875 \n",
       "Q 87.890625 51.171875 93.359375 51.5625 \n",
       "L 93.359375 44.53125 \n",
       "Q 87.890625 44.921875 83.984375 44.921875 \n",
       "L 68.359375 44.921875 \n",
       "Q 70.3125 32.8125 73.4375 25 \n",
       "Q 76.5625 17.1875 80.46875 12.6875 \n",
       "Q 84.375 8.203125 88.46875 5.65625 \n",
       "Q 92.578125 3.125 96.09375 1.171875 \n",
       "Q 90.625 -1.171875 87.890625 -7.03125 \n",
       "Q 82.03125 -1.953125 78.3125 2.734375 \n",
       "Q 74.609375 7.421875 72.0625 12.109375 \n",
       "Q 69.53125 16.796875 67.765625 21.484375 \n",
       "Q 66.015625 26.171875 64.84375 31.25 \n",
       "Q 62.890625 22.265625 60.15625 16.015625 \n",
       "Q 57.421875 9.765625 54.296875 4.875 \n",
       "Q 51.171875 0 43.75 -8.59375 \n",
       "z\n",
       "M 90.234375 62.5 \n",
       "Q 86.71875 60.15625 83.984375 57.8125 \n",
       "Q 81.640625 61.328125 79.484375 64.25 \n",
       "Q 77.34375 67.1875 74.609375 70.3125 \n",
       "Q 77.734375 72.65625 80.46875 74.609375 \n",
       "Q 83.59375 71.484375 85.734375 68.546875 \n",
       "Q 87.890625 65.625 90.234375 62.5 \n",
       "z\n",
       "M 7.03125 60.15625 \n",
       "Q 9.765625 62.109375 13.28125 64.0625 \n",
       "Q 15.625 60.546875 18.359375 56.640625 \n",
       "Q 21.09375 52.734375 23.4375 48.828125 \n",
       "Q 19.53125 46.484375 17.1875 44.140625 \n",
       "Q 14.84375 48.828125 12.6875 52.140625 \n",
       "Q 10.546875 55.46875 7.03125 60.15625 \n",
       "z\n",
       "M 12.109375 12.109375 \n",
       "Q 7.8125 16.015625 5.078125 18.359375 \n",
       "Q 9.765625 21.875 14.84375 26.75 \n",
       "Q 19.921875 31.640625 26.953125 40.234375 \n",
       "L 26.953125 30.078125 \n",
       "Q 24.21875 26.953125 19.140625 21.09375 \n",
       "Q 14.0625 15.234375 12.109375 12.109375 \n",
       "z\n",
       "M 26.5625 78.515625 \n",
       "L 34.765625 78.515625 \n",
       "Q 34.375 72.65625 34.375 64.453125 \n",
       "L 34.375 12.5 \n",
       "Q 34.375 1.953125 34.765625 -8.203125 \n",
       "L 26.5625 -8.203125 \n",
       "Q 26.953125 2.34375 26.953125 12.5 \n",
       "L 26.953125 64.453125 \n",
       "Q 26.953125 72.65625 26.5625 78.515625 \n",
       "z\n",
       "\" id=\"SimHei-29366\"/>\n",
       "     <path d=\"M 7.421875 66.015625 \n",
       "Q 11.328125 69.140625 13.671875 72.65625 \n",
       "Q 15.625 69.921875 20.109375 65.625 \n",
       "Q 24.609375 61.328125 28.90625 56.25 \n",
       "Q 25 53.515625 21.875 50.390625 \n",
       "Q 18.359375 55.078125 7.421875 66.015625 \n",
       "z\n",
       "M 22.265625 41.40625 \n",
       "Q 25.390625 36.71875 28.125 34.765625 \n",
       "Q 25 26.953125 20.703125 17.1875 \n",
       "Q 16.40625 7.421875 14.0625 1.5625 \n",
       "Q 10.15625 6.25 7.03125 8.59375 \n",
       "Q 12.5 17.1875 15.625 23.828125 \n",
       "Q 18.75 30.46875 22.265625 41.40625 \n",
       "z\n",
       "M 36.71875 73.4375 \n",
       "L 84.375 73.4375 \n",
       "Q 83.59375 67.578125 83.59375 55.265625 \n",
       "Q 83.59375 42.96875 84.375 35.546875 \n",
       "L 70.3125 35.546875 \n",
       "L 70.3125 7.421875 \n",
       "Q 70.3125 2.34375 73.046875 1.953125 \n",
       "Q 75.78125 1.5625 79.296875 1.75 \n",
       "Q 82.8125 1.953125 83.59375 4.484375 \n",
       "Q 84.375 7.03125 84.765625 15.234375 \n",
       "Q 89.453125 11.328125 94.140625 10.546875 \n",
       "Q 91.40625 -1.953125 88.078125 -3.515625 \n",
       "Q 84.765625 -5.078125 77.921875 -5.265625 \n",
       "Q 71.09375 -5.46875 67.1875 -4.484375 \n",
       "Q 63.28125 -3.515625 63.28125 4.296875 \n",
       "L 63.28125 35.546875 \n",
       "L 53.90625 35.546875 \n",
       "Q 54.296875 1.5625 28.90625 -10.15625 \n",
       "Q 26.953125 -5.46875 21.875 -2.34375 \n",
       "Q 47.265625 3.90625 46.484375 35.546875 \n",
       "L 36.71875 35.546875 \n",
       "Q 37.109375 42.96875 37.109375 55.46875 \n",
       "Q 37.109375 67.96875 36.71875 73.4375 \n",
       "z\n",
       "M 44.921875 67.1875 \n",
       "L 44.921875 41.796875 \n",
       "L 75.78125 41.796875 \n",
       "L 75.78125 67.1875 \n",
       "z\n",
       "\" id=\"SimHei-20917\"/>\n",
       "     <path d=\"M 10.15625 71.484375 \n",
       "Q 12.5 74.609375 14.453125 77.34375 \n",
       "Q 17.96875 74.609375 21.484375 72.0625 \n",
       "Q 25 69.53125 28.90625 66.796875 \n",
       "Q 25.78125 63.671875 23.828125 60.9375 \n",
       "Q 19.921875 64.453125 16.984375 66.796875 \n",
       "Q 14.0625 69.140625 10.15625 71.484375 \n",
       "z\n",
       "M 5.859375 48.046875 \n",
       "Q 8.203125 50.78125 9.765625 53.90625 \n",
       "Q 14.0625 51.171875 17.1875 49.21875 \n",
       "Q 20.3125 47.265625 26.171875 43.359375 \n",
       "Q 23.4375 40.234375 21.875 37.109375 \n",
       "Q 17.1875 40.625 14.0625 42.765625 \n",
       "Q 10.9375 44.921875 5.859375 48.046875 \n",
       "z\n",
       "M 20.3125 28.90625 \n",
       "Q 23.046875 25.390625 26.171875 23.828125 \n",
       "Q 22.65625 16.40625 20.5 11.328125 \n",
       "Q 18.359375 6.25 16.40625 1.953125 \n",
       "Q 14.453125 -2.34375 12.890625 -7.03125 \n",
       "Q 8.59375 -4.296875 5.078125 -3.125 \n",
       "Q 9.375 3.125 13.671875 12.5 \n",
       "Q 17.96875 21.875 20.3125 28.90625 \n",
       "z\n",
       "M 37.5 32.421875 \n",
       "L 37.5 17.578125 \n",
       "L 49.21875 17.578125 \n",
       "L 49.21875 32.421875 \n",
       "z\n",
       "M 70.703125 69.140625 \n",
       "L 70.703125 51.953125 \n",
       "L 84.375 51.953125 \n",
       "L 84.375 69.140625 \n",
       "z\n",
       "M 70.703125 46.09375 \n",
       "Q 70.3125 33.984375 70.3125 29.6875 \n",
       "L 84.375 29.6875 \n",
       "L 84.375 46.09375 \n",
       "z\n",
       "M 55.859375 38.28125 \n",
       "Q 55.46875 32.421875 55.46875 24.015625 \n",
       "Q 55.46875 15.625 55.859375 5.859375 \n",
       "L 49.21875 5.859375 \n",
       "L 49.21875 11.71875 \n",
       "L 37.5 11.71875 \n",
       "L 37.5 1.953125 \n",
       "L 30.859375 1.953125 \n",
       "Q 31.25 7.03125 31.25 19.53125 \n",
       "Q 31.25 32.03125 30.859375 38.28125 \n",
       "L 40.625 38.28125 \n",
       "L 40.625 53.515625 \n",
       "Q 32.03125 53.515625 27.734375 53.125 \n",
       "L 27.734375 59.765625 \n",
       "Q 32.03125 59.375 40.625 59.375 \n",
       "L 40.625 68.75 \n",
       "Q 40.625 73.4375 40.234375 80.078125 \n",
       "L 47.265625 80.078125 \n",
       "Q 46.875 74.21875 46.875 68.75 \n",
       "L 46.875 59.375 \n",
       "Q 54.6875 59.375 59.375 59.765625 \n",
       "L 59.375 53.125 \n",
       "Q 54.296875 53.515625 46.875 53.515625 \n",
       "L 46.875 38.28125 \n",
       "z\n",
       "M 64.0625 75 \n",
       "L 91.015625 75 \n",
       "Q 90.625 66.796875 90.625 61.328125 \n",
       "L 90.625 2.734375 \n",
       "Q 89.84375 -3.90625 86.328125 -5.65625 \n",
       "Q 82.8125 -7.421875 76.5625 -8.203125 \n",
       "Q 75.390625 -4.296875 73.4375 -0.390625 \n",
       "Q 79.6875 -0.78125 81.828125 -0.1875 \n",
       "Q 83.984375 0.390625 84.375 5.078125 \n",
       "L 84.375 23.828125 \n",
       "L 69.921875 23.828125 \n",
       "Q 69.140625 17.1875 66.984375 10.734375 \n",
       "Q 64.84375 4.296875 61.125 -0.96875 \n",
       "Q 57.421875 -6.25 53.90625 -10.15625 \n",
       "Q 51.171875 -7.8125 46.09375 -5.859375 \n",
       "Q 52.734375 -1.5625 56.640625 4.484375 \n",
       "Q 60.546875 10.546875 62.109375 17.96875 \n",
       "Q 63.671875 25.390625 64.0625 35.34375 \n",
       "Q 64.453125 45.3125 64.453125 56.4375 \n",
       "Q 64.453125 67.578125 64.0625 75 \n",
       "z\n",
       "\" id=\"SimHei-28246\"/>\n",
       "     <path d=\"M 9.765625 50.78125 \n",
       "Q 16.015625 50.390625 20.703125 50.390625 \n",
       "L 33.984375 50.390625 \n",
       "L 33.984375 69.140625 \n",
       "Q 33.984375 72.65625 33.59375 77.734375 \n",
       "L 42.1875 77.734375 \n",
       "Q 41.40625 72.65625 41.40625 69.140625 \n",
       "L 41.40625 4.6875 \n",
       "Q 41.40625 0.390625 41.796875 -5.859375 \n",
       "L 33.59375 -5.859375 \n",
       "Q 33.984375 0.390625 33.984375 7.421875 \n",
       "Q 26.171875 5.46875 19.71875 3.3125 \n",
       "Q 13.28125 1.171875 10.15625 -0.78125 \n",
       "Q 8.203125 3.90625 5.46875 8.984375 \n",
       "Q 10.546875 9.375 19.71875 11.328125 \n",
       "Q 28.90625 13.28125 33.984375 14.84375 \n",
       "L 33.984375 43.359375 \n",
       "L 20.703125 43.359375 \n",
       "Q 16.015625 43.359375 9.765625 42.96875 \n",
       "z\n",
       "M 55.46875 77.734375 \n",
       "L 63.671875 77.734375 \n",
       "Q 63.28125 73.4375 63.28125 69.921875 \n",
       "L 63.28125 44.140625 \n",
       "Q 73.828125 48.4375 85.9375 58.59375 \n",
       "Q 88.671875 54.296875 92.96875 50 \n",
       "Q 88.28125 49.21875 79.09375 44.53125 \n",
       "Q 69.921875 39.84375 63.28125 37.109375 \n",
       "L 63.28125 7.8125 \n",
       "Q 63.28125 1.953125 69.140625 1.953125 \n",
       "L 78.515625 1.953125 \n",
       "Q 83.203125 1.953125 84.375 3.90625 \n",
       "Q 85.546875 5.859375 86.71875 13.28125 \n",
       "Q 90.234375 9.375 95.703125 8.59375 \n",
       "Q 92.578125 0.390625 90.234375 -2.34375 \n",
       "Q 87.890625 -5.078125 83.203125 -5.078125 \n",
       "L 65.234375 -5.078125 \n",
       "Q 55.859375 -5.078125 55.859375 4.6875 \n",
       "L 55.859375 69.921875 \n",
       "Q 55.859375 72.65625 55.46875 77.734375 \n",
       "z\n",
       "\" id=\"SimHei-21271\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(287.301562 16.7625)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#SimHei-30123\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-24773\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-29366\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-20917\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-45\"/>\n",
       "     <use x=\"450\" xlink:href=\"#SimHei-28246\"/>\n",
       "     <use x=\"550\" xlink:href=\"#SimHei-21271\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 54.301563 59.35625 \n",
       "L 166.301562 59.35625 \n",
       "Q 168.301562 59.35625 168.301562 57.35625 \n",
       "L 168.301562 29.7625 \n",
       "Q 168.301562 27.7625 166.301562 27.7625 \n",
       "L 54.301563 27.7625 \n",
       "Q 52.301563 27.7625 52.301563 29.7625 \n",
       "L 52.301563 57.35625 \n",
       "Q 52.301563 59.35625 54.301563 59.35625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 56.301563 36.270312 \n",
       "L 76.301563 36.270312 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <g>\n",
       "      <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"66.301563\" xlink:href=\"#m82bc647565\" y=\"36.270312\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_63\">\n",
       "     <!-- 新增确诊人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 26.171875 78.515625 \n",
       "Q 29.6875 79.296875 33.984375 80.46875 \n",
       "Q 35.9375 72.65625 36.328125 69.53125 \n",
       "Q 44.921875 69.53125 52.34375 69.921875 \n",
       "L 52.34375 62.5 \n",
       "Q 44.53125 62.890625 39.453125 62.890625 \n",
       "L 21.484375 62.890625 \n",
       "Q 15.234375 62.890625 9.375 62.5 \n",
       "L 9.375 69.921875 \n",
       "Q 15.625 69.53125 21.484375 69.53125 \n",
       "L 28.515625 69.53125 \n",
       "Q 27.734375 73.828125 26.171875 78.515625 \n",
       "z\n",
       "M 15.234375 57.8125 \n",
       "Q 17.96875 59.375 21.09375 60.546875 \n",
       "Q 23.828125 55.078125 25.78125 50 \n",
       "Q 22.265625 49.21875 19.53125 47.65625 \n",
       "Q 17.578125 53.515625 15.234375 57.8125 \n",
       "z\n",
       "M 38.28125 60.9375 \n",
       "Q 41.40625 60.15625 46.484375 58.59375 \n",
       "Q 44.140625 57.03125 40.625 46.875 \n",
       "Q 46.875 46.875 53.90625 47.265625 \n",
       "L 53.90625 39.84375 \n",
       "Q 47.265625 40.234375 34.765625 40.234375 \n",
       "L 34.765625 30.46875 \n",
       "Q 46.09375 30.46875 53.125 30.859375 \n",
       "L 53.125 23.4375 \n",
       "Q 46.09375 23.828125 34.765625 23.828125 \n",
       "L 34.765625 0.78125 \n",
       "Q 34.765625 -5.078125 31.25 -6.828125 \n",
       "Q 27.734375 -8.59375 21.875 -8.59375 \n",
       "Q 20.703125 -4.296875 18.359375 -0.390625 \n",
       "Q 23.4375 -0.78125 25.578125 -0.390625 \n",
       "Q 27.734375 0 27.734375 3.125 \n",
       "L 27.734375 23.828125 \n",
       "Q 15.625 23.828125 8.984375 23.4375 \n",
       "L 8.984375 30.859375 \n",
       "Q 16.015625 30.46875 27.734375 30.46875 \n",
       "L 27.734375 40.234375 \n",
       "Q 13.671875 40.234375 7.03125 39.84375 \n",
       "L 7.03125 47.265625 \n",
       "Q 13.671875 46.875 19.921875 46.875 \n",
       "L 33.984375 46.875 \n",
       "Q 37.109375 55.859375 38.28125 60.9375 \n",
       "z\n",
       "M 17.96875 21.484375 \n",
       "Q 21.484375 18.359375 25 16.796875 \n",
       "Q 22.65625 14.0625 19.71875 9.953125 \n",
       "Q 16.796875 5.859375 11.328125 -1.171875 \n",
       "Q 8.59375 1.5625 5.46875 3.515625 \n",
       "Q 13.28125 12.109375 17.96875 21.484375 \n",
       "z\n",
       "M 37.5 16.40625 \n",
       "Q 39.84375 18.359375 42.96875 20.3125 \n",
       "Q 47.265625 14.453125 51.171875 7.8125 \n",
       "Q 47.265625 5.859375 45.3125 3.125 \n",
       "Q 42.1875 9.765625 37.5 16.40625 \n",
       "z\n",
       "M 88.671875 79.296875 \n",
       "Q 91.796875 73.4375 93.75 71.09375 \n",
       "Q 87.890625 71.09375 66.015625 68.75 \n",
       "L 66.015625 49.609375 \n",
       "L 85.546875 49.609375 \n",
       "Q 89.453125 49.609375 94.140625 50 \n",
       "L 94.140625 42.578125 \n",
       "Q 88.671875 42.96875 85.15625 42.96875 \n",
       "L 85.15625 4.296875 \n",
       "Q 85.15625 -2.34375 85.546875 -9.375 \n",
       "L 77.734375 -9.375 \n",
       "Q 78.125 -2.34375 78.125 3.90625 \n",
       "L 78.125 42.96875 \n",
       "L 66.015625 42.96875 \n",
       "Q 66.015625 33.59375 65.234375 25 \n",
       "Q 64.453125 16.40625 62.109375 7.8125 \n",
       "Q 59.765625 -0.78125 54.6875 -9.765625 \n",
       "Q 51.171875 -7.8125 47.265625 -6.25 \n",
       "Q 53.515625 2.734375 55.859375 12.296875 \n",
       "Q 58.203125 21.875 58.59375 29.09375 \n",
       "Q 58.984375 36.328125 58.984375 50.96875 \n",
       "Q 58.984375 65.625 58.59375 74.21875 \n",
       "Q 75.390625 75 88.671875 79.296875 \n",
       "z\n",
       "\" id=\"SimHei-26032\"/>\n",
       "      <path d=\"M 54.296875 79.6875 \n",
       "Q 55.859375 77.34375 60.15625 71.09375 \n",
       "Q 56.640625 69.140625 53.90625 67.1875 \n",
       "Q 52.34375 69.53125 48.046875 76.171875 \n",
       "Q 50.78125 77.734375 54.296875 79.6875 \n",
       "z\n",
       "M 74.21875 81.25 \n",
       "Q 78.90625 78.90625 83.203125 77.34375 \n",
       "Q 81.25 75 79.296875 71.671875 \n",
       "Q 77.34375 68.359375 76.171875 65.625 \n",
       "L 91.796875 65.625 \n",
       "Q 91.40625 61.328125 91.40625 54.6875 \n",
       "L 91.40625 44.140625 \n",
       "Q 91.40625 37.109375 91.796875 32.8125 \n",
       "L 38.28125 32.8125 \n",
       "Q 38.671875 39.84375 38.671875 44.921875 \n",
       "L 38.671875 55.859375 \n",
       "Q 38.671875 62.109375 38.28125 65.625 \n",
       "L 69.53125 65.625 \n",
       "Q 73.046875 75.390625 74.21875 81.25 \n",
       "z\n",
       "M 45.703125 60.15625 \n",
       "L 45.703125 38.28125 \n",
       "L 60.9375 38.28125 \n",
       "L 60.9375 60.15625 \n",
       "z\n",
       "M 67.96875 60.15625 \n",
       "L 67.96875 38.28125 \n",
       "L 84.375 38.28125 \n",
       "L 84.375 60.15625 \n",
       "z\n",
       "M 51.953125 42.578125 \n",
       "Q 50 48.046875 47.65625 51.953125 \n",
       "Q 50 53.515625 53.90625 55.078125 \n",
       "Q 55.078125 52.734375 58.203125 45.703125 \n",
       "Q 55.078125 44.53125 51.953125 42.578125 \n",
       "z\n",
       "M 74.609375 55.46875 \n",
       "Q 77.734375 53.515625 81.640625 52.34375 \n",
       "Q 80.46875 50 77.34375 42.96875 \n",
       "Q 73.828125 44.53125 71.09375 45.3125 \n",
       "Q 73.046875 50.390625 74.609375 55.46875 \n",
       "z\n",
       "M 42.578125 26.5625 \n",
       "L 87.890625 26.5625 \n",
       "Q 87.5 21.484375 87.5 17.96875 \n",
       "L 87.5 2.734375 \n",
       "Q 87.5 -3.90625 87.890625 -8.59375 \n",
       "L 80.46875 -8.59375 \n",
       "L 80.46875 -3.515625 \n",
       "L 50 -3.515625 \n",
       "L 50 -8.59375 \n",
       "L 42.578125 -8.59375 \n",
       "Q 42.96875 -0.390625 42.96875 1.953125 \n",
       "L 42.96875 17.578125 \n",
       "Q 42.96875 21.875 42.578125 26.5625 \n",
       "z\n",
       "M 50 21.09375 \n",
       "L 50 14.0625 \n",
       "L 80.46875 14.0625 \n",
       "L 80.46875 21.09375 \n",
       "z\n",
       "M 50 8.59375 \n",
       "L 50 1.953125 \n",
       "L 80.46875 1.953125 \n",
       "L 80.46875 8.59375 \n",
       "z\n",
       "M 25 15.625 \n",
       "Q 32.421875 17.1875 35.9375 18.359375 \n",
       "L 35.9375 12.109375 \n",
       "Q 31.25 11.328125 21.875 8.390625 \n",
       "Q 12.5 5.46875 6.640625 2.734375 \n",
       "Q 5.46875 7.03125 3.90625 11.328125 \n",
       "Q 7.421875 11.71875 10.9375 12.5 \n",
       "Q 14.453125 13.28125 17.96875 14.0625 \n",
       "L 17.96875 45.703125 \n",
       "L 15.625 45.703125 \n",
       "Q 10.9375 45.703125 5.078125 45.3125 \n",
       "L 5.078125 51.5625 \n",
       "Q 10.9375 51.171875 15.625 51.171875 \n",
       "L 17.96875 51.171875 \n",
       "L 17.96875 65.625 \n",
       "Q 17.96875 69.53125 17.578125 75 \n",
       "L 25.390625 75 \n",
       "Q 25 69.140625 25 65.625 \n",
       "L 25 51.171875 \n",
       "L 27.734375 51.171875 \n",
       "Q 32.03125 51.171875 35.9375 51.5625 \n",
       "L 35.9375 45.3125 \n",
       "Q 30.859375 45.703125 27.734375 45.703125 \n",
       "L 25 45.703125 \n",
       "z\n",
       "\" id=\"SimHei-22686\"/>\n",
       "      <path d=\"M 21.484375 39.84375 \n",
       "L 21.484375 14.84375 \n",
       "L 32.03125 14.84375 \n",
       "L 32.03125 39.84375 \n",
       "z\n",
       "M 10.15625 25 \n",
       "Q 7.8125 28.125 3.515625 30.46875 \n",
       "Q 8.984375 35.546875 13.671875 43.9375 \n",
       "Q 18.359375 52.34375 20.703125 65.234375 \n",
       "Q 13.28125 65.234375 8.59375 64.84375 \n",
       "L 8.59375 71.09375 \n",
       "Q 14.0625 70.703125 19.140625 70.703125 \n",
       "L 29.296875 70.703125 \n",
       "Q 35.9375 70.703125 40.625 71.09375 \n",
       "L 40.625 64.84375 \n",
       "Q 35.9375 65.234375 27.734375 65.234375 \n",
       "Q 25.390625 54.6875 22.265625 45.3125 \n",
       "L 38.671875 45.3125 \n",
       "Q 38.28125 38.671875 38.28125 32.8125 \n",
       "L 38.28125 16.40625 \n",
       "Q 38.28125 10.15625 38.671875 1.953125 \n",
       "L 32.03125 1.953125 \n",
       "L 32.03125 9.375 \n",
       "L 21.484375 9.375 \n",
       "L 21.484375 -4.6875 \n",
       "L 14.84375 -4.6875 \n",
       "Q 15.234375 3.515625 15.234375 9.375 \n",
       "L 15.234375 33.203125 \n",
       "Q 12.890625 29.296875 10.15625 25 \n",
       "z\n",
       "M 70.3125 30.859375 \n",
       "L 70.3125 20.3125 \n",
       "L 83.203125 20.3125 \n",
       "L 83.203125 30.859375 \n",
       "z\n",
       "M 78.515625 -10.546875 \n",
       "Q 78.125 -6.640625 75.390625 -3.125 \n",
       "Q 80.078125 -3.125 81.640625 -2.53125 \n",
       "Q 83.203125 -1.953125 83.203125 1.953125 \n",
       "L 83.203125 14.84375 \n",
       "L 70.3125 14.84375 \n",
       "L 70.3125 -6.25 \n",
       "L 64.0625 -6.25 \n",
       "L 64.0625 14.84375 \n",
       "L 53.515625 14.84375 \n",
       "Q 53.125 9.765625 50.78125 3.703125 \n",
       "Q 48.4375 -2.34375 42.578125 -9.375 \n",
       "Q 39.84375 -5.46875 35.546875 -4.6875 \n",
       "Q 40.234375 -0.390625 42.765625 4.484375 \n",
       "Q 45.3125 9.375 46.09375 15.625 \n",
       "Q 46.875 21.875 47.0625 33.78125 \n",
       "Q 47.265625 45.703125 46.875 53.125 \n",
       "L 64.84375 53.125 \n",
       "Q 68.359375 59.375 70.703125 65.234375 \n",
       "L 55.46875 65.234375 \n",
       "Q 52.34375 60.15625 44.921875 50.390625 \n",
       "Q 41.796875 53.125 38.28125 54.296875 \n",
       "Q 45.703125 61.71875 49.21875 68.15625 \n",
       "Q 52.734375 74.609375 55.46875 82.03125 \n",
       "Q 59.765625 80.078125 64.0625 78.90625 \n",
       "Q 62.109375 77.734375 58.59375 70.703125 \n",
       "L 81.25 70.703125 \n",
       "Q 74.609375 58.59375 72.65625 53.125 \n",
       "L 89.84375 53.125 \n",
       "Q 89.453125 46.09375 89.453125 37.890625 \n",
       "L 89.453125 -0.78125 \n",
       "Q 89.84375 -5.46875 87.5 -7.21875 \n",
       "Q 85.15625 -8.984375 78.515625 -10.546875 \n",
       "z\n",
       "M 53.515625 47.65625 \n",
       "L 53.515625 36.328125 \n",
       "L 64.0625 36.328125 \n",
       "L 64.0625 47.65625 \n",
       "z\n",
       "M 53.515625 30.859375 \n",
       "L 53.515625 20.3125 \n",
       "L 64.0625 20.3125 \n",
       "L 64.0625 30.859375 \n",
       "z\n",
       "M 70.3125 47.65625 \n",
       "L 70.3125 36.328125 \n",
       "L 83.203125 36.328125 \n",
       "L 83.203125 47.65625 \n",
       "z\n",
       "\" id=\"SimHei-30830\"/>\n",
       "      <path d=\"M 12.5 71.484375 \n",
       "Q 15.234375 73.828125 18.75 76.171875 \n",
       "Q 22.265625 72.265625 29.6875 62.890625 \n",
       "Q 26.171875 60.546875 23.4375 57.8125 \n",
       "Q 16.796875 66.796875 12.5 71.484375 \n",
       "z\n",
       "M 26.171875 12.5 \n",
       "Q 30.078125 17.1875 32.421875 20.3125 \n",
       "Q 34.765625 16.796875 37.5 12.890625 \n",
       "Q 33.203125 8.203125 29.296875 3.90625 \n",
       "Q 25.390625 -0.390625 21.09375 -6.640625 \n",
       "Q 17.578125 -3.90625 14.0625 -1.171875 \n",
       "Q 16.015625 1.171875 17.1875 3.125 \n",
       "Q 18.359375 5.078125 18.359375 8.203125 \n",
       "L 18.359375 42.1875 \n",
       "L 15.234375 42.1875 \n",
       "Q 10.15625 42.1875 4.6875 41.796875 \n",
       "L 4.6875 48.828125 \n",
       "Q 9.765625 48.4375 15.234375 48.4375 \n",
       "L 26.5625 48.4375 \n",
       "Q 26.171875 41.40625 26.171875 33.59375 \n",
       "z\n",
       "M 37.5 38.28125 \n",
       "Q 35.15625 40.234375 29.296875 43.75 \n",
       "Q 34.765625 46.875 39.25 50.78125 \n",
       "Q 43.75 54.6875 47.0625 59.375 \n",
       "Q 50.390625 64.0625 52.734375 69.328125 \n",
       "Q 55.078125 74.609375 56.640625 80.46875 \n",
       "Q 61.328125 78.90625 67.1875 77.34375 \n",
       "L 66.015625 73.828125 \n",
       "Q 69.53125 63.28125 76.953125 58.390625 \n",
       "Q 84.375 53.515625 93.75 50.390625 \n",
       "Q 91.796875 48.046875 87.890625 41.40625 \n",
       "Q 76.171875 47.265625 69.71875 55.265625 \n",
       "Q 63.28125 63.28125 60.9375 69.140625 \n",
       "Q 57.421875 62.5 52.921875 55.265625 \n",
       "Q 48.4375 48.046875 37.5 38.28125 \n",
       "z\n",
       "M 62.5 52.34375 \n",
       "Q 65.234375 49.609375 69.140625 46.484375 \n",
       "Q 63.28125 40.234375 57.21875 34.765625 \n",
       "Q 51.171875 29.296875 44.53125 24.609375 \n",
       "Q 41.40625 28.125 38.671875 31.25 \n",
       "Q 44.53125 33.984375 50.96875 39.25 \n",
       "Q 57.421875 44.53125 62.5 52.34375 \n",
       "z\n",
       "M 48.046875 7.421875 \n",
       "Q 45.703125 10.9375 42.578125 14.453125 \n",
       "Q 52.734375 17.96875 61.328125 25.578125 \n",
       "Q 69.921875 33.203125 73.4375 40.625 \n",
       "Q 77.34375 37.109375 80.859375 33.984375 \n",
       "Q 76.5625 29.6875 71.484375 24.015625 \n",
       "Q 66.40625 18.359375 59.5625 14.0625 \n",
       "Q 52.734375 9.765625 48.046875 7.421875 \n",
       "z\n",
       "M 43.359375 -10.9375 \n",
       "Q 40.625 -6.640625 38.28125 -3.125 \n",
       "Q 45.703125 -1.953125 52.734375 0.78125 \n",
       "Q 59.765625 3.515625 65.625 7.421875 \n",
       "Q 71.484375 11.328125 76.171875 16.015625 \n",
       "Q 80.859375 20.703125 84.765625 25.78125 \n",
       "Q 87.5 21.484375 92.1875 18.359375 \n",
       "Q 88.28125 16.015625 84.5625 12.6875 \n",
       "Q 80.859375 9.375 76.171875 5.265625 \n",
       "Q 71.484375 1.171875 62.6875 -3.125 \n",
       "Q 53.90625 -7.421875 43.359375 -10.9375 \n",
       "z\n",
       "\" id=\"SimHei-35786\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(84.301563 39.770312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-26032\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-22686\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-30830\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-35786\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 56.301563 50.567187 \n",
       "L 76.301563 50.567187 \n",
       "\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <g>\n",
       "      <use style=\"fill:#0000ff;stroke:#0000ff;\" x=\"66.301563\" xlink:href=\"#m35e814b78a\" y=\"50.567187\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_64\">\n",
       "     <!-- 新增累计确诊人数 -->\n",
       "     <defs>\n",
       "      <path d=\"M 16.015625 77.734375 \n",
       "L 86.71875 77.734375 \n",
       "Q 86.328125 71.875 86.328125 62.109375 \n",
       "Q 86.328125 52.34375 86.71875 46.09375 \n",
       "L 73.046875 46.09375 \n",
       "Q 76.171875 43.359375 80.46875 40.234375 \n",
       "Q 75.390625 39.0625 67.1875 35.34375 \n",
       "Q 58.984375 31.640625 52.34375 28.703125 \n",
       "Q 45.703125 25.78125 38.671875 22.65625 \n",
       "Q 60.546875 23.828125 72.65625 24.21875 \n",
       "Q 69.140625 26.5625 64.84375 28.515625 \n",
       "Q 67.96875 30.859375 70.703125 33.203125 \n",
       "Q 80.078125 27.734375 91.796875 20.703125 \n",
       "Q 89.0625 17.96875 85.9375 14.84375 \n",
       "Q 82.8125 17.578125 78.90625 19.921875 \n",
       "Q 66.40625 19.140625 55.46875 18.359375 \n",
       "L 55.46875 0.78125 \n",
       "Q 55.46875 -4.6875 51.359375 -6.25 \n",
       "Q 47.265625 -7.8125 41.015625 -8.984375 \n",
       "Q 40.234375 -4.6875 38.28125 0 \n",
       "Q 45.3125 0 46.875 0.578125 \n",
       "Q 48.4375 1.171875 48.4375 4.296875 \n",
       "L 48.4375 17.96875 \n",
       "Q 37.890625 17.1875 32.21875 16.59375 \n",
       "Q 26.5625 16.015625 15.625 13.671875 \n",
       "Q 14.453125 17.578125 12.890625 21.875 \n",
       "Q 21.484375 22.65625 27.921875 24.609375 \n",
       "Q 34.375 26.5625 49.609375 33.984375 \n",
       "Q 45.3125 33.203125 37.890625 32.609375 \n",
       "Q 30.46875 32.03125 21.484375 29.6875 \n",
       "Q 20.703125 33.984375 18.75 37.109375 \n",
       "Q 23.4375 37.5 29.484375 40.03125 \n",
       "Q 35.546875 42.578125 39.84375 46.09375 \n",
       "L 16.015625 46.09375 \n",
       "Q 16.40625 52.734375 16.40625 62.296875 \n",
       "Q 16.40625 71.875 16.015625 77.734375 \n",
       "z\n",
       "M 23.4375 72.65625 \n",
       "L 23.4375 64.0625 \n",
       "L 47.265625 64.0625 \n",
       "L 47.265625 72.65625 \n",
       "z\n",
       "M 23.4375 58.984375 \n",
       "L 23.4375 51.171875 \n",
       "L 47.265625 51.171875 \n",
       "L 47.265625 58.984375 \n",
       "z\n",
       "M 54.296875 72.65625 \n",
       "L 54.296875 64.0625 \n",
       "L 79.296875 64.0625 \n",
       "L 79.296875 72.65625 \n",
       "z\n",
       "M 54.296875 58.984375 \n",
       "L 54.296875 51.171875 \n",
       "L 79.296875 51.171875 \n",
       "L 79.296875 58.984375 \n",
       "z\n",
       "M 37.890625 37.890625 \n",
       "Q 48.828125 38.28125 58.984375 38.671875 \n",
       "Q 66.40625 42.1875 71.484375 46.09375 \n",
       "L 51.5625 46.09375 \n",
       "Q 46.875 42.96875 37.890625 37.890625 \n",
       "z\n",
       "M 32.421875 13.671875 \n",
       "Q 34.765625 10.9375 39.453125 7.8125 \n",
       "Q 35.15625 6.25 29.484375 2.53125 \n",
       "Q 23.828125 -1.171875 16.796875 -5.859375 \n",
       "Q 13.671875 -2.734375 9.765625 -0.390625 \n",
       "Q 15.625 1.953125 21.484375 5.65625 \n",
       "Q 27.34375 9.375 32.421875 13.671875 \n",
       "z\n",
       "M 62.890625 8.203125 \n",
       "Q 66.015625 11.328125 67.96875 14.0625 \n",
       "Q 73.046875 11.71875 78.703125 9.171875 \n",
       "Q 84.375 6.640625 91.796875 3.125 \n",
       "Q 89.0625 -0.390625 87.109375 -3.90625 \n",
       "Q 80.46875 0.390625 74.609375 3.125 \n",
       "Q 68.75 5.859375 62.890625 8.203125 \n",
       "z\n",
       "\" id=\"SimHei-32047\"/>\n",
       "      <path d=\"M 15.234375 72.265625 \n",
       "Q 17.96875 74.21875 22.265625 76.5625 \n",
       "Q 23.828125 73.828125 32.421875 61.328125 \n",
       "Q 28.90625 59.375 25 57.03125 \n",
       "Q 23.046875 60.546875 15.234375 72.265625 \n",
       "z\n",
       "M 5.46875 47.65625 \n",
       "Q 11.328125 47.265625 13.28125 47.265625 \n",
       "L 27.34375 47.265625 \n",
       "Q 26.953125 40.234375 26.953125 32.421875 \n",
       "L 26.953125 7.8125 \n",
       "Q 32.8125 14.453125 37.5 19.921875 \n",
       "Q 38.671875 16.015625 41.40625 13.28125 \n",
       "Q 37.890625 8.984375 32.609375 3.515625 \n",
       "Q 27.34375 -1.953125 23.4375 -7.8125 \n",
       "Q 19.53125 -4.296875 16.015625 -2.34375 \n",
       "Q 19.53125 2.34375 19.53125 8.203125 \n",
       "L 19.53125 40.625 \n",
       "Q 10.15625 40.625 5.46875 39.84375 \n",
       "z\n",
       "M 37.109375 47.65625 \n",
       "Q 42.96875 47.265625 48.828125 47.265625 \n",
       "L 63.28125 47.265625 \n",
       "L 63.28125 67.96875 \n",
       "Q 63.28125 72.65625 62.890625 76.953125 \n",
       "L 71.09375 76.953125 \n",
       "Q 70.703125 71.875 70.703125 67.96875 \n",
       "L 70.703125 47.265625 \n",
       "L 85.546875 47.265625 \n",
       "Q 89.0625 47.265625 94.53125 47.65625 \n",
       "L 94.53125 40.234375 \n",
       "Q 88.671875 40.625 85.9375 40.625 \n",
       "L 70.703125 40.625 \n",
       "L 70.703125 3.125 \n",
       "Q 70.703125 -3.125 71.09375 -9.765625 \n",
       "L 62.890625 -9.765625 \n",
       "Q 63.28125 -3.125 63.28125 2.734375 \n",
       "L 63.28125 40.625 \n",
       "L 49.21875 40.625 \n",
       "Q 42.96875 40.625 37.109375 40.234375 \n",
       "z\n",
       "\" id=\"SimHei-35745\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(84.301563 54.067187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#SimHei-26032\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-22686\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-32047\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-35745\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-30830\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-35786\"/>\n",
       "      <use x=\"600\" xlink:href=\"#SimHei-20154\"/>\n",
       "      <use x=\"700\" xlink:href=\"#SimHei-25968\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pb25375afca\">\n",
       "   <rect height=\"326.16\" width=\"558\" x=\"47.301563\" y=\"22.7625\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model_predict(model_city_date_path, data_hubei, city_name='湖北')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>new_confirmed</th>\n",
       "      <th>suspected</th>\n",
       "      <th>new_suspected</th>\n",
       "      <th>dead</th>\n",
       "      <th>new_death</th>\n",
       "      <th>cured</th>\n",
       "      <th>new_cured</th>\n",
       "      <th>close_contact</th>\n",
       "      <th>under_medical_observation</th>\n",
       "      <th>quit_medical_observation</th>\n",
       "      <th>time</th>\n",
       "      <th>I</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291</td>\n",
       "      <td>77</td>\n",
       "      <td>54</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1739</td>\n",
       "      <td>922</td>\n",
       "      <td>817</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>285</td>\n",
       "      <td>2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>440</td>\n",
       "      <td>149</td>\n",
       "      <td>136</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2197</td>\n",
       "      <td>1349</td>\n",
       "      <td>848</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>431</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>571</td>\n",
       "      <td>131</td>\n",
       "      <td>393</td>\n",
       "      <td>257</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5897</td>\n",
       "      <td>4928</td>\n",
       "      <td>969</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>554</td>\n",
       "      <td>11218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>830</td>\n",
       "      <td>259</td>\n",
       "      <td>1072</td>\n",
       "      <td>680</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>9507</td>\n",
       "      <td>8420</td>\n",
       "      <td>1087</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>771</td>\n",
       "      <td>18999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1287</td>\n",
       "      <td>444</td>\n",
       "      <td>1965</td>\n",
       "      <td>1118</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>15197</td>\n",
       "      <td>13967</td>\n",
       "      <td>1230</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>1208</td>\n",
       "      <td>31129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1975</td>\n",
       "      <td>688</td>\n",
       "      <td>2684</td>\n",
       "      <td>1309</td>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>23431</td>\n",
       "      <td>21556</td>\n",
       "      <td>1875</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>1870</td>\n",
       "      <td>47671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2744</td>\n",
       "      <td>769</td>\n",
       "      <td>5794</td>\n",
       "      <td>3806</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>32799</td>\n",
       "      <td>30453</td>\n",
       "      <td>2346</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>2613</td>\n",
       "      <td>69046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4515</td>\n",
       "      <td>1771</td>\n",
       "      <td>6973</td>\n",
       "      <td>2077</td>\n",
       "      <td>106</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>47833</td>\n",
       "      <td>44132</td>\n",
       "      <td>3701</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>4349</td>\n",
       "      <td>98938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5974</td>\n",
       "      <td>1459</td>\n",
       "      <td>9239</td>\n",
       "      <td>3248</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "      <td>103</td>\n",
       "      <td>43</td>\n",
       "      <td>65537</td>\n",
       "      <td>59990</td>\n",
       "      <td>5547</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>5739</td>\n",
       "      <td>134766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7711</td>\n",
       "      <td>1737</td>\n",
       "      <td>12167</td>\n",
       "      <td>4148</td>\n",
       "      <td>170</td>\n",
       "      <td>38</td>\n",
       "      <td>124</td>\n",
       "      <td>21</td>\n",
       "      <td>88693</td>\n",
       "      <td>81947</td>\n",
       "      <td>6746</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>7417</td>\n",
       "      <td>182807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9692</td>\n",
       "      <td>1982</td>\n",
       "      <td>15238</td>\n",
       "      <td>4812</td>\n",
       "      <td>213</td>\n",
       "      <td>43</td>\n",
       "      <td>171</td>\n",
       "      <td>47</td>\n",
       "      <td>113579</td>\n",
       "      <td>102427</td>\n",
       "      <td>11152</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>9308</td>\n",
       "      <td>231244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11791</td>\n",
       "      <td>2102</td>\n",
       "      <td>17988</td>\n",
       "      <td>5019</td>\n",
       "      <td>259</td>\n",
       "      <td>46</td>\n",
       "      <td>243</td>\n",
       "      <td>72</td>\n",
       "      <td>136987</td>\n",
       "      <td>118478</td>\n",
       "      <td>18509</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>11289</td>\n",
       "      <td>273453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14380</td>\n",
       "      <td>2590</td>\n",
       "      <td>19544</td>\n",
       "      <td>4562</td>\n",
       "      <td>304</td>\n",
       "      <td>45</td>\n",
       "      <td>328</td>\n",
       "      <td>85</td>\n",
       "      <td>163844</td>\n",
       "      <td>137594</td>\n",
       "      <td>26250</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>13748</td>\n",
       "      <td>320982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17205</td>\n",
       "      <td>2829</td>\n",
       "      <td>21558</td>\n",
       "      <td>5173</td>\n",
       "      <td>361</td>\n",
       "      <td>57</td>\n",
       "      <td>475</td>\n",
       "      <td>147</td>\n",
       "      <td>189583</td>\n",
       "      <td>152700</td>\n",
       "      <td>36883</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>16369</td>\n",
       "      <td>363841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20438</td>\n",
       "      <td>3235</td>\n",
       "      <td>23214</td>\n",
       "      <td>5072</td>\n",
       "      <td>425</td>\n",
       "      <td>64</td>\n",
       "      <td>632</td>\n",
       "      <td>157</td>\n",
       "      <td>221015</td>\n",
       "      <td>171329</td>\n",
       "      <td>49686</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>19381</td>\n",
       "      <td>415558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24324</td>\n",
       "      <td>3887</td>\n",
       "      <td>23260</td>\n",
       "      <td>3971</td>\n",
       "      <td>490</td>\n",
       "      <td>65</td>\n",
       "      <td>892</td>\n",
       "      <td>262</td>\n",
       "      <td>252154</td>\n",
       "      <td>185555</td>\n",
       "      <td>66599</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>22942</td>\n",
       "      <td>460969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28018</td>\n",
       "      <td>3694</td>\n",
       "      <td>24702</td>\n",
       "      <td>5328</td>\n",
       "      <td>563</td>\n",
       "      <td>73</td>\n",
       "      <td>1153</td>\n",
       "      <td>261</td>\n",
       "      <td>282813</td>\n",
       "      <td>186354</td>\n",
       "      <td>96459</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>26302</td>\n",
       "      <td>493869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31161</td>\n",
       "      <td>3143</td>\n",
       "      <td>26395</td>\n",
       "      <td>4833</td>\n",
       "      <td>636</td>\n",
       "      <td>73</td>\n",
       "      <td>1540</td>\n",
       "      <td>387</td>\n",
       "      <td>314028</td>\n",
       "      <td>186045</td>\n",
       "      <td>127983</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>28985</td>\n",
       "      <td>526468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>34546</td>\n",
       "      <td>3399</td>\n",
       "      <td>27657</td>\n",
       "      <td>4214</td>\n",
       "      <td>722</td>\n",
       "      <td>86</td>\n",
       "      <td>2050</td>\n",
       "      <td>510</td>\n",
       "      <td>345498</td>\n",
       "      <td>189660</td>\n",
       "      <td>155838</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>31774</td>\n",
       "      <td>562815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37198</td>\n",
       "      <td>2656</td>\n",
       "      <td>28942</td>\n",
       "      <td>3916</td>\n",
       "      <td>811</td>\n",
       "      <td>89</td>\n",
       "      <td>2649</td>\n",
       "      <td>600</td>\n",
       "      <td>371905</td>\n",
       "      <td>188183</td>\n",
       "      <td>183722</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>33738</td>\n",
       "      <td>589030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40171</td>\n",
       "      <td>3062</td>\n",
       "      <td>23589</td>\n",
       "      <td>4008</td>\n",
       "      <td>908</td>\n",
       "      <td>97</td>\n",
       "      <td>3281</td>\n",
       "      <td>632</td>\n",
       "      <td>399487</td>\n",
       "      <td>187518</td>\n",
       "      <td>211969</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>35982</td>\n",
       "      <td>610594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confirmed  new_confirmed  suspected  new_suspected  dead  new_death  \\\n",
       "0         291             77         54             27     6          6   \n",
       "1         440            149        136             82     9          3   \n",
       "2         571            131        393            257    17          8   \n",
       "3         830            259       1072            680    25          8   \n",
       "4        1287            444       1965           1118    41         16   \n",
       "5        1975            688       2684           1309    56         15   \n",
       "6        2744            769       5794           3806    80         24   \n",
       "7        4515           1771       6973           2077   106         26   \n",
       "8        5974           1459       9239           3248   132         26   \n",
       "9        7711           1737      12167           4148   170         38   \n",
       "10       9692           1982      15238           4812   213         43   \n",
       "11      11791           2102      17988           5019   259         46   \n",
       "12      14380           2590      19544           4562   304         45   \n",
       "13      17205           2829      21558           5173   361         57   \n",
       "14      20438           3235      23214           5072   425         64   \n",
       "15      24324           3887      23260           3971   490         65   \n",
       "16      28018           3694      24702           5328   563         73   \n",
       "17      31161           3143      26395           4833   636         73   \n",
       "18      34546           3399      27657           4214   722         86   \n",
       "19      37198           2656      28942           3916   811         89   \n",
       "20      40171           3062      23589           4008   908         97   \n",
       "\n",
       "    cured  new_cured  close_contact  under_medical_observation  \\\n",
       "0       0          0           1739                        922   \n",
       "1       0          0           2197                       1349   \n",
       "2       0          0           5897                       4928   \n",
       "3      34          6           9507                       8420   \n",
       "4      38          3          15197                      13967   \n",
       "5      49         11          23431                      21556   \n",
       "6      51          2          32799                      30453   \n",
       "7      60          9          47833                      44132   \n",
       "8     103         43          65537                      59990   \n",
       "9     124         21          88693                      81947   \n",
       "10    171         47         113579                     102427   \n",
       "11    243         72         136987                     118478   \n",
       "12    328         85         163844                     137594   \n",
       "13    475        147         189583                     152700   \n",
       "14    632        157         221015                     171329   \n",
       "15    892        262         252154                     185555   \n",
       "16   1153        261         282813                     186354   \n",
       "17   1540        387         314028                     186045   \n",
       "18   2050        510         345498                     189660   \n",
       "19   2649        600         371905                     188183   \n",
       "20   3281        632         399487                     187518   \n",
       "\n",
       "    quit_medical_observation       time      I       E  \n",
       "0                        817 2020-01-20    285    2715  \n",
       "1                        848 2020-01-21    431    3682  \n",
       "2                        969 2020-01-22    554   11218  \n",
       "3                       1087 2020-01-23    771   18999  \n",
       "4                       1230 2020-01-24   1208   31129  \n",
       "5                       1875 2020-01-25   1870   47671  \n",
       "6                       2346 2020-01-26   2613   69046  \n",
       "7                       3701 2020-01-27   4349   98938  \n",
       "8                       5547 2020-01-28   5739  134766  \n",
       "9                       6746 2020-01-29   7417  182807  \n",
       "10                     11152 2020-01-30   9308  231244  \n",
       "11                     18509 2020-01-31  11289  273453  \n",
       "12                     26250 2020-02-01  13748  320982  \n",
       "13                     36883 2020-02-02  16369  363841  \n",
       "14                     49686 2020-02-03  19381  415558  \n",
       "15                     66599 2020-02-04  22942  460969  \n",
       "16                     96459 2020-02-05  26302  493869  \n",
       "17                    127983 2020-02-06  28985  526468  \n",
       "18                    155838 2020-02-07  31774  562815  \n",
       "19                    183722 2020-02-08  33738  589030  \n",
       "20                    211969 2020-02-09  35982  610594  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_china = read_data('./ncov/dta/nation_截至0209_24时.csv')\n",
    "data_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data['I'] = data['confirmed']-data['dead']-data['cured']\n",
    "    data['E']=data['suspected']+data['close_contact']+data['under_medical_observation']\n",
    "    data['time']= pd.to_datetime(data['time'])\n",
    "    # data['time'] = data['time'].apply(lambda x:x-np.timedelta64(1,'D'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/china\\02-10\n",
      "(21, 3)\n",
      "21\n",
      "Training step:  0\n",
      "Loss: 110729725.99577776\n",
      "Training step:  1\n",
      "Loss: 54522034.84472122\n",
      "Training step:  2\n",
      "Loss: 39381296.1485002\n",
      "Training step: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SEIR_model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SEIR_cell. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3\n",
      "Loss: 36580289.82006091\n",
      "Training step:  4\n",
      "Loss: 26768522.037949234\n",
      "Training step:  5\n",
      "Loss: 24139021.75185706\n",
      "Training step:  6\n",
      "Loss: 18757562.26283764\n",
      "Training step:  7\n",
      "Loss: 16296538.76527815\n",
      "Training step:  8\n",
      "Loss: 13412598.078488618\n",
      "Training step:  9\n",
      "Loss: 11763489.50084396\n",
      "Training step:  10\n",
      "Loss: 10310742.144076122\n",
      "Training step:  11\n",
      "Loss: 9381921.750488834\n",
      "Training step:  12\n",
      "Loss: 8600506.811358485\n",
      "Training step:  13\n",
      "Loss: 7999175.002693756\n",
      "Training step:  14\n",
      "Loss: 7468680.567313196\n",
      "Training step:  15\n",
      "Loss: 6981774.101316891\n",
      "Training step:  16\n",
      "Loss: 6529917.377634196\n",
      "Training step:  17\n",
      "Loss: 6100431.243330378\n",
      "Training step:  18\n",
      "Loss: 5696530.19287293\n",
      "Training step:  19\n",
      "Loss: 5317899.44332194\n",
      "Training step:  20\n",
      "Loss: 4963591.18391772\n",
      "Training step:  21\n",
      "Loss: 4633245.10070584\n",
      "Training step:  22\n",
      "Loss: 4325660.411684379\n",
      "Training step:  23\n",
      "Loss: 4039413.6407327084\n",
      "Training step:  24\n",
      "Loss: 3773224.4983895435\n",
      "Training step:  25\n",
      "Loss: 3525847.793638177\n",
      "Training step:  26\n",
      "Loss: 3296057.958779959\n",
      "Training step:  27\n",
      "Loss: 3082672.6802649978\n",
      "Training step:  28\n",
      "Loss: 2884561.201736508\n",
      "Training step:  29\n",
      "Loss: 2700652.785974548\n",
      "Training step:  30\n",
      "Loss: 2529937.7556649554\n",
      "Training step:  31\n",
      "Loss: 2371474.012231011\n",
      "Training step:  32\n",
      "Loss: 2224384.8684190246\n",
      "Training step:  33\n",
      "Loss: 2087857.3711261458\n",
      "Training step:  34\n",
      "Loss: 1961138.1022411154\n",
      "Training step:  35\n",
      "Loss: 1843529.2251043639\n",
      "Training step:  36\n",
      "Loss: 1734384.3968525773\n",
      "Training step:  37\n",
      "Loss: 1633104.5371101645\n",
      "Training step:  38\n",
      "Loss: 1539134.0280500632\n",
      "Training step:  39\n",
      "Loss: 1451956.7146003584\n",
      "Training step:  40\n",
      "Loss: 1371092.7194314671\n",
      "Training step:  41\n",
      "Loss: 1296094.9266866029\n",
      "Training step:  42\n",
      "Loss: 1226546.724560774\n",
      "Training step:  43\n",
      "Loss: 1162058.8816038962\n",
      "Training step:  44\n",
      "Loss: 1102268.64738943\n",
      "Training step:  45\n",
      "Loss: 1046836.8265397786\n",
      "Training step:  46\n",
      "Loss: 995450.557893662\n",
      "Training step:  47\n",
      "Loss: 947824.4350691854\n",
      "Training step:  48\n",
      "Loss: 903731.1830033995\n",
      "Training step:  49\n",
      "Loss: 863085.7424966117\n",
      "Training step:  50\n",
      "Loss: 826370.0367984698\n",
      "Training step:  51\n",
      "Loss: 796241.0499550161\n",
      "Training step:  52\n",
      "Loss: 785392.3586821902\n",
      "Training step:  53\n",
      "Loss: 847403.5079829771\n",
      "Training step:  54\n",
      "Loss: 1258558.3242283512\n",
      "Training step:  55\n",
      "Loss: 2979435.3401706\n",
      "Training step:  56\n",
      "Loss: 11821099.670003677\n",
      "Training step:  57\n",
      "Loss: 16246374.303203283\n",
      "Training step:  58\n",
      "Loss: 40721909.83013\n",
      "Training step:  59\n",
      "Loss: 3325186.5286562815\n",
      "Training step:  60\n",
      "Loss: 40006308.83773448\n",
      "Training step:  61\n",
      "Loss: 56154158.427353375\n",
      "Training step:  62\n",
      "Loss: 42703085.58668788\n",
      "Training step:  63\n",
      "Loss: 1265287.4735716525\n",
      "Training step:  64\n",
      "Loss: 16817475.450807814\n",
      "Training step:  65\n",
      "Loss: 14189033.226742195\n",
      "Training step:  66\n",
      "Loss: 6312267.589790973\n",
      "Training step:  67\n",
      "Loss: 5185695.605449754\n",
      "Training step:  68\n",
      "Loss: 556167.0819852285\n",
      "Training step:  69\n",
      "Loss: 1466320.3711172575\n",
      "Training step:  70\n",
      "Loss: 593464.476768425\n",
      "Training step:  71\n",
      "Loss: 675221.7758207277\n",
      "Training step:  72\n",
      "Loss: 604469.7491508742\n",
      "Training step:  73\n",
      "Loss: 512736.4209462603\n",
      "Training step:  74\n",
      "Loss: 535342.912634878\n",
      "Training step:  75\n",
      "Loss: 494418.0590762536\n",
      "Training step:  76\n",
      "Loss: 492609.8477086653\n",
      "Training step:  77\n",
      "Loss: 484151.79522090673\n",
      "Training step:  78\n",
      "Loss: 475661.2835685953\n",
      "Training step:  79\n",
      "Loss: 471331.02424644935\n",
      "Training step:  80\n",
      "Loss: 465096.49086083984\n",
      "Training step:  81\n",
      "Loss: 460065.5741606249\n",
      "Training step:  82\n",
      "Loss: 455137.1080956135\n",
      "Training step:  83\n",
      "Loss: 450208.9912696647\n",
      "Training step:  84\n",
      "Loss: 445564.8152910556\n",
      "Training step:  85\n",
      "Loss: 440983.7049952181\n",
      "Training step:  86\n",
      "Loss: 436524.8725865041\n",
      "Training step:  87\n",
      "Loss: 432186.6376160451\n",
      "Training step:  88\n",
      "Loss: 427942.9576829698\n",
      "Training step:  89\n",
      "Loss: 423801.9043603315\n",
      "Training step:  90\n",
      "Loss: 419756.6056529625\n",
      "Training step:  91\n",
      "Loss: 415802.0701363627\n",
      "Training step:  92\n",
      "Loss: 411936.42987604794\n",
      "Training step:  93\n",
      "Loss: 408155.8456402669\n",
      "Training step:  94\n",
      "Loss: 404457.20841913874\n",
      "Training step:  95\n",
      "Loss: 400837.75643686566\n",
      "Training step:  96\n",
      "Loss: 397294.5961107092\n",
      "Training step:  97\n",
      "Loss: 393825.046666638\n",
      "Training step:  98\n",
      "Loss: 390426.5533875417\n",
      "Training step:  99\n",
      "Loss: 387096.6370133294\n",
      "Training step:  100\n",
      "Loss: 383832.9318603948\n",
      "Training step:  101\n",
      "Loss: 380633.1694212981\n",
      "Training step:  102\n",
      "Loss: 377495.16966506536\n",
      "Training step:  103\n",
      "Loss: 374416.84221325535\n",
      "Training step:  104\n",
      "Loss: 371396.18098923704\n",
      "Training step:  105\n",
      "Loss: 368431.2605691651\n",
      "Training step:  106\n",
      "Loss: 365520.2333671077\n",
      "Training step:  107\n",
      "Loss: 362661.32622925553\n",
      "Training step:  108\n",
      "Loss: 359852.8376179377\n",
      "Training step:  109\n",
      "Loss: 357093.13472361\n",
      "Training step:  110\n",
      "Loss: 354380.65067548474\n",
      "Training step:  111\n",
      "Loss: 351713.8820056482\n",
      "Training step:  112\n",
      "Loss: 349091.3860693692\n",
      "Training step:  113\n",
      "Loss: 346511.7786047347\n",
      "Training step:  114\n",
      "Loss: 343973.7314151996\n",
      "Training step:  115\n",
      "Loss: 341475.9700785626\n",
      "Training step:  116\n",
      "Loss: 339017.2717669097\n",
      "Training step:  117\n",
      "Loss: 336596.46314398263\n",
      "Training step:  118\n",
      "Loss: 334212.4183209599\n",
      "Training step:  119\n",
      "Loss: 331864.0568983514\n",
      "Training step:  120\n",
      "Loss: 329550.34207272925\n",
      "Training step:  121\n",
      "Loss: 327270.2788097251\n",
      "Training step:  122\n",
      "Loss: 325022.9120878499\n",
      "Training step:  123\n",
      "Loss: 322807.32520376495\n",
      "Training step:  124\n",
      "Loss: 320622.6381416895\n",
      "Training step:  125\n",
      "Loss: 318468.0060048716\n",
      "Training step:  126\n",
      "Loss: 316342.61750582606\n",
      "Training step:  127\n",
      "Loss: 314245.693515669\n",
      "Training step:  128\n",
      "Loss: 312176.4856698571\n",
      "Training step:  129\n",
      "Loss: 310134.2750289291\n",
      "Training step:  130\n",
      "Loss: 308118.37079302606\n",
      "Training step:  131\n",
      "Loss: 306128.1090681479\n",
      "Training step:  132\n",
      "Loss: 304162.8516828895\n",
      "Training step:  133\n",
      "Loss: 302221.9850539806\n",
      "Training step:  134\n",
      "Loss: 300304.919099036\n",
      "Training step:  135\n",
      "Loss: 298411.0861950681\n",
      "Training step:  136\n",
      "Loss: 296539.9401811485\n",
      "Training step:  137\n",
      "Loss: 294690.95540375425\n",
      "Training step:  138\n",
      "Loss: 292863.62580330076\n",
      "Training step:  139\n",
      "Loss: 291057.464040381\n",
      "Training step:  140\n",
      "Loss: 289272.0006602923\n",
      "Training step:  141\n",
      "Loss: 287506.7832944151\n",
      "Training step:  142\n",
      "Loss: 285761.37589707406\n",
      "Training step:  143\n",
      "Loss: 284035.35801651573\n",
      "Training step:  144\n",
      "Loss: 282328.3240986904\n",
      "Training step:  145\n",
      "Loss: 280639.8828225329\n",
      "Training step:  146\n",
      "Loss: 278969.65646550443\n",
      "Training step:  147\n",
      "Loss: 277317.2802981517\n",
      "Training step:  148\n",
      "Loss: 275682.4020065142\n",
      "Training step:  149\n",
      "Loss: 274064.68114120944\n",
      "Training step:  150\n",
      "Loss: 272463.7885920964\n",
      "Training step:  151\n",
      "Loss: 270879.4060874156\n",
      "Training step:  152\n",
      "Loss: 269311.2257163695\n",
      "Training step:  153\n",
      "Loss: 267758.94947412977\n",
      "Training step:  154\n",
      "Loss: 266222.28882828663\n",
      "Training step:  155\n",
      "Loss: 264700.9643058018\n",
      "Training step:  156\n",
      "Loss: 263194.70509955264\n",
      "Training step:  157\n",
      "Loss: 261703.24869358694\n",
      "Training step:  158\n",
      "Loss: 260226.3405062491\n",
      "Training step:  159\n",
      "Loss: 258763.73355036016\n",
      "Training step:  160\n",
      "Loss: 257315.1881096668\n",
      "Training step:  161\n",
      "Loss: 255880.47143082003\n",
      "Training step:  162\n",
      "Loss: 254459.35743014683\n",
      "Training step:  163\n",
      "Loss: 253051.62641453196\n",
      "Training step:  164\n",
      "Loss: 251657.06481574\n",
      "Training step:  165\n",
      "Loss: 250275.4649375488\n",
      "Training step:  166\n",
      "Loss: 248906.6247150689\n",
      "Training step:  167\n",
      "Loss: 247550.34748568462\n",
      "Training step:  168\n",
      "Loss: 246206.44177103386\n",
      "Training step:  169\n",
      "Loss: 244874.72106951269\n",
      "Training step:  170\n",
      "Loss: 243555.00365878033\n",
      "Training step:  171\n",
      "Loss: 242247.11240777595\n",
      "Training step:  172\n",
      "Loss: 240950.87459778285\n",
      "Training step:  173\n",
      "Loss: 239666.121752095\n",
      "Training step:  174\n",
      "Loss: 238392.68947385205\n",
      "Training step:  175\n",
      "Loss: 237130.41729164304\n",
      "Training step:  176\n",
      "Loss: 235879.1485124916\n",
      "Training step:  177\n",
      "Loss: 234638.73008184237\n",
      "Training step:  178\n",
      "Loss: 233409.01245021162\n",
      "Training step:  179\n",
      "Loss: 232189.8494461505\n",
      "Training step:  180\n",
      "Loss: 230981.09815521474\n",
      "Training step:  181\n",
      "Loss: 229782.61880462547\n",
      "Training step:  182\n",
      "Loss: 228594.2746533381\n",
      "Training step:  183\n",
      "Loss: 227415.93188724085\n",
      "Training step:  184\n",
      "Loss: 226247.45951922116\n",
      "Training step:  185\n",
      "Loss: 225088.7292938513\n",
      "Training step:  186\n",
      "Loss: 223939.61559645485\n",
      "Training step:  187\n",
      "Loss: 222799.99536633154\n",
      "Training step:  188\n",
      "Loss: 221669.74801392393\n",
      "Training step:  189\n",
      "Loss: 220548.75534172574\n",
      "Training step:  190\n",
      "Loss: 219436.90146873426\n",
      "Training step:  191\n",
      "Loss: 218334.07275827363\n",
      "Training step:  192\n",
      "Loss: 217240.15774900303\n",
      "Training step:  193\n",
      "Loss: 216155.04708895553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  194\n",
      "Loss: 215078.63347244676\n",
      "Training step:  195\n",
      "Loss: 214010.81157970673\n",
      "Training step:  196\n",
      "Loss: 212951.47801909567\n",
      "Training step:  197\n",
      "Loss: 211900.53127176728\n",
      "Training step:  198\n",
      "Loss: 210857.8716386594\n",
      "Training step:  199\n",
      "Loss: 209823.40118968973\n",
      "Training step:  200\n",
      "Loss: 208797.0237150433\n",
      "Training step:  201\n",
      "Loss: 207778.6446784445\n",
      "Training step:  202\n",
      "Loss: 206768.1711723176\n",
      "Training step:  203\n",
      "Loss: 205765.5118747358\n",
      "Training step:  204\n",
      "Loss: 204770.57700806303\n",
      "Training step:  205\n",
      "Loss: 203783.2782992213\n",
      "Training step:  206\n",
      "Loss: 202803.52894147421\n",
      "Training step:  207\n",
      "Loss: 201831.243557686\n",
      "Training step:  208\n",
      "Loss: 200866.3381649399\n",
      "Training step:  209\n",
      "Loss: 199908.73014049983\n",
      "Training step:  210\n",
      "Loss: 198958.33818898659\n",
      "Training step:  211\n",
      "Loss: 198015.08231079395\n",
      "Training step:  212\n",
      "Loss: 197078.88377156103\n",
      "Training step:  213\n",
      "Loss: 196149.66507282978\n",
      "Training step:  214\n",
      "Loss: 195227.34992356715\n",
      "Training step:  215\n",
      "Loss: 194311.86321290713\n",
      "Training step:  216\n",
      "Loss: 193403.13098344635\n",
      "Training step:  217\n",
      "Loss: 192501.08040601024\n",
      "Training step:  218\n",
      "Loss: 191605.63975435373\n",
      "Training step:  219\n",
      "Loss: 190716.73838210243\n",
      "Training step:  220\n",
      "Loss: 189834.3066981946\n",
      "Training step:  221\n",
      "Loss: 188958.27614671545\n",
      "Training step:  222\n",
      "Loss: 188088.5791816042\n",
      "Training step:  223\n",
      "Loss: 187225.1492516984\n",
      "Training step:  224\n",
      "Loss: 186367.92077123612\n",
      "Training step:  225\n",
      "Loss: 185516.82911775823\n",
      "Training step:  226\n",
      "Loss: 184671.8105917622\n",
      "Training step:  227\n",
      "Loss: 183832.8024583568\n",
      "Training step:  228\n",
      "Loss: 182999.74290472746\n",
      "Training step:  229\n",
      "Loss: 182172.5713025715\n",
      "Training step:  230\n",
      "Loss: 181351.2284643628\n",
      "Training step:  231\n",
      "Loss: 180535.65853910765\n",
      "Training step:  232\n",
      "Loss: 179725.81334380416\n",
      "Training step:  233\n",
      "Loss: 178921.6696180796\n",
      "Training step:  234\n",
      "Loss: 178123.2802644039\n",
      "Training step:  235\n",
      "Loss: 177330.95444619565\n",
      "Training step:  236\n",
      "Loss: 176545.8441583379\n",
      "Training step:  237\n",
      "Loss: 175771.97252772056\n",
      "Training step:  238\n",
      "Loss: 175023.09287417648\n",
      "Training step:  239\n",
      "Loss: 174346.8240163338\n",
      "Training step:  240\n",
      "Loss: 173907.35489973542\n",
      "Training step:  241\n",
      "Loss: 174288.70340012584\n",
      "Training step:  242\n",
      "Loss: 177511.97944360768\n",
      "Training step:  243\n",
      "Loss: 191135.45698930716\n",
      "Training step:  244\n",
      "Loss: 240340.72436303232\n",
      "Training step:  245\n",
      "Loss: 430913.191148628\n",
      "Training step:  246\n",
      "Loss: 1048072.192385227\n",
      "Training step:  247\n",
      "Loss: 3724080.3223146163\n",
      "Training step:  248\n",
      "Loss: 8869333.080668038\n",
      "Training step:  249\n",
      "Loss: 35344763.91267721\n",
      "Training step:  250\n",
      "Loss: 3349894.665846217\n",
      "Training step:  251\n",
      "Loss: 508321.7452865644\n",
      "Training step:  252\n",
      "Loss: 202261.0802742103\n",
      "Training step:  253\n",
      "Loss: 167808.11193243222\n",
      "Training step:  254\n",
      "Loss: 165001.49612046115\n",
      "Training step:  255\n",
      "Loss: 165586.7928459277\n",
      "Training step:  256\n",
      "Loss: 166359.59748033425\n",
      "Training step:  257\n",
      "Loss: 170142.64652877516\n",
      "Training step:  258\n",
      "Loss: 183911.10460575286\n",
      "Training step:  259\n",
      "Loss: 223543.78912657924\n",
      "Training step:  260\n",
      "Loss: 349038.30781573034\n",
      "Training step:  261\n",
      "Loss: 672491.9378010586\n",
      "Training step:  262\n",
      "Loss: 1827159.9338281273\n",
      "Training step:  263\n",
      "Loss: 3932005.641742874\n",
      "Training step:  264\n",
      "Loss: 13409756.732331397\n",
      "Training step:  265\n",
      "Loss: 10634276.996240815\n",
      "Training step:  266\n",
      "Loss: 28726159.688694965\n",
      "Training step:  267\n",
      "Loss: 2135909.505632482\n",
      "Training step:  268\n",
      "Loss: 261756.2632687182\n",
      "Training step:  269\n",
      "Loss: 1516856.4155506715\n",
      "Training step:  270\n",
      "Loss: 2972397.798948609\n",
      "Training step:  271\n",
      "Loss: 7638810.99233476\n",
      "Training step:  272\n",
      "Loss: 5951184.374072343\n",
      "Training step:  273\n",
      "Loss: 12354545.360760089\n",
      "Training step:  274\n",
      "Loss: 4517798.286856018\n",
      "Training step:  275\n",
      "Loss: 5322836.795388877\n",
      "Training step:  276\n",
      "Loss: 2894840.8043474653\n",
      "Training step:  277\n",
      "Loss: 3901679.6545324796\n",
      "Training step:  278\n",
      "Loss: 2645873.4250411154\n",
      "Training step:  279\n",
      "Loss: 3871753.2070099665\n",
      "Training step:  280\n",
      "Loss: 2662821.817699315\n",
      "Training step:  281\n",
      "Loss: 3845051.1088141473\n",
      "Training step:  282\n",
      "Loss: 2548770.996580201\n",
      "Training step:  283\n",
      "Loss: 3501566.9183011707\n",
      "Training step:  284\n",
      "Loss: 2301719.0999322142\n",
      "Training step:  285\n",
      "Loss: 3029391.943616102\n",
      "Training step:  286\n",
      "Loss: 2039405.4397430778\n",
      "Training step:  287\n",
      "Loss: 2622194.9415028966\n",
      "Training step:  288\n",
      "Loss: 1828605.1065663872\n",
      "Training step:  289\n",
      "Loss: 2327557.091067928\n",
      "Training step:  290\n",
      "Loss: 1676394.1386774592\n",
      "Training step:  291\n",
      "Loss: 2124494.6885989397\n",
      "Training step:  292\n",
      "Loss: 1569162.7704543928\n",
      "Training step:  293\n",
      "Loss: 1984235.6031828336\n",
      "Training step:  294\n",
      "Loss: 1493431.4754555384\n",
      "Training step:  295\n",
      "Loss: 1886580.977059783\n",
      "Training step:  296\n",
      "Loss: 1440124.5833138837\n",
      "Training step:  297\n",
      "Loss: 1819158.9503012574\n",
      "Training step:  298\n",
      "Loss: 1403453.5513391565\n",
      "Training step:  299\n",
      "Loss: 1774100.5051100315\n",
      "Training step:  300\n",
      "Loss: 1379423.0075045067\n",
      "Training step:  301\n",
      "Loss: 1745865.7696991786\n",
      "Training step:  302\n",
      "Loss: 1364993.4156028498\n",
      "Training step:  303\n",
      "Loss: 1730209.2056058003\n",
      "Training step:  304\n",
      "Loss: 1357706.405759231\n",
      "Training step:  305\n",
      "Loss: 1723708.1518399087\n",
      "Training step:  306\n",
      "Loss: 1355513.7900370965\n",
      "Training step:  307\n",
      "Loss: 1723531.2310448294\n",
      "Training step:  308\n",
      "Loss: 1356697.7337433586\n",
      "Training step:  309\n",
      "Loss: 1727331.3968132492\n",
      "Training step:  310\n",
      "Loss: 1359842.4548483714\n",
      "Training step:  311\n",
      "Loss: 1733210.871750316\n",
      "Training step:  312\n",
      "Loss: 1363830.4608141067\n",
      "Training step:  313\n",
      "Loss: 1739713.8567122216\n",
      "Training step:  314\n",
      "Loss: 1367839.59405022\n",
      "Training step:  315\n",
      "Loss: 1745813.4052021536\n",
      "Training step:  316\n",
      "Loss: 1371326.4547107676\n",
      "Training step:  317\n",
      "Loss: 1750875.8695575679\n",
      "Training step:  318\n",
      "Loss: 1373992.415433321\n",
      "Training step:  319\n",
      "Loss: 1754601.2224682756\n",
      "Training step:  320\n",
      "Loss: 1375735.8000231378\n",
      "Training step:  321\n",
      "Loss: 1756946.6792025631\n",
      "Training step:  322\n",
      "Loss: 1376597.3264732596\n",
      "Training step:  323\n",
      "Loss: 1758044.8928556326\n",
      "Training step:  324\n",
      "Loss: 1376706.5143952286\n",
      "Training step:  325\n",
      "Loss: 1758127.7637048804\n",
      "Training step:  326\n",
      "Loss: 1376235.3003390464\n",
      "Training step:  327\n",
      "Loss: 1757463.8705867534\n",
      "Training step:  328\n",
      "Loss: 1375362.5183802643\n",
      "Training step:  329\n",
      "Loss: 1756313.30957856\n",
      "Training step:  330\n",
      "Loss: 1374250.1955515996\n",
      "Training step:  331\n",
      "Loss: 1754899.868165538\n",
      "Training step:  332\n",
      "Loss: 1373030.5408585018\n",
      "Training step:  333\n",
      "Loss: 1753397.8854720788\n",
      "Training step:  334\n",
      "Loss: 1371801.3604332341\n",
      "Training step:  335\n",
      "Loss: 1751929.9980964\n",
      "Training step:  336\n",
      "Loss: 1370627.3056564322\n",
      "Training step:  337\n",
      "Loss: 1750571.913949104\n",
      "Training step:  338\n",
      "Loss: 1369544.5782776573\n",
      "Training step:  339\n",
      "Loss: 1749360.9303061021\n",
      "Training step:  340\n",
      "Loss: 1368567.1999134917\n",
      "Training step:  341\n",
      "Loss: 1748305.731431033\n",
      "Training step:  342\n",
      "Loss: 1367693.5029036668\n",
      "Training step:  343\n",
      "Loss: 1747395.8189585574\n",
      "Training step:  344\n",
      "Loss: 1366912.0003076706\n",
      "Training step:  345\n",
      "Loss: 1746609.6208152382\n",
      "Training step:  346\n",
      "Loss: 1366206.194559781\n",
      "Training step:  347\n",
      "Loss: 1745920.8507742598\n",
      "Training step:  348\n",
      "Loss: 1365558.17688876\n",
      "Training step:  349\n",
      "Loss: 1745303.055644584\n",
      "Training step:  350\n",
      "Loss: 1364951.0634657475\n",
      "Training step:  351\n",
      "Loss: 1744732.515412497\n",
      "Training step:  352\n",
      "Loss: 1364370.4276514668\n",
      "Training step:  353\n",
      "Loss: 1744189.7834867323\n",
      "Training step:  354\n",
      "Loss: 1363804.9401713067\n",
      "Training step:  355\n",
      "Loss: 1743660.198262529\n",
      "Training step:  356\n",
      "Loss: 1363246.4383924382\n",
      "Training step:  357\n",
      "Loss: 1743133.6884371645\n",
      "Training step:  358\n",
      "Loss: 1362689.6273378618\n",
      "Training step:  359\n",
      "Loss: 1742604.153518428\n",
      "Training step:  360\n",
      "Loss: 1362131.5809756357\n",
      "Training step:  361\n",
      "Loss: 1742068.6440052302\n",
      "Training step:  362\n",
      "Loss: 1361571.1721094293\n",
      "Training step:  363\n",
      "Loss: 1741526.5048665325\n",
      "Training step:  364\n",
      "Loss: 1361008.5195533736\n",
      "Training step:  365\n",
      "Loss: 1740978.5893436705\n",
      "Training step:  366\n",
      "Loss: 1360444.5064203246\n",
      "Training step:  367\n",
      "Loss: 1740426.6025431068\n",
      "Training step:  368\n",
      "Loss: 1359880.395447\n",
      "Training step:  369\n",
      "Loss: 1739872.5977867588\n",
      "Training step:  370\n",
      "Loss: 1359317.546895007\n",
      "Training step:  371\n",
      "Loss: 1739318.6232700422\n",
      "Training step:  372\n",
      "Loss: 1358757.2312121084\n",
      "Training step:  373\n",
      "Loss: 1738766.500988149\n",
      "Training step:  374\n",
      "Loss: 1358200.5211836682\n",
      "Training step:  375\n",
      "Loss: 1738217.7121880774\n",
      "Training step:  376\n",
      "Loss: 1357648.2453625672\n",
      "Training step:  377\n",
      "Loss: 1737673.361672995\n",
      "Training step:  378\n",
      "Loss: 1357100.984760442\n",
      "Training step:  379\n",
      "Loss: 1737134.1951605529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  380\n",
      "Loss: 1356559.096896625\n",
      "Training step:  381\n",
      "Loss: 1736600.6479007562\n",
      "Training step:  382\n",
      "Loss: 1356022.7543571529\n",
      "Training step:  383\n",
      "Loss: 1736072.9076325886\n",
      "Training step:  384\n",
      "Loss: 1355491.988320225\n",
      "Training step:  385\n",
      "Loss: 1735550.9798300336\n",
      "Training step:  386\n",
      "Loss: 1354966.7305877113\n",
      "Training step:  387\n",
      "Loss: 1735034.7475118833\n",
      "Training step:  388\n",
      "Loss: 1354446.8502752115\n",
      "Training step:  389\n",
      "Loss: 1734524.021401861\n",
      "Training step:  390\n",
      "Loss: 1353932.1833384775\n",
      "Training step:  391\n",
      "Loss: 1734018.5788467266\n",
      "Training step:  392\n",
      "Loss: 1353422.5545662162\n",
      "Training step:  393\n",
      "Loss: 1733518.191696571\n",
      "Training step:  394\n",
      "Loss: 1352917.792606146\n",
      "Training step:  395\n",
      "Loss: 1733022.6444359592\n",
      "Training step:  396\n",
      "Loss: 1352417.7391046192\n",
      "Training step:  397\n",
      "Loss: 1732531.744382245\n",
      "Training step:  398\n",
      "Loss: 1351922.253245502\n",
      "Training step:  399\n",
      "Loss: 1732045.3259067566\n",
      "Training step:  400\n",
      "Loss: 1351431.2129635743\n",
      "Training step:  401\n",
      "Loss: 1731563.2505099915\n",
      "Training step:  402\n",
      "Loss: 1350944.5139667157\n",
      "Training step:  403\n",
      "Loss: 1731085.4043120325\n",
      "Training step:  404\n",
      "Loss: 1350462.0674935246\n",
      "Training step:  405\n",
      "Loss: 1730611.6941891487\n",
      "Training step:  406\n",
      "Loss: 1349983.797508819\n",
      "Training step:  407\n",
      "Loss: 1730142.0434552394\n",
      "Training step:  408\n",
      "Loss: 1349509.637830471\n",
      "Training step:  409\n",
      "Loss: 1729676.3876944585\n",
      "Training step:  410\n",
      "Loss: 1349039.5294973445\n",
      "Training step:  411\n",
      "Loss: 1729214.6710948262\n",
      "Training step:  412\n",
      "Loss: 1348573.4185439658\n",
      "Training step:  413\n",
      "Loss: 1728756.8434556897\n",
      "Training step:  414\n",
      "Loss: 1348111.2542462004\n",
      "Training step:  415\n",
      "Loss: 1728302.8579040163\n",
      "Training step:  416\n",
      "Loss: 1347652.9878270598\n",
      "Training step:  417\n",
      "Loss: 1727852.6692697068\n",
      "Training step:  418\n",
      "Loss: 1347198.5715708414\n",
      "Training step:  419\n",
      "Loss: 1727406.233023533\n",
      "Training step:  420\n",
      "Loss: 1346747.958273049\n",
      "Training step:  421\n",
      "Loss: 1726963.5046625973\n",
      "Training step:  422\n",
      "Loss: 1346301.1009475212\n",
      "Training step:  423\n",
      "Loss: 1726524.4394273995\n",
      "Training step:  424\n",
      "Loss: 1345857.95271818\n",
      "Training step:  425\n",
      "Loss: 1726088.9922485163\n",
      "Training step:  426\n",
      "Loss: 1345418.4668313188\n",
      "Training step:  427\n",
      "Loss: 1725657.117834265\n",
      "Training step:  428\n",
      "Loss: 1344982.5967381024\n",
      "Training step:  429\n",
      "Loss: 1725228.770834824\n",
      "Training step:  430\n",
      "Loss: 1344550.296209546\n",
      "Training step:  431\n",
      "Loss: 1724803.9060338035\n",
      "Training step:  432\n",
      "Loss: 1344121.5194580737\n",
      "Training step:  433\n",
      "Loss: 1724382.4785356484\n",
      "Training step:  434\n",
      "Loss: 1343696.2212483583\n",
      "Training step:  435\n",
      "Loss: 1723964.4439292925\n",
      "Training step:  436\n",
      "Loss: 1343274.35698943\n",
      "Training step:  437\n",
      "Loss: 1723549.758420372\n",
      "Training step:  438\n",
      "Loss: 1342855.8828040576\n",
      "Training step:  439\n",
      "Loss: 1723138.3789272776\n",
      "Training step:  440\n",
      "Loss: 1342440.7555748057\n",
      "Training step:  441\n",
      "Loss: 1722730.263144995\n",
      "Training step:  442\n",
      "Loss: 1342028.9329707276\n",
      "Training step:  443\n",
      "Loss: 1722325.369580888\n",
      "Training step:  444\n",
      "Loss: 1341620.373456742\n",
      "Training step:  445\n",
      "Loss: 1721923.6575672037\n",
      "Training step:  446\n",
      "Loss: 1341215.036290168\n",
      "Training step:  447\n",
      "Loss: 1721525.087257089\n",
      "Training step:  448\n",
      "Loss: 1340812.8815081944\n",
      "Training step:  449\n",
      "Loss: 1721129.6196086516\n",
      "Training step:  450\n",
      "Loss: 1340413.8699090772\n",
      "Training step:  451\n",
      "Loss: 1720737.2163620687\n",
      "Training step:  452\n",
      "Loss: 1340017.9630302482\n",
      "Training step:  453\n",
      "Loss: 1720347.840012191\n",
      "Training step:  454\n",
      "Loss: 1339625.1231236388\n",
      "Training step:  455\n",
      "Loss: 1719961.45377859\n",
      "Training step:  456\n",
      "Loss: 1339235.3131319273\n",
      "Training step:  457\n",
      "Loss: 1719578.0215781957\n",
      "Training step:  458\n",
      "Loss: 1338848.496665217\n",
      "Training step:  459\n",
      "Loss: 1719197.5079971713\n",
      "Training step:  460\n",
      "Loss: 1338464.6379786984\n",
      "Training step:  461\n",
      "Loss: 1718819.8782660377\n",
      "Training step:  462\n",
      "Loss: 1338083.7019522435\n",
      "Training step:  463\n",
      "Loss: 1718445.098236313\n",
      "Training step:  464\n",
      "Loss: 1337705.654071517\n",
      "Training step:  465\n",
      "Loss: 1718073.1343600103\n",
      "Training step:  466\n",
      "Loss: 1337330.4604103626\n",
      "Training step:  467\n",
      "Loss: 1717703.953670006\n",
      "Training step:  468\n",
      "Loss: 1336958.0876144208\n",
      "Training step:  469\n",
      "Loss: 1717337.5237629118\n",
      "Training step:  470\n",
      "Loss: 1336588.5028864727\n",
      "Training step:  471\n",
      "Loss: 1716973.8127836448\n",
      "Training step:  472\n",
      "Loss: 1336221.6739726607\n",
      "Training step:  473\n",
      "Loss: 1716612.789411373\n",
      "Training step:  474\n",
      "Loss: 1335857.5691493768\n",
      "Training step:  475\n",
      "Loss: 1716254.4228453308\n",
      "Training step:  476\n",
      "Loss: 1335496.1572105621\n",
      "Training step:  477\n",
      "Loss: 1715898.6827923462\n",
      "Training step:  478\n",
      "Loss: 1335137.407456468\n",
      "Training step:  479\n",
      "Loss: 1715545.539455776\n",
      "Training step:  480\n",
      "Loss: 1334781.2896821406\n",
      "Training step:  481\n",
      "Loss: 1715194.9635227574\n",
      "Training step:  482\n",
      "Loss: 1334427.774166238\n",
      "Training step:  483\n",
      "Loss: 1714846.9261540386\n",
      "Training step:  484\n",
      "Loss: 1334076.8316609913\n",
      "Training step:  485\n",
      "Loss: 1714501.398973216\n",
      "Training step:  486\n",
      "Loss: 1333728.4333817433\n",
      "Training step:  487\n",
      "Loss: 1714158.354056507\n",
      "Training step:  488\n",
      "Loss: 1333382.550997016\n",
      "Training step:  489\n",
      "Loss: 1713817.7639224115\n",
      "Training step:  490\n",
      "Loss: 1333039.1566189157\n",
      "Training step:  491\n",
      "Loss: 1713479.6015226739\n",
      "Training step:  492\n",
      "Loss: 1332698.222793931\n",
      "Training step:  493\n",
      "Loss: 1713143.8402324002\n",
      "Training step:  494\n",
      "Loss: 1332359.722493524\n",
      "Training step:  495\n",
      "Loss: 1712810.4538409763\n",
      "Training step:  496\n",
      "Loss: 1332023.6291052925\n",
      "Training step:  497\n",
      "Loss: 1712479.4165431738\n",
      "Training step:  498\n",
      "Loss: 1331689.9164246132\n",
      "Training step:  499\n",
      "Loss: 1712150.702930834\n",
      "Training step:  500\n",
      "Loss: 1331358.5586456961\n",
      "Training step:  501\n",
      "Loss: 1711824.287983389\n",
      "Training step:  502\n",
      "Loss: 1331029.5303535697\n",
      "Training step:  503\n",
      "Loss: 1711500.1470607584\n",
      "Training step:  504\n",
      "Loss: 1330702.8065164764\n",
      "Training step:  505\n",
      "Loss: 1711178.255895264\n",
      "Training step:  506\n",
      "Loss: 1330378.3624775242\n",
      "Training step:  507\n",
      "Loss: 1710858.5905829086\n",
      "Training step:  508\n",
      "Loss: 1330056.1739472817\n",
      "Training step:  509\n",
      "Loss: 1710541.127577015\n",
      "Training step:  510\n",
      "Loss: 1329736.2169968737\n",
      "Training step:  511\n",
      "Loss: 1710225.843680675\n",
      "Training step:  512\n",
      "Loss: 1329418.4680503444\n",
      "Training step:  513\n",
      "Loss: 1709912.7160393237\n",
      "Training step:  514\n",
      "Loss: 1329102.9038777757\n",
      "Training step:  515\n",
      "Loss: 1709601.72213388\n",
      "Training step:  516\n",
      "Loss: 1328789.501588514\n",
      "Training step:  517\n",
      "Loss: 1709292.8397742172\n",
      "Training step:  518\n",
      "Loss: 1328478.2386245516\n",
      "Training step:  519\n",
      "Loss: 1708986.0470924147\n",
      "Training step:  520\n",
      "Loss: 1328169.092754037\n",
      "Training step:  521\n",
      "Loss: 1708681.3225367065\n",
      "Training step:  522\n",
      "Loss: 1327862.0420652877\n",
      "Training step:  523\n",
      "Loss: 1708378.644865351\n",
      "Training step:  524\n",
      "Loss: 1327557.0649603882\n",
      "Training step:  525\n",
      "Loss: 1708077.9931402868\n",
      "Training step:  526\n",
      "Loss: 1327254.1401491237\n",
      "Training step:  527\n",
      "Loss: 1707779.3467210683\n",
      "Training step:  528\n",
      "Loss: 1326953.2466433067\n",
      "Training step:  529\n",
      "Loss: 1707482.6852598493\n",
      "Training step:  530\n",
      "Loss: 1326654.3637512212\n",
      "Training step:  531\n",
      "Loss: 1707187.988695249\n",
      "Training step:  532\n",
      "Loss: 1326357.4710717818\n",
      "Training step:  533\n",
      "Loss: 1706895.2372471048\n",
      "Training step:  534\n",
      "Loss: 1326062.5484894968\n",
      "Training step:  535\n",
      "Loss: 1706604.411411604\n",
      "Training step:  536\n",
      "Loss: 1325769.5761691332\n",
      "Training step:  537\n",
      "Loss: 1706315.4919556503\n",
      "Training step:  538\n",
      "Loss: 1325478.5345504128\n",
      "Training step:  539\n",
      "Loss: 1706028.4599120617\n",
      "Training step:  540\n",
      "Loss: 1325189.404342983\n",
      "Training step:  541\n",
      "Loss: 1705743.2965742394\n",
      "Training step:  542\n",
      "Loss: 1324902.1665213862\n",
      "Training step:  543\n",
      "Loss: 1705459.9834917164\n",
      "Training step:  544\n",
      "Loss: 1324616.8023207157\n",
      "Training step:  545\n",
      "Loss: 1705178.502465868\n",
      "Training step:  546\n",
      "Loss: 1324333.293231681\n",
      "Training step:  547\n",
      "Loss: 1704898.8355449133\n",
      "Training step:  548\n",
      "Loss: 1324051.620995949\n",
      "Training step:  549\n",
      "Loss: 1704620.965019262\n",
      "Training step:  550\n",
      "Loss: 1323771.7676017408\n",
      "Training step:  551\n",
      "Loss: 1704344.8734177237\n",
      "Training step:  552\n",
      "Loss: 1323493.7152795398\n",
      "Training step:  553\n",
      "Loss: 1704070.5435028253\n",
      "Training step:  554\n",
      "Loss: 1323217.446497765\n",
      "Training step:  555\n",
      "Loss: 1703797.9582669928\n",
      "Training step:  556\n",
      "Loss: 1322942.9439586226\n",
      "Training step:  557\n",
      "Loss: 1703527.1009281904\n",
      "Training step:  558\n",
      "Loss: 1322670.1905939283\n",
      "Training step:  559\n",
      "Loss: 1703257.9549261713\n",
      "Training step:  560\n",
      "Loss: 1322399.1695612571\n",
      "Training step:  561\n",
      "Loss: 1702990.5039184354\n",
      "Training step:  562\n",
      "Loss: 1322129.8642399102\n",
      "Training step:  563\n",
      "Loss: 1702724.7317767753\n",
      "Training step:  564\n",
      "Loss: 1321862.2582274943\n",
      "Training step:  565\n",
      "Loss: 1702460.6225837157\n",
      "Training step:  566\n",
      "Loss: 1321596.335335851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  567\n",
      "Loss: 1702198.160628404\n",
      "Training step:  568\n",
      "Loss: 1321332.0795872977\n",
      "Training step:  569\n",
      "Loss: 1701937.3304028553\n",
      "Training step:  570\n",
      "Loss: 1321069.4752110045\n",
      "Training step:  571\n",
      "Loss: 1701678.1165989889\n",
      "Training step:  572\n",
      "Loss: 1320808.506639985\n",
      "Training step:  573\n",
      "Loss: 1701420.5041056152\n",
      "Training step:  574\n",
      "Loss: 1320549.1585074896\n",
      "Training step:  575\n",
      "Loss: 1701164.4780044649\n",
      "Training step:  576\n",
      "Loss: 1320291.4156432992\n",
      "Training step:  577\n",
      "Loss: 1700910.0235669045\n",
      "Training step:  578\n",
      "Loss: 1320035.2630708427\n",
      "Training step:  579\n",
      "Loss: 1700657.1262514163\n",
      "Training step:  580\n",
      "Loss: 1319780.6860038831\n",
      "Training step:  581\n",
      "Loss: 1700405.7716998223\n",
      "Training step:  582\n",
      "Loss: 1319527.6698431747\n",
      "Training step:  583\n",
      "Loss: 1700155.9457346727\n",
      "Training step:  584\n",
      "Loss: 1319276.200173937\n",
      "Training step:  585\n",
      "Loss: 1699907.6343564068\n",
      "Training step:  586\n",
      "Loss: 1319026.2627622571\n",
      "Training step:  587\n",
      "Loss: 1699660.8237400504\n",
      "Training step:  588\n",
      "Loss: 1318777.8435525675\n",
      "Training step:  589\n",
      "Loss: 1699415.5002327191\n",
      "Training step:  590\n",
      "Loss: 1318530.928664343\n",
      "Training step:  591\n",
      "Loss: 1699171.6503501215\n",
      "Training step:  592\n",
      "Loss: 1318285.5043894055\n",
      "Training step:  593\n",
      "Loss: 1698929.260774679\n",
      "Training step:  594\n",
      "Loss: 1318041.5571894697\n",
      "Training step:  595\n",
      "Loss: 1698688.3183526553\n",
      "Training step:  596\n",
      "Loss: 1317799.0736931479\n",
      "Training step:  597\n",
      "Loss: 1698448.8100912625\n",
      "Training step:  598\n",
      "Loss: 1317558.0406931816\n",
      "Training step:  599\n",
      "Loss: 1698210.7231561237\n",
      "Training step:  600\n",
      "Loss: 1317318.4451441641\n",
      "Training step:  601\n",
      "Loss: 1697974.0448692334\n",
      "Training step:  602\n",
      "Loss: 1317080.2741596766\n",
      "Training step:  603\n",
      "Loss: 1697738.7627057447\n",
      "Training step:  604\n",
      "Loss: 1316843.5150098992\n",
      "Training step:  605\n",
      "Loss: 1697504.864292109\n",
      "Training step:  606\n",
      "Loss: 1316608.1551192417\n",
      "Training step:  607\n",
      "Loss: 1697272.3374037417\n",
      "Training step:  608\n",
      "Loss: 1316374.1820639416\n",
      "Training step:  609\n",
      "Loss: 1697041.1699624779\n",
      "Training step:  610\n",
      "Loss: 1316141.5835694382\n",
      "Training step:  611\n",
      "Loss: 1696811.3500339363\n",
      "Training step:  612\n",
      "Loss: 1315910.3475081117\n",
      "Training step:  613\n",
      "Loss: 1696582.8658258955\n",
      "Training step:  614\n",
      "Loss: 1315680.461897369\n",
      "Training step:  615\n",
      "Loss: 1696355.7056860945\n",
      "Training step:  616\n",
      "Loss: 1315451.9148972624\n",
      "Training step:  617\n",
      "Loss: 1696129.8581000147\n",
      "Training step:  618\n",
      "Loss: 1315224.694808127\n",
      "Training step:  619\n",
      "Loss: 1695905.3116883913\n",
      "Training step:  620\n",
      "Loss: 1314998.79006844\n",
      "Training step:  621\n",
      "Loss: 1695682.0552053459\n",
      "Training step:  622\n",
      "Loss: 1314774.1892528145\n",
      "Training step:  623\n",
      "Loss: 1695460.0775365797\n",
      "Training step:  624\n",
      "Loss: 1314550.8810701105\n",
      "Training step:  625\n",
      "Loss: 1695239.3676973844\n",
      "Training step:  626\n",
      "Loss: 1314328.854361098\n",
      "Training step:  627\n",
      "Loss: 1695019.9148303699\n",
      "Training step:  628\n",
      "Loss: 1314108.0980966997\n",
      "Training step:  629\n",
      "Loss: 1694801.7082039171\n",
      "Training step:  630\n",
      "Loss: 1313888.6013760688\n",
      "Training step:  631\n",
      "Loss: 1694584.7372104307\n",
      "Training step:  632\n",
      "Loss: 1313670.3534245156\n",
      "Training step:  633\n",
      "Loss: 1694368.9913636523\n",
      "Training step:  634\n",
      "Loss: 1313453.3435914177\n",
      "Training step:  635\n",
      "Loss: 1694154.460297403\n",
      "Training step:  636\n",
      "Loss: 1313237.5613487887\n",
      "Training step:  637\n",
      "Loss: 1693941.1337641375\n",
      "Training step:  638\n",
      "Loss: 1313022.9962894334\n",
      "Training step:  639\n",
      "Loss: 1693729.0016328034\n",
      "Training step:  640\n",
      "Loss: 1312809.6381249682\n",
      "Training step:  641\n",
      "Loss: 1693518.0538871537\n",
      "Training step:  642\n",
      "Loss: 1312597.4766842318\n",
      "Training step:  643\n",
      "Loss: 1693308.2806243764\n",
      "Training step:  644\n",
      "Loss: 1312386.50191157\n",
      "Training step:  645\n",
      "Loss: 1693099.6720530333\n",
      "Training step:  646\n",
      "Loss: 1312176.7038650888\n",
      "Training step:  647\n",
      "Loss: 1692892.218491863\n",
      "Training step:  648\n",
      "Loss: 1311968.0727150452\n",
      "Training step:  649\n",
      "Loss: 1692685.9103676735\n",
      "Training step:  650\n",
      "Loss: 1311760.5987421502\n",
      "Training step:  651\n",
      "Loss: 1692480.7382143838\n",
      "Training step:  652\n",
      "Loss: 1311554.2723361827\n",
      "Training step:  653\n",
      "Loss: 1692276.6926710736\n",
      "Training step:  654\n",
      "Loss: 1311349.0839940652\n",
      "Training step:  655\n",
      "Loss: 1692073.7644802942\n",
      "Training step:  656\n",
      "Loss: 1311145.024318586\n",
      "Training step:  657\n",
      "Loss: 1691871.9444871906\n",
      "Training step:  658\n",
      "Loss: 1310942.0840169098\n",
      "Training step:  659\n",
      "Loss: 1691671.2236377003\n",
      "Training step:  660\n",
      "Loss: 1310740.2538991144\n",
      "Training step:  661\n",
      "Loss: 1691471.5929774093\n",
      "Training step:  662\n",
      "Loss: 1310539.5248766267\n",
      "Training step:  663\n",
      "Loss: 1691273.0436495435\n",
      "Training step:  664\n",
      "Loss: 1310339.887960736\n",
      "Training step:  665\n",
      "Loss: 1691075.5668943126\n",
      "Training step:  666\n",
      "Loss: 1310141.3342613878\n",
      "Training step:  667\n",
      "Loss: 1690879.154047065\n",
      "Training step:  668\n",
      "Loss: 1309943.8549857477\n",
      "Training step:  669\n",
      "Loss: 1690683.7965373807\n",
      "Training step:  670\n",
      "Loss: 1309747.4414367534\n",
      "Training step:  671\n",
      "Loss: 1690489.48588728\n",
      "Training step:  672\n",
      "Loss: 1309552.0850118734\n",
      "Training step:  673\n",
      "Loss: 1690296.213710453\n",
      "Training step:  674\n",
      "Loss: 1309357.7772017654\n",
      "Training step:  675\n",
      "Loss: 1690103.9717105723\n",
      "Training step:  676\n",
      "Loss: 1309164.509588971\n",
      "Training step:  677\n",
      "Loss: 1689912.7516802028\n",
      "Training step:  678\n",
      "Loss: 1308972.273846549\n",
      "Training step:  679\n",
      "Loss: 1689722.5454994934\n",
      "Training step:  680\n",
      "Loss: 1308781.0617369688\n",
      "Training step:  681\n",
      "Loss: 1689533.345135224\n",
      "Training step:  682\n",
      "Loss: 1308590.8651110379\n",
      "Training step:  683\n",
      "Loss: 1689345.142639703\n",
      "Training step:  684\n",
      "Loss: 1308401.6759064756\n",
      "Training step:  685\n",
      "Loss: 1689157.9301491675\n",
      "Training step:  686\n",
      "Loss: 1308213.4861466081\n",
      "Training step:  687\n",
      "Loss: 1688971.6998826242\n",
      "Training step:  688\n",
      "Loss: 1308026.2879393366\n",
      "Training step:  689\n",
      "Loss: 1688786.4441412895\n",
      "Training step:  690\n",
      "Loss: 1307840.0734762808\n",
      "Training step:  691\n",
      "Loss: 1688602.155307248\n",
      "Training step:  692\n",
      "Loss: 1307654.8350314212\n",
      "Training step:  693\n",
      "Loss: 1688418.8258424944\n",
      "Training step:  694\n",
      "Loss: 1307470.5649598953\n",
      "Training step:  695\n",
      "Loss: 1688236.4482873057\n",
      "Training step:  696\n",
      "Loss: 1307287.2556971398\n",
      "Training step:  697\n",
      "Loss: 1688055.015260193\n",
      "Training step:  698\n",
      "Loss: 1307104.8997576318\n",
      "Training step:  699\n",
      "Loss: 1687874.5194556375\n",
      "Training step:  700\n",
      "Loss: 1306923.4897337165\n",
      "Training step:  701\n",
      "Loss: 1687694.9536438473\n",
      "Training step:  702\n",
      "Loss: 1306743.0182948278\n",
      "Training step:  703\n",
      "Loss: 1687516.3106696473\n",
      "Training step:  704\n",
      "Loss: 1306563.4781864337\n",
      "Training step:  705\n",
      "Loss: 1687338.5834515847\n",
      "Training step:  706\n",
      "Loss: 1306384.8622290916\n",
      "Training step:  707\n",
      "Loss: 1687161.7649810296\n",
      "Training step:  708\n",
      "Loss: 1306207.1633173076\n",
      "Training step:  709\n",
      "Loss: 1686985.848320697\n",
      "Training step:  710\n",
      "Loss: 1306030.3744185972\n",
      "Training step:  711\n",
      "Loss: 1686810.8266044804\n",
      "Training step:  712\n",
      "Loss: 1305854.488572752\n",
      "Training step:  713\n",
      "Loss: 1686636.693035985\n",
      "Training step:  714\n",
      "Loss: 1305679.4988904493\n",
      "Training step:  715\n",
      "Loss: 1686463.4408875874\n",
      "Training step:  716\n",
      "Loss: 1305505.398552885\n",
      "Training step:  717\n",
      "Loss: 1686291.063500258\n",
      "Training step:  718\n",
      "Loss: 1305332.1808103207\n",
      "Training step:  719\n",
      "Loss: 1686119.55428128\n",
      "Training step:  720\n",
      "Loss: 1305159.838981445\n",
      "Training step:  721\n",
      "Loss: 1685948.9067050356\n",
      "Training step:  722\n",
      "Loss: 1304988.3664527624\n",
      "Training step:  723\n",
      "Loss: 1685779.1143112818\n",
      "Training step:  724\n",
      "Loss: 1304817.7566773053\n",
      "Training step:  725\n",
      "Loss: 1685610.1707043664\n",
      "Training step:  726\n",
      "Loss: 1304648.0031740905\n",
      "Training step:  727\n",
      "Loss: 1685442.069552494\n",
      "Training step:  728\n",
      "Loss: 1304479.099526789\n",
      "Training step:  729\n",
      "Loss: 1685274.8045865982\n",
      "Training step:  730\n",
      "Loss: 1304311.0393835844\n",
      "Training step:  731\n",
      "Loss: 1685108.369600581\n",
      "Training step:  732\n",
      "Loss: 1304143.8164561493\n",
      "Training step:  733\n",
      "Loss: 1684942.7584494613\n",
      "Training step:  734\n",
      "Loss: 1303977.4245183377\n",
      "Training step:  735\n",
      "Loss: 1684777.9650485711\n",
      "Training step:  736\n",
      "Loss: 1303811.8574058753\n",
      "Training step:  737\n",
      "Loss: 1684613.9833735856\n",
      "Training step:  738\n",
      "Loss: 1303647.109015761\n",
      "Training step:  739\n",
      "Loss: 1684450.8074596138\n",
      "Training step:  740\n",
      "Loss: 1303483.173305017\n",
      "Training step:  741\n",
      "Loss: 1684288.4313995482\n",
      "Training step:  742\n",
      "Loss: 1303320.0442900003\n",
      "Training step:  743\n",
      "Loss: 1684126.849344356\n",
      "Training step:  744\n",
      "Loss: 1303157.7160461931\n",
      "Training step:  745\n",
      "Loss: 1683966.0555023944\n",
      "Training step:  746\n",
      "Loss: 1302996.1827070653\n",
      "Training step:  747\n",
      "Loss: 1683806.0441380183\n",
      "Training step:  748\n",
      "Loss: 1302835.438463151\n",
      "Training step:  749\n",
      "Loss: 1683646.8095710254\n",
      "Training step:  750\n",
      "Loss: 1302675.477561546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  751\n",
      "Loss: 1683488.3461760695\n",
      "Training step:  752\n",
      "Loss: 1302516.2943053618\n",
      "Training step:  753\n",
      "Loss: 1683330.6483825445\n",
      "Training step:  754\n",
      "Loss: 1302357.8830531498\n",
      "Training step:  755\n",
      "Loss: 1683173.7106735122\n",
      "Training step:  756\n",
      "Loss: 1302200.2382179308\n",
      "Training step:  757\n",
      "Loss: 1683017.5275848028\n",
      "Training step:  758\n",
      "Loss: 1302043.3542663525\n",
      "Training step:  759\n",
      "Loss: 1682862.0937041675\n",
      "Training step:  760\n",
      "Loss: 1301887.2257183017\n",
      "Training step:  761\n",
      "Loss: 1682707.403671462\n",
      "Training step:  762\n",
      "Loss: 1301731.847146547\n",
      "Training step:  763\n",
      "Loss: 1682553.4521779092\n",
      "Training step:  764\n",
      "Loss: 1301577.2131756733\n",
      "Training step:  765\n",
      "Loss: 1682400.2339646132\n",
      "Training step:  766\n",
      "Loss: 1301423.3184814588\n",
      "Training step:  767\n",
      "Loss: 1682247.7438228815\n",
      "Training step:  768\n",
      "Loss: 1301270.157790515\n",
      "Training step:  769\n",
      "Loss: 1682095.9765931575\n",
      "Training step:  770\n",
      "Loss: 1301117.7258795209\n",
      "Training step:  771\n",
      "Loss: 1681944.9271647064\n",
      "Training step:  772\n",
      "Loss: 1300966.0175747192\n",
      "Training step:  773\n",
      "Loss: 1681794.590474845\n",
      "Training step:  774\n",
      "Loss: 1300815.0277512288\n",
      "Training step:  775\n",
      "Loss: 1681644.961508434\n",
      "Training step:  776\n",
      "Loss: 1300664.7513323203\n",
      "Training step:  777\n",
      "Loss: 1681496.0352969193\n",
      "Training step:  778\n",
      "Loss: 1300515.1832890569\n",
      "Training step:  779\n",
      "Loss: 1681347.80691846\n",
      "Training step:  780\n",
      "Loss: 1300366.3186397876\n",
      "Training step:  781\n",
      "Loss: 1681200.2714972396\n",
      "Training step:  782\n",
      "Loss: 1300218.1524495778\n",
      "Training step:  783\n",
      "Loss: 1681053.424202665\n",
      "Training step:  784\n",
      "Loss: 1300070.6798294792\n",
      "Training step:  785\n",
      "Loss: 1680907.2602489972\n",
      "Training step:  786\n",
      "Loss: 1299923.8959360505\n",
      "Training step:  787\n",
      "Loss: 1680761.7748946585\n",
      "Training step:  788\n",
      "Loss: 1299777.7959709198\n",
      "Training step:  789\n",
      "Loss: 1680616.963441811\n",
      "Training step:  790\n",
      "Loss: 1299632.37518003\n",
      "Training step:  791\n",
      "Loss: 1680472.8212358989\n",
      "Training step:  792\n",
      "Loss: 1299487.62885355\n",
      "Training step:  793\n",
      "Loss: 1680329.34366541\n",
      "Training step:  794\n",
      "Loss: 1299343.5523249023\n",
      "Training step:  795\n",
      "Loss: 1680186.526160624\n",
      "Training step:  796\n",
      "Loss: 1299200.14097059\n",
      "Training step:  797\n",
      "Loss: 1680044.3641941135\n",
      "Training step:  798\n",
      "Loss: 1299057.3902095442\n",
      "Training step:  799\n",
      "Loss: 1679902.853279416\n",
      "Training step:  800\n",
      "Loss: 1298915.2955026424\n",
      "Training step:  801\n",
      "Loss: 1679761.9889710776\n",
      "Training step:  802\n",
      "Loss: 1298773.8523522192\n",
      "Training step:  803\n",
      "Loss: 1679621.7668637875\n",
      "Training step:  804\n",
      "Loss: 1298633.0563015828\n",
      "Training step:  805\n",
      "Loss: 1679482.1825922555\n",
      "Training step:  806\n",
      "Loss: 1298492.9029347033\n",
      "Training step:  807\n",
      "Loss: 1679343.2318308349\n",
      "Training step:  808\n",
      "Loss: 1298353.387875507\n",
      "Training step:  809\n",
      "Loss: 1679204.9102923525\n",
      "Training step:  810\n",
      "Loss: 1298214.5067873767\n",
      "Training step:  811\n",
      "Loss: 1679067.2137286083\n",
      "Training step:  812\n",
      "Loss: 1298076.255373385\n",
      "Training step:  813\n",
      "Loss: 1678930.137929853\n",
      "Training step:  814\n",
      "Loss: 1297938.6293750375\n",
      "Training step:  815\n",
      "Loss: 1678793.6787235264\n",
      "Training step:  816\n",
      "Loss: 1297801.6245718675\n",
      "Training step:  817\n",
      "Loss: 1678657.8319740312\n",
      "Training step:  818\n",
      "Loss: 1297665.2367815096\n",
      "Training step:  819\n",
      "Loss: 1678522.5935834297\n",
      "Training step:  820\n",
      "Loss: 1297529.461859196\n",
      "Training step:  821\n",
      "Loss: 1678387.9594899393\n",
      "Training step:  822\n",
      "Loss: 1297394.2956970392\n",
      "Training step:  823\n",
      "Loss: 1678253.9256677984\n",
      "Training step:  824\n",
      "Loss: 1297259.7342236768\n",
      "Training step:  825\n",
      "Loss: 1678120.4881268071\n",
      "Training step:  826\n",
      "Loss: 1297125.7734039489\n",
      "Training step:  827\n",
      "Loss: 1677987.6429119532\n",
      "Training step:  828\n",
      "Loss: 1296992.4092385557\n",
      "Training step:  829\n",
      "Loss: 1677855.3861033926\n",
      "Training step:  830\n",
      "Loss: 1296859.637763588\n",
      "Training step:  831\n",
      "Loss: 1677723.7138155496\n",
      "Training step:  832\n",
      "Loss: 1296727.4550500894\n",
      "Training step:  833\n",
      "Loss: 1677592.6221968317\n",
      "Training step:  834\n",
      "Loss: 1296595.857203686\n",
      "Training step:  835\n",
      "Loss: 1677462.107429628\n",
      "Training step:  836\n",
      "Loss: 1296464.8403643528\n",
      "Training step:  837\n",
      "Loss: 1677332.1657295153\n",
      "Training step:  838\n",
      "Loss: 1296334.4007057971\n",
      "Training step:  839\n",
      "Loss: 1677202.7933450183\n",
      "Training step:  840\n",
      "Loss: 1296204.5344351393\n",
      "Training step:  841\n",
      "Loss: 1677073.986557239\n",
      "Training step:  842\n",
      "Loss: 1296075.2377929315\n",
      "Training step:  843\n",
      "Loss: 1676945.7416802032\n",
      "Training step:  844\n",
      "Loss: 1295946.5070524265\n",
      "Training step:  845\n",
      "Loss: 1676818.055059148\n",
      "Training step:  846\n",
      "Loss: 1295818.3385189183\n",
      "Training step:  847\n",
      "Loss: 1676690.9230709325\n",
      "Training step:  848\n",
      "Loss: 1295690.7285300086\n",
      "Training step:  849\n",
      "Loss: 1676564.3421238773\n",
      "Training step:  850\n",
      "Loss: 1295563.6734550553\n",
      "Training step:  851\n",
      "Loss: 1676438.308657395\n",
      "Training step:  852\n",
      "Loss: 1295437.169694732\n",
      "Training step:  853\n",
      "Loss: 1676312.8191410128\n",
      "Training step:  854\n",
      "Loss: 1295311.2136805302\n",
      "Training step:  855\n",
      "Loss: 1676187.870074698\n",
      "Training step:  856\n",
      "Loss: 1295185.8018748616\n",
      "Training step:  857\n",
      "Loss: 1676063.4579883483\n",
      "Training step:  858\n",
      "Loss: 1295060.9307703616\n",
      "Training step:  859\n",
      "Loss: 1675939.57944154\n",
      "Training step:  860\n",
      "Loss: 1294936.5968898833\n",
      "Training step:  861\n",
      "Loss: 1675816.231023173\n",
      "Training step:  862\n",
      "Loss: 1294812.7967859153\n",
      "Training step:  863\n",
      "Loss: 1675693.4093511452\n",
      "Training step:  864\n",
      "Loss: 1294689.527040159\n",
      "Training step:  865\n",
      "Loss: 1675571.1110713747\n",
      "Training step:  866\n",
      "Loss: 1294566.7842633151\n",
      "Training step:  867\n",
      "Loss: 1675449.332858746\n",
      "Training step:  868\n",
      "Loss: 1294444.565095243\n",
      "Training step:  869\n",
      "Loss: 1675328.0714163815\n",
      "Training step:  870\n",
      "Loss: 1294322.8662041908\n",
      "Training step:  871\n",
      "Loss: 1675207.323474998\n",
      "Training step:  872\n",
      "Loss: 1294201.684286492\n",
      "Training step:  873\n",
      "Loss: 1675087.0857927098\n",
      "Training step:  874\n",
      "Loss: 1294081.016066339\n",
      "Training step:  875\n",
      "Loss: 1674967.3551548843\n",
      "Training step:  876\n",
      "Loss: 1293960.8582954523\n",
      "Training step:  877\n",
      "Loss: 1674848.1283735163\n",
      "Training step:  878\n",
      "Loss: 1293841.2077527856\n",
      "Training step:  879\n",
      "Loss: 1674729.402287563\n",
      "Training step:  880\n",
      "Loss: 1293722.0612445779\n",
      "Training step:  881\n",
      "Loss: 1674611.1737624165\n",
      "Training step:  882\n",
      "Loss: 1293603.415603589\n",
      "Training step:  883\n",
      "Loss: 1674493.4396893405\n",
      "Training step:  884\n",
      "Loss: 1293485.2676890674\n",
      "Training step:  885\n",
      "Loss: 1674376.1969853304\n",
      "Training step:  886\n",
      "Loss: 1293367.614386234\n",
      "Training step:  887\n",
      "Loss: 1674259.4425928975\n",
      "Training step:  888\n",
      "Loss: 1293250.4526063993\n",
      "Training step:  889\n",
      "Loss: 1674143.173479953\n",
      "Training step:  890\n",
      "Loss: 1293133.779286407\n",
      "Training step:  891\n",
      "Loss: 1674027.3866393184\n",
      "Training step:  892\n",
      "Loss: 1293017.5913885513\n",
      "Training step:  893\n",
      "Loss: 1673912.0790889275\n",
      "Training step:  894\n",
      "Loss: 1292901.8859003542\n",
      "Training step:  895\n",
      "Loss: 1673797.2478709908\n",
      "Training step:  896\n",
      "Loss: 1292786.6598339465\n",
      "Training step:  897\n",
      "Loss: 1673682.8900518105\n",
      "Training step:  898\n",
      "Loss: 1292671.910226043\n",
      "Training step:  899\n",
      "Loss: 1673569.0027218556\n",
      "Training step:  900\n",
      "Loss: 1292557.63413789\n",
      "Training step:  901\n",
      "Loss: 1673455.5829954348\n",
      "Training step:  902\n",
      "Loss: 1292443.828654673\n",
      "Training step:  903\n",
      "Loss: 1673342.6280103514\n",
      "Training step:  904\n",
      "Loss: 1292330.490885542\n",
      "Training step:  905\n",
      "Loss: 1673230.134927532\n",
      "Training step:  906\n",
      "Loss: 1292217.6179629406\n",
      "Training step:  907\n",
      "Loss: 1673118.1009307927\n",
      "Training step:  908\n",
      "Loss: 1292105.2070428433\n",
      "Training step:  909\n",
      "Loss: 1673006.5232271005\n",
      "Training step:  910\n",
      "Loss: 1291993.2553044737\n",
      "Training step:  911\n",
      "Loss: 1672895.399046017\n",
      "Training step:  912\n",
      "Loss: 1291881.7599499407\n",
      "Training step:  913\n",
      "Loss: 1672784.7256395589\n",
      "Training step:  914\n",
      "Loss: 1291770.7182039756\n",
      "Training step:  915\n",
      "Loss: 1672674.50028166\n",
      "Training step:  916\n",
      "Loss: 1291660.12731377\n",
      "Training step:  917\n",
      "Loss: 1672564.7202683948\n",
      "Training step:  918\n",
      "Loss: 1291549.984548495\n",
      "Training step:  919\n",
      "Loss: 1672455.3829168219\n",
      "Training step:  920\n",
      "Loss: 1291440.2871993186\n",
      "Training step:  921\n",
      "Loss: 1672346.4855662223\n",
      "Training step:  922\n",
      "Loss: 1291331.0325794523\n",
      "Training step:  923\n",
      "Loss: 1672238.0255769012\n",
      "Training step:  924\n",
      "Loss: 1291222.2180234098\n",
      "Training step:  925\n",
      "Loss: 1672130.0003299618\n",
      "Training step:  926\n",
      "Loss: 1291113.8408868476\n",
      "Training step:  927\n",
      "Loss: 1672022.4072275641\n",
      "Training step:  928\n",
      "Loss: 1291005.898547168\n",
      "Training step:  929\n",
      "Loss: 1671915.243693006\n",
      "Training step:  930\n",
      "Loss: 1290898.388402216\n",
      "Training step:  931\n",
      "Loss: 1671808.5071691675\n",
      "Training step:  932\n",
      "Loss: 1290791.3078705773\n",
      "Training step:  933\n",
      "Loss: 1671702.195119751\n",
      "Training step:  934\n",
      "Loss: 1290684.6543915218\n",
      "Training step:  935\n",
      "Loss: 1671596.305028363\n",
      "Training step:  936\n",
      "Loss: 1290578.4254243965\n",
      "Training step:  937\n",
      "Loss: 1671490.834398193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  938\n",
      "Loss: 1290472.6184487154\n",
      "Training step:  939\n",
      "Loss: 1671385.7807523045\n",
      "Training step:  940\n",
      "Loss: 1290367.230963895\n",
      "Training step:  941\n",
      "Loss: 1671281.1416331802\n",
      "Training step:  942\n",
      "Loss: 1290262.26048908\n",
      "Training step:  943\n",
      "Loss: 1671176.9146025365\n",
      "Training step:  944\n",
      "Loss: 1290157.7045627711\n",
      "Training step:  945\n",
      "Loss: 1671073.0972409055\n",
      "Training step:  946\n",
      "Loss: 1290053.5607428262\n",
      "Training step:  947\n",
      "Loss: 1670969.687147961\n",
      "Training step:  948\n",
      "Loss: 1289949.8266064192\n",
      "Training step:  949\n",
      "Loss: 1670866.681942462\n",
      "Training step:  950\n",
      "Loss: 1289846.4997498004\n",
      "Training step:  951\n",
      "Loss: 1670764.0792613865\n",
      "Training step:  952\n",
      "Loss: 1289743.57778757\n",
      "Training step:  953\n",
      "Loss: 1670661.876759774\n",
      "Training step:  954\n",
      "Loss: 1289641.058353114\n",
      "Training step:  955\n",
      "Loss: 1670560.0721111726\n",
      "Training step:  956\n",
      "Loss: 1289538.9390980797\n",
      "Training step:  957\n",
      "Loss: 1670458.6630067236\n",
      "Training step:  958\n",
      "Loss: 1289437.2176923747\n",
      "Training step:  959\n",
      "Loss: 1670357.6471557233\n",
      "Training step:  960\n",
      "Loss: 1289335.891824073\n",
      "Training step:  961\n",
      "Loss: 1670257.0222852665\n",
      "Training step:  962\n",
      "Loss: 1289234.959199206\n",
      "Training step:  963\n",
      "Loss: 1670156.7861397103\n",
      "Training step:  964\n",
      "Loss: 1289134.4175410764\n",
      "Training step:  965\n",
      "Loss: 1670056.936480376\n",
      "Training step:  966\n",
      "Loss: 1289034.2645909267\n",
      "Training step:  967\n",
      "Loss: 1669957.47108656\n",
      "Training step:  968\n",
      "Loss: 1288934.4981072806\n",
      "Training step:  969\n",
      "Loss: 1669858.3877538485\n",
      "Training step:  970\n",
      "Loss: 1288835.1158656923\n",
      "Training step:  971\n",
      "Loss: 1669759.684294786\n",
      "Training step:  972\n",
      "Loss: 1288736.1156587491\n",
      "Training step:  973\n",
      "Loss: 1669661.3585385964\n",
      "Training step:  974\n",
      "Loss: 1288637.4952961043\n",
      "Training step:  975\n",
      "Loss: 1669563.4083313318\n",
      "Training step:  976\n",
      "Loss: 1288539.2526041546\n",
      "Training step:  977\n",
      "Loss: 1669465.8315351775\n",
      "Training step:  978\n",
      "Loss: 1288441.3854256289\n",
      "Training step:  979\n",
      "Loss: 1669368.626028437\n",
      "Training step:  980\n",
      "Loss: 1288343.8916198802\n",
      "Training step:  981\n",
      "Loss: 1669271.7897057\n",
      "Training step:  982\n",
      "Loss: 1288246.7690621887\n",
      "Training step:  983\n",
      "Loss: 1669175.3204767003\n",
      "Training step:  984\n",
      "Loss: 1288150.0156439496\n",
      "Training step:  985\n",
      "Loss: 1669079.2162677913\n",
      "Training step:  986\n",
      "Loss: 1288053.6292730283\n",
      "Training step:  987\n",
      "Loss: 1668983.4750209462\n",
      "Training step:  988\n",
      "Loss: 1287957.6078725746\n",
      "Training step:  989\n",
      "Loss: 1668888.0946929373\n",
      "Training step:  990\n",
      "Loss: 1287861.9493814472\n",
      "Training step:  991\n",
      "Loss: 1668793.0732563501\n",
      "Training step:  992\n",
      "Loss: 1287766.6517542312\n",
      "Training step:  993\n",
      "Loss: 1668698.4086987297\n",
      "Training step:  994\n",
      "Loss: 1287671.7129604304\n",
      "Training step:  995\n",
      "Loss: 1668604.0990224723\n",
      "Training step:  996\n",
      "Loss: 1287577.130985107\n",
      "Training step:  997\n",
      "Loss: 1668510.1422452922\n",
      "Training step:  998\n",
      "Loss: 1287482.9038284223\n",
      "Training step:  999\n",
      "Loss: 1668416.5363994925\n",
      "Training step:  1000\n",
      "Loss: 1287389.029505216\n",
      "Training step:  1001\n",
      "Loss: 1668323.2795317695\n",
      "Training step:  1002\n",
      "Loss: 1287295.5060453143\n",
      "Training step:  1003\n",
      "Loss: 1668230.369703689\n",
      "Training step:  1004\n",
      "Loss: 1287202.3314931334\n",
      "Training step:  1005\n",
      "Loss: 1668137.8049907833\n",
      "Training step:  1006\n",
      "Loss: 1287109.5039074766\n",
      "Training step:  1007\n",
      "Loss: 1668045.5834828827\n",
      "Training step:  1008\n",
      "Loss: 1287017.0213616702\n",
      "Training step:  1009\n",
      "Loss: 1667953.703283988\n",
      "Training step:  1010\n",
      "Loss: 1286924.8819432238\n",
      "Training step:  1011\n",
      "Loss: 1667862.1625120682\n",
      "Training step:  1012\n",
      "Loss: 1286833.0837539104\n",
      "Training step:  1013\n",
      "Loss: 1667770.9592989841\n",
      "Training step:  1014\n",
      "Loss: 1286741.624909272\n",
      "Training step:  1015\n",
      "Loss: 1667680.0917899695\n",
      "Training step:  1016\n",
      "Loss: 1286650.503538889\n",
      "Training step:  1017\n",
      "Loss: 1667589.5581444066\n",
      "Training step:  1018\n",
      "Loss: 1286559.7177861952\n",
      "Training step:  1019\n",
      "Loss: 1667499.356534889\n",
      "Training step:  1020\n",
      "Loss: 1286469.2658079525\n",
      "Training step:  1021\n",
      "Loss: 1667409.485146956\n",
      "Training step:  1022\n",
      "Loss: 1286379.1457743447\n",
      "Training step:  1023\n",
      "Loss: 1667319.9421795418\n",
      "Training step:  1024\n",
      "Loss: 1286289.3558690548\n",
      "Training step:  1025\n",
      "Loss: 1667230.7258446338\n",
      "Training step:  1026\n",
      "Loss: 1286199.894289102\n",
      "Training step:  1027\n",
      "Loss: 1667141.834367814\n",
      "Training step:  1028\n",
      "Loss: 1286110.759244766\n",
      "Training step:  1029\n",
      "Loss: 1667053.265986971\n",
      "Training step:  1030\n",
      "Loss: 1286021.9489590805\n",
      "Training step:  1031\n",
      "Loss: 1666965.0189528826\n",
      "Training step:  1032\n",
      "Loss: 1285933.4616680772\n",
      "Training step:  1033\n",
      "Loss: 1666877.0915288632\n",
      "Training step:  1034\n",
      "Loss: 1285845.2956204303\n",
      "Training step:  1035\n",
      "Loss: 1666789.481990678\n",
      "Training step:  1036\n",
      "Loss: 1285757.4490775517\n",
      "Training step:  1037\n",
      "Loss: 1666702.1886266372\n",
      "Training step:  1038\n",
      "Loss: 1285669.9203134135\n",
      "Training step:  1039\n",
      "Loss: 1666615.2097372324\n",
      "Training step:  1040\n",
      "Loss: 1285582.707614285\n",
      "Training step:  1041\n",
      "Loss: 1666528.5436350084\n",
      "Training step:  1042\n",
      "Loss: 1285495.8092789017\n",
      "Training step:  1043\n",
      "Loss: 1666442.1886450925\n",
      "Training step:  1044\n",
      "Loss: 1285409.223618401\n",
      "Training step:  1045\n",
      "Loss: 1666356.143104305\n",
      "Training step:  1046\n",
      "Loss: 1285322.9489556996\n",
      "Training step:  1047\n",
      "Loss: 1666270.4053611858\n",
      "Training step:  1048\n",
      "Loss: 1285236.9836257324\n",
      "Training step:  1049\n",
      "Loss: 1666184.9737759256\n",
      "Training step:  1050\n",
      "Loss: 1285151.3259754374\n",
      "Training step:  1051\n",
      "Loss: 1666099.8467208873\n",
      "Training step:  1052\n",
      "Loss: 1285065.974363674\n",
      "Training step:  1053\n",
      "Loss: 1666015.0225797596\n",
      "Training step:  1054\n",
      "Loss: 1284980.9271608286\n",
      "Training step:  1055\n",
      "Loss: 1665930.4997475082\n",
      "Training step:  1056\n",
      "Loss: 1284896.182748657\n",
      "Training step:  1057\n",
      "Loss: 1665846.276630307\n",
      "Training step:  1058\n",
      "Loss: 1284811.739520706\n",
      "Training step:  1059\n",
      "Loss: 1665762.3516461262\n",
      "Training step:  1060\n",
      "Loss: 1284727.595881807\n",
      "Training step:  1061\n",
      "Loss: 1665678.7232236087\n",
      "Training step:  1062\n",
      "Loss: 1284643.7502479283\n",
      "Training step:  1063\n",
      "Loss: 1665595.3898024869\n",
      "Training step:  1064\n",
      "Loss: 1284560.2010462445\n",
      "Training step:  1065\n",
      "Loss: 1665512.3498335185\n",
      "Training step:  1066\n",
      "Loss: 1284476.9467152143\n",
      "Training step:  1067\n",
      "Loss: 1665429.6017786853\n",
      "Training step:  1068\n",
      "Loss: 1284393.9857042052\n",
      "Training step:  1069\n",
      "Loss: 1665347.1441103462\n",
      "Training step:  1070\n",
      "Loss: 1284311.3164733965\n",
      "Training step:  1071\n",
      "Loss: 1665264.975311654\n",
      "Training step:  1072\n",
      "Loss: 1284228.937493729\n",
      "Training step:  1073\n",
      "Loss: 1665183.0938761542\n",
      "Training step:  1074\n",
      "Loss: 1284146.8472468934\n",
      "Training step:  1075\n",
      "Loss: 1665101.4983080963\n",
      "Training step:  1076\n",
      "Loss: 1284065.044225048\n",
      "Training step:  1077\n",
      "Loss: 1665020.1871218495\n",
      "Training step:  1078\n",
      "Loss: 1283983.5269311445\n",
      "Training step:  1079\n",
      "Loss: 1664939.1588427303\n",
      "Training step:  1080\n",
      "Loss: 1283902.293878516\n",
      "Training step:  1081\n",
      "Loss: 1664858.4120058157\n",
      "Training step:  1082\n",
      "Loss: 1283821.343590572\n",
      "Training step:  1083\n",
      "Loss: 1664777.94515599\n",
      "Training step:  1084\n",
      "Loss: 1283740.6746009886\n",
      "Training step:  1085\n",
      "Loss: 1664697.756848681\n",
      "Training step:  1086\n",
      "Loss: 1283660.2854538977\n",
      "Training step:  1087\n",
      "Loss: 1664617.845649324\n",
      "Training step:  1088\n",
      "Loss: 1283580.1747033661\n",
      "Training step:  1089\n",
      "Loss: 1664538.2101331416\n",
      "Training step:  1090\n",
      "Loss: 1283500.3409134108\n",
      "Training step:  1091\n",
      "Loss: 1664458.8488848852\n",
      "Training step:  1092\n",
      "Loss: 1283420.7826577176\n",
      "Training step:  1093\n",
      "Loss: 1664379.7604989244\n",
      "Training step:  1094\n",
      "Loss: 1283341.4985199932\n",
      "Training step:  1095\n",
      "Loss: 1664300.9435797087\n",
      "Training step:  1096\n",
      "Loss: 1283262.487093881\n",
      "Training step:  1097\n",
      "Loss: 1664222.3967413253\n",
      "Training step:  1098\n",
      "Loss: 1283183.7469825365\n",
      "Training step:  1099\n",
      "Loss: 1664144.1186069883\n",
      "Training step:  1100\n",
      "Loss: 1283105.2767983829\n",
      "Training step:  1101\n",
      "Loss: 1664066.107808798\n",
      "Training step:  1102\n",
      "Loss: 1283027.0751633642\n",
      "Training step:  1103\n",
      "Loss: 1663988.3629888594\n",
      "Training step:  1104\n",
      "Loss: 1282949.1407092414\n",
      "Training step:  1105\n",
      "Loss: 1663910.8827985502\n",
      "Training step:  1106\n",
      "Loss: 1282871.4720768114\n",
      "Training step:  1107\n",
      "Loss: 1663833.6658979715\n",
      "Training step:  1108\n",
      "Loss: 1282794.0679160876\n",
      "Training step:  1109\n",
      "Loss: 1663756.7109566568\n",
      "Training step:  1110\n",
      "Loss: 1282716.92688659\n",
      "Training step:  1111\n",
      "Loss: 1663680.0166532618\n",
      "Training step:  1112\n",
      "Loss: 1282640.0476566097\n",
      "Training step:  1113\n",
      "Loss: 1663603.5816748478\n",
      "Training step:  1114\n",
      "Loss: 1282563.4289033636\n",
      "Training step:  1115\n",
      "Loss: 1663527.4047174507\n",
      "Training step:  1116\n",
      "Loss: 1282487.0693132433\n",
      "Training step:  1117\n",
      "Loss: 1663451.4844862318\n",
      "Training step:  1118\n",
      "Loss: 1282410.9675814242\n",
      "Training step:  1119\n",
      "Loss: 1663375.8196945991\n",
      "Training step:  1120\n",
      "Loss: 1282335.1224116737\n",
      "Training step:  1121\n",
      "Loss: 1663300.4090646033\n",
      "Training step:  1122\n",
      "Loss: 1282259.5325166285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1123\n",
      "Loss: 1663225.2513271335\n",
      "Training step:  1124\n",
      "Loss: 1282184.1966177002\n",
      "Training step:  1125\n",
      "Loss: 1663150.345221552\n",
      "Training step:  1126\n",
      "Loss: 1282109.113444768\n",
      "Training step:  1127\n",
      "Loss: 1663075.6894955127\n",
      "Training step:  1128\n",
      "Loss: 1282034.281736109\n",
      "Training step:  1129\n",
      "Loss: 1663001.28290493\n",
      "Training step:  1130\n",
      "Loss: 1281959.700238573\n",
      "Training step:  1131\n",
      "Loss: 1662927.1242142466\n",
      "Training step:  1132\n",
      "Loss: 1281885.367707308\n",
      "Training step:  1133\n",
      "Loss: 1662853.2121958022\n",
      "Training step:  1134\n",
      "Loss: 1281811.2829057502\n",
      "Training step:  1135\n",
      "Loss: 1662779.5456304688\n",
      "Training step:  1136\n",
      "Loss: 1281737.4446056439\n",
      "Training step:  1137\n",
      "Loss: 1662706.1233067533\n",
      "Training step:  1138\n",
      "Loss: 1281663.8515865607\n",
      "Training step:  1139\n",
      "Loss: 1662632.9440211102\n",
      "Training step:  1140\n",
      "Loss: 1281590.502636394\n",
      "Training step:  1141\n",
      "Loss: 1662560.0065783665\n",
      "Training step:  1142\n",
      "Loss: 1281517.3965511855\n",
      "Training step:  1143\n",
      "Loss: 1662487.3097910958\n",
      "Training step:  1144\n",
      "Loss: 1281444.5321348251\n",
      "Training step:  1145\n",
      "Loss: 1662414.852479688\n",
      "Training step:  1146\n",
      "Loss: 1281371.9081990158\n",
      "Training step:  1147\n",
      "Loss: 1662342.6334719975\n",
      "Training step:  1148\n",
      "Loss: 1281299.5235632344\n",
      "Training step:  1149\n",
      "Loss: 1662270.6516038508\n",
      "Training step:  1150\n",
      "Loss: 1281227.3770550103\n",
      "Training step:  1151\n",
      "Loss: 1662198.9057187713\n",
      "Training step:  1152\n",
      "Loss: 1281155.467509228\n",
      "Training step:  1153\n",
      "Loss: 1662127.3946673486\n",
      "Training step:  1154\n",
      "Loss: 1281083.79376848\n",
      "Training step:  1155\n",
      "Loss: 1662056.1173081358\n",
      "Training step:  1156\n",
      "Loss: 1281012.354683102\n",
      "Training step:  1157\n",
      "Loss: 1661985.0725069765\n",
      "Training step:  1158\n",
      "Loss: 1280941.1491108055\n",
      "Training step:  1159\n",
      "Loss: 1661914.2591372237\n",
      "Training step:  1160\n",
      "Loss: 1280870.1759168995\n",
      "Training step:  1161\n",
      "Loss: 1661843.6760793086\n",
      "Training step:  1162\n",
      "Loss: 1280799.4339737464\n",
      "Training step:  1163\n",
      "Loss: 1661773.3222209807\n",
      "Training step:  1164\n",
      "Loss: 1280728.9221614744\n",
      "Training step:  1165\n",
      "Loss: 1661703.196457417\n",
      "Training step:  1166\n",
      "Loss: 1280658.6393671108\n",
      "Training step:  1167\n",
      "Loss: 1661633.2976904986\n",
      "Training step:  1168\n",
      "Loss: 1280588.5844850473\n",
      "Training step:  1169\n",
      "Loss: 1661563.624829529\n",
      "Training step:  1170\n",
      "Loss: 1280518.7564168319\n",
      "Training step:  1171\n",
      "Loss: 1661494.1767908505\n",
      "Training step:  1172\n",
      "Loss: 1280449.1540713026\n",
      "Training step:  1173\n",
      "Loss: 1661424.9524978343\n",
      "Training step:  1174\n",
      "Loss: 1280379.7763638992\n",
      "Training step:  1175\n",
      "Loss: 1661355.950880069\n",
      "Training step:  1176\n",
      "Loss: 1280310.6222171134\n",
      "Training step:  1177\n",
      "Loss: 1661287.1708745891\n",
      "Training step:  1178\n",
      "Loss: 1280241.690560677\n",
      "Training step:  1179\n",
      "Loss: 1661218.6114254112\n",
      "Training step:  1180\n",
      "Loss: 1280172.9803311862\n",
      "Training step:  1181\n",
      "Loss: 1661150.2714832628\n",
      "Training step:  1182\n",
      "Loss: 1280104.490471895\n",
      "Training step:  1183\n",
      "Loss: 1661082.1500052446\n",
      "Training step:  1184\n",
      "Loss: 1280036.2199327704\n",
      "Training step:  1185\n",
      "Loss: 1661014.245955148\n",
      "Training step:  1186\n",
      "Loss: 1279968.167670591\n",
      "Training step:  1187\n",
      "Loss: 1660946.5583035473\n",
      "Training step:  1188\n",
      "Loss: 1279900.3326485988\n",
      "Training step:  1189\n",
      "Loss: 1660879.0860270848\n",
      "Training step:  1190\n",
      "Loss: 1279832.7138368133\n",
      "Training step:  1191\n",
      "Loss: 1660811.8281096094\n",
      "Training step:  1192\n",
      "Loss: 1279765.3102119956\n",
      "Training step:  1193\n",
      "Loss: 1660744.7835411574\n",
      "Training step:  1194\n",
      "Loss: 1279698.1207571032\n",
      "Training step:  1195\n",
      "Loss: 1660677.9513178503\n",
      "Training step:  1196\n",
      "Loss: 1279631.1444615442\n",
      "Training step:  1197\n",
      "Loss: 1660611.3304423052\n",
      "Training step:  1198\n",
      "Loss: 1279564.3803213006\n",
      "Training step:  1199\n",
      "Loss: 1660544.9199236673\n",
      "Training step:  1200\n",
      "Loss: 1279497.8273385821\n",
      "Training step:  1201\n",
      "Loss: 1660478.7187768049\n",
      "Training step:  1202\n",
      "Loss: 1279431.484521767\n",
      "Training step:  1203\n",
      "Loss: 1660412.7260231331\n",
      "Training step:  1204\n",
      "Loss: 1279365.350885821\n",
      "Training step:  1205\n",
      "Loss: 1660346.940690345\n",
      "Training step:  1206\n",
      "Loss: 1279299.4254516212\n",
      "Training step:  1207\n",
      "Loss: 1660281.361811893\n",
      "Training step:  1208\n",
      "Loss: 1279233.707246476\n",
      "Training step:  1209\n",
      "Loss: 1660215.9884277203\n",
      "Training step:  1210\n",
      "Loss: 1279168.195303565\n",
      "Training step:  1211\n",
      "Loss: 1660150.8195832775\n",
      "Training step:  1212\n",
      "Loss: 1279102.8886621497\n",
      "Training step:  1213\n",
      "Loss: 1660085.854330118\n",
      "Training step:  1214\n",
      "Loss: 1279037.7863673924\n",
      "Training step:  1215\n",
      "Loss: 1660021.0917255117\n",
      "Training step:  1216\n",
      "Loss: 1278972.8874704752\n",
      "Training step:  1217\n",
      "Loss: 1659956.5308327794\n",
      "Training step:  1218\n",
      "Loss: 1278908.1910286224\n",
      "Training step:  1219\n",
      "Loss: 1659892.1707213095\n",
      "Training step:  1220\n",
      "Loss: 1278843.6961049852\n",
      "Training step:  1221\n",
      "Loss: 1659828.010466042\n",
      "Training step:  1222\n",
      "Loss: 1278779.4017684287\n",
      "Training step:  1223\n",
      "Loss: 1659764.0491477\n",
      "Training step:  1224\n",
      "Loss: 1278715.307093521\n",
      "Training step:  1225\n",
      "Loss: 1659700.2858524823\n",
      "Training step:  1226\n",
      "Loss: 1278651.4111606586\n",
      "Training step:  1227\n",
      "Loss: 1659636.7196723926\n",
      "Training step:  1228\n",
      "Loss: 1278587.7130558493\n",
      "Training step:  1229\n",
      "Loss: 1659573.3497049715\n",
      "Training step:  1230\n",
      "Loss: 1278524.2118708342\n",
      "Training step:  1231\n",
      "Loss: 1659510.1750534563\n",
      "Training step:  1232\n",
      "Loss: 1278460.906702951\n",
      "Training step:  1233\n",
      "Loss: 1659447.1948263387\n",
      "Training step:  1234\n",
      "Loss: 1278397.7966549813\n",
      "Training step:  1235\n",
      "Loss: 1659384.4081377373\n",
      "Training step:  1236\n",
      "Loss: 1278334.8808354186\n",
      "Training step:  1237\n",
      "Loss: 1659321.8141074122\n",
      "Training step:  1238\n",
      "Loss: 1278272.1583581043\n",
      "Training step:  1239\n",
      "Loss: 1659259.4118598585\n",
      "Training step:  1240\n",
      "Loss: 1278209.6283420497\n",
      "Training step:  1241\n",
      "Loss: 1659197.2005252342\n",
      "Training step:  1242\n",
      "Loss: 1278147.2899120422\n",
      "Training step:  1243\n",
      "Loss: 1659135.1792391709\n",
      "Training step:  1244\n",
      "Loss: 1278085.142198085\n",
      "Training step:  1245\n",
      "Loss: 1659073.3471424629\n",
      "Training step:  1246\n",
      "Loss: 1278023.1843355682\n",
      "Training step:  1247\n",
      "Loss: 1659011.703381282\n",
      "Training step:  1248\n",
      "Loss: 1277961.4154652094\n",
      "Training step:  1249\n",
      "Loss: 1658950.2471068513\n",
      "Training step:  1250\n",
      "Loss: 1277899.8347327097\n",
      "Training step:  1251\n",
      "Loss: 1658888.9774753891\n",
      "Training step:  1252\n",
      "Loss: 1277838.4412891099\n",
      "Training step:  1253\n",
      "Loss: 1658827.8936483497\n",
      "Training step:  1254\n",
      "Loss: 1277777.2342905677\n",
      "Training step:  1255\n",
      "Loss: 1658766.9947922193\n",
      "Training step:  1256\n",
      "Loss: 1277716.2128984442\n",
      "Training step:  1257\n",
      "Loss: 1658706.280078777\n",
      "Training step:  1258\n",
      "Loss: 1277655.376279046\n",
      "Training step:  1259\n",
      "Loss: 1658645.748684273\n",
      "Training step:  1260\n",
      "Loss: 1277594.723603728\n",
      "Training step:  1261\n",
      "Loss: 1658585.3997902244\n",
      "Training step:  1262\n",
      "Loss: 1277534.254048866\n",
      "Training step:  1263\n",
      "Loss: 1658525.232583121\n",
      "Training step:  1264\n",
      "Loss: 1277473.9667959148\n",
      "Training step:  1265\n",
      "Loss: 1658465.246254262\n",
      "Training step:  1266\n",
      "Loss: 1277413.8610309851\n",
      "Training step:  1267\n",
      "Loss: 1658405.4399994998\n",
      "Training step:  1268\n",
      "Loss: 1277353.9359452522\n",
      "Training step:  1269\n",
      "Loss: 1658345.813019905\n",
      "Training step:  1270\n",
      "Loss: 1277294.1907346863\n",
      "Training step:  1271\n",
      "Loss: 1658286.3645210636\n",
      "Training step:  1272\n",
      "Loss: 1277234.6246001518\n",
      "Training step:  1273\n",
      "Loss: 1658227.093713634\n",
      "Training step:  1274\n",
      "Loss: 1277175.236747381\n",
      "Training step:  1275\n",
      "Loss: 1658167.999812764\n",
      "Training step:  1276\n",
      "Loss: 1277116.026386552\n",
      "Training step:  1277\n",
      "Loss: 1658109.082037984\n",
      "Training step:  1278\n",
      "Loss: 1277056.992732627\n",
      "Training step:  1279\n",
      "Loss: 1658050.339613658\n",
      "Training step:  1280\n",
      "Loss: 1276998.135005298\n",
      "Training step:  1281\n",
      "Loss: 1657991.771768886\n",
      "Training step:  1282\n",
      "Loss: 1276939.4524289756\n",
      "Training step:  1283\n",
      "Loss: 1657933.377737258\n",
      "Training step:  1284\n",
      "Loss: 1276880.944232649\n",
      "Training step:  1285\n",
      "Loss: 1657875.156757014\n",
      "Training step:  1286\n",
      "Loss: 1276822.6096498151\n",
      "Training step:  1287\n",
      "Loss: 1657817.108070595\n",
      "Training step:  1288\n",
      "Loss: 1276764.4479184137\n",
      "Training step:  1289\n",
      "Loss: 1657759.2309249386\n",
      "Training step:  1290\n",
      "Loss: 1276706.458280962\n",
      "Training step:  1291\n",
      "Loss: 1657701.5245715436\n",
      "Training step:  1292\n",
      "Loss: 1276648.6399845318\n",
      "Training step:  1293\n",
      "Loss: 1657643.9882664653\n",
      "Training step:  1294\n",
      "Loss: 1276590.9922806493\n",
      "Training step:  1295\n",
      "Loss: 1657586.6212699453\n",
      "Training step:  1296\n",
      "Loss: 1276533.5144250905\n",
      "Training step:  1297\n",
      "Loss: 1657529.4228463557\n",
      "Training step:  1298\n",
      "Loss: 1276476.2056779817\n",
      "Training step:  1299\n",
      "Loss: 1657472.3922647096\n",
      "Training step:  1300\n",
      "Loss: 1276419.0653040367\n",
      "Training step:  1301\n",
      "Loss: 1657415.52879821\n",
      "Training step:  1302\n",
      "Loss: 1276362.0925720008\n",
      "Training step:  1303\n",
      "Loss: 1657358.8317239685\n",
      "Training step:  1304\n",
      "Loss: 1276305.286754927\n",
      "Training step:  1305\n",
      "Loss: 1657302.300323697\n",
      "Training step:  1306\n",
      "Loss: 1276248.6471303192\n",
      "Training step:  1307\n",
      "Loss: 1657245.9338832558\n",
      "Training step:  1308\n",
      "Loss: 1276192.1729797777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1309\n",
      "Loss: 1657189.7316925584\n",
      "Training step:  1310\n",
      "Loss: 1276135.8635890095\n",
      "Training step:  1311\n",
      "Loss: 1657133.6930454546\n",
      "Training step:  1312\n",
      "Loss: 1276079.718247907\n",
      "Training step:  1313\n",
      "Loss: 1657077.8172401194\n",
      "Training step:  1314\n",
      "Loss: 1276023.7362505302\n",
      "Training step:  1315\n",
      "Loss: 1657022.1035787612\n",
      "Training step:  1316\n",
      "Loss: 1275967.91689503\n",
      "Training step:  1317\n",
      "Loss: 1656966.551367509\n",
      "Training step:  1318\n",
      "Loss: 1275912.2594836126\n",
      "Training step:  1319\n",
      "Loss: 1656911.1599167422\n",
      "Training step:  1320\n",
      "Loss: 1275856.7633225892\n",
      "Training step:  1321\n",
      "Loss: 1656855.928540649\n",
      "Training step:  1322\n",
      "Loss: 1275801.4277221758\n",
      "Training step:  1323\n",
      "Loss: 1656800.8565571094\n",
      "Training step:  1324\n",
      "Loss: 1275746.2519963004\n",
      "Training step:  1325\n",
      "Loss: 1656745.9432879058\n",
      "Training step:  1326\n",
      "Loss: 1275691.2354632022\n",
      "Training step:  1327\n",
      "Loss: 1656691.1880592161\n",
      "Training step:  1328\n",
      "Loss: 1275636.3774451145\n",
      "Training step:  1329\n",
      "Loss: 1656636.5902009215\n",
      "Training step:  1330\n",
      "Loss: 1275581.6772679081\n",
      "Training step:  1331\n",
      "Loss: 1656582.1490463426\n",
      "Training step:  1332\n",
      "Loss: 1275527.1342612857\n",
      "Training step:  1333\n",
      "Loss: 1656527.863932896\n",
      "Training step:  1334\n",
      "Loss: 1275472.7477590118\n",
      "Training step:  1335\n",
      "Loss: 1656473.7342018757\n",
      "Training step:  1336\n",
      "Loss: 1275418.517098602\n",
      "Training step:  1337\n",
      "Loss: 1656419.7591982703\n",
      "Training step:  1338\n",
      "Loss: 1275364.4416212337\n",
      "Training step:  1339\n",
      "Loss: 1656365.9382704995\n",
      "Training step:  1340\n",
      "Loss: 1275310.5206717832\n",
      "Training step:  1341\n",
      "Loss: 1656312.2707708084\n",
      "Training step:  1342\n",
      "Loss: 1275256.753599085\n",
      "Training step:  1343\n",
      "Loss: 1656258.7560556012\n",
      "Training step:  1344\n",
      "Loss: 1275203.1397557163\n",
      "Training step:  1345\n",
      "Loss: 1656205.3934844737\n",
      "Training step:  1346\n",
      "Loss: 1275149.6784977147\n",
      "Training step:  1347\n",
      "Loss: 1656152.1824206628\n",
      "Training step:  1348\n",
      "Loss: 1275096.3691846947\n",
      "Training step:  1349\n",
      "Loss: 1656099.1222307712\n",
      "Training step:  1350\n",
      "Loss: 1275043.2111799687\n",
      "Training step:  1351\n",
      "Loss: 1656046.2122852048\n",
      "Training step:  1352\n",
      "Loss: 1274990.2038504505\n",
      "Training step:  1353\n",
      "Loss: 1655993.4519579024\n",
      "Training step:  1354\n",
      "Loss: 1274937.3465667071\n",
      "Training step:  1355\n",
      "Loss: 1655940.8406264184\n",
      "Training step:  1356\n",
      "Loss: 1274884.6387027819\n",
      "Training step:  1357\n",
      "Loss: 1655888.3776716432\n",
      "Training step:  1358\n",
      "Loss: 1274832.0796362716\n",
      "Training step:  1359\n",
      "Loss: 1655836.0624779745\n",
      "Training step:  1360\n",
      "Loss: 1274779.668748207\n",
      "Training step:  1361\n",
      "Loss: 1655783.8944333885\n",
      "Training step:  1362\n",
      "Loss: 1274727.4054232843\n",
      "Training step:  1363\n",
      "Loss: 1655731.872929277\n",
      "Training step:  1364\n",
      "Loss: 1274675.2890495274\n",
      "Training step:  1365\n",
      "Loss: 1655679.9973604258\n",
      "Training step:  1366\n",
      "Loss: 1274623.3190183775\n",
      "Training step:  1367\n",
      "Loss: 1655628.2671247437\n",
      "Training step:  1368\n",
      "Loss: 1274571.494724513\n",
      "Training step:  1369\n",
      "Loss: 1655576.6816235394\n",
      "Training step:  1370\n",
      "Loss: 1274519.815566122\n",
      "Training step:  1371\n",
      "Loss: 1655525.2402615235\n",
      "Training step:  1372\n",
      "Loss: 1274468.2809447935\n",
      "Training step:  1373\n",
      "Loss: 1655473.9424468516\n",
      "Training step:  1374\n",
      "Loss: 1274416.8902653574\n",
      "Training step:  1375\n",
      "Loss: 1655422.7875905815\n",
      "Training step:  1376\n",
      "Loss: 1274365.64293578\n",
      "Training step:  1377\n",
      "Loss: 1655371.7751070713\n",
      "Training step:  1378\n",
      "Loss: 1274314.5383676908\n",
      "Training step:  1379\n",
      "Loss: 1655320.9044147027\n",
      "Training step:  1380\n",
      "Loss: 1274263.57597607\n",
      "Training step:  1381\n",
      "Loss: 1655270.174934523\n",
      "Training step:  1382\n",
      "Loss: 1274212.755178721\n",
      "Training step:  1383\n",
      "Loss: 1655219.5860904446\n",
      "Training step:  1384\n",
      "Loss: 1274162.0753967226\n",
      "Training step:  1385\n",
      "Loss: 1655169.1373098735\n",
      "Training step:  1386\n",
      "Loss: 1274111.536054445\n",
      "Training step:  1387\n",
      "Loss: 1655118.8280231694\n",
      "Training step:  1388\n",
      "Loss: 1274061.1365793278\n",
      "Training step:  1389\n",
      "Loss: 1655068.6576640124\n",
      "Training step:  1390\n",
      "Loss: 1274010.8764021052\n",
      "Training step:  1391\n",
      "Loss: 1655018.6256691965\n",
      "Training step:  1392\n",
      "Loss: 1273960.7549566755\n",
      "Training step:  1393\n",
      "Loss: 1654968.7314785775\n",
      "Training step:  1394\n",
      "Loss: 1273910.7716797702\n",
      "Training step:  1395\n",
      "Loss: 1654918.974534784\n",
      "Training step:  1396\n",
      "Loss: 1273860.9260114597\n",
      "Training step:  1397\n",
      "Loss: 1654869.3542840339\n",
      "Training step:  1398\n",
      "Loss: 1273811.2173949284\n",
      "Training step:  1399\n",
      "Loss: 1654819.8701753155\n",
      "Training step:  1400\n",
      "Loss: 1273761.645276271\n",
      "Training step:  1401\n",
      "Loss: 1654770.5216605167\n",
      "Training step:  1402\n",
      "Loss: 1273712.2091045233\n",
      "Training step:  1403\n",
      "Loss: 1654721.3081944487\n",
      "Training step:  1404\n",
      "Loss: 1273662.9083317802\n",
      "Training step:  1405\n",
      "Loss: 1654672.2292348717\n",
      "Training step:  1406\n",
      "Loss: 1273613.7424130312\n",
      "Training step:  1407\n",
      "Loss: 1654623.2842424712\n",
      "Training step:  1408\n",
      "Loss: 1273564.710806259\n",
      "Training step:  1409\n",
      "Loss: 1654574.4726808723\n",
      "Training step:  1410\n",
      "Loss: 1273515.812972492\n",
      "Training step:  1411\n",
      "Loss: 1654525.7940169016\n",
      "Training step:  1412\n",
      "Loss: 1273467.0483758128\n",
      "Training step:  1413\n",
      "Loss: 1654477.2477201957\n",
      "Training step:  1414\n",
      "Loss: 1273418.4164830346\n",
      "Training step:  1415\n",
      "Loss: 1654428.833263035\n",
      "Training step:  1416\n",
      "Loss: 1273369.916763761\n",
      "Training step:  1417\n",
      "Loss: 1654380.550120494\n",
      "Training step:  1418\n",
      "Loss: 1273321.5486905894\n",
      "Training step:  1419\n",
      "Loss: 1654332.3977706968\n",
      "Training step:  1420\n",
      "Loss: 1273273.3117388426\n",
      "Training step:  1421\n",
      "Loss: 1654284.375694303\n",
      "Training step:  1422\n",
      "Loss: 1273225.2053867187\n",
      "Training step:  1423\n",
      "Loss: 1654236.483374748\n",
      "Training step:  1424\n",
      "Loss: 1273177.22911512\n",
      "Training step:  1425\n",
      "Loss: 1654188.720298598\n",
      "Training step:  1426\n",
      "Loss: 1273129.3824080892\n",
      "Training step:  1427\n",
      "Loss: 1654141.085954925\n",
      "Training step:  1428\n",
      "Loss: 1273081.6647519486\n",
      "Training step:  1429\n",
      "Loss: 1654093.5798353367\n",
      "Training step:  1430\n",
      "Loss: 1273034.0756360616\n",
      "Training step:  1431\n",
      "Loss: 1654046.2014344851\n",
      "Training step:  1432\n",
      "Loss: 1272986.6145525458\n",
      "Training step:  1433\n",
      "Loss: 1653998.9502497183\n",
      "Training step:  1434\n",
      "Loss: 1272939.2809961117\n",
      "Training step:  1435\n",
      "Loss: 1653951.8257807028\n",
      "Training step:  1436\n",
      "Loss: 1272892.0744641132\n",
      "Training step:  1437\n",
      "Loss: 1653904.827530021\n",
      "Training step:  1438\n",
      "Loss: 1272844.9944566991\n",
      "Training step:  1439\n",
      "Loss: 1653857.9550027982\n",
      "Training step:  1440\n",
      "Loss: 1272798.0404765392\n",
      "Training step:  1441\n",
      "Loss: 1653811.207706665\n",
      "Training step:  1442\n",
      "Loss: 1272751.2120289518\n",
      "Training step:  1443\n",
      "Loss: 1653764.5851520186\n",
      "Training step:  1444\n",
      "Loss: 1272704.508622105\n",
      "Training step:  1445\n",
      "Loss: 1653718.0868521158\n",
      "Training step:  1446\n",
      "Loss: 1272657.929766721\n",
      "Training step:  1447\n",
      "Loss: 1653671.7123224847\n",
      "Training step:  1448\n",
      "Loss: 1272611.4749759287\n",
      "Training step:  1449\n",
      "Loss: 1653625.4610811202\n",
      "Training step:  1450\n",
      "Loss: 1272565.1437654744\n",
      "Training step:  1451\n",
      "Loss: 1653579.3326486014\n",
      "Training step:  1452\n",
      "Loss: 1272518.9356537703\n",
      "Training step:  1453\n",
      "Loss: 1653533.3265483754\n",
      "Training step:  1454\n",
      "Loss: 1272472.850161779\n",
      "Training step:  1455\n",
      "Loss: 1653487.4423058282\n",
      "Training step:  1456\n",
      "Loss: 1272426.8868124522\n",
      "Training step:  1457\n",
      "Loss: 1653441.6794485347\n",
      "Training step:  1458\n",
      "Loss: 1272381.0451317835\n",
      "Training step:  1459\n",
      "Loss: 1653396.0375077103\n",
      "Training step:  1460\n",
      "Loss: 1272335.3246483947\n",
      "Training step:  1461\n",
      "Loss: 1653350.5160163\n",
      "Training step:  1462\n",
      "Loss: 1272289.72489288\n",
      "Training step:  1463\n",
      "Loss: 1653305.1145095492\n",
      "Training step:  1464\n",
      "Loss: 1272244.2453985345\n",
      "Training step:  1465\n",
      "Loss: 1653259.832525407\n",
      "Training step:  1466\n",
      "Loss: 1272198.8857012643\n",
      "Training step:  1467\n",
      "Loss: 1653214.6696046516\n",
      "Training step:  1468\n",
      "Loss: 1272153.6453393141\n",
      "Training step:  1469\n",
      "Loss: 1653169.6252896877\n",
      "Training step:  1470\n",
      "Loss: 1272108.5238529672\n",
      "Training step:  1471\n",
      "Loss: 1653124.6991252769\n",
      "Training step:  1472\n",
      "Loss: 1272063.5207850784\n",
      "Training step:  1473\n",
      "Loss: 1653079.8906588214\n",
      "Training step:  1474\n",
      "Loss: 1272018.6356810362\n",
      "Training step:  1475\n",
      "Loss: 1653035.1994402304\n",
      "Training step:  1476\n",
      "Loss: 1271973.8680885076\n",
      "Training step:  1477\n",
      "Loss: 1652990.6250215007\n",
      "Training step:  1478\n",
      "Loss: 1271929.217557477\n",
      "Training step:  1479\n",
      "Loss: 1652946.1669569323\n",
      "Training step:  1480\n",
      "Loss: 1271884.6836401997\n",
      "Training step:  1481\n",
      "Loss: 1652901.8248032387\n",
      "Training step:  1482\n",
      "Loss: 1271840.2658914577\n",
      "Training step:  1483\n",
      "Loss: 1652857.5981195243\n",
      "Training step:  1484\n",
      "Loss: 1271795.9638681388\n",
      "Training step:  1485\n",
      "Loss: 1652813.4864668457\n",
      "Training step:  1486\n",
      "Loss: 1271751.7771295195\n",
      "Training step:  1487\n",
      "Loss: 1652769.4894090325\n",
      "Training step:  1488\n",
      "Loss: 1271707.7052371446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1489\n",
      "Loss: 1652725.6065114404\n",
      "Training step:  1490\n",
      "Loss: 1271663.7477545452\n",
      "Training step:  1491\n",
      "Loss: 1652681.8373419973\n",
      "Training step:  1492\n",
      "Loss: 1271619.9042478625\n",
      "Training step:  1493\n",
      "Loss: 1652638.181471108\n",
      "Training step:  1494\n",
      "Loss: 1271576.1742852994\n",
      "Training step:  1495\n",
      "Loss: 1652594.638470882\n",
      "Training step:  1496\n",
      "Loss: 1271532.5574371202\n",
      "Training step:  1497\n",
      "Loss: 1652551.2079157406\n",
      "Training step:  1498\n",
      "Loss: 1271489.053275944\n",
      "Training step:  1499\n",
      "Loss: 1652507.8893823833\n",
      "Training step:  1500\n",
      "Loss: 1271445.661376482\n",
      "Training step:  1501\n",
      "Loss: 1652464.6824495308\n",
      "Training step:  1502\n",
      "Loss: 1271402.3813158374\n",
      "Training step:  1503\n",
      "Loss: 1652421.5866985372\n",
      "Training step:  1504\n",
      "Loss: 1271359.2126731656\n",
      "Training step:  1505\n",
      "Loss: 1652378.601712284\n",
      "Training step:  1506\n",
      "Loss: 1271316.1550294727\n",
      "Training step:  1507\n",
      "Loss: 1652335.7270756874\n",
      "Training step:  1508\n",
      "Loss: 1271273.2079683202\n",
      "Training step:  1509\n",
      "Loss: 1652292.9623766646\n",
      "Training step:  1510\n",
      "Loss: 1271230.371075235\n",
      "Training step:  1511\n",
      "Loss: 1652250.3072041452\n",
      "Training step:  1512\n",
      "Loss: 1271187.6439375659\n",
      "Training step:  1513\n",
      "Loss: 1652207.7611495415\n",
      "Training step:  1514\n",
      "Loss: 1271145.026145013\n",
      "Training step:  1515\n",
      "Loss: 1652165.3238064346\n",
      "Training step:  1516\n",
      "Loss: 1271102.5172894076\n",
      "Training step:  1517\n",
      "Loss: 1652122.994770444\n",
      "Training step:  1518\n",
      "Loss: 1271060.1169644922\n",
      "Training step:  1519\n",
      "Loss: 1652080.7736391611\n",
      "Training step:  1520\n",
      "Loss: 1271017.824766192\n",
      "Training step:  1521\n",
      "Loss: 1652038.6600123278\n",
      "Training step:  1522\n",
      "Loss: 1270975.6402924315\n",
      "Training step:  1523\n",
      "Loss: 1651996.6534915357\n",
      "Training step:  1524\n",
      "Loss: 1270933.563142945\n",
      "Training step:  1525\n",
      "Loss: 1651954.7536801163\n",
      "Training step:  1526\n",
      "Loss: 1270891.5929195937\n",
      "Training step:  1527\n",
      "Loss: 1651912.9601836395\n",
      "Training step:  1528\n",
      "Loss: 1270849.7292262027\n",
      "Training step:  1529\n",
      "Loss: 1651871.272609721\n",
      "Training step:  1530\n",
      "Loss: 1270807.971668754\n",
      "Training step:  1531\n",
      "Loss: 1651829.69056787\n",
      "Training step:  1532\n",
      "Loss: 1270766.3198550532\n",
      "Training step:  1533\n",
      "Loss: 1651788.2136696146\n",
      "Training step:  1534\n",
      "Loss: 1270724.7733949397\n",
      "Training step:  1535\n",
      "Loss: 1651746.8415282704\n",
      "Training step:  1536\n",
      "Loss: 1270683.3319000963\n",
      "Training step:  1537\n",
      "Loss: 1651705.57375914\n",
      "Training step:  1538\n",
      "Loss: 1270641.9949841744\n",
      "Training step:  1539\n",
      "Loss: 1651664.4099793376\n",
      "Training step:  1540\n",
      "Loss: 1270600.762262826\n",
      "Training step:  1541\n",
      "Loss: 1651623.34980825\n",
      "Training step:  1542\n",
      "Loss: 1270559.6333536757\n",
      "Training step:  1543\n",
      "Loss: 1651582.3928668902\n",
      "Training step:  1544\n",
      "Loss: 1270518.6078760861\n",
      "Training step:  1545\n",
      "Loss: 1651541.5387779807\n",
      "Training step:  1546\n",
      "Loss: 1270477.6854512\n",
      "Training step:  1547\n",
      "Loss: 1651500.7871661368\n",
      "Training step:  1548\n",
      "Loss: 1270436.865702123\n",
      "Training step:  1549\n",
      "Loss: 1651460.1376577148\n",
      "Training step:  1550\n",
      "Loss: 1270396.1482537761\n",
      "Training step:  1551\n",
      "Loss: 1651419.5898813074\n",
      "Training step:  1552\n",
      "Loss: 1270355.5327333477\n",
      "Training step:  1553\n",
      "Loss: 1651379.1434675541\n",
      "Training step:  1554\n",
      "Loss: 1270315.018769441\n",
      "Training step:  1555\n",
      "Loss: 1651338.7980480348\n",
      "Training step:  1556\n",
      "Loss: 1270274.6059924187\n",
      "Training step:  1557\n",
      "Loss: 1651298.553256652\n",
      "Training step:  1558\n",
      "Loss: 1270234.2940347057\n",
      "Training step:  1559\n",
      "Loss: 1651258.4087290652\n",
      "Training step:  1560\n",
      "Loss: 1270194.0825303998\n",
      "Training step:  1561\n",
      "Loss: 1651218.3641026635\n",
      "Training step:  1562\n",
      "Loss: 1270153.9711154923\n",
      "Training step:  1563\n",
      "Loss: 1651178.419016784\n",
      "Training step:  1564\n",
      "Loss: 1270113.959427762\n",
      "Training step:  1565\n",
      "Loss: 1651138.5731123914\n",
      "Training step:  1566\n",
      "Loss: 1270074.047106634\n",
      "Training step:  1567\n",
      "Loss: 1651098.826031936\n",
      "Training step:  1568\n",
      "Loss: 1270034.2337931525\n",
      "Training step:  1569\n",
      "Loss: 1651059.1774197407\n",
      "Training step:  1570\n",
      "Loss: 1269994.51913046\n",
      "Training step:  1571\n",
      "Loss: 1651019.6269223196\n",
      "Training step:  1572\n",
      "Loss: 1269954.9027634521\n",
      "Training step:  1573\n",
      "Loss: 1650980.1741875568\n",
      "Training step:  1574\n",
      "Loss: 1269915.3843384031\n",
      "Training step:  1575\n",
      "Loss: 1650940.8188647386\n",
      "Training step:  1576\n",
      "Loss: 1269875.963503525\n",
      "Training step:  1577\n",
      "Loss: 1650901.5606054633\n",
      "Training step:  1578\n",
      "Loss: 1269836.6399088346\n",
      "Training step:  1579\n",
      "Loss: 1650862.399062677\n",
      "Training step:  1580\n",
      "Loss: 1269797.413205865\n",
      "Training step:  1581\n",
      "Loss: 1650823.3338909233\n",
      "Training step:  1582\n",
      "Loss: 1269758.283047746\n",
      "Training step:  1583\n",
      "Loss: 1650784.3647463275\n",
      "Training step:  1584\n",
      "Loss: 1269719.2490894154\n",
      "Training step:  1585\n",
      "Loss: 1650745.4912869441\n",
      "Training step:  1586\n",
      "Loss: 1269680.3109875289\n",
      "Training step:  1587\n",
      "Loss: 1650706.7131724425\n",
      "Training step:  1588\n",
      "Loss: 1269641.4684004034\n",
      "Training step:  1589\n",
      "Loss: 1650668.0300640147\n",
      "Training step:  1590\n",
      "Loss: 1269602.72098781\n",
      "Training step:  1591\n",
      "Loss: 1650629.4416245113\n",
      "Training step:  1592\n",
      "Loss: 1269564.0684114231\n",
      "Training step:  1593\n",
      "Loss: 1650590.9475184695\n",
      "Training step:  1594\n",
      "Loss: 1269525.5103343406\n",
      "Training step:  1595\n",
      "Loss: 1650552.5474119338\n",
      "Training step:  1596\n",
      "Loss: 1269487.046421337\n",
      "Training step:  1597\n",
      "Loss: 1650514.2409725094\n",
      "Training step:  1598\n",
      "Loss: 1269448.6763388012\n",
      "Training step:  1599\n",
      "Loss: 1650476.0278696418\n",
      "Training step:  1600\n",
      "Loss: 1269410.3997548155\n",
      "Training step:  1601\n",
      "Loss: 1650437.9077741608\n",
      "Training step:  1602\n",
      "Loss: 1269372.216338846\n",
      "Training step:  1603\n",
      "Loss: 1650399.8803582543\n",
      "Training step:  1604\n",
      "Loss: 1269334.1257619387\n",
      "Training step:  1605\n",
      "Loss: 1650361.945295925\n",
      "Training step:  1606\n",
      "Loss: 1269296.127696909\n",
      "Training step:  1607\n",
      "Loss: 1650324.102262822\n",
      "Training step:  1608\n",
      "Loss: 1269258.2218180937\n",
      "Training step:  1609\n",
      "Loss: 1650286.350936048\n",
      "Training step:  1610\n",
      "Loss: 1269220.4078012076\n",
      "Training step:  1611\n",
      "Loss: 1650248.6909939644\n",
      "Training step:  1612\n",
      "Loss: 1269182.6853235713\n",
      "Training step:  1613\n",
      "Loss: 1650211.122116744\n",
      "Training step:  1614\n",
      "Loss: 1269145.0540640366\n",
      "Training step:  1615\n",
      "Loss: 1650173.64398577\n",
      "Training step:  1616\n",
      "Loss: 1269107.5137029123\n",
      "Training step:  1617\n",
      "Loss: 1650136.2562842928\n",
      "Training step:  1618\n",
      "Loss: 1269070.0639223126\n",
      "Training step:  1619\n",
      "Loss: 1650098.9586971172\n",
      "Training step:  1620\n",
      "Loss: 1269032.704405566\n",
      "Training step:  1621\n",
      "Loss: 1650061.7509100887\n",
      "Training step:  1622\n",
      "Loss: 1268995.4348375911\n",
      "Training step:  1623\n",
      "Loss: 1650024.6326109052\n",
      "Training step:  1624\n",
      "Loss: 1268958.254904726\n",
      "Training step:  1625\n",
      "Loss: 1649987.6034884062\n",
      "Training step:  1626\n",
      "Loss: 1268921.164294824\n",
      "Training step:  1627\n",
      "Loss: 1649950.6632333102\n",
      "Training step:  1628\n",
      "Loss: 1268884.1626974412\n",
      "Training step:  1629\n",
      "Loss: 1649913.8115376304\n",
      "Training step:  1630\n",
      "Loss: 1268847.2498031494\n",
      "Training step:  1631\n",
      "Loss: 1649877.0480944468\n",
      "Training step:  1632\n",
      "Loss: 1268810.425304254\n",
      "Training step:  1633\n",
      "Loss: 1649840.3725989058\n",
      "Training step:  1634\n",
      "Loss: 1268773.6888946216\n",
      "Training step:  1635\n",
      "Loss: 1649803.7847472124\n",
      "Training step:  1636\n",
      "Loss: 1268737.0402691248\n",
      "Training step:  1637\n",
      "Loss: 1649767.2842367105\n",
      "Training step:  1638\n",
      "Loss: 1268700.479124229\n",
      "Training step:  1639\n",
      "Loss: 1649730.870766431\n",
      "Training step:  1640\n",
      "Loss: 1268664.0051579974\n",
      "Training step:  1641\n",
      "Loss: 1649694.5440370662\n",
      "Training step:  1642\n",
      "Loss: 1268627.6180698278\n",
      "Training step:  1643\n",
      "Loss: 1649658.3037504437\n",
      "Training step:  1644\n",
      "Loss: 1268591.317560493\n",
      "Training step:  1645\n",
      "Loss: 1649622.1496097532\n",
      "Training step:  1646\n",
      "Loss: 1268555.1033319859\n",
      "Training step:  1647\n",
      "Loss: 1649586.0813193382\n",
      "Training step:  1648\n",
      "Loss: 1268518.9750877933\n",
      "Training step:  1649\n",
      "Loss: 1649550.098585216\n",
      "Training step:  1650\n",
      "Loss: 1268482.9325328781\n",
      "Training step:  1651\n",
      "Loss: 1649514.2011147593\n",
      "Training step:  1652\n",
      "Loss: 1268446.975373457\n",
      "Training step:  1653\n",
      "Loss: 1649478.3886166683\n",
      "Training step:  1654\n",
      "Loss: 1268411.1033174426\n",
      "Training step:  1655\n",
      "Loss: 1649442.66080149\n",
      "Training step:  1656\n",
      "Loss: 1268375.3160738258\n",
      "Training step:  1657\n",
      "Loss: 1649407.0173801589\n",
      "Training step:  1658\n",
      "Loss: 1268339.6133526948\n",
      "Training step:  1659\n",
      "Loss: 1649371.4580652695\n",
      "Training step:  1660\n",
      "Loss: 1268303.9948657416\n",
      "Training step:  1661\n",
      "Loss: 1649335.98257087\n",
      "Training step:  1662\n",
      "Loss: 1268268.4603259412\n",
      "Training step:  1663\n",
      "Loss: 1649300.5906122492\n",
      "Training step:  1664\n",
      "Loss: 1268233.00944761\n",
      "Training step:  1665\n",
      "Loss: 1649265.281905977\n",
      "Training step:  1666\n",
      "Loss: 1268197.6419462448\n",
      "Training step:  1667\n",
      "Loss: 1649230.0561699225\n",
      "Training step:  1668\n",
      "Loss: 1268162.3575388892\n",
      "Training step:  1669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1649194.9131234626\n",
      "Training step:  1670\n",
      "Loss: 1268127.155943801\n",
      "Training step:  1671\n",
      "Loss: 1649159.85248714\n",
      "Training step:  1672\n",
      "Loss: 1268092.0368804818\n",
      "Training step:  1673\n",
      "Loss: 1649124.873982562\n",
      "Training step:  1674\n",
      "Loss: 1268057.0000695887\n",
      "Training step:  1675\n",
      "Loss: 1649089.9773327198\n",
      "Training step:  1676\n",
      "Loss: 1268022.0452332245\n",
      "Training step:  1677\n",
      "Loss: 1649055.1622618868\n",
      "Training step:  1678\n",
      "Loss: 1267987.1720947067\n",
      "Training step:  1679\n",
      "Loss: 1649020.4284956998\n",
      "Training step:  1680\n",
      "Loss: 1267952.3803786363\n",
      "Training step:  1681\n",
      "Loss: 1648985.775760757\n",
      "Training step:  1682\n",
      "Loss: 1267917.6698106527\n",
      "Training step:  1683\n",
      "Loss: 1648951.2037849529\n",
      "Training step:  1684\n",
      "Loss: 1267883.040118021\n",
      "Training step:  1685\n",
      "Loss: 1648916.712297923\n",
      "Training step:  1686\n",
      "Loss: 1267848.4910290963\n",
      "Training step:  1687\n",
      "Loss: 1648882.3010299862\n",
      "Training step:  1688\n",
      "Loss: 1267814.0222733712\n",
      "Training step:  1689\n",
      "Loss: 1648847.9697128478\n",
      "Training step:  1690\n",
      "Loss: 1267779.6335815894\n",
      "Training step:  1691\n",
      "Loss: 1648813.7180792282\n",
      "Training step:  1692\n",
      "Loss: 1267745.3246856402\n",
      "Training step:  1693\n",
      "Loss: 1648779.5458633306\n",
      "Training step:  1694\n",
      "Loss: 1267711.0953189372\n",
      "Training step:  1695\n",
      "Loss: 1648745.4528006844\n",
      "Training step:  1696\n",
      "Loss: 1267676.945215727\n",
      "Training step:  1697\n",
      "Loss: 1648711.4386273748\n",
      "Training step:  1698\n",
      "Loss: 1267642.8741116296\n",
      "Training step:  1699\n",
      "Loss: 1648677.5030814155\n",
      "Training step:  1700\n",
      "Loss: 1267608.881743522\n",
      "Training step:  1701\n",
      "Loss: 1648643.6459015403\n",
      "Training step:  1702\n",
      "Loss: 1267574.967849222\n",
      "Training step:  1703\n",
      "Loss: 1648609.8668275322\n",
      "Training step:  1704\n",
      "Loss: 1267541.1321677295\n",
      "Training step:  1705\n",
      "Loss: 1648576.1656003941\n",
      "Training step:  1706\n",
      "Loss: 1267507.3744393452\n",
      "Training step:  1707\n",
      "Loss: 1648542.5419627135\n",
      "Training step:  1708\n",
      "Loss: 1267473.694405833\n",
      "Training step:  1709\n",
      "Loss: 1648508.995658227\n",
      "Training step:  1710\n",
      "Loss: 1267440.091809757\n",
      "Training step:  1711\n",
      "Loss: 1648475.5264314257\n",
      "Training step:  1712\n",
      "Loss: 1267406.5663948613\n",
      "Training step:  1713\n",
      "Loss: 1648442.1340279696\n",
      "Training step:  1714\n",
      "Loss: 1267373.117905893\n",
      "Training step:  1715\n",
      "Loss: 1648408.8181944855\n",
      "Training step:  1716\n",
      "Loss: 1267339.7460889157\n",
      "Training step:  1717\n",
      "Loss: 1648375.5786792575\n",
      "Training step:  1718\n",
      "Loss: 1267306.4506913407\n",
      "Training step:  1719\n",
      "Loss: 1648342.4152315871\n",
      "Training step:  1720\n",
      "Loss: 1267273.2314613392\n",
      "Training step:  1721\n",
      "Loss: 1648309.327601489\n",
      "Training step:  1722\n",
      "Loss: 1267240.0881483785\n",
      "Training step:  1723\n",
      "Loss: 1648276.3155403677\n",
      "Training step:  1724\n",
      "Loss: 1267207.020502854\n",
      "Training step:  1725\n",
      "Loss: 1648243.378800489\n",
      "Training step:  1726\n",
      "Loss: 1267174.028276501\n",
      "Training step:  1727\n",
      "Loss: 1648210.5171355847\n",
      "Training step:  1728\n",
      "Loss: 1267141.111221984\n",
      "Training step:  1729\n",
      "Loss: 1648177.7303001527\n",
      "Training step:  1730\n",
      "Loss: 1267108.2690931784\n",
      "Training step:  1731\n",
      "Loss: 1648145.0180498543\n",
      "Training step:  1732\n",
      "Loss: 1267075.5016448165\n",
      "Training step:  1733\n",
      "Loss: 1648112.3801412492\n",
      "Training step:  1734\n",
      "Loss: 1267042.8086329033\n",
      "Training step:  1735\n",
      "Loss: 1648079.816332354\n",
      "Training step:  1736\n",
      "Loss: 1267010.1898147499\n",
      "Training step:  1737\n",
      "Loss: 1648047.3263825767\n",
      "Training step:  1738\n",
      "Loss: 1266977.644948605\n",
      "Training step:  1739\n",
      "Loss: 1648014.910051642\n",
      "Training step:  1740\n",
      "Loss: 1266945.1737934065\n",
      "Training step:  1741\n",
      "Loss: 1647982.5671001156\n",
      "Training step:  1742\n",
      "Loss: 1266912.7761091164\n",
      "Training step:  1743\n",
      "Loss: 1647950.2972899338\n",
      "Training step:  1744\n",
      "Loss: 1266880.4516573192\n",
      "Training step:  1745\n",
      "Loss: 1647918.1003847893\n",
      "Training step:  1746\n",
      "Loss: 1266848.200200525\n",
      "Training step:  1747\n",
      "Loss: 1647885.976148691\n",
      "Training step:  1748\n",
      "Loss: 1266816.0215019027\n",
      "Training step:  1749\n",
      "Loss: 1647853.9243465324\n",
      "Training step:  1750\n",
      "Loss: 1266783.9153258854\n",
      "Training step:  1751\n",
      "Loss: 1647821.9447446608\n",
      "Training step:  1752\n",
      "Loss: 1266751.8814379533\n",
      "Training step:  1753\n",
      "Loss: 1647790.0371102092\n",
      "Training step:  1754\n",
      "Loss: 1266719.9196045557\n",
      "Training step:  1755\n",
      "Loss: 1647758.2012114716\n",
      "Training step:  1756\n",
      "Loss: 1266688.0295932293\n",
      "Training step:  1757\n",
      "Loss: 1647726.4368175883\n",
      "Training step:  1758\n",
      "Loss: 1266656.211172294\n",
      "Training step:  1759\n",
      "Loss: 1647694.743698581\n",
      "Training step:  1760\n",
      "Loss: 1266624.4641113142\n",
      "Training step:  1761\n",
      "Loss: 1647663.1216258025\n",
      "Training step:  1762\n",
      "Loss: 1266592.788180706\n",
      "Training step:  1763\n",
      "Loss: 1647631.570371251\n",
      "Training step:  1764\n",
      "Loss: 1266561.1831520235\n",
      "Training step:  1765\n",
      "Loss: 1647600.0897083962\n",
      "Training step:  1766\n",
      "Loss: 1266529.6487977623\n",
      "Training step:  1767\n",
      "Loss: 1647568.6794111663\n",
      "Training step:  1768\n",
      "Loss: 1266498.1848913354\n",
      "Training step:  1769\n",
      "Loss: 1647537.3392548107\n",
      "Training step:  1770\n",
      "Loss: 1266466.7912071813\n",
      "Training step:  1771\n",
      "Loss: 1647506.0690152738\n",
      "Training step:  1772\n",
      "Loss: 1266435.467520687\n",
      "Training step:  1773\n",
      "Loss: 1647474.868469768\n",
      "Training step:  1774\n",
      "Loss: 1266404.2136082577\n",
      "Training step:  1775\n",
      "Loss: 1647443.7373961178\n",
      "Training step:  1776\n",
      "Loss: 1266373.0292471282\n",
      "Training step:  1777\n",
      "Loss: 1647412.6755733776\n",
      "Training step:  1778\n",
      "Loss: 1266341.9142157815\n",
      "Training step:  1779\n",
      "Loss: 1647381.6827817047\n",
      "Training step:  1780\n",
      "Loss: 1266310.8682933927\n",
      "Training step:  1781\n",
      "Loss: 1647350.7588015744\n",
      "Training step:  1782\n",
      "Loss: 1266279.8912599778\n",
      "Training step:  1783\n",
      "Loss: 1647319.903414827\n",
      "Training step:  1784\n",
      "Loss: 1266248.9828968318\n",
      "Training step:  1785\n",
      "Loss: 1647289.1164043276\n",
      "Training step:  1786\n",
      "Loss: 1266218.1429859025\n",
      "Training step:  1787\n",
      "Loss: 1647258.3975535354\n",
      "Training step:  1788\n",
      "Loss: 1266187.3713103028\n",
      "Training step:  1789\n",
      "Loss: 1647227.7466472068\n",
      "Training step:  1790\n",
      "Loss: 1266156.6676537916\n",
      "Training step:  1791\n",
      "Loss: 1647197.1634704035\n",
      "Training step:  1792\n",
      "Loss: 1266126.0318011348\n",
      "Training step:  1793\n",
      "Loss: 1647166.6478097436\n",
      "Training step:  1794\n",
      "Loss: 1266095.463538222\n",
      "Training step:  1795\n",
      "Loss: 1647136.199452489\n",
      "Training step:  1796\n",
      "Loss: 1266064.9626516278\n",
      "Training step:  1797\n",
      "Loss: 1647105.818186746\n",
      "Training step:  1798\n",
      "Loss: 1266034.5289289316\n",
      "Training step:  1799\n",
      "Loss: 1647075.5038017344\n",
      "Training step:  1800\n",
      "Loss: 1266004.1621586399\n",
      "Training step:  1801\n",
      "Loss: 1647045.256087309\n",
      "Training step:  1802\n",
      "Loss: 1265973.8621299926\n",
      "Training step:  1803\n",
      "Loss: 1647015.074834256\n",
      "Training step:  1804\n",
      "Loss: 1265943.6286333555\n",
      "Training step:  1805\n",
      "Loss: 1646984.9598346606\n",
      "Training step:  1806\n",
      "Loss: 1265913.461460114\n",
      "Training step:  1807\n",
      "Loss: 1646954.9108814043\n",
      "Training step:  1808\n",
      "Loss: 1265883.3604021587\n",
      "Training step:  1809\n",
      "Loss: 1646924.9277674835\n",
      "Training step:  1810\n",
      "Loss: 1265853.3252521607\n",
      "Training step:  1811\n",
      "Loss: 1646895.0102871277\n",
      "Training step:  1812\n",
      "Loss: 1265823.3558039097\n",
      "Training step:  1813\n",
      "Loss: 1646865.1582357965\n",
      "Training step:  1814\n",
      "Loss: 1265793.4518522087\n",
      "Training step:  1815\n",
      "Loss: 1646835.3714095124\n",
      "Training step:  1816\n",
      "Loss: 1265763.613192293\n",
      "Training step:  1817\n",
      "Loss: 1646805.649604983\n",
      "Training step:  1818\n",
      "Loss: 1265733.8396206766\n",
      "Training step:  1819\n",
      "Loss: 1646775.9926203163\n",
      "Training step:  1820\n",
      "Loss: 1265704.1309345576\n",
      "Training step:  1821\n",
      "Loss: 1646746.4002538936\n",
      "Training step:  1822\n",
      "Loss: 1265674.4869318865\n",
      "Training step:  1823\n",
      "Loss: 1646716.8723053366\n",
      "Training step:  1824\n",
      "Loss: 1265644.9074118182\n",
      "Training step:  1825\n",
      "Loss: 1646687.4085750838\n",
      "Training step:  1826\n",
      "Loss: 1265615.3921738847\n",
      "Training step:  1827\n",
      "Loss: 1646658.0088640277\n",
      "Training step:  1828\n",
      "Loss: 1265585.9410187693\n",
      "Training step:  1829\n",
      "Loss: 1646628.6729743876\n",
      "Training step:  1830\n",
      "Loss: 1265556.5537478898\n",
      "Training step:  1831\n",
      "Loss: 1646599.4007087797\n",
      "Training step:  1832\n",
      "Loss: 1265527.230163375\n",
      "Training step:  1833\n",
      "Loss: 1646570.191870779\n",
      "Training step:  1834\n",
      "Loss: 1265497.9700683288\n",
      "Training step:  1835\n",
      "Loss: 1646541.046264815\n",
      "Training step:  1836\n",
      "Loss: 1265468.7732665741\n",
      "Training step:  1837\n",
      "Loss: 1646511.9636961836\n",
      "Training step:  1838\n",
      "Loss: 1265439.639562892\n",
      "Training step:  1839\n",
      "Loss: 1646482.9439708043\n",
      "Training step:  1840\n",
      "Loss: 1265410.5687625865\n",
      "Training step:  1841\n",
      "Loss: 1646453.9868955067\n",
      "Training step:  1842\n",
      "Loss: 1265381.5606721744\n",
      "Training step:  1843\n",
      "Loss: 1646425.0922781185\n",
      "Training step:  1844\n",
      "Loss: 1265352.6150987656\n",
      "Training step:  1845\n",
      "Loss: 1646396.2599271347\n",
      "Training step:  1846\n",
      "Loss: 1265323.7318502367\n",
      "Training step:  1847\n",
      "Loss: 1646367.4896516006\n",
      "Training step:  1848\n",
      "Loss: 1265294.9107352905\n",
      "Training step:  1849\n",
      "Loss: 1646338.7812616525\n",
      "Training step:  1850\n",
      "Loss: 1265266.1515633005\n",
      "Training step:  1851\n",
      "Loss: 1646310.134567774\n",
      "Training step:  1852\n",
      "Loss: 1265237.4541445062\n",
      "Training step:  1853\n",
      "Loss: 1646281.5493815844\n",
      "Training step:  1854\n",
      "Loss: 1265208.818289898\n",
      "Training step:  1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1646253.025515328\n",
      "Training step:  1856\n",
      "Loss: 1265180.2438114113\n",
      "Training step:  1857\n",
      "Loss: 1646224.562782462\n",
      "Training step:  1858\n",
      "Loss: 1265151.7305217613\n",
      "Training step:  1859\n",
      "Loss: 1646196.160996753\n",
      "Training step:  1860\n",
      "Loss: 1265123.2782341768\n",
      "Training step:  1861\n",
      "Loss: 1646167.8199726916\n",
      "Training step:  1862\n",
      "Loss: 1265094.8867627962\n",
      "Training step:  1863\n",
      "Loss: 1646139.5395258004\n",
      "Training step:  1864\n",
      "Loss: 1265066.555922521\n",
      "Training step:  1865\n",
      "Loss: 1646111.319472033\n",
      "Training step:  1866\n",
      "Loss: 1265038.2855288938\n",
      "Training step:  1867\n",
      "Loss: 1646083.1596282863\n",
      "Training step:  1868\n",
      "Loss: 1265010.0753983469\n",
      "Training step:  1869\n",
      "Loss: 1646055.0598122578\n",
      "Training step:  1870\n",
      "Loss: 1264981.9253481126\n",
      "Training step:  1871\n",
      "Loss: 1646027.019842389\n",
      "Training step:  1872\n",
      "Loss: 1264953.835196038\n",
      "Training step:  1873\n",
      "Loss: 1645999.0395377644\n",
      "Training step:  1874\n",
      "Loss: 1264925.8047607467\n",
      "Training step:  1875\n",
      "Loss: 1645971.1187180954\n",
      "Training step:  1876\n",
      "Loss: 1264897.8338614563\n",
      "Training step:  1877\n",
      "Loss: 1645943.2572037892\n",
      "Training step:  1878\n",
      "Loss: 1264869.9223182972\n",
      "Training step:  1879\n",
      "Loss: 1645915.4548164173\n",
      "Training step:  1880\n",
      "Loss: 1264842.0699523077\n",
      "Training step:  1881\n",
      "Loss: 1645887.711378141\n",
      "Training step:  1882\n",
      "Loss: 1264814.2765850292\n",
      "Training step:  1883\n",
      "Loss: 1645860.0267116108\n",
      "Training step:  1884\n",
      "Loss: 1264786.5420385043\n",
      "Training step:  1885\n",
      "Loss: 1645832.4006399158\n",
      "Training step:  1886\n",
      "Loss: 1264758.8661358866\n",
      "Training step:  1887\n",
      "Loss: 1645804.8329877125\n",
      "Training step:  1888\n",
      "Loss: 1264731.248700849\n",
      "Training step:  1889\n",
      "Loss: 1645777.323579516\n",
      "Training step:  1890\n",
      "Loss: 1264703.6895577388\n",
      "Training step:  1891\n",
      "Loss: 1645749.8722409548\n",
      "Training step:  1892\n",
      "Loss: 1264676.188531657\n",
      "Training step:  1893\n",
      "Loss: 1645722.4787982907\n",
      "Training step:  1894\n",
      "Loss: 1264648.7454484403\n",
      "Training step:  1895\n",
      "Loss: 1645695.1430783602\n",
      "Training step:  1896\n",
      "Loss: 1264621.3601345355\n",
      "Training step:  1897\n",
      "Loss: 1645667.8649090005\n",
      "Training step:  1898\n",
      "Loss: 1264594.03241741\n",
      "Training step:  1899\n",
      "Loss: 1645640.6441187814\n",
      "Training step:  1900\n",
      "Loss: 1264566.762124882\n",
      "Training step:  1901\n",
      "Loss: 1645613.4805364488\n",
      "Training step:  1902\n",
      "Loss: 1264539.549085469\n",
      "Training step:  1903\n",
      "Loss: 1645586.3739918177\n",
      "Training step:  1904\n",
      "Loss: 1264512.3931286235\n",
      "Training step:  1905\n",
      "Loss: 1645559.3243155165\n",
      "Training step:  1906\n",
      "Loss: 1264485.294084307\n",
      "Training step:  1907\n",
      "Loss: 1645532.3313383865\n",
      "Training step:  1908\n",
      "Loss: 1264458.2517829433\n",
      "Training step:  1909\n",
      "Loss: 1645505.3948919482\n",
      "Training step:  1910\n",
      "Loss: 1264431.2660558813\n",
      "Training step:  1911\n",
      "Loss: 1645478.5148087179\n",
      "Training step:  1912\n",
      "Loss: 1264404.3367351645\n",
      "Training step:  1913\n",
      "Loss: 1645451.6909218933\n",
      "Training step:  1914\n",
      "Loss: 1264377.4636535626\n",
      "Training step:  1915\n",
      "Loss: 1645424.9230654263\n",
      "Training step:  1916\n",
      "Loss: 1264350.646644444\n",
      "Training step:  1917\n",
      "Loss: 1645398.211073566\n",
      "Training step:  1918\n",
      "Loss: 1264323.8855417378\n",
      "Training step:  1919\n",
      "Loss: 1645371.5547813533\n",
      "Training step:  1920\n",
      "Loss: 1264297.1801800304\n",
      "Training step:  1921\n",
      "Loss: 1645344.9540244364\n",
      "Training step:  1922\n",
      "Loss: 1264270.5303946144\n",
      "Training step:  1923\n",
      "Loss: 1645318.4086391071\n",
      "Training step:  1924\n",
      "Loss: 1264243.9360213352\n",
      "Training step:  1925\n",
      "Loss: 1645291.918462162\n",
      "Training step:  1926\n",
      "Loss: 1264217.3968967632\n",
      "Training step:  1927\n",
      "Loss: 1645265.4833314316\n",
      "Training step:  1928\n",
      "Loss: 1264190.9128583735\n",
      "Training step:  1929\n",
      "Loss: 1645239.10308547\n",
      "Training step:  1930\n",
      "Loss: 1264164.483744072\n",
      "Training step:  1931\n",
      "Loss: 1645212.7775631691\n",
      "Training step:  1932\n",
      "Loss: 1264138.1093923731\n",
      "Training step:  1933\n",
      "Loss: 1645186.5066039555\n",
      "Training step:  1934\n",
      "Loss: 1264111.7896423533\n",
      "Training step:  1935\n",
      "Loss: 1645160.2900480237\n",
      "Training step:  1936\n",
      "Loss: 1264085.524333875\n",
      "Training step:  1937\n",
      "Loss: 1645134.1277362818\n",
      "Training step:  1938\n",
      "Loss: 1264059.3133073903\n",
      "Training step:  1939\n",
      "Loss: 1645108.0195100885\n",
      "Training step:  1940\n",
      "Loss: 1264033.1564038952\n",
      "Training step:  1941\n",
      "Loss: 1645081.9652114992\n",
      "Training step:  1942\n",
      "Loss: 1264007.0534649938\n",
      "Training step:  1943\n",
      "Loss: 1645055.964682952\n",
      "Training step:  1944\n",
      "Loss: 1263981.0043328675\n",
      "Training step:  1945\n",
      "Loss: 1645030.0177677353\n",
      "Training step:  1946\n",
      "Loss: 1263955.0088505507\n",
      "Training step:  1947\n",
      "Loss: 1645004.124309942\n",
      "Training step:  1948\n",
      "Loss: 1263929.0668616267\n",
      "Training step:  1949\n",
      "Loss: 1644978.284154142\n",
      "Training step:  1950\n",
      "Loss: 1263903.1782102734\n",
      "Training step:  1951\n",
      "Loss: 1644952.4971454365\n",
      "Training step:  1952\n",
      "Loss: 1263877.3427411767\n",
      "Training step:  1953\n",
      "Loss: 1644926.763129516\n",
      "Training step:  1954\n",
      "Loss: 1263851.5602997579\n",
      "Training step:  1955\n",
      "Loss: 1644901.0819528182\n",
      "Training step:  1956\n",
      "Loss: 1263825.8307319894\n",
      "Training step:  1957\n",
      "Loss: 1644875.4534621474\n",
      "Training step:  1958\n",
      "Loss: 1263800.1538842788\n",
      "Training step:  1959\n",
      "Loss: 1644849.877504918\n",
      "Training step:  1960\n",
      "Loss: 1263774.5296038396\n",
      "Training step:  1961\n",
      "Loss: 1644824.3539292985\n",
      "Training step:  1962\n",
      "Loss: 1263748.9577383809\n",
      "Training step:  1963\n",
      "Loss: 1644798.8825839362\n",
      "Training step:  1964\n",
      "Loss: 1263723.4381362353\n",
      "Training step:  1965\n",
      "Loss: 1644773.4633180809\n",
      "Training step:  1966\n",
      "Loss: 1263697.9706462813\n",
      "Training step:  1967\n",
      "Loss: 1644748.095981497\n",
      "Training step:  1968\n",
      "Loss: 1263672.5551179303\n",
      "Training step:  1969\n",
      "Loss: 1644722.780424455\n",
      "Training step:  1970\n",
      "Loss: 1263647.1914012197\n",
      "Training step:  1971\n",
      "Loss: 1644697.516498073\n",
      "Training step:  1972\n",
      "Loss: 1263621.8793469088\n",
      "Training step:  1973\n",
      "Loss: 1644672.3040539804\n",
      "Training step:  1974\n",
      "Loss: 1263596.6188062823\n",
      "Training step:  1975\n",
      "Loss: 1644647.142944439\n",
      "Training step:  1976\n",
      "Loss: 1263571.4096311815\n",
      "Training step:  1977\n",
      "Loss: 1644622.0330221863\n",
      "Training step:  1978\n",
      "Loss: 1263546.2516739261\n",
      "Training step:  1979\n",
      "Loss: 1644596.9741403\n",
      "Training step:  1980\n",
      "Loss: 1263521.1447874408\n",
      "Training step:  1981\n",
      "Loss: 1644571.966152865\n",
      "Training step:  1982\n",
      "Loss: 1263496.088825369\n",
      "Training step:  1983\n",
      "Loss: 1644547.0089142174\n",
      "Training step:  1984\n",
      "Loss: 1263471.0836416688\n",
      "Training step:  1985\n",
      "Loss: 1644522.1022792861\n",
      "Training step:  1986\n",
      "Loss: 1263446.129091041\n",
      "Training step:  1987\n",
      "Loss: 1644497.2461036646\n",
      "Training step:  1988\n",
      "Loss: 1263421.2250285489\n",
      "Training step:  1989\n",
      "Loss: 1644472.4402430796\n",
      "Training step:  1990\n",
      "Loss: 1263396.3713098557\n",
      "Training step:  1991\n",
      "Loss: 1644447.6845542414\n",
      "Training step:  1992\n",
      "Loss: 1263371.5677913432\n",
      "Training step:  1993\n",
      "Loss: 1644422.9788944959\n",
      "Training step:  1994\n",
      "Loss: 1263346.8143300118\n",
      "Training step:  1995\n",
      "Loss: 1644398.3231216592\n",
      "Training step:  1996\n",
      "Loss: 1263322.110783044\n",
      "Training step:  1997\n",
      "Loss: 1644373.717093547\n",
      "Training step:  1998\n",
      "Loss: 1263297.4570083634\n",
      "Training step:  1999\n",
      "Loss: 1644349.1606692297\n",
      "Loss_min: tensor(165001.4961, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N_init = (max(data_china['E'])+max(data_china['I'])+max(data_china['cured'])+max(data_china['dead']))*100.\n",
    "model_city_date_path = train_with_city_data(data_china,N_init,'02-10','全国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  291   440   571   830  1287  1975  2744  4515  5974  7711  9692 11791\n",
      " 14380 17205 20438 24324 28018 31161 34546 37198 40171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20840 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20840 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "差分序列次数为： 2\n",
      "0 0\n",
      "0 1\n",
      "1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "BIC最小的p值和q值为：1、0\n",
      "-0.012209780116558697\n",
      "差分序列次数为： 2\n",
      "0 0\n",
      "0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC最小的p值和q值为：0、0\n",
      "-0.0003202084876587969\n",
      "差分序列次数为： 2\n",
      "0 0\n",
      "0 1\n",
      "0 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n",
      "2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\base\\model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20840 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20840 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39044 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC最小的p值和q值为：0、0\n",
      "-0.00037388656283452555\n",
      "{'beta': 0.07541153183200418, 'gamma_2': 0.015157766021571067, 'theta': 0.0007813486904893674}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 27979 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAGDCAYAAACvCP20AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZyO1f/H8deZxZZ9GWFElso+GEtfikmiTZREiko/7SXZ+pYSFaKilPbS8rWULJW0WBIlBpMWiiLGvmQrwyzn98fnnu4ZRtbZzPv5eNyP+77Odd3Xfa6pHt/P95zzOR/nvUdEREREcp+Q7O6AiIiIiJwYBXIiIiIiuZQCOREREZFcSoGciIiISC6lQE5EREQkl1IgJyIiIpJLKZATERERyaXCsrsDIiJZwTl3FdA3g1OfA5dk0L7Je3+tc24aUCqD8x2B24GLMzj3hPf+00N+Px8wO6O+ee+bO+deBmplcPoe7/2yjL4nIqJATkTyinLAIO/9l6kNzrnCwGvAXO/9w2kvds59EPiY6L1vfsi5kUAB4Dygpfc+Kc25K4CyGfx+CLDWe3/DEX6nVAa/czdQ7NgfUUTyGk2tioiIiORSCuREREREcikFciIiIiK5lAI5EZFM4Jzr6pzbF3h9evRviIgcPyU7iIhkAu/9e8B7qcfOuQLZ2B0ROU1pRE5EREQkl1IgJyIiIpJLKZATERERyaW0Rk5E8pKnnXN/pjkOBTYANzrnmh9ybWo1hzrOubmHnKsKjAl8nuWc84d87+kj/H7rDO6VWs2hTAbnKgD/d4R7iYjgvPdHv0pEREREchxNrYqIiIjkUgrkRERERHIpBXIiIiIiuVSeS3YoXbq0r1y5cnZ3Q0REROSolixZst17X+ZI5/NcIFe5cmViY2OzuxsiIiIiR+Wc++PfzmtqVUREROQYVK4MdepAVBRER1vboEFQoYK1RUXBjBnWvnYtFCwYbL/99uB92raFevWgVi1rT07+93v9mzw3IiciIiJyoubMgdKl07fdfz/06XP4tVWrQlzc4e2TJkHRouA9dOwI778PnTv/+72ORCNyIiIiIlmoaFF7T0qCgwfBuRO/l0bkgMTEROLj40lISMjurpy2ChQoQGRkJOHh4dndFRERkRPiHFxyib3fdhv07GntY8bA22/bdOvTT0OJEta+Zg3Ur2+B2+OPwwUXBO/Vpg0sWgSXXmqjcqkOvddR+5TXKjtER0f7Q5Md1qxZQ5EiRShVqhTuZMJiyZD3nh07drB3717OPvvs7O6OiIjICdm4EcqXh61boXVreP55OPdcm2p1DgYOhE2b4I034MAB2LcPSpWCJUugfXv46afgaBxAQgJ07Wrr5Fq3hi1bDr/Xm2+6Jd776CP1SVOrQEJCgoK4TOSco1SpUhrxFBGRXK18eXuPiIAOHWxErWxZCA2FkBD4v/+zNoD8+S2IA2jY0NbL/fpr+vsVKADt2sG0aXZ8pHv9GwVyAQriMpf+viIikpv99Rfs3Rv8/PnnULu2jZqlmjLF2gC2bQtmo/7+O6xaBVWq2Chd6neSkiwz9bzz7PhI9/o3WiMnIiIichRbttgoHFgAdv31to3IjTdaZqpztj3Jyy/bNfPmwSOPQFiYjbK99BKULGn3adfOpl6Tk+Gii4Jbk/Trd/i9Jk78935pjRywYsUKatSocWw3eOopaNQIYmKCbXPmwOLF9k9Ajui4/s4iIiKCc/++Rk4jcserUSPo1Mk2gYmJsSAu9fgEDRo0iIULFxIWZv84kpKSaNq0aYZtQKa2Dxo06ISfQ0RE5HSWE8dyFMgdqlevjHfvS6t8ecsbLlfOJrRr1IDHHrNXRqKiYNSof73lhAkTKF68OAC7du1i1KhRGbYd6dpT2S4iIiKHy4SxnJOmQO5ElChhQdy6dXDWWcENY0REROS0FRNjQdu119p+cl98EQzqsosCuUMdy6hUagg+cCCMHQuPPpq9/xRFREQkS1SvbskI48fDAw9k///8a/uR45V2HHXwYHvv1MnaRURE5LS1ciU0aAA7dkC3bjBuXPb/z78CueO1eHH6cdTUcdbFi7O3XyIiIpJpFi2CJk1g+3bbFmTcuJwxlqOp1eOVUVpKTEz2j62KiIhIpvjiC9tDLn9+q4N6ww3WnnYsJ7vCAAVyIiIiIkcwcaJt+lujBsycabmOaWX3WI4CuRwgIiKCbt26ERJiM90pKSm0bds2wzYg09tFREQEXngB7rkHmjeH6dMhsGNXjqLKDqjiQFbR31lERHID74Pbw7ZrBxMmQMGC2dOXo1V2ULKDiIiInJYqV4Y6dWxf/uhAKNS3rxWpr1vX1r3t2hW8fuhQqFbNaqI+9hjcfDM8+SScf77dIyoKihZNv1PZ88/DuedCrVrZU91BU6siIiJy2pozB0qXDh63bm0BW1gY9O9vn4cPh59/tr3hoqJg8mSbRn3lFbsuteBTcjJUqGABYOq9p02D5cstEWLr1qx/Po3IiYiISJ5xySUWnAE0bQrx8fZ50iT4+28L4kaMgMaND99ZbNYsqFoVKlWy47FjYcAAC+IAIiKy5hnSUiAnIiIipyXnLHBr2NBG1w71xhtw6aWwbRu8+CL8/ju89Rb06QORkbBhQ/rrJ0yALl2Cx7/+Cl9/bfvLtWiRPVvKKpA7Tk89dfjGf3PmWLuIiIjkHAsWwNKl8OmnloE6b17w3BNP2Mhc8+b22rkT7r8funcPXuNc8PPBg5a5eu21wbakJPjzT1i40EbxOnWyRImspDVyx6lRo2CFrpiY9BW7TtSgQYNYuHAhYYGx3qSkJJo2bZphG5Ar2gcNGnTifxAREZFToHx5e4+IsHVtixbBhRdaVYaPP7ZEhebN4a+/oEeP9Gvp4uOD3wcLBhs0gLJlg22RkXD11RbwNW4MISFW+aFMmax5PlAgd5hevYKLGo+kfHlo08Y2Bdy0yTYJTE1TzkhUVPoMl4xMmDCB4oENanbt2sWoUaMybDvStTmxXUREJLv89RekpECRIvb588/hkUdsU9/hw2HkSJt2LVDARupCQuD666F3b9i4EVatsuAs1fjx6adVAdq3h9mzoWVLm2Y9eDB9MJgVFMidgBIlLIhbtw7OOsuORUREJOfYsiWYXZqUZEFa27a2vcju3XDFFRAebm116th1nTpBzZo25frCCxAaau1//21lul5+Of1v3HKLvWrXhnz5bKQv7XRsVlAgd4hjGUxKnU4dONAyVh59VKVWRUREcpIqVeD77w9vHzTI9oerX9+mS9Nmmj70kL0OVagQ7NhxeHu+fPDuu6esyydEyQ7HKe2auMGD7b1Tp8MTIERERCR7HZqgOGqU1U096yxrz47tQk41BXLHafHiYKID2PukSdmTciwiIiJHlpqgOHs2/Pe/lpWaL59tNVK0aHb37tTQ1Opxyqj8RkyMplZFRERympgY+N//4PLLISHBEhs++gguvji7e3bqaERORERETkt79lh2akKCHffpc3oFcaARuRwhIiKCbt26ERJicXVKSgpt27bNsA3INe0iIiLZZf16G4n76ScoXNimVceOhYsuOr1m0ZzP6i2Is1l0dLSPjY1N17ZixQpq1KiRTT3KO/R3FhGRrLB0qW0vsnu3bTEyZcrhm/jnlmDOObfEex99pPOaWg3IawFtVtPfV0REssLHH1v1hvBwuO22YBAHp2eCoqZWgQIFCrBjxw5KlSqFy+qd/PIA7z07duygQIEC2d0VERE5jY0ZA/fdZ3vEffSRbd5/qNMtQVGBHBAZGUl8fDzbtm3L7q6ctgoUKEBkZGR2d0NERHKw5GSIjoYKFWxkbdYs6NvXSm0VLgxvvWWVGdats+L2u3bZd554wrYYGTUKSpWClSutbcwYu+/ff1ux+99+s2oNV14Jw4Zl66OeMgrkgPDwcM4+++zs7oaIiEieNnq01S/fs8eO77gDpk2zthdfhMcft2Du8cdtrdsdd0BsrE2l7t8Pd95p7StWwI8/pr93nz42EnfwILRqZVUdLr00yx/xlNMaOREREcl28fHwySdw663BNueCQd3u3VC+fPr2zZutUsP+/fDcc1YftUUL2y8urUKFgtOp+fJBgwb2e6eDTA3knHNrnXM/OOfinHOxgbaSzrkvnHOrAu8lAu3OOfecc261c265c65Bmvt0D1y/yjnXPU17w8D9Vwe+qwVuIiIiuVCvXlZSKyRNZPLaa3DZZRAZCe+8AwMGWPugQfD669a+ciU88wzcc8+x/c6uXbZ+rlWrU/4I2SIrRuRivPdRaVJnBwCzvPfVgVmBY4BLgeqBV09gLFjgBzwKNAEaA4+mBn+Ba3qm+Z42MBMREcllPv7Y6p42bJi+/dlnYcYMGz27+Wbo3dvaBw+2feLKlIE33oBXX7V1dEeTlARdusC990KVKqf+ObJDdkytXgWMC3weB7RP0/62NwuB4s65ckAb4Avv/U7v/Z/AF0DbwLmi3vtvve1t8Xaae4mIiEgusWABTJ8OlStD586WuHD55fD999CkiV1z3XXwzTfw5pvw0ktW+P677yzAS0iA7duP/js9e0L16jb6d7rI7EDOA58755Y453oG2sp67zcBBN4jAu0VgPVpvhsfaPu39vgM2g/jnOvpnIt1zsUqM1VERCRnGTrURt3WroUJE6z6wrRpti7u11/tms8/B+/hllssM/W++yyYW7HCArkyZf79Nx5+2O43alSmP06Wyuys1Wbe+43OuQjgC+fcyn+5NqP1bf4E2g9v9P4V4BWwyg7/3mURERHJbmFhNmV6zTWW3LBlC2zdaskQd99tGaovv2zn3nrL3sFG9fbssezUqVMtACxa1LYjOe88S3QAu0faxIrcKlMDOe/9xsD7VufcFGyN2xbnXDnv/abA9OjWwOXxQMU0X48ENgbaWx7SPjfQHpnB9SIiIpJLtWxpL4AOHWxrkQ4d4Icf4MknLeHBOZuOzcjatRm3n64FhjJtatU5d4ZzrkjqZ+AS4EdgOpCaedodmBb4PB3oFshebQrsDky9fgZc4pwrEUhyuAT4LHBur3OuaSBbtVuae4mIiEgut3o1nH8+LFpkU64PPhgceROTmSNyZYEpgR1BwoD/ee9nOucWA5Occz2AdcC1getnAJcBq4G/gZsBvPc7nXNDgNTKaIO99zsDn+8A3gIKAp8GXiIiIpILPfUUNGpke7598w20aweJibYu7rrrsrt3OVOmBXLe+9+Behm07wAO270lkHl61xHu9QbwRgbtsUDtk+6siIiIZLtGjYIVG556CkqXtm1Frr326N/Nq1TZQURERHKEFi1sA+AhQ2xfuYQEmDz59Cpyf6opkBMREZFst28fdOwIb78Ndevahr933qkg7mgUyImIiEi2+v13S2qYNs2Ct40bYeBAGDsW5szJ7t7lbArkREREJNvMnm1r4zZsgGHDYNIkew0ebO+dOimY+zcK5ERERCTLeQ9jxsAll0DZsrbFiPcWvKVOp8bE2PHixf9+r7xMgZyIiIickORkqF8frrjCjm+6Cc4+G6Ki7BUXZ+0jRgTbateG0FDo1g3uuQeKFLHjq66Cv/4KBnFr1lid1Z49YckSq9Qgh1MgJyIiIidk9GioUSN924gRFsDFxVngBtC3b7Ctf38oXBjefRceegj++MOqNsTFwcyZsHChfad/f7j/fli1CkqUgNdfz9pnyy0UyImIiMhxi4+HTz45vnqlsbFw2222rcikSfD441YHFWzj38REq9zgva2d69jRznXvbnVT5XAK5EREROS49eplm/aGHBJJPPSQbR9y//1w4ECw/X//g+bNre3zz4Ob/CYn28hdRAS0bm3TqTt2QPHiEBYoWxAZackQcjgFciIiInJcPv7YAq+GDdO3Dx0KK1dacsLOnTB8uAVq/ftD1662fu7ii23j31ShoTatGh9vCQ8//phxgXvVWM2YAjkRERE5LgsWwPTpULkydO5s06A33ADlylnAlT8/3HyzXXfllTZyd/vtcM45Nk2akeLFoWVLWydXujTs2gVJSXYuPh7Kl8+qp8tdFMiJiIjIcRk61IKrtWthwgS46CJLXti0yc57D2++aWvivvjCNvYdNgy+/tqyU1Nt22YBG8D+/fDll3DeeRYMxsTABx/YuXHj0n9PgsKyuwMiIiJyeuja1YKzvXutOkPRojBrFlx4Ibz1lu0Zd8YZwes3bbIRuuRkSEmxzX9TtzIZPtxG+x5+2LY46dEjWx4px3M+o4no01h0dLSPjY3N7m6IiIicdryHkSNtTVzdulZyq1Kl7O5V7uacW+K9jz7SeU2tioiIyHF76qn0pbP277es0379bNuQBQsUxGUFBXIiIiJy3Bo1CtZBjY+3LURmzYJbboGJE9NPoUrm0Ro5EREROW6pdVA7dLDs0r/+giFDbE2bZB0FciIiInLcvIdly2DPHvt8++0K4rKDplZFRETkuOzZY5UZHngAwsOtluoHH6RfMydZQ4GciIhITpScbPtupO7HsWaN1a+qXh2uuw4OHrT2efOgQQOrZ5W68RpYVBUVFXwVKBAsWDpmDFSrZhu2bd9+XN364QeIjoYpU2wd3KefWuLDpEnBNXOSdRTIiYiI5ESjR0ONGsHj/v2tgOmqVVCiBLz+urWfdZZt0nb99em/HxNjta/i4mD2bHyhQpz/6CUWFzZrxn21viQ+rBLNm1uCQmKifW33bqvGUK8e1KplG/uC3aZaNWtfs8Y2Af7oI3sfMwb+7/8sJpw7N5P/LpKOAjkREZGcJj4ePvkEbr3Vjr23OlgdO9px9+7B0bXKlW3TtkOr16f1wQesrHwpZ9cqZMf169PmtspUqGDVFvbvh9des1MvvAA1a8L331tQ9sADNpU6dCj89pvVSV282Gqi1q9v32nWzKoyVKoE99xzqv8Y8m8UyImIiOQ0vXrZfGVqcLZjhxUjDQvkKEZGwoYNx3y7hHETeDe5yz9xIcBll4HDZlcbN7bYkcDx3r0WO+7bZ9UZWra0qdMBA6zkVlQURERYFQewgK5y5ZN9aDkRCuRERERyko8/tiipYcNgW0ZVmJw7tvtt2sSB2B+4+pU2GQ7aJSbCO+9A27Z2fPfdsGKFFamvWdNiyN9/tyoNQ4daLLlokS3Rq1r1+B9PTi0FciIiIjnJggUwfboNcXXubFOqvXpZdfmkJLsmPt4irWPw06OT+KFqBxo2Cc/wfL9+Vgv1ggvs+LPPbKb25pshIcECtrlzoV07O79pE9x4o62d+7fZXMka+kcgIiKSkwwdaoHa2rUwYYJlE7z3niUvpGaljhsHV111TLcr8sl4ntvWJV1ceMMNdm7XLktQeOaZ4PUvvwzz51s3br0Vzj8/mCC7Zw9cfjk8/jg0bXrKnlhOggI5ERGR3GD4cIu4qlWz+c4ePax98WJbM/f++3DbbZZqmmrtWs5iPZO2tEgXF77b+Dn+KhFJ4d3xvB1Xl5CetnhuwQL45htLdHjzTQvYVq2CKlUsmOvQAbp1sz3kJGdwPqN599NYdHS0j42Nze5uiIiIZLm5c2HkSFuGFxZmWaZFiti5M8+0WqkVKkC5cpbo4L0lONxwA7z7rk23po0T33rLEh+ee85yMzZvtuV9l10WzIKVk+OcW+K9jz7ieQVyIiIiedeePTa498EH0L69BWfFimV3ryTV0QI5Ta2KiIjkUT/8AI0aWZWGESPgww8VxOU2CuRERETygKeeSl8+6513rNTWxo2WANGnz7HvaCI5hwI5ERGRPKBRI6uF+tlncPvtlrTgvU2lXnhhdvdOTlRYdndAREREMl9MDDz9NFxxhW1HV7CgbVd38cXZ3TM5GRqRExEROc2ljrzdeWewylefPgriTgcK5ERERE5ju3dD1662dUi1alCoEAwcCGPHpl8zJ7mTAjkREZGTkZBgVefr1bNN1h591NovuMA2WYuKsnJa7dtb+8qVVi4hf37b1C2t0aOhdm2oVYuUZ0ZRv75NhRIXR0L9pvx6RhQ/FIjmvxcv+qfawoEDcN11FqQ1aWIFIcCKQZxzju3rNn68tf3xh20zMm8eFCgArVvb97Zuzew/kmQWBXIiIiInI39+S/v8/nuIi4OZM2HhQvj6azuOi7PA7eqr7fqSJW0H3T590t/nxx/h1VetIv3337P+pY+JiVxl5/r145nCj7L09TjqfDiYm37ux+uv26nXX4cSJWD1arj/fujfH1JSYP16WLPGNvd95x372Q8/tLVyYFuOfPEF9OxpwZ7kTgrkREREToZzULiwfU5MtFfafTz27rVAL3VELiLCUkjDDyliv2KFFTAtVIj4zWHMTmrBneWmAOCd4/e4PXTsCOzeTcna5Zk61b42bRp0726fO3a04Kx1a3jwQYsd4+Lg558tUzU1iEsVEwP9+p3aP4dkLQVyIiIiJys52aZQIyIsimrSJHhuyhRo1QqKFv33e9SubXOeO3bQ7+6/ubbwDApsXw/ArkdHMTihL2FnV4Q+fTj42FA2bLCvbdgAFSva55kzbU3ct99aiawJE6B4cZg4Ebp0Sf9zN99sXR4yxJIhJHdSICciInKyQkNt6Cs+3qZGf/wxeG78+MOjqIzUqAH9+7O7cWseW9SWwv+phw+1FNP8b47liVLP2nzps89Ssm+Pfwb9vLd1cvfdB1deaVmps2ZZ2S3n4LvvLMGhdu3gT733nlV1+Ppre73zzin8W0iWUiAnIiJyqhQvDi1b2tAYwI4dFthdfvmxfb9HD4Z1WkpMyDxeGF+SFz6rzuzZwLhxTEy8mqQk4NprCVu2iPLl7SslSkDbtrbs7p57oEgRm6FNNWHC4XFkhQr2XqQIXH+9dVFyJwVyIiIiJ2PbNti1yz7v3w9ffgnnnWfH779vaacFChzbvbZuZehQiP9mHXeV+5Ar3uvCRRdBoarluav2V3zwATB7NhsKVaddO0t0WLTIBuo++gj+8x+46KLgEr2UFOtC587Bn0hKgu3b7XNiInz8cfrROsldVNlBRETkZGzaZNkGyckWOXXqFNgzBBsOGzAg/fWbN1uR0z17ICQERo2ybISiReGaa2wULzwcXniBpNAS9p1XX+W/t9/HuluSiEspwDtNX+GPOTB5MrRoYbkWvXpZZuqECcGfmjcPIiOhSpVg24ED0KaNBXHJybYp8P/9X+b+iSTzOJ/HVjhGR0f72NjY7O6GiIjICfnmG5sOjY+Hxx+Hvn1tiZ6cnpxzS7z30Uc6n+lTq865UOfcMufcx4Hjs51z3znnVjnnJjrn8gXa8weOVwfOV05zjwcD7b8459qkaW8baFvtnBtw6G+LiIjkVk9dNpc5zyz75zg5GXpctpHmzVNwDubPt8E+BXF5W1askbsPWJHmeDjwrPe+OvAn0CPQ3gP403tfDXg2cB3OuZpAZ6AW0BZ4MRAchgIvAJcCNYEugWtFRERyvUYXF6NTn4rMGRHLhg3Q8Ny9vPFpeVrW20VcXPqEBsm7MjWQc85FApcDrwWOHXAR8EHgknFAYIdErgocEzjfKnD9VcAE7/0B7/0aYDXQOPBa7b3/3Xt/EJgQuFZERCTXi+ldn0n//Z72/apT7awDfP9bYfpd9wezlpakWLHs7p3kFJk9IjcK6AekBI5LAbu890mB43ggkARNBWA9QOD87sD1/7Qf8p0jtYuIiOR6yTO/4POnf2APxUhIyc+dDRcxfEKldEUjRDItkHPOXQFs9d4vSducwaX+KOeOtz2jvvR0zsU652K3bdv2L70WERHJZt6zfeBo2l7qGJbQiwIk8GCzeUxaWjXdmjkRyNwRuWZAO+fcWmza8yJshK64cy5125NIYGPgczxQESBwvhiwM237Id85UvthvPeveO+jvffRZcqUOfknExERyQx79hB7UT8aPt6er1wLCrOPGU+v4Mn5FzJp5HpbM6dgTtLItEDOe/+g9z7Se18ZS1aY7b3vCswBOgYu6w5MC3yeHjgmcH62t71RpgOdA1mtZwPVgUXAYqB6IAs2X+A3pmfW84iIyGkiIQEaN4Z69aBWLXj00fTn77nHNmZL9dZbUKaMFSaNirIipmnt2WOlEu6+O9h28CD07AnnnGObA0+efPR+rVjB6+cMp/ncIVCiBLef/z3Tn15FTO/6QGDN3Mj1LP5y94k9t5yWsmND4P7ABOfc48Ay4PVA++vAO8651dhIXGcA7/1PzrlJwM9AEnCX9z4ZwDl3N/AZEAq84b3/KUufREREcp/8+WH2bAvWEhOheXO49FJLA42NDVZpSOu662DMmAxvl/TgQGYltODPCTBkDnTsCI/xBONmRvBsyV9xPoXEu3ZS7R2YOhVWrrSC9UuXwhNPQJ8+cGDCFO65cRevJj1BofzJhBQrQPkro4npbb9x003w1VdQrJgFdZfEWUwpkiWBnPd+LjA38Pl3LOP00GsSgGuP8P0ngCcyaJ8BzDiFXRURkdOdc8ERt8REezlnG7X17Qv/+x9MmXJs91qyhNAdW2jxRFsK/BjLNc9aXPjftW/Q/feVdD8DIIRrrinNVYF9FUqWtLqoU6cCKcmsv30Y17zcmsV0oHjRFBbFhlKpEjRqBO3aQc3AxlojRliQKJKWaq2KiEjek5xsQ1oREdC6NTRpYiNu7dpBuXKHXz95MtSta5HU+sCGCSkp8MADuBEj/imlmpgI+fcHRvQGDoQGDUjscC0/fLmF9oHNtiIiLEgLP/gXq0fPoMHLPVkZXoehQ5Jo3DSE6tUhXz6rjzpt2uFdEUlLgZyIiOQ9oaEQF2d1rhYtsqKk779v6+MOdeWVsHYtLF9uhUm7B5Zzv/giXHYZVKxISorVOI2IgFYtksi/NR6aNYOlS4kreD6vFu9D0aLBW/pFi1nw/BJe2Xg5ZcqHs2h5QaqdF0bFNCl8kZGwYUPw+KGHLJa8/36rlyoCCuRERCQvK14cWraEOXNg9WqoVg0qV4a//7bPAKVK2bo6sOrySwK7an37rY3iVa5MSL8+dD74NttvHcDcH0qRUrAQdOgAwHMbr6V+ytJ/fnLv82/Rqek6vjxwIbWrJfDdyuKcdx5kVPo8dc+4oUNtbd3ixbBzJwwfnjl/Dsl9FMiJiEjesm1bMKFh/3748kto2BA2b7aRt7VroVAhC3a/PqEAACAASURBVOwANm0Kfnf6dKhRwz6/9x6sW2fXjxwJ3bpRYNQwWsY4fj3nSpg7lx07oFjsLM5oVBMSElh57UCa3NuYD317Wrc4yI09C1GkiN0uMjI4aws2WFi+vH0uV86Cuvz5LVFi0aJM/PtIrpIdWasiIiLZZ9Mmmx5NTrZ1bp06wRVXHPn6556zAC4szDIV3nor3elt2+CMv6EQwbiw+b3DOW/QjfB7L+4oUobQvo/zYe1HuOm3hylQKIQvp8FX8/Olq9LQqBGsWgVr1thuJhMmWN5FapfLlbNRu6lToXbtU/5XkVzK+YzGck9j0dHRPjY2Nru7ISIip4nlyw+PCx95xM61bAl9W8fx9RPzGL7/XhpX38mL40ty1VW2/VxIiCXQ/vwzFC0KM2ZAr152r1tusXVxABddZAGj95aj8dJL6be6k9OXc26J9z76iOcVyImIiGQC79n26Bi6DKnBLC7mtut2MXpc8X+W24kci6MFclojJyIicpKeumxu+tJZe/cytvozVB9yA/NDLuSNFxN4aYKCODn1tEZORETkJDW6uBid+lRkEsuIuawgfRp/xdN7e1O2wB5mfR1Ow2h39JuInAAFciIiIicppnd9JvmldHrgLCo+sJ5l3EbDyM3MXHYmpUtnd+/kdKapVRERkZP155+Um/UuISSxjPo0K/c7361VECeZT4GciIjISfBfzuLNKkOI+vQJthFB55rf88vmoswbvezoXxY5SQrkRERETkRCAnvuepCurbdwy65nSCGUiY/8zPif6jFp5Ho69amYPgFCJBMokBMRkTwlIQEaN4Z69aBWLXj00fTn77kn/R5tL70EderY/m3Nm9uebyxfzrhqgynz4iDG04XC+Q7w327xXPuY7dRb/5b61KwTynWPnEuNGlbNSyQzKNlBRETylPz5YfZsC9YSEy04u/RSaNoUYmOD1btSXX893H67fZ4+NYX7O6zjkt/eY0DyEM4sncyEqY4qVfJTr14VHk6yAhD33Qc33lOCW2+FgwetdKtIZtCInIiI5GxHGkIbM8YK2zsH27cHr1+5Es4/3yK2kSPT32vXLty1HSkcfR7UqEHy/G9JTIRSs9/H16pFg0YhPNs1/abxRYsGPqxfz8YBo1n6ayH6JA/nyss83/9SkGbNrIup5bb27IF586BHDzvOlw+KFz/1fxYRUCAnIiI5XeoQ2vffQ1wczJwJCxdCs2ZW2LRSpfTXlyxp9VH79Dn8XvfdB23bkvzTSqLDv6fqFTVo3Rqqd6jN21d9yIaqF2aYafrCLbGUrxTGXb/cy+7QkrwwxjP54/ysWmWxZZ06NgUbFga//w5lylhx+/r14dZb4a+/MudPI6JATkREcjbngovWEhPt5ZxFSZUrH359RIRVoA8PT9+eZqgsNBRil+fjpw3FWbQI5m2rwavzziWywiH32rWLpOu7sfHNz9jsy1I2wtP2sjDuvMvhHDRpAj/9BIsXw9ChNjKXlARLl8Idd8CyZXDGGTBsWGb8YUQUyImISG6QnGzZBhER0Lq1RVDHK4OhsuLhf9GyJcyZA6tXw3ffwZVX2pq2ahX280fNS2kx/nae5CFuuRl+WR3GV18dfusaNSxg+/FHiIy0V2oXO3a0wE4kMyiQExGRnC801KZV4+Nh0SKLmI5XYKjsz853sGuODZUlDhnGl19Cw4awebMlPHw0+SCFwg4wfOONRG2ZyfcFmjB+PLz2Rghz50L16na7NWvslgB//AG//GIDhGeeCRUr2jHArFlQs+ap+COIHE5ZqyIiknsULw4tW9o6udq1j++7gaGy9eWb0D0G6u3pyC1bh9G6L1xxReCav/4iodv/cSAxjo58QKP6ydSsHcqQITY9WqIEjBtnl86fb23h4RASAi++yD/r655/Hrp2tYzVKlXgzTdP1R9AJD0FciIikrNt22bRUvHisH+/JTj073/89wkMldXN/wvLukyzxW0RNbnwESAlBe69l79if+aWkDdJIpy+feHxx0PJly/j2914o70yEhVlW5mIZDbnvc/uPmSp6OhoH6v/ukREco/ly6F7d1snl5ICnTrBI49YZupTT9mcaEQEXHYZvPaaHUdHW3JDSIglSvz8s+0jEhcHt97K1jX7cHt2U2byy9CwIf7CC9n9+w4Ksp89rjiufhSll3yW3U8ugnNuifc++ojnFciJiEheM2cOdOpwkEmJV9MgeTHtD0xgLjHUr+/55BNHuXLZ3UMRc7RATlOrIiKS58TEwKQen3P1M+8AsIvi9OgBr7ziCFEaoOQi+tdVRETyFu/hscfY+cyb7KMwuyjBTfnH81rXOQriJNfRv7IiIpJ3JCXhe97GsEH76chkCA2ld2/4uEBH5rQfbXOuIrmIAjkREckb/v6bgx2uo8drTXmQYeQPT+HjT0J4+mmYNCUfndwk5kzYkt29FDkuCuREROT0t2MHO1t0oM3Hd/Mmt9CqFcyYGUKbNnY6JsaCucVVO2dvP0WOk5IdRETk9LZ2Lasuuo0r1j7P2rCqvPMm3HDD4ZfFxNhLJDfRiJyIiORoCQnQuDHUqwe1asGjj1r7mDFQrRo4B9u3B69fuRLOPx/y54eRvTcyr+H9NF07nq2Fz6ZWnVCeeMLuM3p08Ds7d1oJ1+rV7f3PP7P2GUVOlAI5ERHJ0fLnh9mz4fvvbT/fmTNh4UJo1syKPFSqlP76kiVtr+A+HdcS+/w3XLxzImUqn8GMz8J57TVYscK+/8ILtk8wWKmtVq1g1Sp7HzYs659T5EQokBMRkVNn/Xqbn6xRI/2wV1ycVaSPirKqC4sWWbv3cO+9NrRWty4sXRq8V9u2ULw47sorKFzYmhITof7OWdTp3oD6N0dR+YbmVEpcna4LERHQcNUEvv7feiYmdeSC/6Tw7ZL8nH8+NGhg1xQpYl3csMGOp02z4hFg71OnZtLfR+QUUyAnIiKnTlgYPP304cNe/frZnGhcHAwebMcAn35qw2CrVsErr8AddwTv1bcvvGMb9iYnWwwYEQFDdtzBGVPfs3tdfz337H48XRf2D3+OLl0dX3MBjRskMXNuAUqUSN/NtWth2TJo0sSOt2zhn2oO5crB1q2Z8LcRyQQK5ERE5NQpVy7jYS/nrPYpwO7dUL68fZ42Dbp1s/NNm8KuXbBpk51r1cruAYSGWtwWHw/7Exy/LQvea0to4F4pKWy5YxAxAxrzPtdy8UXJdOwcRnh4+i7u2wfXXAOjRln5VZHcTFmrIiKSOdIOe40aBW3aQJ8+Vvj+m2/smg0boGLF4HciI63tCMVOixeHKZ1fo/P/XQb9CkLRoowttpDrDh7kxysHcsWMO9gaVp7JEzzf/xCKc+m/n5hoQVzXrnD11cH2smUtfixXzt4jIk7tn0Iks2hETkRETr1Dh73GjoVnn7U1dM8+Cz162HXeH/7dQ6KvAwdtoA5g/36oMv1ZlgyeYcNzN9/MwzvvZ3bb4fxnxkMcLFKKed+E0+Ga0MNu6739bI0a0Lt3+nPt2sG4cfZ53Di46qqT/QOIZA3nM/qP6DQWHR3tY2Njs7sbIiKnr8REuOIKG4FLjZiKFbNozDmLqIoVs6nW226Dli2hSxe77txzYe7c4Ijc3LnseWQkLfZ+THIyFDu4jWlbm1Jy52889xy8+8Qa3tp6ObX4iZJnHCBuRQHCwy2fYs8eCAmBwoVtmd7y5XDBBVCnDv/UVH3ySbjsMtixAzp1gnXr4Kyz4P33LftVJLs555Z476OPdF5TqyIicuocadirfHn46isL2mbPtg3bwIbCxoyBzp3hu+8swDtkWrVoUVg2L3CQVALO3A2//spdraFM/6GsoAaXN9rG+FkRqUvqiI8/vGvNm2c8AAhQqhTMmnVSTy6SLRTIiYjIqbNggWWa1qljaaZgw16vvgr33QdJSVCggGWogg2HzZhh248UKgRvvhm81wUX2O6++/ZZgPfQQ5bt+uqrJLe9jHVrUijHWcy/YjjTpkYQevhsqshpT1OrIiKS4z112280mvAAMVPvY/0fKVx5S2l+8LVp13ADU2LPyu7uiWSao02tKtlBRERyvEadq9LJTeLltlNocnMNfvXVKFwohXtHKIiTvE2BnIiI5HgxFyZzd6053H5wNH9TiAL5HVM/DleRe8nzFMiJiEiO5nfv4cla7zHomzZUYAO7Kc7dIS8Sw5zs7ppItlMgJyIiOdaBFb/TvdJcHvqlG61C5nCgWAQDB8LYfPcyp/1omKNgTvK2TAvknHMFnHOLnHPfO+d+cs49Fmg/2zn3nXNulXNuonMuX6A9f+B4deB85TT3ejDQ/otzrk2a9raBttXOuQGZ9SwiIpL1tk77lovqbuOd3e24+Zz5fF+kGZOm5GPwYJg0JR+d3CTmTNiS3d0UyVaZOSJ3ALjIe18PiALaOueaAsOBZ7331YE/gcD23vQA/vTeVwOeDVyHc64m0BmoBbQFXnTOhTrnQoEXgEuBmkCXwLUiIpLL/Tj4Q5q0P5NlyXWZNHoT5/VozqQp+f5ZExcTY8Hc4qqds7ejItks0wI5b/YFDsMDLw9cBHwQaB8HtA98vipwTOB8K+ecC7RP8N4f8N6vAVYDjQOv1d773733B4EJgWtFRCSbrF9vQVaNGlCrFowebe3XXWfbykVFQeXKwS3mDh6Em2+2befq1YO5s5KZ0eFV/vPoxRzIX5R5s5J458tyvP026RIbnn8ebr/dymn165fljymSY2TqhsCBUbMlQDVs9Ow3YJf3PilwSTxQIfC5ArAewHuf5JzbDZQKtC9Mc9u031l/SHuTTHgMERE5RmFh8PTT0KAB7N0LDRtC69YwcWLwmgcesP19wfYJBvjhB9iyag/RdQ6w4cAtRJXZyPRF5Vi0NIzChdP/xpw5MG2aldzKnx+2bs2aZxPJiTI12cF7n+y9jwIisRG0GhldFnh3Rzh3vO2Hcc71dM7FOudit23bdvSOi4jICSlXzoI4gCJFbGRuw4bgee9h0qRgadWff4ZWrSBx5W8MbDyT+ANlaHHOZr5eU5HipcN45hl4+OH0vzF2LAwYYEEcQERE5j+XSE6VJVmr3vtdwFygKVDcOZc6EhgJbAx8jgcqAgTOFwN2pm0/5DtHas/o91/x3kd776PLlClzKh5JRESOYu1aWLYMmqSZK/n6ayhbNlhqtV49eH/sdlrX3siruzqRPzyFOx+vwBlnwMCBNnpXqFD6+/76q92nSRNo0QIWL86yRxLJcTIza7WMc6544HNB4GJgBTAH6Bi4rDswLfB5euCYwPnZ3uqHTQc6B7JazwaqA4uAxUD1QBZsPiwhYnpmPY+IiBy7ffvgmmtg1Cgrep9q/PjgaBxA842TmPdNKPOSm1G/ZgIXXRxCvnwQFwerV0OHDoffOykJ/vwTFi6EESOgUycb6RPJizJzRK4cMMc5txwLur7w3n8M9Ad6O+dWY2vgXg9c/zpQKtDeGxgA4L3/CZgE/AzMBO4KTNkmAXcDn2EB4qTAtSIicqyOlJ2QauRIcA62b7fjadOgbl3LVoiOhvnzrT0uDs4/H2rVwtepy3PNJtK1K1x9dfBWKXfdw8iXC3PddUBSErM7PE/zxy4mLDyEeZ/+zdKfCrBrl43WffstLFliiRHNm9soXMuWdp/ISLuvc9C4MYSEBLsnktc4n8f+b0x0dLSPjY3N7m6IiOQMmzbZK212wtSpULOmBXm33gorV1pUVbq0DbWdcYZFUcuX23DYypUWaTmHr1ad+67dyJBPG1JswwooXtx+JzaWDf1HU2LuFArtiOeVZm9x1893Ub3kdt6fXYZa9cL44gsYMgTmzUvfxbVr4Yor4Mcf7fill2DjRhg82H62VStYt866JHK6cc4t8d5HH+m8KjuIiORl/5adcP/98NRT6SOkwoWDx3/9Ffx8zjlQvToLFsDzk8uzOSWCdudvIyoKZnyUDH378lSppwgP9fSqMo3bfu5F69qbmTi3HFd3CqNGDRg+HN555+hdvuUW+P13qF0bOne2LUgUxElelanbj4iISC6SNjth+nSoUMGyEQ41ZQo8+KDt+/HJJ+lONW8O/rtF0P0g03+qasMFo8dAu3YMqfoLSe+nMPrP7vTqGM+I8RUJC4Nffvn3blWuHByNA8iXD95992QfVuT0cEyBnHPukaNcstV7/9Ip6I+IiGSHtNkJYWHwxBPw+ecZX9uhg73mzbPU0i+/DJ7btAluvBEuvhi++grOPRfef581F/8fV15VmoWE8tKQbdz2cGTWPJfIae6Y1sg552ZgWaFHGrwe571vf4RzOYrWyImIHCIx0RahtWkDvXvb7rytWgX3/YiPh/LlYdEiOPPM9N89+2zb/6N0adizxzISHnyQp75sQKMJDxDTrxEHhwxn84HieBwVWU9I1SqWkioiR3W0NXLHOrWa7L3f8y8/krcyJkREThfeQ48etjaud29rq1MnfbmEypUhNtaCtdWroWpVW5S2dKnV2CpVyt47dIBu3eDaa2lUGjpNmMitj4zimZRtlGEbfxcuy9akEoQoiBM5ZY41kDtaoKZATkQkN1qwwDIM6tQJFkB98km47LKMr588Gd5+G8LDoWBBq73lnJVrmDcPduyAt96iZXIy94TewqMp/anEGvYVLMvk6eGEXZl1jyaSFxzr1OqnwHVHOg287b3PFQXrNbUqIpK5/I6d9Kv1CSO33Eht9xM/+loMLDiSwZ80tD3rROSYnaqp1YVAryP9BvDp8XZMREROP0mbt3Nbrfm8sfNG2od+xPzCbRh4L4x97l5i2nciZioK5kROoWMN5JpwlGQHQFmrIiJ5WMK6rVxfZzlT9rTnxqoL+HR7GyZNyUdMDMTE5KNTh0lMmvCh4jiRU0jJDiIictL2rtpM+6i1zP77Ykbf+QsJlZpxc6Pg4FtMDEyako/FizujOE7k1FGyg4iInJTtyzdyWePtLD0Qzdv/XcGNT9TI8Dobmcvizomc5o41kAt3zhU9wjkHhJ6i/oiISC4SvzCeSy7cz++J5zBl2K9c2b9mdndJJE853mSHI62Rm3lquiMiIllp/Xrb+m3zZggJgZ494b77gudHjoS+fWHbNttGLtXixdC0qackBTmYUoTPXvydFnfUZM8e25KuQwcYMyb9b7VrZzVS05bbEpGTc0yBnPf+sczuiIiIZL2wMHj6aWjQAPbuhYYNoXVrqFnTgrwvvoCzzkr/neRkuLNHAmEpIRwkjDnvbqBBVxuJGzgQWrQ4/Hc+/BAKF86CBxLJY0KyuwMiIpJ9ypWzIA6gSBEbTduwwY7vvx+eesr2+02rV7ed/PiDJ5xEhvTb+08Qt2QJbNkCl1yS/vp9++CZZ+DhhzP5YUTyIAVyIiICwNq1sGwZNGkC06dDhQpQr176a956Ip4X/leMSiHrubR1EuUbRQKQkgIPPAAjRhx+34ED7Vxq6VYROXUUyImICPv2wTXXwKhRNt36xBMweHD6a9598g9ufrg854b+xvz5jjPKF/vn3IsvWlWvihXTfycuzsqzduiQBQ8hkgcda7KDiIicphITLYjr2hWuvhp++AHWrAmOxsXHQ/UqSezaW4kCJPB3xNlEdwln+3aYMcMCv2+/ha+/toBu3z44eNDWxFWqZFOulStDUhJs3QotW8Lcudn4wCKnEY3IiYjkJuvX22ZsNWpArVowerS179xpWQrVq9v7n3+m/97ixRAaCh98YMd//AENG+KjothSphY9El+id287VefH8WwtW4e1Reuy5ry2nFVgM7v2htG+4Ez+/HkTf2wMZ+1a6NjRArf27eG992DdOpueHTnSMmGHDYM77oCNG619/nw45xwFcSKnkgI5EZHcJDXNdMUKWLgQXngBfv7ZoqZWrWDVKnsfNiz4neRk6N8f2rQJtpUrB998w4IxcZy3+zuazR9G61obaVgviQN33Adz5pASt5xZa6rQ7a+X6HLGNN7/oQYFapyd9c8sIkfkvM9bRRmio6N9bGxsdndDROTUuOoquPtue82dawHapk02f/nLL3bNqFEQHm6jcldcYUNpae3YAfXrW2BYpgyUL0/it7HcdHsBLpj1KKUK/k3HX57EVYzM6qcTyfOcc0u899FHOq81ciIiuVXaNNMtWyyIA3vfutU+b9gAU6bA7NkWyKW1fj1cfjmJK1ez5o4RnFO+PAAHRo0l6dw6jEw5g8TwQlRcOVdBnEgOpalVEZHcKG2aadEjVVAEevWC4cNtfdyhKlaE5ctZ1Gkk+154i/mTt7BrWyLLbh1D3ZSljCjwCGfd0AL39rjMew4ROSkakRMRyW0OTTMFKFvWplRTp1YjIqw9NhY6d7bPadNM27f/53bNetRg06QtPHjjHDaHRtI3IZSujGfw/2pDqZvSr7cTkRxFI3IiIrmJ99Cjh2WtpqaZghUyHRcYORs3ztbOge0jsnYth6WZxsfD/v12TVQUpUvB6v2RLN9XhQYsZfC4Srb52xdf2G+JSI6kQE5EJDdZsADeecfWvEVF2WvGDBgwwIKu6tXtfcCAf7/PihW2tq5ePQ6c34IBu/vzDf+hDZ/xRPgg/ho4FOrWtR19//vfrHk2ETluyloVEcnDli+Hls0OsmtfGC+F3EnP3kWY88oqOrlJTJqSj5iY7O6hSN52tKxVjciJiORR330HLZsnkrzvb95wPeg5uS2MGEHM1PuY5DuxeMJv2d1FETkKBXIiInnQ3Llw8UXJlNi3nriSF3PTB1cGEyBiYoiZeh/9qk7O1j6KyNEpa1VEJI/55BPoeE0KVRJ/5YtKt1J+wXQI7CH3j5gYNK8qkvNpRE5EJA+ZOBHat/fUSvqeryJvoPy8CYcHcSKSayiQExHJRdavt4GyGjWgVi0YPdrad+6E1q0tabV1a/jzT2vfvRuuvBLq1YMKFaBzZ8/5LGRQidFcfMa3RF1ZkagoKFAApk617/ToYdfXrWs7luzblz3PKiJHp6xVEZFcZNMmezVoAHv3QsOGFoC99RaULGm7jgwbZoHc8OHw5JMWzJUrB/ffD+EksrVsHYrP/xiqVQMsCKxWzbaWK1QI9uwJFovo3dv2Fj7abiYikjlUa1VE5DRSrlywpGqRIjYyt2EDTJtmCQwA3btDy5YWyAHMmWNlVtvmm8WvyVUpOnvqP0EcwAcfwKWXWhAHwSDOe9sz2LkseTQROQGaWhURyaXWroVly2xf3y1bggFeuXKwdasFYps3WxBXkP18fbApzz0HITXPS3efCROgS5f09775ZjjzTFi5Eu65J2ueR0SOnwI5EZFcaN8+K7c6alRwBO1Qt90Gzz8PUeE/sbdYJHHT/uDuEZXZsyd4zaZN8MMP0KZN+u+++SZs3GgjfhMnZt5ziMjJUSAnIpKZbrnFFpnVrh1su+66YHmtypXtHay0VsOGUKeOvc+eHfzOkiXWXq0ayXffyzVXe7p2hauXD4IKFfg2IYrEWlaua906SE6GV1+FqmF/MDrsAUK//Ixq7Wpy9tk2ypZq0iQrqRoefnjXQ0Otq5O1nZxIjqU1ciIimemmm+Duu6Fbt2Bb2iGuBx6AYsXsc+nS8NFHth3Ijz/aMNmGDXbujjvglVfwTZryY8XLuLrRTG7rfSkMAu6/nze29KFUKeh1EbSpb4kQw8uMZM2fxZnd5VUujK7Ili3wyy9QpUrw58ePh6FDg8few2+/2RI6760756WfiRWRHESBnIhIZrrwQlvMlhHvbUgsdeStfv3guVq1ICEBDhywtNI9e+D881kwH17Y2I2rv55KVNSl3L4ZWlwOA56yqdbBg2H/fs+IsiPps3cQGyfO4qaXKlKnjv3c8OEWL4J1a/16aNEifZe6d7ef8962IRk7NjP+MCJyKiiQExHJLl9/DWXL2uZvh5o82QK7/PltVC4yEoDmzaH5vEgYvoFrP8ZG5N4aQ9KFb9NnWzQ3HRjJK2c9zQ1bn4GPP6Z8q6Z8fnXGP1+5cnDAL1VICCxYcAqfUUQyldbIiYhkl/HjD08XBfjpJ+jfH15+2Y4z2u8zdU+QO+5gyze/ER0ax487zmTJGS24YfNImDIFWrXKvL6LSI6gETkRkeyQlAQffmhJDGnFx1v2wdtvQ9Wq1hYZae0BH42NpwHlqQCsO1CW1q3hjz88u0qcTaUdP8L06dC2bdY9i4hkG43IiYhkhy+/tCyCwJQpALt2weWXW/ZBs2bB9nLlbPffhQvBe/7z29v0mXcV77wD1/xnExs2eAom7aPHzhHwn/9YTS4RyRMUyImIZKYuXeD88y1dNDISXn/d2jPahXfMGFi9GoYMCW5PsnWrnRs7Fm69FapVo1Tobi68qQrdu8P9m/ux6K/arE8uR/Xyf1uZBhHJM1RrVUQkl/lk6HI6/bcq+c7Ix66/whnIYAYXGWl1umJisrt7InIKHa3WaqaNyDnnKjrn5jjnVjjnfnLO3RdoL+mc+8I5tyrwXiLQ7pxzzznnVjvnljvnGqS5V/fA9aucc93TtDd0zv0Q+M5zzqkioIic3l59Fdo9XJfI8p6Qv/YwkMGM5U7mDPpKQZxIHpSZU6tJwAPe+xpAU+Au51xNYAAwy3tfHZgVOAa4FKgeePUExoIFfsCjQBOgMfBoavAXuKZnmu9pda+InJa8h0cegZ49IbruAXZsSeQDrmUwjzLpxo/oNLQ+c+Zkdy9FJKtlWiDnvd/kvV8a+LwXWAFUAK4CxgUuGwe0D3y+Cnjbm4VAcedcOaAN8IX3fqf3/k/gC6Bt4FxR7/233uaH305zLxGR00ZiolX6GjIEely1nfarn+b90C7EFF0CAwcS82k/Jj24jMWLs7unIpLVsmT7EedcZaA+8B1Q1nu/CSzYc85FBC6rAKxP87X4QNu/tcdn0J7R7/fERu4466yzTu5hRESy0N690LEjfP45DOqykkemNsQVKQzhiTB5qk2nxsQQ0+kSYiZNAjS9KpKXZHrWqnOuMDAZ6OW93UvM6AAAIABJREFU3/Nvl2bQ5k+g/fBG71/x3kd776PLlClztC6LiJwyt9wCERFQu3aw7brrgkmplSvbO1jJrIIFg+e6dbPyWV9+6alTbhvjx0Nt/wMDqr1vlR9iYli3DmIGx1C/+O/Uvb4WM2Zkx1OKSHbJ1EDOOReOBXHvee8/DDRvCUyLEngP5NYTD1RM8/VIYONR2iMzaBcRyTFuuglmzkzfNnEixMXZ65pr4Oo0JbSqVrX28eNh3jz49VfPB61fZvSmTqy8+iGWbTqTBSEX8mmCjbw9/jh06gTLVhVhwqwI7rwz655NRLJfZmatOuB1YIX3/pk0p6YDqZmn3YFpadq7BbJXmwK7A1OwnwGXOOdKBJIcLgE+C5zb65xrGvitbmnuJSJyYjIaQks1cqSVxtq+3Y6nTYO6dW34LDoa5s8PXtuvH9SqxYW31aDac/cGy2wtWQJ16kC1avh77mXSRH/YdnLz59t+wAn7U/iq7r10+OwOYvo2gvff///27js8irJr4PBv0iAQehMJEOk9AQKIryArooB0MDQLzcIrAiqifKAiFjAiio1XEUQRgVgQVFBakCJoQm/SEQJICSWEENKe74+zy26SDTUJKee+rr12d3ZmduZJgMNTzsGneCEaNXIWerAsKXAPcO4c3H575jaHUiqHM8ZkyQO4Gxnq3AJssj/aA6WQ1ap77M8l7ftbwMfAPmArEOxyrgHAXvujv8v2YGCb/ZiPsOfFu9KjcePGRimlMvT778asX29M3bqptx86ZMz99xtTqZIxJ0/KtvPnjUlJkdebNxtTs6a8XrPGmLvuMiYpyZikJHOx4Z2mX0C4fNakiTF//GFMSoqJbtrWPFNt4eWvOHDAmAIFjLEsY3wLJps5FZ83xtPTmM8+u7zPmTPG3HGHMfv2yfujR42pV8+YChWMKV7cmMjIzG8SpdStA0SaK8Q1WbbYwRizGvfz2ADSVXK2X+zTGZxrOjDdzfZIwM1/m5VS6ga1bCmT1dJ69lkIDYXOnZ3b/Pycry9ccBaytyyIj4eEBDAGKymRaK9ycOyYdJ81bw7AvCKPMtDjRyT7kpRevXQJmteP5fWo/vSLeo928x6kaGcZRk1KkmIQQ4dClSryVbNny/Dt88/D2rXwyCOwbRt4aN0epfIF/aOulFJXs2ABVKgAgYHpP5s3T2qmPvggTLf/f7N5c1lNWr48lC/PxRYPsL9AbThy5HJt1aQkmL/enxqFj5CSAiNGSDDWtdlRlu2pROuiEVRtXILdFZyrUJ94AqpXh+HDnV8/bZrMkXN8bXy8c+RXKZX3aSCnlFJXEhcHb74J48a5/7xrV/j7b/jxR3j5Zdm2dy/s3CkT2Y4coeDa5TS+sNI5Tw5YuhQqVwafAhZ9+8K778LApluY82cAvoE12B8WyZ6jhS/3vI0ZI3Pg3n8/9ddXqgTLlsnrnTslkNPF+UrlH9mSR04ppXKtffvgwAFnb1xUFDRqBH/9Bbfd5tyvZUvZ99Qp6aW7807w86N3b2i4px3l49bRqNMjLCeK4sCcOfBQvSh+WX47c47B202/p8pf39Cw6D684irg+ZQH//sflCwpX/nmm9Lx18hevHDIEBg0SALAxx+H996TEd0ZM5wjvEqpvE8DOaWUupL69eHECef7gACIjITSpaXnrWpViZw2bJA5caVKSTfZ1KkwahSzvzLQ9ncYPpwJHctDkyKwbh2vj2vGwbpf8c7FIcyqN54+f/0fjBpFjzcqpJvg5u+fqjMvlTp1YM2arLt9pVTOpoGcUkq56t0bVqyQnjV/f3jtNRg40P2+338PX30F3t6SyXfuXAnqevSA5cslCLQsIkq1Jdavo9RcmDKF+F79SDpwkW20Zbj/d9z799cyv65//2y8UaVUXmCZjP6bl0cFBwebyMjIW30ZSql8JDxcFiSEhUFKCnTqBPEXDZ/5PctAzy9luapNS2sppdKzLGu9MSY4o8+1R04ppbKYLSKUsFFt6Ny5oWQpIYVvrIfp6f0brFkrk9+UUuoGaCCnlFJZzAQ3YUWHpZy/2BCAF5hIT69v4fMwDeKUUjdFAzmllMpCFy9Cv09thF20UYB4nuNdpvIE7d60Yeva5FZfnlIql9NATimlssjRo9ClC0REGAp7XGRByoPcywraPFyekHcGENZEp8YppW6OJgRWSqkssGEDNG0KO7Yk8qjXN/xU4CHuLboBXn4Z268vEjZqIxERt/oqlVK5nQZySqnca8AAKFsW6rmUXP72W6hbV3Kxua5QnzULgoKcDw8P2LRJPps7Fxo0kONGjnQes3KlZOD18oLvvrvmy/rhB2jRwuBx9jRrLgXzZc3x2HzXSfWHceMgLAzb+PsZ2ST8JhtAKZXfaSCnlMq9+vWDX39Nva1ePYmkWrZMvb1vXwncNm2CmTMlsW9QEERHwwsvSJ2r7dtZ88NxuhdfJrFhpUpSKqFPHwAmTpQ0cY5apvPnS/wXFATBwbBqFbz1FnTvDjVTdnLHhS30KrmEOidWcPCjn8Fm46OPoNrjNqxTJzm1YlsWN5BSKq/TOXJKqdyrZUs4eDD1ttq1r37c7NmS+Bdg/36oUeNygdJSPe/jf7u/x7aztQR7AB4enDoFS5ZIbOfQurXkhLMsiIiA++6DmBjo4zmXw0kVGfNGIdqMLktsLHh4lAbgP/+BDh2gVSvgmWdu5u6VUkp75JRS+dDcuc5Arlo1KXp/8CAkJVHr7x8pfPpwukNmzIDQ0NR1TP385P3x4zCgXzIxMfA6Y/i/Bj+T0rAxbUY3vbxfoUJyTMOGzvhQKaVulgZySqn85c8/JapyzKsrUQKmTIGePaFFCwgIwHilHqw4dFiK1wcGpj/d+++DfwXDth0evMH/MWZUCntGz6B42QJ06yaB2wsvQHJyNtybUirf0UBOKZW/zJnj7I1z6NhRAry1a6FmTZICql/+KC4OtmyBnr3Sn+rnn+HlUYmUTTnGp4WfIzzoeXjrLZKMJ6tWyZy6iAgZvZ0xI2tvSymVP2kgp5TKP1JSZFVrrzRR2YkT8nzmDHzyCed7Drr80b59EHseRjwvQ6JRUbKQ9dX/S6BTxxRqxm/mr6bP8MSuEew7W4pTp8DfX3riqlSRBa9dukg6EqWUymwayCmlcq/evaF5c9i1S6KnadNg3jx5vXYtPPggPPCAc/+VK+WzKlVSn2fYMKhTR1YivPQSSVVqyPaICOq386eX57dMSXmSg4Xr4u8PLQPPMm68Dw/wK7+PXEiF1XPZcLwCCQlQqhQ0aSIx4cmTcprly+X0SimV2SxjzK2+hmwVHBxsIl1zSymllIvevWHFCkkxUq4cvPYaDBwon0VHQ4XbkrmU5MmYQpMo3KsjM9dVx9sbfH3hnXfg7rtl3yVL4PnnwRho3Bg++wx8fOCDD2TRxL//Sgq89u3h889v2e0qpXI4y7LWG2OCM/xcAzmllLq6nevj6Gg7T9T5YkyvPZE+ywZC+fK3+rKUUnnc1QI5HVpVSikXoe1XED5pY+ptD0XQMNiD2POGFQO/ps/WURrEKaVyBA3klFLZZ/JkSftRt67k7XD48EOoWTN1iayEBOjfH+rXl7wfK1bI9rg4mftWq5bs/9JLmXqJTe4rRsiIihLMGcPQRqt48btgKngc469v9nHn54PA0zNTv1MppW6UVnZQSmWPbdtg6lT46y+ZLNa2rQRkUVFS62rLFihQwLmCdOpUed66Vba1a8flKvMjRoDNJsFe69awaJF8nglszzUkjI2EjKhEwOjtRMa34K7Cm/htc3n8qv4nU75DKaUyiwZySqnssXMn3Hmns8TBPffICtPISOlVK1BAtpctK887dkiQ5thWvLjs27SpBHEgAWGjRhIMZqI6d1ykEHFExtejedGtrDxZH08f7YVTSuU8OrSqlMoe9epJ+o/oaBkeXbgQDh+G3bul2nyzZhLcOXrdAgOlpy4pCQ4cgPXrZX9XZ8/CTz85A76bFR/P2t4fULdbdQ4Zf7pUXM+e8+VZ+dGWzDm/UkplMu2RU0plj9q14cUXoU0bKT4aGCjZcpOSJOnaunUSxIWESCmEAQOkFy84GCpXhrvukv0dkpIkV8jQoenzwt0AExHJlI4LGXp8FAYPpj6zlUEfNCZ80kZCRlQkjI3Ynmt409+jlFKZSXvklFLZZ+BAKXGwcqUUL61eXRL0dusm1eebNgUPD0ni5uUF770HmzZJz9zZs7K/wxNPyPvhw2/umhITuTj6Dfo128HTx1+hWrFTzHt9O4M+aADY58xNPEzE0nM39z1KKZUFNJBTSmUfx0KGQ4fghx+kR61LFyl9ADLMmpAApUvL8OuFC7J9yRIJ7BzlEcaMgXPnGHj+fcqWlVFbh2+/lcWsHh4ypc7hr78gKEgegYEyPY8dOzjQqDvV3+rHV+YRypRK4clXy9NpjARxp09LB+ITUxqyJLEVZ85kbfMopdT10kBOKZV9uneXYKxjR/j4YyhRQoZQ9++XaKxXL/jyS+mdO3FCFjLUrg1vvw0zZ8o5oqLgzTdhxw4mr27EwRJBdD/jLI1Qr57EiC1bpv7qevUksNu0CX5dmMKTj8axMPAlgrbN5Jh1O999Z3H0Xw9++QX27JFjJkyQ6Xd79sjzhAnZ1E5KKXWNtLKDUipXO3gQOnSQ7CauWrWCiRNlil3aA/aFjCIwYioXKEQl/xSaNfciLEw+fv11WUA7cqSktluxQnL/Hjsm59y1K8tvSSmlLtPKDkopBWAMf45eQO0ql6gZMZML+NG3r8W8+V5s2pR+MS3A8ePOAg7lyztHhpVSKqfQVatKqbzv2DF4/HEK/3KQJN9fIcGTShVg6lQLX1/3i2mVUio30B45pZR7u3Y5VwcEBUHRolJWq2dP57aAAHkG6dKy2SQaGjIk9blGj4aKFeWz7BYWBvXqMWdxSZr5bCS2WAVWrLCoUgW2b5dd3C2mBShXTmJAkGdHrmKllMopNJBTSrlXs6asDNi0SZLxFioEXbvC3LnO7d27S+oQgIIFZYLZxInpz9WxoywbzU5JiTB6NIk9+/Kc94f0TvyKoGBvNmywqFhR4tSAANnV3WJagE6dZO0FyHPnztl7C0opdTU6gKCUurply6BqVUnM62CM9HY5UocULgx33w1796Y//s47s+SyeveGFb/EciquEP7+Hrz2mvSoPdPvPCdjfGjHcJILjuHMcV/atJEFr+3aSWqSTz6RLCcg8Wh0NHh7OxfTglQOCwmBadOgUiVJbaKUUjmJBnJKqaubM8fZTeWwapWMPbom6c1ms2cD4fZqEDPDoEkT6N2brjE/s/a2rvRInsOZWB9mzoSHH874PKtWud9eqpTEsEoplVNpIKeUurKEBFiwAMaPT7199uz0wd0tEBpho8moxdi62sCyMGfP8mz1X/hwXzsCAizWLpEFDEoplRdpIKeUurJFiyQxb7lyzm1JSTKZbP36W3dddk3K/kPIk1UIS2jInayjy+1bWLynPs2ayaU7hkmVUiov0sUOSqkrc9fztnQp1KoldVJvlePHYfBgbIOqEmb1ogffc0fhEyw+Wp9H7z/GH39oEKeUyvs0kFNKZSwuTuqcOlamOribMweyDPS552DGDAnyduyQ7SNHyvu4OHkeO/bmrunNN6FaNfj8c+jUiSPeAcR6Fef4hSL0tB3nyw0N8Pg9/Ma/Qymlcgkt0aWUyh1SUuDrryUnXVQUdOnC2dHv8PTjCXyzqQ5eXjB4sHQgho3aiC1piQSQSimVi2mJLqXyk4AAqF9fkvQ6ioxu3gzNm8v2jh0hJka2z5qVOuGvh4fkhnPVqZNUm88k770HdevKKXv3hvh4aNHCeQm33w5dusi+xsDQodLx1qBKLBtq94XHHmNTsZY0r3OOOzbNo+xd1Zi9uQ6FCsl8uA8+kIwoIeMbEt5EgzilVN6ngZxSeU14uARkjp7nQYNgwgTYulUS+r7zjmzv29eZ2HfmzNRVGkAWM2RiJYYjRyTQioyUAvfJyTJCu2qV8zKaN3eO4i5aBHs2xrKnZgc+O3Afgw++CN98g/ecmTRqVZRDh6T+qa+vnOe+++Q4m02CuYiITLt0pZTKsbIskLMsa7plWScsy9rmsq2kZVlLLMvaY38uYd9uWZb1gWVZey3L2mJZViOXYx6z77/HsqzHXLY3tixrq/2YDyzLsrLqXpTK1XbtgpYt5XWbNvD99+n3SbugITYWJk2CMWMy9VKSkuDiRXmOi5MeOIfz5yW3cJcuwPHjzB+xkkfXPIm1ZjV3hnbnbOUG/FG5NwMGevDJJ/DooxIQVqsm6y5c2Ww6qqqUyh+yskduBtA2zbaXgGXGmOrAMvt7gHZAdfvjCWAKSOAHvAo0A5oCrzqCP/s+T7gcl/a7lMp/LAvuvx8aN4bPPpNt9epJHjiQ0gSHD6c/bu7c1IHcyy/D889LWa5MUqECjBghFRLKl4dixeRSHebNg9atkij6wRtQrRpH/j5Pxe5NYe9ezIgX8PTyoHVr2L1bLveLL2DnTklzV7Vqpl2mUkrlKlkWyBljVgKn02zuDNgrF/Il0MVl+1dGrAOKW5ZVHngAWGKMOW2MOQMsAdraPytqjFlrZLXGVy7nUir/WrNGqr8vWiS1plauhOnT5XXjxtLt5eOT+pg//5SAzTEXbtMmKbPVtWumXtqZMzB/Phw4AEePwoULsnYBgORkZk+MovfK/0oQef/9mJatYNgwTnuUJiREgrY6dWDLFinkcOwYPPKIBHQeOklEKZVPZfdff+WMMccA7M9l7dsrAK7dBFH2bVfaHuVmu1L5m2OssmxZCcT++kvGHRcvluS9vXun775Km0pk7VrZNyBAaqfu3g2tWt30pS1dCnfcAWW+CMV7dTjdusEffwDLlhFdrRl/bfXlwTt2SPD5/ff41yzMr79Cgwbw449SF3X+fKhYUdZrPPggvPFGlpVxVUqpXCGn/D/W3fw2cwPb3Z/csp6wLCvSsqzIkydP3uAlKpXDXbggPW6O14sXSy/biROyLSVFIp+nnnIek5Iiw629ejm3DR4sXWYHD8Lq1VCjBqxYcdOXV6kSrFsHcfWbYR4KYdmne6n9+//gvvv49p+mdKh/iIJ/rYQWLUhIkCL2b74pnYVTp0oQ6O8vQ6ldu8ocuYceuunLUkqpXC27A7nj9mFR7M/2f2GIAiq67OcPHL3Kdn83290yxnxmjAk2xgSXKVPmpm9CqRzp+HHpQQsMhKZNpcuqbVtZyFCjhvTM3X479O/vPGblSomOqlTJ8str1gx69IBGQ5pTPz6ClD/W8sTekVC4MHPqvUHv0Ibg4cGuXbJ69fvvZSg1KQnefRc++UTOExYmlz1jhjNtSdqsKUoplV9kaUJgy7ICgJ+NMfXs798Boo0xEyzLegkoaYwZaVnWg8AQoD2ysOEDY0xT+2KH9YBjFesGoLEx5rRlWRHAM8CfwELgQ2PMwqtdkyYEVjlKcrLke6tQAX7+Gfr1g99/l5UA4IxW/v5bArANG6SbasQI5zkCAqBIEfD0BC8vZ9qRnObYMekRnDpVrjUoSLroXn4Zxo3DGPlo+HDphZs2DTp3vtUXrZRSt9bVEgJ7ZeEXzwZaAaUty4pCVp9OAMIsyxoIHAIcAyMLkSBuLxAH9AewB2yvA46MUOOMMY4FFIORlbG+wCL7Q6ncZfJkqF3bmaQXJM9bjx6p9ytZUpKw/fij+/OEh8skspzo9GkIDZXrT0yUvHY2Gzz9tARxU6ZwqtH9DJpxN/PnS4aUGTNSpyZRSinlXpYFcsYYN4UYAWjtZl8DPJ3BeaYD091sjwQyL+W8UtktKgp++UVKTk2adOV9y5aVxy+/ZM+1ZYbYWHj/fQlMz5+XBMRjxxIaCk0efx7bj2Fgs7HYrxu9ulYixiOFSZM8GDZMV6EqpdS10r8ulbpVhg+Xnqq0Ucvo0bJU89ln4dKlq5/HXe64Wyk+Xnoaq1SRHjebTcqEzZwJVavShAhCrDB+S7Dx3HPwwItBxHiU4H9dfuPZZzWIU0qp65FlPXJKqSv4+WfpYWvcOPWK0PHj4bbbZGnmE0/A22/DK69c+Vxr1sg45IkTMi5Zq5azkkN2SkqCL7+E116TpMOtW8t8vmbNUu1m+7QXr9STtRjJyVCwIMybZ9G2bbvsv2allMrl9P++St0Ka9ZItYWAAEn9sXw5PPywlDywLChQQBY3/PXX1c/lLndcJjl7Vqbr1aolU/nWrpVOtgYNZK3C/ffD0agUKbVQty4rBs0kKHopdSuf557EpZeDOMd5qleHEiVg6FAoXFi+44UXZHGtUkqp66eBnFK3wvjxMkfu4EFJyHvvvVLm4Ngx+dwYWdhQ7yrTQDPKHZdJhg2TIOvvv2V0tHZtCby2bIFNGw0dqmxnXNAP0KsXZz1L8V//n1iwozrbD/rx7bepz1O0qAR0MTFST9Xb+/JaB8LDM+2SlVIqX9GhVaVykr594eRJCeSCguB//5Pt//4raUpiYmQS2fvvw44dcOqUs5RWUhL06ZNp3VsxMfZ8bXVCIbwJPjabs7rX++/D++9z4Z/eWEXqwddf882Z3nT714NKlWWXsva6LZGRkvstPl7yww0YAKNGSR5im00eISGyj82WKZeulFL5RpbmkcuJNI+cUtdm0yaZplen5DE2Lz1F4wdKMXnUcQo/+wSjI7vwlUc/ipXzJTyyCGVu92b4cMkusn27dBIOHgz//AMTJkhc2rQpXLwoPXFjx0L79s7vCg+HiAgYOfKW3a5SSuVIV8sjp0OrSl2Lw4elu6h2bahbV1ZlAvTs6SwvEBAgz64OHQI/P5g4MfX25GRo2BA6dMiWy78RSUmSf3jwa+XZ+PEfFP71Bya0+BnWr+fNJw9zOLYkfZ8pyUefel/ef/16yZDy4osSyL3xhsyjA3jvPdi4UXrl1q5N/V02mwZxSil1IzSQU+paeHlJnaidO6Uawccfy9Dm3LnSdbVpE3TvDt26pT7u2WehnZvVmI5EwDmYfwWDf+mLNBt9Hzz1FD08fmADjWSS3P/+B76+9OkjpbRAKn395z8ydNqzpyxmeOUVqdDg7+9cvNqjhwSISimlbp4Gckpdi/LloZG9UlyRIhKEHTni/NwYmeTV2yUP9o8/Si61unVTn8uRCHjQoKy/7huRmAizZnFbu4ZUPB7Jrq2SCmWZd1vqNC/GnqkrLq9OWLBAVrQmJ8tw6uTJcttjxkjVsYcekmwqFSvCrl1y+mXLpIaqUkqpm6eLHZS6XgcPyhiha360VaugXDnJrwGygvTtt2HJkvTDqo5EwI7VpjlFbCx8/rmMgR46BHXq8OHY0/Sd9RMJ06KocmdZvvipDIM6/8SuNtF4VI6lch0/Bg+Wpli/Xm4/JQXmzYPHH3cuoP3wQ1nHkZAgse0XX9zaW1VKqbxCAzmVdw0Y4Ey8u22bbNu8GZ56SoKWgACYNUvyYsyaJaWkHLZskfG/oCBo1UrSgvj6SteTY9Vo0aLO/WfPTt0b9+qrMqzq55f6mjJKBHwrHT8udVCnTIEzZ6BFCxk6bt+eIA8PIn1DoUkTsEnP4vcry0L4ds6t/I0xp4bToYPEsHPmyOpTy0r/FUFBsnpVKaVU5tJVqyrvWrlSAqlHH3UGck2aSA/ZPffA9Olw4AC8/nrq47Zuhc6dYf9+ed+qlRwTGCiLEx54AJ57zrl/UpKMI65fL5PBQIKhw4fl9dmzEvyNGyfDsTNnypy7+HjJ8dGtm+SQy267d8u8vy+/lK6yrl1l/tudd6baLdQRx9lTgxgjcer770s8/PTTsqihWLHsvwWllMrrdNWqyr9atoSSJVNv27XLWb6qTRvnTH1XaXvXQKKXgQNlbpxrEAewdKlMFHMEcSBDrQcPymP4cPi//4MhQzJOBJyJMloQ+8wz9g7CtWuhWzcO1WyDbWofGvrtpkH1iywc+P3lIG78eKhWDWrWlGNDQmRa3L59kkbk9ddl7tuff8qwqQZxSil1a+jQqspf6tWTGfqdO0tGWkevmau5c2H+/NTbevaU3rty5ZxDom+9JcnQ5sxJH/jdKqGhTD7Yjdq1qxETY98WHk7kD4c4u601XCwJd90FJUrwRsPfCOlZk8EvFmXHDrmVgwdlMe6cOZIP7uhRuO8+mdPWoQNcuiRz4IYMkR45T89bebNKKaW0R07lDAMGyNwx1/JSL7wgPV0NGsiw39mzsj0xER57DOrXlx6y8eNl+65dzpxuQUEyh2369NTfM326zP9q3FgWG1wuVWD3559QqFDq65g1S4ZZY2LkWp57TtKNODLazpgh8+4yMnYsjBiRfnurVjJnLhNFBdzNL58fZVDjjbLht99I7tiFF6ZWJ3RFE+lZnDwZDh3CatKEGGSe37lzzpKt8+dL+dcCBeRH4uUlo9NxcdLbN3So9MJpEKeUUreeBnIqZ+jXD379NfW2Nm1kbtuWLVCjhjNg+/Zb6RraulXmpX36qXQl1azpzOm2fr0EZI5stA61akk90vXrpRetatXUn7vrXatQQZ6LFJESWJlYlD6zDQ+7i9APffEYN1by3bVvz0cX+tGp1B+Un/WutMnQoeDnx9ixMqrr7y8x6YcfyjmOHJEA7t13ZYXp7t1QvLgMn778ssS1WhtVKaVyBg3kVM7gbj7b/fdLdxDI3K2oKHltWZLeIylJaj75+KReQQqSrKxq1dTz1gBOnJDnlBSZoe/ak5aSIkFir17ObUlJUs8UpCfw558ztSh9Zvp5QQplLx2mcfi70tsYfYqjFZrwbd2xPHPweQlCcS4pnT1b4ueoKFi4EB55RA7bsEEW3I4YIR2QzZpJE8ybJ+s1wsKcc+aUUkrdWjpHTt2Y996TnGOWJUOcX3whyxcjI2X4rkYNGXL085Pes0cflV6wUqVkDlpAwPV93/TpMk8NpDTA/PmSpDcuTq4lbRA4Z46zSvupUxLQvfaaLLP8+GPZp1s36N/k9cY4AAAgAElEQVTfeczKlbJflSrObZcuySrVxEQZV7zvPkmQlpMcOgRffMGaSWVYENOJhdbbxJsCxHiWpG7U3RQo7ku16hLAxcXJIoa9e6XigqMTtEEDyUJyxx0QHS37LFoklRpq1JDpgI5VqzabBHMREVrkXimlbjljTL56NG7c2ORLlSsbU6+eMYGBxjjaICRE3gcGyueBgbL91CljWrUypnBhY55+Ov25oqKMCQgwJi5O3j/0kDFffGHMuXPOfZ591pjx4+X1xx8b8+ST8nr2bPledw4cMKZu3fTb33jDmC5djElJkferVxvTp48xCQnGHD9uTI0axuzb59z/0iVjSpUy5t9/r94uuVV8vDFz5hjTpo0xliWPNm2MGTPGmNKlTfikDebBB40xy5cbU7q0PBv5kTq0bWvM//5nTGioMSVKGAPG3HefMV99ZUyDBvIV+/cbc8cdxiQl3ZrbVEqp/A6INFeIa7RHLidLTobgYJmj5Top/plnpAcsNlbeX2uPV3g4lC7tfD93rvP18887c0gULCj5JbZtc+ZfS8sxrOntLd08t9/uHN40Rj5zZIadP18m/IP0pg0ZIvu4yxyb1pdfyr0vW+bc/5tvoG1b+e6yZaXbKDLS2ZO2aJGU0ypX7urnz222bJGutK+/htOnoVIlKWjar5/8zENDpbvMagjLyLD7LDZWymQNGSI/yiJFYNIkGVKFy4Ud8PKSDkxd2KCUUjmTzpHLDIcPyz+StWtLXc3Jk2X75s0ytFe/PnTsyOV8ENHRsr+fn/xLmhF3hdUjI52rNx2mTYMSJWS87Nln4cUXr+/609YJLVwY7r5bAjp3KlSQCVSVKsnwZrFizkUF/ftLgrG//5aAE2T2fMWK8trLS/aPjr76df36q5S5WrBAJuk7VKoEy5fLdV+4IJP6a9Vyfu4uD1wOFB8vOdkCA+XX5tVXZfuBAzIvrXp1GU1OOHFWqi4EBxMW+AZ1PniKukmb6NPqKOzfT/g9YwnqEiCLdb8ZScF2Ns6edYn9bTYYORKAf/+VWO+OOyRwu/deWLNGfjUdQRzA6NGSM27XLmjXLnvbRSml1HW4UnddXnxkydDq0aPGrF8vr2NijKle3Zjt240JDjZmxQrZPm2aDHsZY0xsrDGrVhkzZYr7oUtjjDl82Jh77zVm2TIjY2RGxrdatZLvcx0ju/9+Y/74Q14nJsqwomMY0iEgwJiGDY1p1MiYTz9N/dnvvzuHW1198YX76zt92hibzZgTJ2R4s3NnY2bOdH6elGTM4MHGTJ8u7+vUkftxqFJFhm9d9eplzG23GePlZUyFCsZ8/rkxVasa4+/vHP51DM+eP29Mjx5y3tq1ZWzQ4cIFY0qWNObs2fTXncOkpBhzftwkY5YvNwkJxjRtaszatcY8dM9xM7v3fGPCw82T1ZeaT7yeMQbM7podTFCFE+b03mhjjIwqp/Xqq8YUKSLN4LB8uTHjxhkzYYKMsoIxDzzg/JVRSimVc6FDq9mgfHl5gIxR1a4tvVBpqwg88IAMWTp6vPbuzfic7gqrf/QRdOrk/C6HjHq8XIdR16yR4c8TJ+RaatVyXtv19mAtXSpdOmXKyPtu3eCPP+Dhh+W9p6d0Jb3zjvTQ+ftLr6W/v4zjnTuXfnHC7Nnpv2fgQPff7+cnq0vdKVTo2nr7cgDLAr+7gyAkhMSvviMx8R6sZUtZ/nsQ35QfArMP81jh+xhbfjKDf3iUqXMb83RNixL2jClly6Y/5/nzUm3rzz+lI+6XX+RH4ekpvW4PPCA9f82bZ++9KqWUyho6tJrZDh6EjRtlbMxRRQAyriLgjmthdYejR+UcjuFKV8ZNvdy0888c2V7LlpXkuo5caElJ8MMPzhWh16JSJRnOjIuT7162TIJXR2BqDPz0k3O4s1MnmesG8N13Mp53LfPj8oHkljaCiu2nbPvGtDnwGVXH9KI4Z/GqWRVmzsR/wwKOFK0DwcHs3mOxe7dMCbzzzvRp90B+9V55BR56CFq3lhH9CxekmMPatXKMBnFKKZV3aI9cZoqNhe7dpXaRo6rA0KGSfKtTp/RVBDKyZo0EgAsXOgur160rqfarVZN9XPNIXK3H68IFyZFWpIi8XrxY/rUH93VCr6ZZM1m00KiR9AA2bAhPPCEBWkyMBHKBgTKvC6Rn7ZFH5HpLlpTUIAoSE/GcPZtNBd7mLEfoenYeO+v3hHOVnUnaDjtj3qQk2LNHKoRFRUGLFrIWpXhx+TwqSta7lC4t0yiXL5dUel9/fbmEqlJKqTxGA7nMkpgoQVzfvjLUCM4qAiDp8X/55drONX68s4rBihUwcWL6Uk5+fs4eMEePV/Pm7nu8jh+XXjiQaKBPH1n1CRnXCQ0IkKAsIQF+/FHuo04d5+evvSYPV2vWuL+fggUzHgrNJQ4floXB//4LHh4Stw4bJgtHe/aUjtiAAFkzUqKEjCrPmiXHJiXBzp1w8qTEsZNDLzH1vfOYU6d5PGkDw++4SPEiKbQKSmHd+jKc9TIkJUmMHBXl7Ez195eAzNtbRrZr1pTAzs9PfvxTpsiP7NdfZZ/+/eVHd/HirWo1pZRSWe5KE+jy4iNLFjukpBjzyCPGDBuWertjNnpysnw+bVrqzzNaTOAqPNy52MGV62KHixdl8n/VqsY0aZI6p5rKFBmtZ3nhBWe6vPHjjRk5Mv2xCxbI2hBz6pTZOvhjU9dzh7mArznarLNpGXDQ7C7R1MQtWmHuvtuYn97cbHr4zDezx2wzxsj6jo8/lvMsWmTMo4/K6z17jCleXNavgDGenvL+scdSpY1Lm0ZOKaVULsNVFjtYxt38qjwsODjYREZGZu5JV6+Wca769aW7BiQV/p49qasIjB/v7Clz7fEqXjx9j5fK0Tp3lswxQ4ZIp2n58nDsGLRqJWtcXPXpcgFb7M88vnYA38a157dKT/D57MJs8buLB+6OBW9vSpUvQEiIjHjvn7WWXi8FcLpAeRo2lKHRAgWk0zckRKYkxsbKCHb9+pJCrkUL6NJFplA2a5a64kJ4uKSRs2cgUUoplYtYlrXeGBOc4ecayCl1fQ4elAW/27bJug/XtH4lSsCZM/Y3O3cS99b7+H89nr0eNSn5cHt2dh9D5xHVWbsWfH1lQUJwsLNgvTvbt0u1s6+/lqHdUqVkBL9fPwgK0nUjSimVl10tkNM5cirPGjDAuQA4bYGKiRPhhRdk3lrp0pK/uH9/KRj/5puS7xhkrUnLllI8IylJpiMuXuxcz+LWunUwYQLMn89P3g/zn4CjlFwRCZUrUxt48aRkgPHzk161Y8dSHx4eLr18ZcrI3LfISJkv9+CDEry1b3/t62aUUkrlbRrIqTyrXz8Z+nz00dTbDx+GJUukN82hZEn44ANZHOCqQAFZ/ennJwuFy5eX8zrWs5QrJ4FY+dsMx2avoOylqrLopEQJeOUV5kT8H70fLgCVneccONCZIq9vX6lgFh4uqQXfeUfWkCQnyyMoSILG3r3d541TSimVv2keOZVjTJ4sqffq1pXgBWRFaFCQPAIC5BkkEGvcWOaINW4swVZaLVumzzsMUooqNDT1kGTZstCkiaz2dGVZzp6zQYOgQPIF+tRcf/nzTh1S+LLvYqhQgS/7/kZnz1+k9tWhQ5x77jV+X1eAzp1Tn/PECXk+dEjmrj3zjPSylSghpbF8fSVrzaZNkhdu2DAN4pRSSrmnPXLqhp09K8HNtm0S8EyfLkHIU0/JkKSXF3zyidQTdYiIkBQac+dKKjqHbdtg6lTJU+zjI9lRHnxQ9nN4/nkpWgEyHPrTT5KaY9s2qVhw5MjVr3nBAikVGxh47feZnCypPvbtgzLFvHlyaAF4N4a32q3mpe9eIOT4B0zzWkOl2gX4dnlpuE3GPefNkBK0hQs7zxUXJ9lh/v1XXl+8KKOw3t7SZiEhMhcubUCplFJKuaM9cvlIcrLk7u3QQd4vXy45fevVg8cekzlgIPOzihVz9oSNG+f+fMOGScD199+webMUdxg5UkpAbdokx7mulExOhhdflKArrZ07JcArVEgCwHvugXnznJ8bIznaHCnvGjZ05lerW1eCoEuXrnz/cXEy/y2j+8mIp4dh74ooznz9C3WLR/F1rTfYdKA47T9+kFLRu1n22hr2XKrMsh23U/I25+S1fv1g5kypXvb667KitUQJWbwQEyOLHMaOlZ7IYsXg5ZflZ7J69fVdn1JKqfxLA7kcKD5eerECAyVIefVV2d6ihTO4uv12STcBkni2QQN53HWXBFXuTJ4swRZIoYfHHpN8wNu2QeXKzipaju/atEkejiIQrmJiYOVK51wvHx/JomJZ8hlIgQlHsAWyMrN7d/fDhPXqyfmioyXgWrgwdUWzVatkPlr16umP/f57CewKFHB/3w779sGBA9KuAQGSbLdRI+kdS+V8jKySGDtWot7y5aFiRYo/3AGvf/bx0b/dnF16L71EeItXCJ0of5RSUqT9J02SHsWSJaWk1quvSh3UYcNg0SJZ2bpypQz/vv66BKnjxslzSIizsINSSil1JTq0mgkyyvq/ebMMM8bGSuAwa5asdIyOlmHFiAjptfnoo9Tnc51gn5gok+DbtZNgxqF7dy7PvbrjDvj9d+ntWbRIvv/PP1OfMypKCkuMHi1BRnS0fE+NGvJ5mzaS5i6jOvVp7d8vqyr795f7bNxYAsX335cetxEjJKj54w/Z/8gR6WFbvlzuO63ataW3zrGaMzBQeuYcZs92X4Bi+3Y5zlFAI5XQUKjYApDiovXrw4m5zqRqAQEQ+Vs0pTdHwrRI2b68JZw/CrwLlsXJGv/B+95uFL+rDhfrNeH4kCb8dSCZnvu/wfZyR5ZP3kKPyYn0f9ybnj0lADt5Ur6+Rg2pTNa6tfTGlSqV/hIjIiR4c+R9s9nkfURE6lxwSimllFtXyhacFx9ZUdkho6z/wcHGrFgh26dNM2bMGHkdG2vMqlXGTJly9cIOFy5I9v5165zbYmIki/+5c+n3P33amNtvT7+9e3djIiOdhSJSUoypVMmYiAj5fOhQY+rVk9fh4caULGlMgwbGtG1rzLZt6c8XESHVBBzXNXSo3N8zzxjz3Xeybe5cY1q3ltc9ehizdq28fuwxY7799sr3PWqUs6JBYqIxZcsac/hw6n0OH5a2Xr3a/Tl62f41t1n/Gi/PZFOhgjGfD9loTLFixjz+uDE9epjKnofNSUoZA+YY5UwFr2OmiFecKVYw3lQoE2/OHTlvNm82JijImPr1jalb15hXHtlvphYeZor4JpqgIGM8rBQjA7/S7o88YsyMGemvVSmllLoRXKWywy0PrLL7kSUlutLo1MmYxYuNKVJEAiZjjDl0yJjatVPvd6UKXUlJxgQGSiWutGWfvvxSAjN33nnHmIEDU2/76SdjBg+W164Vv/74w5i775aqXqNHS8BijASI58/L619+MaZatfTfc+yYMZUrO9+vXGlM+/bGFC3qvOeUFGkDY4wJCJD9K1eWeypTxph581Kf01HR7J9/jKlZU4JSY6Q0VcuWqfc9c0YCTUfQmEpKijEHDxozf74x/fsb4+NjTIkS5nLEBcZUqWJMSIgxoaFSv+rsWben+OknY956y5hevSSQ8/JISnWaWrWM+XjY3+bvEVMv37dSSimVWa4WyOnQaiY7eFBSRjRrJvO+FiyQIdBvv0095+tqPD1lftrZs1Lvfts2OR/IMOOgQemPCQ+HadPST5Zfs0auY+FCmX8XEwMPPyyrIx3DtYsXw+7d8to10W379vDf/8KpU7JS1OG226BiRSlHVbOmlI2qU0eGXH//XYYSly93zmk7cMB5bL9+MvXMMcfPoXt3GfL19pbKZiVKyPY5c9IPq370EezdC6+/lszro+LhYjyL759I2T1rYMsWOHeOUF6gCQewlSgsk9JsNsLbhRJxoQ4jxxa6fK4zZ2DrZti61fnYts051w9kDmH9+tCpkyceHrIa97//hU8/hdqda1LTVjP9D0QppZTKYhrIZaLYWAlGHFn/p0+XfGDjxklFgBvJxl+8uARFv/4qgVx0tKTocF3RCRK7DBokc+TSzsUaP14eICtSJ06UIO7ECVl4cOkSvP22zJ8DmetXrpwsXPjrL5nr5m5+14cfSkLbhASoUgW++EKC1mHDZAVswYLw2WfXfq+rOoZKMrc0hUJn1ImAJ1+Afw7JjW7ezJjNmxnjvwW27ZHOMYAwP1nx0acPNGhAk6QWhIx+nbDknthebsBvk3fSOyKQp57x5sUXnUFbVFTq9q5fX+a21a8vj3r1nMFteLgsRvj+e7nM1q3lves8N6WUUiq7aCCXSRITJYjr29eZ9b9WLeck/N27ZbHBtTh5UnqliheXPGNLl8qEfpCevQ4dJEhyOHRIvnPmTOfihWvxzjuyODMlBQYPlvxmAN99B1OmyGIDX1/pEXNXzzMoSMpHubr7bli/Pv2+rmbMcL89dF93mrz5PLZZFyTCDAsj/IOtRJRqy8jxJVMXNa1SRVZE2IM2AgNJ8g/g6L8eHDokbXJ4xT7+c3EZbc0PFJ3iwakYA1iMHy9Bde3aEiQ7Arb69SXH3JVql+riBKWUUjmJZRy9GflEcHCwiUwbfdwkYySVR8mSzooE4OzxSkmR4cRWraT+p8OMGRIIpV21umWLnC85WY4NCXGmAGnVCl56SfK3OQwaJD1Ele1loLy80gdYWSLUfQ+aY1WoW8ZIw/zzT7pH+PayhOyfQBgPYWMF4bQihDDC6rxGqxbJnK3ehEOlG3HItwaHThbi8GEuB22HDsnK2JSU1F9Xsmgi3r7eHD8uaUCG2LbTIG4d1ScM1KS7SimlcjzLstYbY4Iz/FwDuZu3erXkXatfX9KPALz1FuzZI3O9QHrMxo939vYEBMgcrIQE6XlbvFjmmGWpGwm8rnS6J/fRZM7z2H4cJucMDye8y2QiHhzLyKdi3AZrHDokE/XskvDkjF8lTpWvT3SZWoQn3U3o+tYEJ//JOs+7qd/QiwtxFocOydC1Kx8fmadXqZI8XF873kdESCA8eLD0MuoQqFJKqdxEA7k0siKQyxKZHHTBFQKvXu8y8tOq7g+6eFFWA5w+ne45fGNxQsK6E2ZCsN22kyWHa9GL2bzDCKqyn1OUJppSnPILINqvMqcK+BPtWYbolBKculSE6AsFOROT8eh+IS5Qp2YyleoWdRuolS3rDJzdccxncwRvad8rpZRSOd3VAjmdI5dJQtuvoMl9xbA91/DytvBJG4lYeo6RC1td//kc88V+JH3QdbWDU1Kk1+viRecjPp4mgV6EzPqGsA4h2B74kPBF8YSYuUw9FsbBHlM4H51A7OkEzp9LkUesxfmkgsTix3mKXH7I+/Kcpwh+Hme4L2UhXocTSUAm7g3ki9TXEwuFDZTygdLFZeHEHaXlubTr8+FNHHjtK0Z5vM0TT3vz+RRvQo/1xTZl2A1FXjqfTSmlVF6X63vkLMtqC0wGPIHPjTETrrR/VvXIhU/aSMiIioRNPIztuYbp3mOMBFRxcZcfKbFxJMZcJPF8PAkx8STGXiLh/CUSYy+xamcpnl1wL+PNSzSoEsvavWV4jVd4rup8qvsc4mK8Rfwli/gEi4uXPIlP8iQ+0ZOLid7Ep3gTT0Eu4ks8BVO9jqYkR/DHh0vE4wtcYWa/Cy/PFIoUSsavkKFIUShSzIMixTwpcukUe9eeYGtyXe7xWk3Pp8tQ6q6aqQO0UqkXZ2TYhk/OIWRuN8Lm+Th70LomENbzB2yf9rq5H5BSSimVC+XpoVXLsjyB3UAbIAqIAHobY3ZkdExWDq2GT9pIu+drU8rjDMdTyuDvcRRvkkg0niQYbxLxJgGfy8/Jmdgh6mGl4OuVSEGvJAp6JePrk0RBnxQK+qTgW9BQsIAEU76XzvL31kS2pNTjLs8/af9wSYo0qo6fHxQpkvrhuq1AATerOe29hCFWGIOH+jDlgwQZZv3xxnrQsmA0WSmllMrV8nog1xwYa4x5wP5+FIAxZnxGx2T1HLngQjtYf7EONbwPUP/2U/j4gLe3hU8BC+8CFj4FPPAu6IFPQU98fD3x9vXEx9cL70Le+BT2xruwNz6FffAu7IPPgV2Ejd9LWEJXHi0wl/9OqkbB/zTG11eCsoIFufzay+vKaTOATA+8tAdNKaWUylp5fY5cBcC1XkIU0OwWXQvhkzbyT3xFXm6xgimr6/H00LOp5sxd38nCCR86meW+Ybz8Ikz5oCv9RoXQ7AaDLoDwOccJscIuB142mw8hXcMIm/PDDZ0yomovwualmYM2z4eIiF7oFDSllFIq611hzV+u4K4PKl0Xo2VZT1iWFWlZVuTJkyez5EJc58SNW9mKsImHCRlRkfBJG2/sfC5B17hxEiCFWGGEzzl+w9cogZdP+sCr6o31no0cmT6mtNl0GFQppZTKLjq0mkkyfdWqzhdTSiml8r28PkfOC1ns0Bo4gix26GOM2Z7RMbkmj5xSSiml8r08PUfOGJNkWdYQ4Dck/cj0KwVxSimllFJ5Sa4O5ACMMQuBhbf6OpRSSimlsltuX+yglFJKKZVvaSCnlFJKKZVLaSCnlFJKKZVLaSCnlFJKKZVLaSCnlFJKKZVLaSCnlFJKKZVLaSCnlFJKKZVLaSCnlFJKKZVL5eoSXTfCsqyTwD+3+jquU2ng1K2+iFxO2zBz5Ld2zG/3m1W0HW+etuHNy61tWNkYUyajD/NdIJcbWZYVeaU6a+rqtA0zR35rx/x2v1lF2/HmaRvevLzahjq0qpRSSimVS2kgp5RSSimVS2kglzt8dqsvIA/QNswc+a0d89v9ZhVtx5unbXjz8mQb6hw5pZRSSqlcSnvklFJKKaVyKQ3kboBlWRUtywq3LGunZVnbLcsaZt9e0rKsJZZl7bE/l7Bv72tZ1hb74w/LsgJdztXWsqxdlmXttSzrpSt852P28+6xLOsxl+1vWpZ12LKs2CscW8iyrF8sy/rbfr0TXD5raVnWBsuykizL6nGzbXOt8lgb9rMs66RlWZvsj0E32z7XIo+1YWXLspbZr22FZVn+Ofmer3Qvbo5vbFnWVvv3fGBZlmXf/pD92BTLsrJtJV0ea8OxlmUdcfmz1z6z2ulq8lg7BlqWtdb+2U+WZRXNrHa6klzahm7/rrMs6yl7+22yLGu1ZVl1brZ9rpkxRh/X+QDKA43sr4sAu4E6QCjwkn37S8Db9td3ASXsr9sBf9pfewL7gCqAD7AZqOPm+0oC++3PJeyvHee70349sVe43kKAzf7aB1gFtLO/DwAaAF8BPbQNb6gN+wEf6e/hTbXht8Bj9tf3AjNz8j1f6V7cnOMvoDlgAYtc7rk2UBNYAQTnt9+bTGrDscCI7P6zlwfbMQK4x/56APC6tmGGbej27zqgqMvrTsCv2fW7qD1yN8AYc8wYs8H++jywE6gAdAa+tO/2JdDFvs8fxpgz9u3rAEdvQ1NgrzFmvzEmAZhjP0daDwBLjDGn7edZArS1n3udMebYVa43zhgTbn+dAGxwXIMx5qAxZguQcp3NcFPyUhveKnmsDesAy+yvwzP4/hxzz9f6+2BZVnnkL/i1Rv6G/8rl2nYaY3Zl2GBZJC+14a2Ux9qxJrDS/noJ0P26G+QG5LY2tH/u9u86Y0yMy9vCQLYtQNBA7iZZlhUANAT+BMo5fsD257JuDhmI/E8I5Bf2sMtnUfZtaV3rftdyvcWBjjj/0bzl8kgbdrd3939nWVbFGznvzcgDbbgZ5z8eXYEilmWVuso5AsgB93yVP1MV7Mdc7XtuiTzShkPsf/amO4bgslseaMdtSC8SwENAvv077Gb+jbQs62nLsvYhPYpDr/f4G6WB3E2wLMsP+B4YniYaz2h/G/LL96Jjk5vd3EXx17rf1b7fC5gNfGCM2X+9x2eFPNKGPwEBxpgGwFKc/5PMFnmkDUcA91iWtRG4BzgCJF3hHDninq/hz1SmtFlWyCNtOAWoCgQBx4B33V58Fsoj7TgAeNqyrPXIEGeC+6vPGrmoDa/IGPOxMaaq/brGXO/xN0oDuRtkWZY38os3yxjzg33zcXv3taMb+4TL/g2Az4HOxpho++YoUv/Pxx84allWM8s5ebdTRvtd4do8XY4f5/LRZ8AeY8z7N3LPmS2vtKExJtoYc8n+dirQ+Frb4GbloTY8aozpZoxpCIy2bzuXC+451b24uecoUg/RXLHNskteaUNjzHFjTLIxJgX5s9f0RtvkRuShdvzbGHO/MaYxEsjsu9E2uV65rA2v1Ryyc/jf3IJJorn9gUT1XwHvp9n+DqknaIbaX1cC9gJ3pdnfC5lseQfOCZp13XxfSeAAMimzhP11yTT7ZDjJ3P75G8gfFo8MPp9B9i52yDNtCJR3ed0VWKdteN1tWNqxDXgTGJfT7/lqf6ZczhGBTJB2TDBvn+bzFWTvYoc804Zp/uw9C8zRdryhdixrf/aw39MAbcOrXnvaxQ7VXV53BCKz7Xcxu74oLz2Au5Hu2C3AJvujPVAKGVffY392/IJ8Dpxx2TfS5VztkZU6+4DRV/jOAfZf4L1Af5ftocj/MlLsz2PdHOtvv96dLtcwyP5ZE/txF4BoYLu24XW34Xhgu/0vj3CglrbhdbdhD/v17rZfZ4GcfM9Xuhc3xwcjc5D2AR/B5UTsXe1tdQk4DvyWn35vMqkNZwJb7feyAJfATtvxutpxmP37dwMTHNu1Dd0e7/bvOmAy8u/AJuTfgXSBZFY9tLKDUkoppVQupXPklFJKKaVyKQ3klFJKKaVyKQ3klFJKKaVyKQ3klFJKKaVyKQ3klFJKKaVyKQ3klFJKKaVyKQ3klFJKKaVyKa9bfQFKKZWbWJY1FsmO76gF6wWsc7fNGDM2u69PKZW/aCCnlFLXr5cx5iyAZVnFgeEZbFNKqSylQ6tKKaWUUrmUBnJKKaWUUrmUBnJKKaWUUrmUBnJKKaWUUqs7FzQAAABtSURBVLmUBnJKKaWUUrmUBnJKKaWUUrmUph9RSqnrcwL4yrKsFPt7D+DXDLYppVSWsowxt/oalFJKKaXUDdChVaWUUkqpXEoDOaWUUkqpXEoDOaWUUkqpXEoDOaWUUkqpXEoDOaWUUkqpXOr/AV+7NQLKFu6aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20840 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26085 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26399 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 29366 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20840 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 26032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22686 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 26032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22686 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30830 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35786 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\85366\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35745 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model_predict(model_city_date_path, data_china, city_name='全国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=[0.34293657018057455, 0.34356958663080606, 0.3445263953665961, 0.3458519761562857, 0.34740290648197797, 0.34875224440622654, 0.35007449584120415, 0.34508720833878614, 0.33534092132194987, 0.3193574121899007, 0.29708575814476124, 0.2736256698740591, 0.24611079652359738, 0.21919780464466446, 0.1942629488927123, 0.15853911003086013, 0.12673063199129236, 0.11688689690813935, 0.10066641344280985]\n",
    "np.argmax(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_city_date_paths = ['models/shenzhen/02-08','models/wuhan/02-08','models/hubei/02-08','models/china/02-08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_i in range(len(model_city_date_paths)):\n",
    "    print(model_city_date_paths[model_i]+':{')\n",
    "    model_city_date_path = model_city_date_paths[model_i]\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    beta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "    print(f'beta_model_{model_i}:{beta}')\n",
    "    gamma_2 = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "    print(f'gamma_2_model_{model_i}:{gamma_2}')\n",
    "    N = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        N.append(model.SEIR_cells[i].N.detach().numpy()[0])\n",
    "    print(f'N_model_{model_i}:{N}')    \n",
    "    theta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "    print(f'theta_model_{model_i}:{theta}')  \n",
    "    print('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.SEIR_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_sz = []\n",
    "for i in range(len(model.SEIR_cells)):\n",
    "    beta_sz.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "beta_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_predict(model_city_date_path, data, N_cur=-1,beta=1e7,gamma_2=1e7,theta=1e7, city_name='深圳',c='confirmed', features=['I','cured','dead'], pred_date_len=5):\n",
    "    global data_dict\n",
    "    temp=[]\n",
    "    I_name,recover_name,dead_name = features\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    I = model.I_tensor_cur\n",
    "    R = model.R_tensor_cur\n",
    "    D = model.D_tensor_cur\n",
    "    I_pred_old = (I.detach().numpy()).astype(np.int)\n",
    "    R_pred_old = (R.detach().numpy()).astype(np.int)\n",
    "    D_pred_old = (D.detach().numpy()).astype(np.int)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    print(city_name)\n",
    "#     print(confirm_origin)\n",
    "#     plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name)\n",
    "    new_confirm = cal_new_confirm(np.array(data[I_name]),np.array(data[recover_name]),np.array(data[dead_name]))\n",
    "    cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    new_confirm_pred = cal_new_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    \n",
    "    beta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "    gamma_2 = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "    theta = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "    param = model.param_pred(beta,gamma_2,theta)\n",
    "\n",
    "#     print(param)\n",
    "    S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(beta=param['beta'],gamma_2=param['gamma_2'],theta=param['theta'], pred_date_len = pred_date_len)\n",
    "    I_pred_new = (I_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    R_pred_new = (R_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    D_pred_new = (D_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    I_pred_total = np.concatenate((I_pred_old,I_pred_new),axis=0)\n",
    "    R_pred_total = np.concatenate((R_pred_old,R_pred_new),axis=0)\n",
    "    D_pred_total = np.concatenate((D_pred_old,D_pred_new),axis=0)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "#     temp.append(data['time'].values)\n",
    "#     temp.append(confirm_origin)\n",
    "    temp.append(confirm_pred)\n",
    "#     temp.append(new_confirm)\n",
    "   \n",
    "    print(confirm_pred)\n",
    "#     plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name, pred_date_len=pred_date_len)\n",
    "#     print(new_confirm)\n",
    "    new_confirm_pred_total = cal_new_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    temp.append(new_confirm_pred_total)\n",
    "    data_dict[city_name]=temp\n",
    "#     print(new_confirm_pred_total)\n",
    "#     plot_daily_new(data, new_confirm, new_confirm_pred_total, city=city_name, pred_date_len=pred_date_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "湖北\n",
      "[  270   337   433   569   759  1027  1405  1933  2670  3667  4974  6618\n",
      "  8626 10995 13682 16669 19685 22391 24974 27225 29584 31776 33877 36082\n",
      " 38396 40824 43372]\n",
      "武汉\n",
      "[  258   318   398   499   628   794  1006  1279  1630  2070  2614  3287\n",
      "  4127  5173  6476  8096  9921 11712 13541 15111 16856 18436 19935 21547\n",
      " 23282 25147 27152]\n",
      "全国\n",
      "[  291   371   491   672   943  1353  1965  2869  4174  5958  8243 10972\n",
      " 14064 17426 20981 24679 28225 31391 34471 37222 40105 42721 44945 47231\n",
      " 49580 51991 54470]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_dict={}\n",
    "citys=['湖北','武汉','全国']\n",
    "paths=['./ncov/data/hubei_截至'+time+'_24时.csv','./ncov/data/wuhan_截至'+time+'_24时.csv','./ncov/data/nation_截至'+time+'_24时.csv']\n",
    "modelpath=['./models/hubei/02-11','./models/wuhan/02-11','./models/china/02-11']\n",
    "for i in range(3):\n",
    "    data=read_data(paths[i])\n",
    "#     print(data)\n",
    "    city_name=citys[i]\n",
    "    # N=0\n",
    "    # if i == 3:\n",
    "    #     N = (max(data['E']) + max(data['I']) + max(data['cured']) + max(data['dead'])) * 100.\n",
    "    # else :\n",
    "    #     N = N_inits[i]\n",
    "    # model_city_date_path = train_with_city_data(data,N,datetime,city_name)\n",
    "    load_model_predict(modelpath[i], data, city_name=city_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_curve(data):\n",
    "    index=0\n",
    "    for i in range(len(data)):\n",
    "        if i== 0 or i==len(data)-1:\n",
    "            print('out')\n",
    "            continue\n",
    "        print(i)\n",
    "        cur=data[i]\n",
    "        left=data[i-1]\n",
    "        right=data[i+1]\n",
    "        if cur>left and cur>right:\n",
    "            index=i\n",
    "    return data[index:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "out\n"
     ]
    }
   ],
   "source": [
    "test=[  60.,   80.,  101.,  129.,  166.,  212.,  273.,  351.,  440.,\n",
    "          544.,  673.,  840., 1046., 1303., 1620., 1825., 1791., 1829.,\n",
    "         1570., 1745., 1580., 1499., 1612., 1735., 1865., 2005.]\n",
    "rec=get_recent_curve(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1745.0, 1580.0, 1499.0, 1612.0, 1735.0, 1865.0, 2005.0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
