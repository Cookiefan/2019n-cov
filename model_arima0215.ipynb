{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.integrate as spi\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['KaiTi'] # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from ncov.reader import get_data,watch_data\n",
    "import statsmodels.tsa.api as smt    \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pickle\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEIR_cell(torch.nn.Module):\n",
    "    def __init__(self, N, beta_init=0.2586, gamma_2_init=0.018, theta_init=0.001, alpha_init=0.2):\n",
    "        super(SEIR_cell, self).__init__()\n",
    "        # self.date_len = date_len\n",
    "        self.beta = Parameter(torch.tensor([beta_init], requires_grad=True))\n",
    "        self.N = Parameter(torch.tensor([N], requires_grad=False))\n",
    "        self.gamma_2 = Parameter(torch.tensor([gamma_2_init], requires_grad=True))\n",
    "        # self.gamma_2 = Parameter(torch.tensor([0.5], requires_grad=True))\n",
    "        self.alpha = Parameter(torch.tensor([alpha_init], requires_grad=True))\n",
    "        self.theta = Parameter(torch.tensor([theta_init], requires_grad=True))\n",
    "        # self.theta = Parameter(torch.tensor([0.2], requires_grad=True))\n",
    "        # self.E_ratio = Parameter(torch.tensor([3.], requires_grad=True))\n",
    "\n",
    "    def clamp(self, X):\n",
    "        # return torch.clamp(X, min=0, max=self.N)\n",
    "        return X\n",
    "\n",
    "    def act(self, X):\n",
    "        return torch.pow(X,2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        S, confirm, Exposed, recover, dead = X\n",
    "        # self.beta = beta_old + self.beta_add\n",
    "        # self.gamma_2 = gamma_2_old + self.gamma_2_add\n",
    "        S_rest = S - self.act(self.beta)*confirm*S/self.N # dS/dt\n",
    "        E = Exposed + self.act(self.beta)*confirm*S/self.N - self.act(self.alpha)*Exposed # dE/dt\n",
    "\n",
    "        I = confirm + self.act(self.alpha)*Exposed - self.act(self.gamma_2)*confirm - self.act(self.theta)*confirm # dI/dt\n",
    "        R = recover + self.act(self.gamma_2)*confirm # dR/dt\n",
    "        D = dead + self.act(self.theta)*confirm\n",
    "\n",
    "        # I = confirm + self.act(self.alpha)*E - self.act(self.gamma_2)*confirm - self.act(self.theta)*confirm # dI/dt\n",
    "        # R = recover + self.act(self.gamma_2)*I # dR/dt\n",
    "        # D = dead + self.act(self.theta)*I\n",
    "\n",
    "        return S_rest, I, E, R, D, self.beta, self.gamma_2, self.theta, self.alpha\n",
    "    \n",
    "    def update_beta(self, b):\n",
    "        self.beta = Parameter(torch.tensor([b], requires_grad=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEIR_model(torch.nn.Module):\n",
    "    def __init__(self, date_len, pred_date_len=0, N=2870000., E_ratio_init=3., I_init=41, R_init=2., D_init=0., param={}):\n",
    "        super(SEIR_model, self).__init__()\n",
    "        self.SEIR_cells = torch.nn.ModuleList()\n",
    "        self.SEIR_pred_cells = torch.nn.ModuleList()\n",
    "        self.N = N\n",
    "        self.E_ratio = E_ratio_init\n",
    "        self.I = I_init\n",
    "        self.E = (self.I * self.E_ratio)\n",
    "        self.R = R_init\n",
    "        self.D = D_init\n",
    "        self.S = (self.N - self.I - self.E - self.R - self.D)\n",
    "        self.date_len = date_len-1\n",
    "        self.pred_date_len = pred_date_len\n",
    "        if param!={}:\n",
    "            len_param=len(param['beta'])\n",
    "            self.beta_save = param['beta']\n",
    "            self.gamma_2_save = param['gamma_2']\n",
    "            self.alpha_save = param['alpha']\n",
    "            self.theta_save = param['theta']\n",
    "            for i in range(len_param):\n",
    "                beta = self.beta_save[i]\n",
    "                gamma_2 = self.gamma_2_save[i]\n",
    "                alpha = self.alpha_save[i]\n",
    "                theta = self.theta_save[i]\n",
    "                self.SEIR_cells.append(SEIR_cell(self.N,beta,gamma_2,theta,alpha))\n",
    "            if self.date_len>len_param:\n",
    "                for i in range(len_param, self.date_len):\n",
    "                    if len_param>=1:\n",
    "                        beta = self.beta_save[len_param-1]\n",
    "                        gamma_2 = self.gamma_2_save[len_param-1]\n",
    "                        alpha = self.alpha_save[len_param-1]\n",
    "                        theta = self.theta_save[len_param-1]\n",
    "                        self.SEIR_cells.append(SEIR_cell(self.N,beta,gamma_2,theta,alpha)) \n",
    "                    else:\n",
    "                        self.SEIR_cells.append(SEIR_cell(self.N)) \n",
    "        else:\n",
    "            for i in range(self.date_len):\n",
    "                self.SEIR_cells.append(SEIR_cell(self.N)) \n",
    "\n",
    "        self.S_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.I_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.E_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.R_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        self.D_tensor_cur = torch.zeros((self.date_len+1,))\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        inp = self.S, self.I, self.E, self.R, self.D\n",
    "        # param = beta_init, gamma_2_init\n",
    "        S_tensor = torch.zeros((self.date_len+1,))\n",
    "        I_tensor = torch.zeros((self.date_len+1,))\n",
    "        E_tensor = torch.zeros((self.date_len+1,))\n",
    "        R_tensor = torch.zeros((self.date_len+1,))\n",
    "        D_tensor = torch.zeros((self.date_len+1,))\n",
    "        S_tensor[0], I_tensor[0], E_tensor[0], R_tensor[0], D_tensor[0] = inp\n",
    "        for i in range(self.date_len):\n",
    "            if i == self.date_len-1: # we cannot update the last beta with grad\n",
    "                self.beta = beta_cur\n",
    "                self.SEIR_cells[i].update_beta(beta_cur)\n",
    "            S, I, E, R, D, beta_cur, gamma_2_cur, theta_cur, alpha_cur = self.SEIR_cells[i](inp)\n",
    "            S_tensor[i+1], I_tensor[i+1], E_tensor[i+1], R_tensor[i+1], D_tensor[i+1] = S, I, E, R, D\n",
    "            self.beta = beta_cur\n",
    "            self.gamma_2 = gamma_2_cur\n",
    "            self.theta = theta_cur\n",
    "            self.alpha = alpha_cur\n",
    "            self.S_cur = S\n",
    "            self.I_cur = I\n",
    "            self.E_cur = E\n",
    "            self.R_cur = R\n",
    "            self.D_cur = D\n",
    "            inp = [S, I, E, R, D]\n",
    "        self.S_tensor_cur, self.I_tensor_cur, self.E_tensor_cur, self.R_tensor_cur, self.D_tensor_cur = S_tensor, I_tensor, E_tensor, R_tensor, D_tensor\n",
    "        return S_tensor, I_tensor, E_tensor, R_tensor, D_tensor, beta_cur, gamma_2_cur\n",
    "\n",
    "    def pred(self, pred_date_len, param={}):\n",
    "        check_positive_replace = lambda x,y:y if x <=0 else x\n",
    "        if param=={}:\n",
    "            N_cur=self.N\n",
    "            beta=self.beta\n",
    "            gamma_2=self.gamma_2\n",
    "            theta=self.theta\n",
    "            alpha=self.alpha\n",
    "        else:\n",
    "            N_cur=self.N\n",
    "            beta=check_positive_replace(param['beta'],self.beta)\n",
    "            gamma_2=check_positive_replace(param['gamma_2'],self.gamma_2)\n",
    "            theta=check_positive_replace(param['theta'],self.theta)\n",
    "            alpha=check_positive_replace(param['alpha'],self.alpha)\n",
    "        cur_pred_cells_len = len(self.SEIR_pred_cells)\n",
    "        # print(\"cur_pred_cells_len:\", cur_pred_cells_len)\n",
    "        if cur_pred_cells_len!=pred_date_len:\n",
    "            self.SEIR_pred_cells = torch.nn.ModuleList()\n",
    "            for i in range(pred_date_len):\n",
    "                self.SEIR_pred_cells.append(SEIR_cell(N_cur,beta,gamma_2,theta,alpha))\n",
    "        S_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        I_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        E_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        R_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        D_pred_tensor = torch.zeros((pred_date_len,))\n",
    "        # pred:\n",
    "        inp = self.S_cur, self.I_cur, self.E_cur, self.R_cur, self.D_cur\n",
    "        for i in range(pred_date_len):\n",
    "            S, I, E, R, D, beta_, gamma_2_, theta_, alpha_ = self.SEIR_pred_cells[i](inp)\n",
    "            S_pred_tensor[i], I_pred_tensor[i], E_pred_tensor[i], R_pred_tensor[i], D_pred_tensor[i] = S, I, E, R, D\n",
    "            inp = [S, I, E, R, D]\n",
    "        return S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor\n",
    "\n",
    "\n",
    "    def beta_pred(self, beta_list):\n",
    "        check_positive = lambda x:0 if x <=0 else np.sqrt(x)\n",
    "        sqrt_datas=[beta_list]\n",
    "        datas = [list(np.square(d)) for d in sqrt_datas]\n",
    "        params=['beta']\n",
    "        param_dict={}\n",
    "        for i in range(len(params)):\n",
    "            param=params[i]\n",
    "            data=datas[i]\n",
    "            print(\"data:\",data)\n",
    "            data_copy=pd.DataFrame(data,columns=[param])\n",
    "            dif_data=data_copy\n",
    "            dif_data_list=[data_copy.values]\n",
    "            dif=0\n",
    "            p_value = adfuller(data_copy[param])[1]\n",
    "            while p_value>0.05:\n",
    "                dif=dif+1\n",
    "                dif_data=dif_data.diff(1).dropna()\n",
    "                dif_data_list.append(dif_data.values)\n",
    "                p_value= adfuller(dif_data[param])[1]  \n",
    "            pmax = int(len(data)/10) \n",
    "            qmax = int(len(data)/10)\n",
    "            if dif>1:\n",
    "                d=0\n",
    "                data=dif_data\n",
    "            else:\n",
    "                d=dif\n",
    "            bic_matrix = [] #bic矩阵\n",
    "            for p in range(pmax+1):\n",
    "                tmp = []\n",
    "                for q in range(qmax+1):\n",
    "                    try: #存在部分报错，所以用try来跳过报错。\n",
    "                        tmp.append(smt.ARIMA(data, (p,d,q)).fit().bic)\n",
    "                    except:\n",
    "                        tmp.append(None)\n",
    "                bic_matrix.append(tmp)\n",
    "            bic_matrix = pd.DataFrame(bic_matrix) #从中可以找出最小值\n",
    "            p,q = bic_matrix.stack().astype('float64').idxmin() #先用stack展平，然后用idxmin找出最小值位置。\n",
    "            \n",
    "            model = smt.ARIMA(data, (p,d,q)).fit() #建立ARIMA模型\n",
    "            param_dict[param]=model.forecast(2)[0]\n",
    "            print(param_dict[param])\n",
    "            if dif>1:\n",
    "                dif_data_list[-1]=np.append(dif_data_list[-1],param_dict[param])\n",
    "                for i in range(dif,0,-1):\n",
    "                    dif_data_list[i-1]=np.append(dif_data_list[i-1],dif_data_list[i][-2:]+dif_data_list[i-1][-2:])\n",
    "                param_dict[param]=dif_data_list[0][-2:]\n",
    "        # update beta by arima\n",
    "        param_dict['beta'][0] = check_positive(param_dict['beta'][0])\n",
    "        # param_dict['beta'][1] = check_positive(param_dict['beta'][1])\n",
    "        self.SEIR_cells[-1].update_beta(param_dict['beta'][0])\n",
    "        \n",
    "        return param_dict['beta'][1]\n",
    "\n",
    "    def param_pred(self,beta_list,gamma_2_list,theta_list,alpha_list):\n",
    "        check_positive = lambda x:0 if x <=0 else np.sqrt(x)\n",
    "        sqrt_datas=[gamma_2_list,theta_list,alpha_list]\n",
    "        datas = [list(np.square(d)) for d in sqrt_datas]\n",
    "        params=['gamma_2','theta','alpha']\n",
    "        param_dict={}\n",
    "\n",
    "        param_dict['beta'] = self.beta_pred(beta_list[:-1])\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            param=params[i]\n",
    "            data=datas[i]\n",
    "            data_copy=pd.DataFrame(data,columns=[param])\n",
    "            dif_data=data_copy\n",
    "            dif_data_list=[data_copy.values]\n",
    "            dif=0\n",
    "            p_value = adfuller(data_copy[param])[1]\n",
    "            while p_value>0.05:\n",
    "                dif=dif+1\n",
    "                dif_data=dif_data.diff(1).dropna()\n",
    "                dif_data_list.append(dif_data.values)\n",
    "                p_value= adfuller(dif_data[param])[1] \n",
    "            pmax = int(len(data)/10) \n",
    "            qmax = int(len(data)/10)\n",
    "            if dif>1:\n",
    "                d=0\n",
    "                data=dif_data\n",
    "            else:\n",
    "                d=dif\n",
    "            bic_matrix = [] #bic矩阵\n",
    "            for p in range(pmax+1):\n",
    "                tmp = []\n",
    "                for q in range(qmax+1):\n",
    "                    try: #存在部分报错，所以用try来跳过报错。\n",
    "                        tmp.append(smt.ARIMA(data, (p,d,q)).fit().bic)\n",
    "                    except:\n",
    "                        tmp.append(None)\n",
    "                bic_matrix.append(tmp)\n",
    "            bic_matrix = pd.DataFrame(bic_matrix) #从中可以找出最小值\n",
    "            p,q = bic_matrix.stack().astype('float64').idxmin() #先用stack展平，然后用idxmin找出最小值位置。\n",
    "            \n",
    "            model = smt.ARIMA(data, (p,d,q)).fit() #建立ARIMA(0, 1, 1)模型\n",
    "            model.summary2() #给出一份模型报告\n",
    "            param_dict[param]=model.forecast(1)[0][0]\n",
    "            if dif>1:\n",
    "                dif_data_list[-1]=np.append(dif_data_list[-1],param_dict[param])\n",
    "                for i in range(1,dif+1,1):\n",
    "                    dif_data_list[-i-1]=np.append(dif_data_list[-i-1],dif_data_list[-i][-1]+ dif_data_list[-i-1][-1])\n",
    "                param_dict[param]=dif_data_list[0][-1]\n",
    "        for k,v in param_dict.items():\n",
    "            param_dict[k]=check_positive(v)\n",
    "        return param_dict\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SEIRD(data, I, R, D, xlen=10, city='武汉', pred_date_len=0):\n",
    "    # len_data = len(list(set(data.index)))\n",
    "    # print(len_data)\n",
    "    plt.figure(figsize=(xlen, 6))\n",
    "    T_name = 'time'\n",
    "    time_val = data[T_name].values\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1,pred_date_len+1):\n",
    "        pred_time.append(max_time_val+np.timedelta64(i,'D')) \n",
    "    # print(pred_time)\n",
    "    if pred_time==[]:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time),axis=0)\n",
    "    plt.plot(merge_time, I, color = 'red', label = 'I-感染人数',marker = '.')\n",
    "    plt.plot(merge_time, R, color = 'blue',label = 'R-治愈人数',marker = '.')\n",
    "    # plt.plot(merge_time, S, color = 'darkgreen',label = 'S-易感人群',marker = '.')\n",
    "    # plt.plot(merge_time, E, color = 'darkorange',label = 'E-疑似人数',marker = '.')\n",
    "    plt.plot(merge_time, D, color = 'black',label = 'D-死亡人数',marker = '.')\n",
    "\n",
    "    for a,b in zip(merge_time, I):\n",
    "        plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,5), textcoords='offset points',color='red')\n",
    "    # for a,b in zip(merge_time, S):\n",
    "    #     plt.annotate('%s'%(b),xy=(a,b),xytext=(-5,20), textcoords='offset points',color='darkgreen')\n",
    "\n",
    "    city_title = '疫情状况-'+city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel('日期')   \n",
    "    plt.ylabel('人数')\n",
    "    plt.show()\n",
    "\n",
    "def plot_param(model,city_name,data,xlen=10):\n",
    "    T_name = 'time'\n",
    "    time_val = data[T_name].values\n",
    "    plt.figure(figsize=(xlen, 10))\n",
    "    # pd.to_datetime()\n",
    "    format_datetime = lambda x :f'0{x.date().month}-{x.date().day}' if x.date().month<10 else f'{x.date().month}-{x.date().day}'\n",
    "    dates_list = [format_datetime(pd.to_datetime(d)) for d in time_val]\n",
    "    beta = []\n",
    "    gamma_2 = []\n",
    "    theta = []\n",
    "    alpha = []\n",
    "    omega = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "        gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "        theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "        alpha.append(model.SEIR_cells[i].alpha.detach().numpy()[0])\n",
    "        omega.append((model.SEIR_cells[i].theta.detach().numpy()[0])*0.)\n",
    "\n",
    "    print('beta:',beta)\n",
    "    print('gamma_2:',gamma_2)\n",
    "    print('theta:',theta)\n",
    "    print('alpha:',alpha)\n",
    "    print('omega:',omega)\n",
    "    plot_title = ['beta-感染率','gamma_2-治愈率','theta-死亡率','alpha-(疑似->感染)率','omega-疑似解除率']\n",
    "    plot_list_sqrt = [beta,gamma_2,theta,alpha,omega]\n",
    "    plot_list=[np.square(p) for p in plot_list_sqrt]\n",
    "    colors=['blue','darkgreen','darkorange','red','purple']\n",
    "    for i in range(len(colors)):\n",
    "        plt.plot(dates_list[:len(beta)], plot_list[i],color=colors[i],label=plot_title[i],marker='x')\n",
    "    for a, b in zip(range(len(beta)), beta):\n",
    "        plt.annotate('%.4f' % (b), xy=(a, b), xytext=(-2, 2), textcoords='offset points', color=colors[0])\n",
    "    plt.legend()\n",
    "    title = 'Param changing process-'+city_name\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_daily_acc(data, accumulated_confirmed, accumulated_pred_confirmed,acc_cured,acc_pred_cured,xlen=10, city=u'武汉', pred_date_len=0):\n",
    "    T_name = 'time'\n",
    "    plt.figure(figsize=(xlen, 10))\n",
    "    time_val = data[T_name].values\n",
    "\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1, pred_date_len + 1):\n",
    "        pred_time.append(max_time_val + np.timedelta64(i, 'D'))\n",
    "    if pred_time == []:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time), axis=0)\n",
    "\n",
    "    '''\n",
    "    意思是在一个2行2列共4个子图的图中，定位第1个图来进行操作（画图）。\n",
    "    最后面那个1表示第1个子图。那个数字的变化来定位不同的子图\n",
    "    '''\n",
    "    #第一行第一列图形\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    #第一行第二列图形\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    #第二行\n",
    "    #选择ax1\n",
    "    plt.sca(ax1)\n",
    "    #绘制红色曲线\n",
    "    plt.plot(time_val, accumulated_confirmed, color='red', label='累计确诊人数', marker='x')\n",
    "    plt.plot(merge_time, accumulated_pred_confirmed, color='blue', label='预测的累计确诊人数', marker='x')\n",
    "    for a, b in zip(merge_time, accumulated_pred_confirmed):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 5), textcoords='offset points', color='blue')\n",
    "    for a, b in zip(time_val, accumulated_confirmed):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 20), textcoords='offset points', color='red')\n",
    "    city_title = u'疫情状况-' + city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')\n",
    "    plt.ylabel(u'人数')\n",
    "    \n",
    "    plt.sca(ax2)\n",
    "    #绘制红色曲线\n",
    "    plt.plot(time_val, acc_cured, color='red', label='累计治愈人数', marker='x')\n",
    "    plt.plot(merge_time, acc_pred_cured, color='blue', label='预测的累计治愈人数', marker='x')\n",
    "    for a, b in zip(merge_time, acc_pred_cured):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 5), textcoords='offset points', color='blue')\n",
    "    for a, b in zip(time_val, acc_cured):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 20), textcoords='offset points', color='red')\n",
    "    city_title = u'疫情状况-' + city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')\n",
    "    plt.ylabel(u'人数')\n",
    "    plt.savefig(city+u'累计预测')\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "def plot_daily_new(data, new_confirm, pred_new_confirm, new_cured,pred_new_cured,xlen=10, city=u'武汉', pred_date_len=0):\n",
    "    plt.figure(figsize=(xlen, 10))\n",
    "    T_name = 'time'\n",
    "    time_val = data[T_name].values\n",
    "    time_val = time_val[1:]\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1,pred_date_len+1):\n",
    "        pred_time.append(max_time_val+np.timedelta64(i,'D'))\n",
    "    if pred_time==[]:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time),axis=0)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    #第一行第二列图形\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    #第二行\n",
    "    #选择ax1\n",
    "    plt.sca(ax1)\n",
    "    #绘制红色曲线\n",
    "    plt.plot(time_val, new_confirm, color='red', label='新增确诊人数', marker='x')\n",
    "    plt.plot(merge_time, pred_new_confirm, color='blue', label='预测的新增确诊人数', marker='x')\n",
    "    for a, b in zip(merge_time, pred_new_confirm):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 5), textcoords='offset points', color='blue')\n",
    "    for a, b in zip(time_val, new_confirm):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 20), textcoords='offset points', color='red')\n",
    "    city_title = u'疫情状况-' + city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')\n",
    "    plt.ylabel(u'人数')\n",
    "    \n",
    "    plt.sca(ax2)\n",
    "    #绘制红色曲线\n",
    "    plt.plot(time_val, new_cured, color='red', label='新增治愈人数', marker='x')\n",
    "    plt.plot(merge_time, pred_new_cured, color='blue', label='预测的新增治愈人数', marker='x')\n",
    "    for a, b in zip(merge_time, pred_new_cured):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 5), textcoords='offset points', color='blue')\n",
    "    for a, b in zip(time_val, new_cured):\n",
    "        plt.annotate('%s' % (b), xy=(a, b), xytext=(-5, 20), textcoords='offset points', color='red')\n",
    "    city_title = u'疫情状况-' + city\n",
    "    plt.title(city_title)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u'日期')\n",
    "    plt.ylabel(u'人数')\n",
    "    plt.savefig(city+u'新增预测')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def cal_acc_confirm(I,R,D):\n",
    "    return I+R+D\n",
    "\n",
    "def cal_new_confirm(I,R,D):\n",
    "    acc_confirm = cal_acc_confirm(I,R,D)\n",
    "    new_confirm = np.zeros((len(acc_confirm)-1))\n",
    "    for i in range(len(acc_confirm)-1):\n",
    "        new_confirm[i] = acc_confirm[i+1]-acc_confirm[i]\n",
    "    return new_confirm\n",
    "\n",
    "def get_data_acc_confirm(data,c='confirmed'):\n",
    "    return np.array(data[c])\n",
    "\n",
    "def save_param(model, model_city_date_path):\n",
    "    save_path = os.path.join(model_city_date_path,'params/')\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    beta = []\n",
    "    theta = []\n",
    "    gamma_2 = []\n",
    "    alpha = []\n",
    "    for i in range(len(model.SEIR_cells)):\n",
    "        beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "        gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "        theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "        alpha.append(model.SEIR_cells[i].alpha.detach().numpy()[0])\n",
    "    param={'beta':beta,'theta':theta,'gamma_2':gamma_2,'alpha':alpha}\n",
    "    with open(save_path + 'param.pkl', 'wb') as f:\n",
    "        pickle.dump(param, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_param(model_city_date_path):\n",
    "    save_path = os.path.join(model_city_date_path,'params/')\n",
    "    with open(save_path + 'param.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def make_dir(city, date):\n",
    "    save_root_path = 'models/'\n",
    "    model_city_path = os.path.join(save_root_path, city)\n",
    "\n",
    "    model_city_date_path = os.path.join(model_city_path, date)\n",
    "\n",
    "    if not os.path.exists(model_city_date_path):\n",
    "        print(model_city_date_path)\n",
    "        os.makedirs(model_city_date_path)\n",
    "    return model_city_date_path\n",
    "\n",
    "def lr_decay(global_step,learning_rate=0.01,decay_rate=0.8,decay_steps=300):\n",
    "    decayed_learning_rate = learning_rate * np.power(decay_rate,(global_step / decay_steps))\n",
    "    return decayed_learning_rate\n",
    "\n",
    "def train(data, model_city_date_path, lr_init=0.01, N=1e7, I_init=1e-6, R_init=1e-6 / 2., D_init=1e-6 / 6., cured_ratio=20., dead_ratio=20.,\n",
    "          param={}, features=['I', 'cured', 'dead'], max_epoches=6000):\n",
    "    model_pt = os.path.join(model_city_date_path, 'model.pt')\n",
    "    data_feat = data[features]\n",
    "    Input = np.array(data_feat, dtype=np.float)\n",
    "    print(Input.shape)\n",
    "    date_len = len(Input)\n",
    "    print(date_len)\n",
    "    model = SEIR_model(date_len, pred_date_len=10, N=N, I_init=I_init, R_init=R_init, D_init=D_init, param=param)\n",
    "\n",
    "    lr = lr_init\n",
    "    # Beta1 hyperparam for Adam optimizers\n",
    "    beta1 = 0.5\n",
    "    loss_list=[]\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    loss_min = 1e8\n",
    "    for epoch_step in range(max_epoches):\n",
    "        print(\"Training step: \", epoch_step)\n",
    "        Input = torch.tensor(Input)\n",
    "        model_inp = Input[:-1]\n",
    "        S, I, E, R, D, beta, gamma_2 = model(model_inp.float())\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        pred_I = I\n",
    "        pred_recovered = R\n",
    "        pred_dead = D\n",
    "        pred_confirmed = I+R+D\n",
    "        \n",
    "        I_gt_tensor = Input[:, 0]\n",
    "        recovered_gt_tensor = Input[:, 1]\n",
    "        dead_gt_tensor = Input[:, 2]\n",
    "        confirmed_gt_tensor=I_gt_tensor+recovered_gt_tensor+dead_gt_tensor\n",
    "\n",
    "        loss = (loss_fn(pred_confirmed, confirmed_gt_tensor) + cured_ratio*loss_fn(pred_recovered, recovered_gt_tensor) + dead_ratio*loss_fn(pred_dead, dead_gt_tensor) + loss_fn(pred_I, I_gt_tensor))/(dead_ratio+cured_ratio+2.)\n",
    "        print(\"Loss: {}\".format(loss))\n",
    "        loss_list.append(loss)\n",
    "        if loss < loss_min:\n",
    "            loss_min = loss\n",
    "            torch.save(model, model_pt)\n",
    "        learning_rate = lr_decay(epoch_step,lr,decay_steps=300)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss_min:\", loss_min)\n",
    "    save_param(model,model_city_date_path)\n",
    "    return S, I, E, R, D, loss_list\n",
    "\n",
    "def load_model_predict(model_city_date_path, data, param_pred=True, city_name='深圳',c='confirmed', features=['I','cured','dead'], pred_date_len=5):\n",
    "    I_name,recover_name,dead_name = features\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    S = model.S_tensor_cur\n",
    "    E = model.E_tensor_cur\n",
    "    I = model.I_tensor_cur\n",
    "    R = model.R_tensor_cur\n",
    "    D = model.D_tensor_cur\n",
    "    I_pred_old = (I.detach().numpy()).astype(np.int)\n",
    "    R_pred_old = (R.detach().numpy()).astype(np.int)\n",
    "    D_pred_old = (D.detach().numpy()).astype(np.int)\n",
    "    S_pred_old = (S.detach().numpy()).astype(np.int)\n",
    "    E_pred_old = (E.detach().numpy()).astype(np.int)\n",
    "#     print(confirm_origin)\n",
    "#   使用原始数据得到的\n",
    "    if param_pred:\n",
    "        beta = []\n",
    "        theta = []\n",
    "        gamma_2 = []\n",
    "        alpha = []\n",
    "        for i in range(len(model.SEIR_cells)):\n",
    "            beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "            gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "            theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "            alpha.append(model.SEIR_cells[i].alpha.detach().numpy()[0])\n",
    "        # if city_name=='深圳':\n",
    "        #     theta=get_recent_curve(theta)\n",
    "        # print(len(theta))\n",
    "        param = model.param_pred(beta,gamma_2,theta,alpha)\n",
    "\n",
    "        print(param)\n",
    "        S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(param=param, pred_date_len = pred_date_len)\n",
    "    else:\n",
    "        S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(pred_date_len = pred_date_len)\n",
    "\n",
    "    I_pred_new = (I_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    R_pred_new = (R_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    D_pred_new = (D_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    S_pred_new = (S_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    E_pred_new = (E_pred_tensor.detach().numpy()).astype(np.int)\n",
    "\n",
    "    I_pred_total = np.concatenate((I_pred_old,I_pred_new),axis=0)\n",
    "    R_pred_total = np.concatenate((R_pred_old,R_pred_new),axis=0)\n",
    "    D_pred_total = np.concatenate((D_pred_old,D_pred_new),axis=0)\n",
    "    S_pred_total = np.concatenate((S_pred_old,S_pred_new),axis=0)\n",
    "    E_pred_total = np.concatenate((E_pred_old,E_pred_new),axis=0)\n",
    "\n",
    "    plot_SEIRD(data, I=I_pred_total, R=R_pred_total, D=D_pred_total, city=city_name, pred_date_len=pred_date_len)\n",
    "    \n",
    "    confirm_pred = cal_acc_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    cured_origin=np.array(data['cured'])\n",
    "    new_cured_orgin=np.diff(cured_origin)\n",
    "    new_cured_pred=np.diff(R_pred_total)\n",
    "    plot_daily_acc(data, confirm_origin, confirm_pred,cured_origin,R_pred_total,city=city_name, pred_date_len=pred_date_len)\n",
    "    new_confirm = cal_new_confirm(np.array(data[I_name]),np.array(data[recover_name]),np.array(data[dead_name]))\n",
    "    new_confirm_pred_total = cal_new_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "#     new_confirm_pred_total\n",
    "\n",
    "    plot_daily_new(data, new_confirm, new_confirm_pred_total,new_cured_orgin,new_cured_pred,city=city_name, pred_date_len=pred_date_len)\n",
    "    print('新增治愈：',new_cured_pred)\n",
    "    print('新增确诊：',new_confirm_pred_total)\n",
    "\n",
    "#     print(\"!!!!!!\\nN:\\n\",S_pred_total+E_pred_total+I_pred_total+R_pred_total+D_pred_total)\n",
    "    return model\n",
    "\n",
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data['I'] = data['confirmed']-data['dead']-data['cured']\n",
    "    data['I/cured']=data['I']/data['cured']\n",
    "    data['I/dead']=data['I']/data['dead']\n",
    "\n",
    "    if 'nation' in path:    #全国有个E\n",
    "        data['E']=data['suspected']+data['close_contact']+data['under_medical_observation']\n",
    "    data['time']= pd.to_datetime(data['time'])\n",
    "    return data\n",
    "\n",
    "def train_with_city_data(data, N, date, cityname='深圳', lr_init=0.01, max_epoches=2000,is_train=True,load_param_save=False,param_path=''):\n",
    "    city_pinyin = {'北京':'beijing','重庆':'chongqing','上海':'shanghai','深圳':'shenzhen', '湖北':'hubei', '武汉':'wuhan', '全国':'china'}\n",
    "    pinyin = city_pinyin[cityname]\n",
    "    model_city_date_path = make_dir(pinyin,date)\n",
    "    features=['I', 'cured','dead']\n",
    "    I_init = float(data['I'].iloc[0])\n",
    "    R_init = float(data['cured'].iloc[0])\n",
    "    D_init = float(data['dead'].iloc[0])\n",
    "    N = N\n",
    "    cured_ratio = float(data['I'].mean()/data['cured'].mean()) if data['cured'].mean()!=0 else 50.\n",
    "    dead_ratio = float(data['I'].mean()/data['dead'].mean()) if data['dead'].mean()!=0 else 50.\n",
    "    print('cured_ratio:',cured_ratio)\n",
    "    print('dead_ratio:',dead_ratio)\n",
    "    param={}\n",
    "    if load_param_save:\n",
    "        if param_path=='':\n",
    "            param_path=model_city_date_path\n",
    "        param = load_param(param_path)\n",
    "    print(param)\n",
    "#     if loss_type='cure':\n",
    "#         cured_ratio*=2\n",
    "#         dead_ratio\\=\n",
    "    #train里面会保存模型\n",
    "    if is_train:\n",
    "        S,I,E,R,D,loss_list = train(data, model_city_date_path, lr_init=lr_init, N=N, I_init=I_init, R_init=R_init, D_init=D_init, cured_ratio=cured_ratio,dead_ratio=dead_ratio*0.01, features=features, max_epoches=max_epoches,param=param)\n",
    "        plt.plot(range(len(loss_list)), loss_list, color='darkorange', label='loss training', marker='x')\n",
    "    return model_city_date_path\n",
    "#read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "citys=['湖北','武汉','深圳','全国']\n",
    "N_inits=[59170000.,2870000.,13026600.]\n",
    "\n",
    "time='0217'\n",
    "# yesterday='02-13'\n",
    "paths=['./ncov/data/hubei_截至'+time+'_24时.csv','./ncov/data/wuhan_截至'+time+'_24时.csv','./ncov/data/shenzhen_截至'+time+'_24时.csv','./ncov/data/nation_截至'+time+'_24时.csv']\n",
    "# param_paths_yes=['models/'+'hubei/'+yesterday,'models/'+'wuhan/'+yesterday,'models/'+'shenzhen/'+yesterday,'models/'+'china/'+yesterday]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cured_ratio: 9.06050896866875\n",
      "dead_ratio: 38.256487025948104\n",
      "{'beta': [0.6996495161577447, 0.7345343975197631, 0.7586860034449338, 0.7946152818267789, 0.8088863008067505, 0.819417036912457, 0.7479609310100307, 0.6948837910705175, 0.6933635727520054, 0.688933325210264, 0.6490299760480985, 0.50698788256202, 0.49668408650802115, 0.49252653375883626, 0.48247454518682276, 0.47315307654185473, 0.4678348502856205, 0.46660491975912344, 0.4626103647049217, 0.45944598790467794, 0.4562070976325193, 0.4612420583089454, 0.3864088248976951, 0.32955350307395587, 0.2972095657599679, 0.2916841021127891, 0.2897858224188724, 0.28978560751072285], 'theta': [-0.048703244061867344, -0.052718764463842216, -0.05628393443811957, 0.06211506725800316, 0.07452812596549145, 0.09349232145727689, -0.0705194071546572, -0.09899502286630121, 0.11397807824131853, -0.08281456779455805, 0.06515966956765751, 0.06120043527709388, -0.06441990532377122, 0.06291699966623297, -0.05809508651235739, 0.05653291317347025, 0.052777622489895704, -0.05447081466246069, -0.052910375400153, -0.053597722720578264, -0.05478663363256539, 0.051236097093698446, -0.08074229019049807, 0.014948411213957602, -0.050544498834785095, -0.05044809660718792, -0.040112705185374006, -0.04538980063695805], 'gamma_2': [-0.07109535768002308, 0.08449657637164447, -0.11756079088278118, -0.09038617362669472, 0.0928950808115114, -0.09602723866961159, 0.04618571780951584, 0.1014892961599814, -0.05877780473294597, 0.07881546382494192, 0.08823457809385332, -0.08678936333735178, 0.10337075207462523, -0.0979109187718029, 0.11582087931492073, -0.10667212505302025, 0.12129734795369444, 0.13264325871992805, 0.13730533994089228, 0.13686431828437146, 0.1409560086619617, 0.14062522105218128, 0.17373796103045985, 0.12432338770744719, 0.15693924466417328, 0.15251575981169127, 0.1575732491646071, 0.17164032625173264], 'alpha': [0.5866897148244025, 0.5592200056709526, 0.5632581909798892, 0.5959900837725624, 0.6564278591657319, 0.680864894144035, 0.8977810140633848, 0.889615528211076, 0.8392221672192444, 0.752601303516856, 0.6449582101239814, 0.6141066463399611, 0.627487504461343, 0.6463103968822487, 0.6770831236152626, 0.6371202839119006, 0.5460721551830218, 0.5073280085099393, 0.40619147390056254, 0.38347367356379075, 0.31822483809079405, 0.26199257935587933, 0.6546010209471991, 0.3945261799229351, 0.30903721910241083, 0.25918597887906514, 0.24967249825182705, 0.2311859924564117]}\n",
      "(29, 3)\n",
      "29\n",
      "Training step:  0\n",
      "Loss: 984.283347001469\n",
      "Training step:  1\n",
      "Loss: 984.3252837646394\n",
      "Training step:  2\n",
      "Loss: 984.2280270018487\n",
      "Training step:  3\n",
      "Loss: 984.2896730316753\n",
      "Training step:  4\n",
      "Loss: 984.1582231757947\n",
      "Training step:  5\n",
      "Loss: 984.269020908602\n",
      "Training step:  6\n",
      "Loss: 984.0935918479277\n",
      "Training step:  7\n",
      "Loss: 984.1690245570735\n",
      "Training step:  8\n",
      "Loss: 984.0275102070731\n",
      "Training step:  9\n",
      "Loss: 984.1466451996062\n",
      "Training step:  10\n",
      "Loss: 983.9641512187569\n",
      "Training step:  11\n",
      "Loss: 984.0298328337263\n",
      "Training step:  12\n",
      "Loss: 983.8995925580906\n",
      "Training step:  13\n",
      "Loss: 984.0061299356173\n",
      "Training step:  14\n",
      "Loss: 983.8351371467324\n",
      "Training step:  15\n",
      "Loss: 983.9071545239802\n",
      "Training step:  16\n",
      "Loss: 983.7696707316994\n",
      "Training step:  17\n",
      "Loss: 983.8844574329639\n",
      "Training step:  18\n",
      "Loss: 983.7064745773456\n",
      "Training step:  19\n",
      "Loss: 983.7744875866765\n",
      "Training step:  20\n",
      "Loss: 983.6416486127019\n",
      "Training step:  21\n",
      "Loss: 983.7513011123069\n",
      "Training step:  22\n",
      "Loss: 983.5781972969014\n",
      "Training step:  23\n",
      "Loss: 983.642308885064\n",
      "Training step:  24\n",
      "Loss: 983.5140751594234\n",
      "Training step:  25\n",
      "Loss: 983.618637846231\n",
      "Training step:  26\n",
      "Loss: 983.4503721325567\n",
      "Training step:  27\n",
      "Loss: 983.5207804186547\n",
      "Training step:  28\n",
      "Loss: 983.3854299178633\n",
      "Training step:  29\n",
      "Loss: 983.498098832092\n",
      "Training step:  30\n",
      "Loss: 983.3229653187975\n",
      "Training step:  31\n",
      "Loss: 983.3839781139716\n",
      "Training step:  32\n",
      "Loss: 983.2595611423347\n",
      "Training step:  33\n",
      "Loss: 983.3600150298689\n",
      "Training step:  34\n",
      "Loss: 983.1960355376258\n",
      "Training step:  35\n",
      "Loss: 983.2631524504329\n",
      "Training step:  36\n",
      "Loss: 983.1316944212508\n",
      "Training step:  37\n",
      "Loss: 983.2401690177626\n",
      "Training step:  38\n",
      "Loss: 983.0693945162654\n",
      "Training step:  39\n",
      "Loss: 983.1326725526574\n",
      "Training step:  40\n",
      "Loss: 983.0057138093154\n",
      "Training step:  41\n",
      "Loss: 983.1092172711091\n",
      "Training step:  42\n",
      "Loss: 982.9431694402284\n",
      "Training step:  43\n",
      "Loss: 983.0126900535906\n",
      "Training step:  44\n",
      "Loss: 982.8787839869387\n",
      "Training step:  45\n",
      "Loss: 982.9902023594038\n",
      "Training step:  46\n",
      "Loss: 982.8174503319724\n",
      "Training step:  47\n",
      "Loss: 982.8776532576896\n",
      "Training step:  48\n",
      "Loss: 982.7544255152363\n",
      "Training step:  49\n",
      "Loss: 982.8539155361211\n",
      "Training step:  50\n",
      "Loss: 982.6920571487385\n",
      "Training step:  51\n",
      "Loss: 982.7583648611502\n",
      "Training step:  52\n",
      "Loss: 982.6282637760693\n",
      "Training step:  53\n",
      "Loss: 982.7355851415197\n",
      "Training step:  54\n",
      "Loss: 982.5670936795751\n",
      "Training step:  55\n",
      "Loss: 982.6243071960693\n",
      "Training step:  56\n",
      "Loss: 982.504749903247\n",
      "Training step:  57\n",
      "Loss: 982.6002940511482\n",
      "Training step:  58\n",
      "Loss: 982.4425591689895\n",
      "Training step:  59\n",
      "Loss: 982.5057090014103\n",
      "Training step:  60\n",
      "Loss: 982.3793515482846\n",
      "Training step:  61\n",
      "Loss: 982.4826443719419\n",
      "Training step:  62\n",
      "Loss: 982.3183467725102\n",
      "Training step:  63\n",
      "Loss: 982.3777756997989\n",
      "Training step:  64\n",
      "Loss: 982.2557541967457\n",
      "Training step:  65\n",
      "Loss: 982.3542588388059\n",
      "Training step:  66\n",
      "Loss: 982.1945166245698\n",
      "Training step:  67\n",
      "Loss: 982.2503103218964\n",
      "Training step:  68\n",
      "Loss: 982.132587812603\n",
      "Training step:  69\n",
      "Loss: 982.226345718225\n",
      "Training step:  70\n",
      "Loss: 982.0711206506264\n",
      "Training step:  71\n",
      "Loss: 982.1328221027583\n",
      "Training step:  72\n",
      "Loss: 982.0084184948655\n",
      "Training step:  73\n",
      "Loss: 982.1097906130553\n",
      "Training step:  74\n",
      "Loss: 981.9481176977581\n",
      "Training step:  75\n",
      "Loss: 982.0010549756964\n",
      "Training step:  76\n",
      "Loss: 981.8868767948786\n",
      "Training step:  77\n",
      "Loss: 981.9768293100515\n",
      "Training step:  78\n",
      "Loss: 981.8255884009538\n",
      "Training step:  79\n",
      "Loss: 981.8842468214077\n",
      "Training step:  80\n",
      "Loss: 981.7634586993513\n",
      "Training step:  81\n",
      "Loss: 981.860945034503\n",
      "Training step:  82\n",
      "Loss: 981.703324692451\n",
      "Training step:  83\n",
      "Loss: 981.7584151238462\n",
      "Training step:  84\n",
      "Loss: 981.6418271834206\n",
      "Training step:  85\n",
      "Loss: 981.7346774030119\n",
      "Training step:  86\n",
      "Loss: 981.5814702715772\n",
      "Training step:  87\n",
      "Loss: 981.6424185062776\n",
      "Training step:  88\n",
      "Loss: 981.5193086460127\n",
      "Training step:  89\n",
      "Loss: 981.6195933102358\n",
      "Training step:  90\n",
      "Loss: 981.4600920299949\n",
      "Training step:  91\n",
      "Loss: 981.5123465977994\n",
      "Training step:  92\n",
      "Loss: 981.3992235977755\n",
      "Training step:  93\n",
      "Loss: 981.4883565999511\n",
      "Training step:  94\n",
      "Loss: 981.3390439090531\n",
      "Training step:  95\n",
      "Loss: 981.3970216347732\n",
      "Training step:  96\n",
      "Loss: 981.2774462374609\n",
      "Training step:  97\n",
      "Loss: 981.3739351295045\n",
      "Training step:  98\n",
      "Loss: 981.2183951339897\n",
      "Training step:  99\n",
      "Loss: 981.2678873455754\n",
      "Training step:  100\n",
      "Loss: 981.1581730314119\n",
      "Training step:  101\n",
      "Loss: 981.2436515384129\n",
      "Training step:  102\n",
      "Loss: 981.098171986085\n",
      "Training step:  103\n",
      "Loss: 981.1532302549499\n",
      "Training step:  104\n",
      "Loss: 981.0371323144218\n",
      "Training step:  105\n",
      "Loss: 981.1298890015075\n",
      "Training step:  106\n",
      "Loss: 980.9782482686012\n",
      "Training step:  107\n",
      "Loss: 981.0298466091564\n",
      "Training step:  108\n",
      "Loss: 980.9177964943134\n",
      "Training step:  109\n",
      "Loss: 981.0060876483549\n",
      "Training step:  110\n",
      "Loss: 980.8587003216325\n",
      "Training step:  111\n",
      "Loss: 980.9159842507743\n",
      "Training step:  112\n",
      "Loss: 980.7976355481484\n",
      "Training step:  113\n",
      "Loss: 980.8701417621426\n",
      "Training step:  114\n",
      "Loss: 980.7377234695028\n",
      "Training step:  115\n",
      "Loss: 980.7818356149389\n",
      "Training step:  116\n",
      "Loss: 980.6782624448381\n",
      "Training step:  117\n",
      "Loss: 980.757196901191\n",
      "Training step:  118\n",
      "Loss: 980.618693365329\n",
      "Training step:  119\n",
      "Loss: 980.6685185896863\n",
      "Training step:  120\n",
      "Loss: 980.5586988127925\n",
      "Training step:  121\n",
      "Loss: 980.6447565960339\n",
      "Training step:  122\n",
      "Loss: 980.5002236952607\n",
      "Training step:  123\n",
      "Loss: 980.5467853393001\n",
      "Training step:  124\n",
      "Loss: 980.4409053911132\n",
      "Training step:  125\n",
      "Loss: 980.5226185778773\n",
      "Training step:  126\n",
      "Loss: 980.3822262796043\n",
      "Training step:  127\n",
      "Loss: 980.4342524572048\n",
      "Training step:  128\n",
      "Loss: 980.3222090619572\n",
      "Training step:  129\n",
      "Loss: 980.4109516670552\n",
      "Training step:  130\n",
      "Loss: 980.2639810207136\n",
      "Training step:  131\n",
      "Loss: 980.3134739449305\n",
      "Training step:  132\n",
      "Loss: 980.20456621318\n",
      "Training step:  133\n",
      "Loss: 980.2896869416085\n",
      "Training step:  134\n",
      "Loss: 980.1466810535253\n",
      "Training step:  135\n",
      "Loss: 980.1929093688875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  136\n",
      "Loss: 980.087873229022\n",
      "Training step:  137\n",
      "Loss: 980.1687262508859\n",
      "Training step:  138\n",
      "Loss: 980.0297891809557\n",
      "Training step:  139\n",
      "Loss: 980.0813933539492\n",
      "Training step:  140\n",
      "Loss: 979.9703040825584\n",
      "Training step:  141\n",
      "Loss: 980.0580624311624\n",
      "Training step:  142\n",
      "Loss: 979.9132830979039\n",
      "Training step:  143\n",
      "Loss: 979.9569658605969\n",
      "Training step:  144\n",
      "Loss: 979.8551031613624\n",
      "Training step:  145\n",
      "Loss: 979.932564218071\n",
      "Training step:  146\n",
      "Loss: 979.7971982291858\n",
      "Training step:  147\n",
      "Loss: 979.84609622433\n",
      "Training step:  148\n",
      "Loss: 979.7382449880098\n",
      "Training step:  149\n",
      "Loss: 979.8225383542738\n",
      "Training step:  150\n",
      "Loss: 979.6813922166391\n",
      "Training step:  151\n",
      "Loss: 979.7270705432214\n",
      "Training step:  152\n",
      "Loss: 979.6230021094224\n",
      "Training step:  153\n",
      "Loss: 979.7031270916241\n",
      "Training step:  154\n",
      "Loss: 979.5659563496484\n",
      "Training step:  155\n",
      "Loss: 979.616966094228\n",
      "Training step:  156\n",
      "Loss: 979.506988944559\n",
      "Training step:  157\n",
      "Loss: 979.5723142444375\n",
      "Training step:  158\n",
      "Loss: 979.4491555584389\n",
      "Training step:  159\n",
      "Loss: 979.4878410848402\n",
      "Training step:  160\n",
      "Loss: 979.391694794027\n",
      "Training step:  161\n",
      "Loss: 979.463084973508\n",
      "Training step:  162\n",
      "Loss: 979.3342175193981\n",
      "Training step:  163\n",
      "Loss: 979.3782678559324\n",
      "Training step:  164\n",
      "Loss: 979.2762617069151\n",
      "Training step:  165\n",
      "Loss: 979.3543387160005\n",
      "Training step:  166\n",
      "Loss: 979.2198149165202\n",
      "Training step:  167\n",
      "Loss: 979.2608282008298\n",
      "Training step:  168\n",
      "Loss: 979.1625040120182\n",
      "Training step:  169\n",
      "Loss: 979.2365255096704\n",
      "Training step:  170\n",
      "Loss: 979.105871760015\n",
      "Training step:  171\n",
      "Loss: 979.1520099902555\n",
      "Training step:  172\n",
      "Loss: 979.0479039992247\n",
      "Training step:  173\n",
      "Loss: 979.1285241545038\n",
      "Training step:  174\n",
      "Loss: 978.9922896984461\n",
      "Training step:  175\n",
      "Loss: 979.0309098052184\n",
      "Training step:  176\n",
      "Loss: 978.9355912724267\n",
      "Training step:  177\n",
      "Loss: 979.0064071795044\n",
      "Training step:  178\n",
      "Loss: 978.8791383059187\n",
      "Training step:  179\n",
      "Loss: 978.9227227197423\n",
      "Training step:  180\n",
      "Loss: 978.821684120182\n",
      "Training step:  181\n",
      "Loss: 978.8990288827533\n",
      "Training step:  182\n",
      "Loss: 978.766238673131\n",
      "Training step:  183\n",
      "Loss: 978.8067792959738\n",
      "Training step:  184\n",
      "Loss: 978.7093382612536\n",
      "Training step:  185\n",
      "Loss: 978.7827218856269\n",
      "Training step:  186\n",
      "Loss: 978.6537129117152\n",
      "Training step:  187\n",
      "Loss: 978.699336607877\n",
      "Training step:  188\n",
      "Loss: 978.596251754193\n",
      "Training step:  189\n",
      "Loss: 978.65553365255\n",
      "Training step:  190\n",
      "Loss: 978.5398759737043\n",
      "Training step:  191\n",
      "Loss: 978.5737608621156\n",
      "Training step:  192\n",
      "Loss: 978.4838545649158\n",
      "Training step:  193\n",
      "Loss: 978.5489367550563\n",
      "Training step:  194\n",
      "Loss: 978.4278260068838\n",
      "Training step:  195\n",
      "Loss: 978.4668392265786\n",
      "Training step:  196\n",
      "Loss: 978.3713358328046\n",
      "Training step:  197\n",
      "Loss: 978.4428078193301\n",
      "Training step:  198\n",
      "Loss: 978.315740683605\n",
      "Training step:  199\n",
      "Loss: 978.3605774939239\n",
      "Training step:  200\n",
      "Loss: 978.2588347415865\n",
      "Training step:  201\n",
      "Loss: 978.3170781700783\n",
      "Training step:  202\n",
      "Loss: 978.2029852445977\n",
      "Training step:  203\n",
      "Loss: 978.2362921716779\n",
      "Training step:  204\n",
      "Loss: 978.1471256020732\n",
      "Training step:  205\n",
      "Loss: 978.2114656147564\n",
      "Training step:  206\n",
      "Loss: 978.0916454500987\n",
      "Training step:  207\n",
      "Loss: 978.130332584375\n",
      "Training step:  208\n",
      "Loss: 978.0356670129713\n",
      "Training step:  209\n",
      "Loss: 978.1062843370055\n",
      "Training step:  210\n",
      "Loss: 977.9811577048577\n",
      "Training step:  211\n",
      "Loss: 978.0248378313354\n",
      "Training step:  212\n",
      "Loss: 977.9247251378049\n",
      "Training step:  213\n",
      "Loss: 977.9656893522194\n",
      "Training step:  214\n",
      "Loss: 977.869129307633\n",
      "Training step:  215\n",
      "Loss: 977.9420139597795\n",
      "Training step:  216\n",
      "Loss: 977.8152673459392\n",
      "Training step:  217\n",
      "Loss: 977.852892066033\n",
      "Training step:  218\n",
      "Loss: 977.7593810970677\n",
      "Training step:  219\n",
      "Loss: 977.8288997558145\n",
      "Training step:  220\n",
      "Loss: 977.7053825921063\n",
      "Training step:  221\n",
      "Loss: 977.7404858442642\n",
      "Training step:  222\n",
      "Loss: 977.6499992743373\n",
      "Training step:  223\n",
      "Loss: 977.7161811080537\n",
      "Training step:  224\n",
      "Loss: 977.5958664365513\n",
      "Training step:  225\n",
      "Loss: 977.6360564465094\n",
      "Training step:  226\n",
      "Loss: 977.5398729334634\n",
      "Training step:  227\n",
      "Loss: 977.5931878444463\n",
      "Training step:  228\n",
      "Loss: 977.485122914795\n",
      "Training step:  229\n",
      "Loss: 977.51456207858\n",
      "Training step:  230\n",
      "Loss: 977.4304540575403\n",
      "Training step:  231\n",
      "Loss: 977.4895939790789\n",
      "Training step:  232\n",
      "Loss: 977.3760107459996\n",
      "Training step:  233\n",
      "Loss: 977.4106367315234\n",
      "Training step:  234\n",
      "Loss: 977.3208823415257\n",
      "Training step:  235\n",
      "Loss: 977.3864575669031\n",
      "Training step:  236\n",
      "Loss: 977.2674065460499\n",
      "Training step:  237\n",
      "Loss: 977.3071731342036\n",
      "Training step:  238\n",
      "Loss: 977.2118236142405\n",
      "Training step:  239\n",
      "Loss: 977.2646682825616\n",
      "Training step:  240\n",
      "Loss: 977.1576513868877\n",
      "Training step:  241\n",
      "Loss: 977.1868577566621\n",
      "Training step:  242\n",
      "Loss: 977.103371210748\n",
      "Training step:  243\n",
      "Loss: 977.1620291020294\n",
      "Training step:  244\n",
      "Loss: 977.049592554917\n",
      "Training step:  245\n",
      "Loss: 977.0838945303337\n",
      "Training step:  246\n",
      "Loss: 976.994862555143\n",
      "Training step:  247\n",
      "Loss: 977.0598419489538\n",
      "Training step:  248\n",
      "Loss: 976.9420353830428\n",
      "Training step:  249\n",
      "Loss: 976.9739887763897\n",
      "Training step:  250\n",
      "Loss: 976.887852620689\n",
      "Training step:  251\n",
      "Loss: 976.9496399506332\n",
      "Training step:  252\n",
      "Loss: 976.8349000164101\n",
      "Training step:  253\n",
      "Loss: 976.8717337828864\n",
      "Training step:  254\n",
      "Loss: 976.7801276258062\n",
      "Training step:  255\n",
      "Loss: 976.8295717736225\n",
      "Training step:  256\n",
      "Loss: 976.7262336087066\n",
      "Training step:  257\n",
      "Loss: 976.7530796550935\n",
      "Training step:  258\n",
      "Loss: 976.6727117205612\n",
      "Training step:  259\n",
      "Loss: 976.7281336261806\n",
      "Training step:  260\n",
      "Loss: 976.6194970939646\n",
      "Training step:  261\n",
      "Loss: 976.6513256869902\n",
      "Training step:  262\n",
      "Loss: 976.565537338002\n",
      "Training step:  263\n",
      "Loss: 976.627139815698\n",
      "Training step:  264\n",
      "Loss: 976.5132541514918\n",
      "Training step:  265\n",
      "Loss: 976.5500209073462\n",
      "Training step:  266\n",
      "Loss: 976.4588613365108\n",
      "Training step:  267\n",
      "Loss: 976.4934531880481\n",
      "Training step:  268\n",
      "Loss: 976.4052283496939\n",
      "Training step:  269\n",
      "Loss: 976.4696805485265\n",
      "Training step:  270\n",
      "Loss: 976.353609389442\n",
      "Training step:  271\n",
      "Loss: 976.3854385783966\n",
      "Training step:  272\n",
      "Loss: 976.3000200376953\n",
      "Training step:  273\n",
      "Loss: 976.3613809640437\n",
      "Training step:  274\n",
      "Loss: 976.2482814140633\n",
      "Training step:  275\n",
      "Loss: 976.2777974375625\n",
      "Training step:  276\n",
      "Loss: 976.1951613738695\n",
      "Training step:  277\n",
      "Loss: 976.2534578437728\n",
      "Training step:  278\n",
      "Loss: 976.1433051023294\n",
      "Training step:  279\n",
      "Loss: 976.1775239401404\n",
      "Training step:  280\n",
      "Loss: 976.0896216536772\n",
      "Training step:  281\n",
      "Loss: 976.1360243983654\n",
      "Training step:  282\n",
      "Loss: 976.0368337949069\n",
      "Training step:  283\n",
      "Loss: 976.0614500984856\n",
      "Training step:  284\n",
      "Loss: 975.9843559947996\n",
      "Training step:  285\n",
      "Loss: 976.036542044012\n",
      "Training step:  286\n",
      "Loss: 975.9322537225306\n",
      "Training step:  287\n",
      "Loss: 975.9616698948711\n",
      "Training step:  288\n",
      "Loss: 975.8793573511092\n",
      "Training step:  289\n",
      "Loss: 975.9374962432443\n",
      "Training step:  290\n",
      "Loss: 975.8281542587607\n",
      "Training step:  291\n",
      "Loss: 975.8623275563382\n",
      "Training step:  292\n",
      "Loss: 975.7748439364981\n",
      "Training step:  293\n",
      "Loss: 975.8069549165331\n",
      "Training step:  294\n",
      "Loss: 975.7222931551831\n",
      "Training step:  295\n",
      "Loss: 975.7831833493261\n",
      "Training step:  296\n",
      "Loss: 975.6717336106215\n",
      "Training step:  297\n",
      "Loss: 975.7011637789182\n",
      "Training step:  298\n",
      "Loss: 975.6191985616277\n",
      "Training step:  299\n",
      "Loss: 975.6771210101319\n",
      "Training step:  300\n",
      "Loss: 975.5680485776235\n",
      "Training step:  301\n",
      "Loss: 975.6027473997683\n",
      "Training step:  302\n",
      "Loss: 975.515097361702\n",
      "Training step:  303\n",
      "Loss: 975.5478170720858\n",
      "Training step:  304\n",
      "Loss: 975.4629489715226\n",
      "Training step:  305\n",
      "Loss: 975.5241090859131\n",
      "Training step:  306\n",
      "Loss: 975.412846855139\n",
      "Training step:  307\n",
      "Loss: 975.4428507703377\n",
      "Training step:  308\n",
      "Loss: 975.3606427653758\n",
      "Training step:  309\n",
      "Loss: 975.4188765460889\n",
      "Training step:  310\n",
      "Loss: 975.3104311082943\n",
      "Training step:  311\n",
      "Loss: 975.3382460300119\n",
      "Training step:  312\n",
      "Loss: 975.2586755726464\n",
      "Training step:  313\n",
      "Loss: 975.3140083920651\n",
      "Training step:  314\n",
      "Loss: 975.2083562703783\n",
      "Training step:  315\n",
      "Loss: 975.2406529560542\n",
      "Training step:  316\n",
      "Loss: 975.1560906840897\n",
      "Training step:  317\n",
      "Loss: 975.1863640589154\n",
      "Training step:  318\n",
      "Loss: 975.1045239100987\n",
      "Training step:  319\n",
      "Loss: 975.1625188824685\n",
      "Training step:  320\n",
      "Loss: 975.0548300645039\n",
      "Training step:  321\n",
      "Loss: 975.0825795557124\n",
      "Training step:  322\n",
      "Loss: 975.0033395933168\n",
      "Training step:  323\n",
      "Loss: 975.0584756243557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  324\n",
      "Loss: 974.9535404589863\n",
      "Training step:  325\n",
      "Loss: 974.9857400126359\n",
      "Training step:  326\n",
      "Loss: 974.9015834270435\n",
      "Training step:  327\n",
      "Loss: 974.9318814806635\n",
      "Training step:  328\n",
      "Loss: 974.8504076773038\n",
      "Training step:  329\n",
      "Loss: 974.9081653830029\n",
      "Training step:  330\n",
      "Loss: 974.8012259267047\n",
      "Training step:  331\n",
      "Loss: 974.8289104253361\n",
      "Training step:  332\n",
      "Loss: 974.750000009265\n",
      "Training step:  333\n",
      "Loss: 974.8049401562643\n",
      "Training step:  334\n",
      "Loss: 974.7007152835898\n",
      "Training step:  335\n",
      "Loss: 974.7262931915844\n",
      "Training step:  336\n",
      "Loss: 974.6499244333656\n",
      "Training step:  337\n",
      "Loss: 974.7020714648828\n",
      "Training step:  338\n",
      "Loss: 974.6005385515169\n",
      "Training step:  339\n",
      "Loss: 974.6304404259723\n",
      "Training step:  340\n",
      "Loss: 974.5492513082829\n",
      "Training step:  341\n",
      "Loss: 974.5772095537827\n",
      "Training step:  342\n",
      "Loss: 974.4986455493143\n",
      "Training step:  343\n",
      "Loss: 974.5533706340333\n",
      "Training step:  344\n",
      "Loss: 974.4498672857015\n",
      "Training step:  345\n",
      "Loss: 974.4753961354754\n",
      "Training step:  346\n",
      "Loss: 974.3993378111535\n",
      "Training step:  347\n",
      "Loss: 974.451310228063\n",
      "Training step:  348\n",
      "Loss: 974.350460639711\n",
      "Training step:  349\n",
      "Loss: 974.3802830111407\n",
      "Training step:  350\n",
      "Loss: 974.299476959823\n",
      "Training step:  351\n",
      "Loss: 974.3274735969239\n",
      "Training step:  352\n",
      "Loss: 974.2492547307821\n",
      "Training step:  353\n",
      "Loss: 974.2877065090197\n",
      "Training step:  354\n",
      "Loss: 974.1993423009117\n",
      "Training step:  355\n",
      "Loss: 974.2182829712783\n",
      "Training step:  356\n",
      "Loss: 974.1497652467284\n",
      "Training step:  357\n",
      "Loss: 974.1934074265567\n",
      "Training step:  358\n",
      "Loss: 974.1001631617963\n",
      "Training step:  359\n",
      "Loss: 974.1237048187083\n",
      "Training step:  360\n",
      "Loss: 974.0501970171836\n",
      "Training step:  361\n",
      "Loss: 974.0995251813857\n",
      "Training step:  362\n",
      "Loss: 974.0017327113611\n",
      "Training step:  363\n",
      "Loss: 974.0295633330472\n",
      "Training step:  364\n",
      "Loss: 973.9514013433359\n",
      "Training step:  365\n",
      "Loss: 973.9773713012936\n",
      "Training step:  366\n",
      "Loss: 973.9017411353313\n",
      "Training step:  367\n",
      "Loss: 973.9535650330399\n",
      "Training step:  368\n",
      "Loss: 973.8538671367621\n",
      "Training step:  369\n",
      "Loss: 973.8774885171216\n",
      "Training step:  370\n",
      "Loss: 973.8042735226378\n",
      "Training step:  371\n",
      "Loss: 973.8534465370157\n",
      "Training step:  372\n",
      "Loss: 973.7563067112566\n",
      "Training step:  373\n",
      "Loss: 973.7840730382792\n",
      "Training step:  374\n",
      "Loss: 973.7062740120919\n",
      "Training step:  375\n",
      "Loss: 973.732293741594\n",
      "Training step:  376\n",
      "Loss: 973.6569899718273\n",
      "Training step:  377\n",
      "Loss: 973.6931118751988\n",
      "Training step:  378\n",
      "Loss: 973.6080175181057\n",
      "Training step:  379\n",
      "Loss: 973.6252911449492\n",
      "Training step:  380\n",
      "Loss: 973.5593454790483\n",
      "Training step:  381\n",
      "Loss: 973.6004937452253\n",
      "Training step:  382\n",
      "Loss: 973.5106875320505\n",
      "Training step:  383\n",
      "Loss: 973.5324060016729\n",
      "Training step:  384\n",
      "Loss: 973.4616423364516\n",
      "Training step:  385\n",
      "Loss: 973.5082827730225\n",
      "Training step:  386\n",
      "Loss: 973.4140831330004\n",
      "Training step:  387\n",
      "Loss: 973.4399451516534\n",
      "Training step:  388\n",
      "Loss: 973.3646878131523\n",
      "Training step:  389\n",
      "Loss: 973.3887699856331\n",
      "Training step:  390\n",
      "Loss: 973.3159545273164\n",
      "Training step:  391\n",
      "Loss: 973.3650109283847\n",
      "Training step:  392\n",
      "Loss: 973.2689688363591\n",
      "Training step:  393\n",
      "Loss: 973.2907788806344\n",
      "Training step:  394\n",
      "Loss: 973.2202914173105\n",
      "Training step:  395\n",
      "Loss: 973.266794933451\n",
      "Training step:  396\n",
      "Loss: 973.1732187360142\n",
      "Training step:  397\n",
      "Loss: 973.199030659794\n",
      "Training step:  398\n",
      "Loss: 973.1241172866349\n",
      "Training step:  399\n",
      "Loss: 973.1482597089046\n",
      "Training step:  400\n",
      "Loss: 973.0757529599252\n",
      "Training step:  401\n",
      "Loss: 973.1096574429474\n",
      "Training step:  402\n",
      "Loss: 973.0277024853315\n",
      "Training step:  403\n",
      "Loss: 973.0433967862416\n",
      "Training step:  404\n",
      "Loss: 972.9768341370367\n",
      "Training step:  405\n",
      "Loss: 973.0190923689646\n",
      "Training step:  406\n",
      "Loss: 972.9297627214804\n",
      "Training step:  407\n",
      "Loss: 972.9522816203327\n",
      "Training step:  408\n",
      "Loss: 972.8813329459845\n",
      "Training step:  409\n",
      "Loss: 972.9285872154181\n",
      "Training step:  410\n",
      "Loss: 972.8350254544491\n",
      "Training step:  411\n",
      "Loss: 972.8556820992883\n",
      "Training step:  412\n",
      "Loss: 972.7869986802383\n",
      "Training step:  413\n",
      "Loss: 972.8317705704965\n",
      "Training step:  414\n",
      "Loss: 972.7406083238862\n",
      "Training step:  415\n",
      "Loss: 972.7651686190421\n",
      "Training step:  416\n",
      "Loss: 972.6921748561234\n",
      "Training step:  417\n",
      "Loss: 972.7151365293498\n",
      "Training step:  418\n",
      "Loss: 972.6444852691214\n",
      "Training step:  419\n",
      "Loss: 972.676972638264\n",
      "Training step:  420\n",
      "Loss: 972.5971223597143\n",
      "Training step:  421\n",
      "Loss: 972.6118367838372\n",
      "Training step:  422\n",
      "Loss: 972.5458842351363\n",
      "Training step:  423\n",
      "Loss: 972.5877010570528\n",
      "Training step:  424\n",
      "Loss: 972.4996025645376\n",
      "Training step:  425\n",
      "Loss: 972.5219406086919\n",
      "Training step:  426\n",
      "Loss: 972.4517420119281\n",
      "Training step:  427\n",
      "Loss: 972.472341454837\n",
      "Training step:  428\n",
      "Loss: 972.4044478878993\n",
      "Training step:  429\n",
      "Loss: 972.4485629514608\n",
      "Training step:  430\n",
      "Loss: 972.3587146890256\n",
      "Training step:  431\n",
      "Loss: 972.3772742780563\n",
      "Training step:  432\n",
      "Loss: 972.3115751992885\n",
      "Training step:  433\n",
      "Loss: 972.3532874865269\n",
      "Training step:  434\n",
      "Loss: 972.2657640515038\n",
      "Training step:  435\n",
      "Loss: 972.2880768738954\n",
      "Training step:  436\n",
      "Loss: 972.2181892929052\n",
      "Training step:  437\n",
      "Loss: 972.238868776704\n",
      "Training step:  438\n",
      "Loss: 972.171252955966\n",
      "Training step:  439\n",
      "Loss: 972.215228512014\n",
      "Training step:  440\n",
      "Loss: 972.1255878013297\n",
      "Training step:  441\n",
      "Loss: 972.1446789736053\n",
      "Training step:  442\n",
      "Loss: 972.0787463138057\n",
      "Training step:  443\n",
      "Loss: 972.1200823219183\n",
      "Training step:  444\n",
      "Loss: 972.0335428893426\n",
      "Training step:  445\n",
      "Loss: 972.0553956553564\n",
      "Training step:  446\n",
      "Loss: 971.9862275515745\n",
      "Training step:  447\n",
      "Loss: 972.0065689011511\n",
      "Training step:  448\n",
      "Loss: 971.9396391722562\n",
      "Training step:  449\n",
      "Loss: 971.9578497194856\n",
      "Training step:  450\n",
      "Loss: 971.8921345397401\n",
      "Training step:  451\n",
      "Loss: 971.9342268559021\n",
      "Training step:  452\n",
      "Loss: 971.8472578042292\n",
      "Training step:  453\n",
      "Loss: 971.864419641398\n",
      "Training step:  454\n",
      "Loss: 971.7979483948967\n",
      "Training step:  455\n",
      "Loss: 971.8270983779174\n",
      "Training step:  456\n",
      "Loss: 971.7519003499004\n",
      "Training step:  457\n",
      "Loss: 971.7641860673468\n",
      "Training step:  458\n",
      "Loss: 971.693247553142\n",
      "Training step:  459\n",
      "Loss: 971.7020107878114\n",
      "Training step:  460\n",
      "Loss: 971.6348176969096\n",
      "Training step:  461\n",
      "Loss: 971.653648694693\n",
      "Training step:  462\n",
      "Loss: 971.5859265674165\n",
      "Training step:  463\n",
      "Loss: 971.6054786284353\n",
      "Training step:  464\n",
      "Loss: 971.5399265183433\n",
      "Training step:  465\n",
      "Loss: 971.5683541760163\n",
      "Training step:  466\n",
      "Loss: 971.4944549532773\n",
      "Training step:  467\n",
      "Loss: 971.506118357995\n",
      "Training step:  468\n",
      "Loss: 971.4372317002653\n",
      "Training step:  469\n",
      "Loss: 971.458155023966\n",
      "Training step:  470\n",
      "Loss: 971.3914273122456\n",
      "Training step:  471\n",
      "Loss: 971.4102873224962\n",
      "Training step:  472\n",
      "Loss: 971.3429232936285\n",
      "Training step:  473\n",
      "Loss: 971.362493636795\n",
      "Training step:  474\n",
      "Loss: 971.2945000406435\n",
      "Training step:  475\n",
      "Loss: 971.3147775602081\n",
      "Training step:  476\n",
      "Loss: 971.2489170891865\n",
      "Training step:  477\n",
      "Loss: 971.2671504138358\n",
      "Training step:  478\n",
      "Loss: 971.2006412925836\n",
      "Training step:  479\n",
      "Loss: 971.2195795370441\n",
      "Training step:  480\n",
      "Loss: 971.1526888901853\n",
      "Training step:  481\n",
      "Loss: 971.1720852097203\n",
      "Training step:  482\n",
      "Loss: 971.1045715763172\n",
      "Training step:  483\n",
      "Loss: 971.1246669097011\n",
      "Training step:  484\n",
      "Loss: 971.0567752375049\n",
      "Training step:  485\n",
      "Loss: 971.0733516851728\n",
      "Training step:  486\n",
      "Loss: 971.0013594047398\n",
      "Training step:  487\n",
      "Loss: 971.0125109968862\n",
      "Training step:  488\n",
      "Loss: 970.9441198707495\n",
      "Training step:  489\n",
      "Loss: 970.9612770896622\n",
      "Training step:  490\n",
      "Loss: 970.8891224390371\n",
      "Training step:  491\n",
      "Loss: 970.9006316262441\n",
      "Training step:  492\n",
      "Loss: 970.8329521938384\n",
      "Training step:  493\n",
      "Loss: 970.8495214088628\n",
      "Training step:  494\n",
      "Loss: 970.7778850154408\n",
      "Training step:  495\n",
      "Loss: 970.7890932463296\n",
      "Training step:  496\n",
      "Loss: 970.7219010086459\n",
      "Training step:  497\n",
      "Loss: 970.7420182973976\n",
      "Training step:  498\n",
      "Loss: 970.6746244661409\n",
      "Training step:  499\n",
      "Loss: 970.6912862460972\n",
      "Training step:  500\n",
      "Loss: 970.6191464989423\n",
      "Training step:  501\n",
      "Loss: 970.6311256163755\n",
      "Training step:  502\n",
      "Loss: 970.5633924773406\n",
      "Training step:  503\n",
      "Loss: 970.5804092359737\n",
      "Training step:  504\n",
      "Loss: 970.5081054470145\n",
      "Training step:  505\n",
      "Loss: 970.5204349403303\n",
      "Training step:  506\n",
      "Loss: 970.4525118300852\n",
      "Training step:  507\n",
      "Loss: 970.4607022717122\n",
      "Training step:  508\n",
      "Loss: 970.396249698752\n",
      "Training step:  509\n",
      "Loss: 970.4138603279041\n",
      "Training step:  510\n",
      "Loss: 970.3412300015656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  511\n",
      "Loss: 970.3541652635423\n",
      "Training step:  512\n",
      "Loss: 970.2858810788828\n",
      "Training step:  513\n",
      "Loss: 970.2947137907473\n",
      "Training step:  514\n",
      "Loss: 970.2298910808044\n",
      "Training step:  515\n",
      "Loss: 970.248113913389\n",
      "Training step:  516\n",
      "Loss: 970.1751619048786\n",
      "Training step:  517\n",
      "Loss: 970.1886966489437\n",
      "Training step:  518\n",
      "Loss: 970.120276551178\n",
      "Training step:  519\n",
      "Loss: 970.129529075519\n",
      "Training step:  520\n",
      "Loss: 970.0653948253149\n",
      "Training step:  521\n",
      "Loss: 970.0830839585337\n",
      "Training step:  522\n",
      "Loss: 970.01090732303\n",
      "Training step:  523\n",
      "Loss: 970.0239763508371\n",
      "Training step:  524\n",
      "Loss: 969.9560698508977\n",
      "Training step:  525\n",
      "Loss: 969.9651098916493\n",
      "Training step:  526\n",
      "Loss: 969.9014506706604\n",
      "Training step:  527\n",
      "Loss: 969.9188430525235\n",
      "Training step:  528\n",
      "Loss: 969.8472122387861\n",
      "Training step:  529\n",
      "Loss: 969.860036728388\n",
      "Training step:  530\n",
      "Loss: 969.7926375642567\n",
      "Training step:  531\n",
      "Loss: 969.8014698114594\n",
      "Training step:  532\n",
      "Loss: 969.7374401081803\n",
      "Training step:  533\n",
      "Loss: 969.7554346871558\n",
      "Training step:  534\n",
      "Loss: 969.6834879426881\n",
      "Training step:  535\n",
      "Loss: 969.6969016478097\n",
      "Training step:  536\n",
      "Loss: 969.629366134696\n",
      "Training step:  537\n",
      "Loss: 969.6386125645447\n",
      "Training step:  538\n",
      "Loss: 969.5752500539742\n",
      "Training step:  539\n",
      "Loss: 969.5920833896083\n",
      "Training step:  540\n",
      "Loss: 969.5212936346253\n",
      "Training step:  541\n",
      "Loss: 969.5338812617616\n",
      "Training step:  542\n",
      "Loss: 969.4672116510033\n",
      "Training step:  543\n",
      "Loss: 969.4758791410311\n",
      "Training step:  544\n",
      "Loss: 969.4133430822476\n",
      "Training step:  545\n",
      "Loss: 969.4301798036125\n",
      "Training step:  546\n",
      "Loss: 969.3598834892092\n",
      "Training step:  547\n",
      "Loss: 969.3722400804421\n",
      "Training step:  548\n",
      "Loss: 969.3060602420345\n",
      "Training step:  549\n",
      "Loss: 969.3145324303035\n",
      "Training step:  550\n",
      "Loss: 969.2524487966515\n",
      "Training step:  551\n",
      "Loss: 969.2690095615104\n",
      "Training step:  552\n",
      "Loss: 969.1992340036217\n",
      "Training step:  553\n",
      "Loss: 969.2113642583064\n",
      "Training step:  554\n",
      "Loss: 969.1456681130218\n",
      "Training step:  555\n",
      "Loss: 969.1539493678239\n",
      "Training step:  556\n",
      "Loss: 969.091496835327\n",
      "Training step:  557\n",
      "Loss: 969.1086488853269\n",
      "Training step:  558\n",
      "Loss: 969.0385627226257\n",
      "Training step:  559\n",
      "Loss: 969.0512709908661\n",
      "Training step:  560\n",
      "Loss: 968.985439405631\n",
      "Training step:  561\n",
      "Loss: 968.9941296321218\n",
      "Training step:  562\n",
      "Loss: 968.932320962602\n",
      "Training step:  563\n",
      "Loss: 968.9489873532326\n",
      "Training step:  564\n",
      "Loss: 968.8796215536578\n",
      "Training step:  565\n",
      "Loss: 968.8919067404915\n",
      "Training step:  566\n",
      "Loss: 968.8265491714607\n",
      "Training step:  567\n",
      "Loss: 968.8350542897128\n",
      "Training step:  568\n",
      "Loss: 968.7736838599429\n",
      "Training step:  569\n",
      "Loss: 968.7900870805942\n",
      "Training step:  570\n",
      "Loss: 968.7212260708366\n",
      "Training step:  571\n",
      "Loss: 968.7332958653348\n",
      "Training step:  572\n",
      "Loss: 968.6684070397821\n",
      "Training step:  573\n",
      "Loss: 968.6767311983011\n",
      "Training step:  574\n",
      "Loss: 968.6150001329272\n",
      "Training step:  575\n",
      "Loss: 968.6307220147767\n",
      "Training step:  576\n",
      "Loss: 968.5627153818508\n",
      "Training step:  577\n",
      "Loss: 968.5742581930207\n",
      "Training step:  578\n",
      "Loss: 968.510109657475\n",
      "Training step:  579\n",
      "Loss: 968.5179414175003\n",
      "Training step:  580\n",
      "Loss: 968.4577079571783\n",
      "Training step:  581\n",
      "Loss: 968.4733734756912\n",
      "Training step:  582\n",
      "Loss: 968.4057797191793\n",
      "Training step:  583\n",
      "Loss: 968.4171172560742\n",
      "Training step:  584\n",
      "Loss: 968.3534248441696\n",
      "Training step:  585\n",
      "Loss: 968.3610851259303\n",
      "Training step:  586\n",
      "Loss: 968.3012724595047\n",
      "Training step:  587\n",
      "Loss: 968.316690739142\n",
      "Training step:  588\n",
      "Loss: 968.2495825954438\n",
      "Training step:  589\n",
      "Loss: 968.2607190919888\n",
      "Training step:  590\n",
      "Loss: 968.1974772422219\n",
      "Training step:  591\n",
      "Loss: 968.204969966896\n",
      "Training step:  592\n",
      "Loss: 968.1455728584478\n",
      "Training step:  593\n",
      "Loss: 968.160748698811\n",
      "Training step:  594\n",
      "Loss: 968.0941203634688\n",
      "Training step:  595\n",
      "Loss: 968.1050599793131\n",
      "Training step:  596\n",
      "Loss: 968.0422632131067\n",
      "Training step:  597\n",
      "Loss: 968.049592230537\n",
      "Training step:  598\n",
      "Loss: 967.9898389736098\n",
      "Training step:  599\n",
      "Loss: 968.0022333922677\n",
      "Training step:  600\n",
      "Loss: 967.9384979550064\n",
      "Training step:  601\n",
      "Loss: 967.9469115673835\n",
      "Training step:  602\n",
      "Loss: 967.8869692322796\n",
      "Training step:  603\n",
      "Loss: 967.8996981179105\n",
      "Training step:  604\n",
      "Loss: 967.8358040286116\n",
      "Training step:  605\n",
      "Loss: 967.8445464237057\n",
      "Training step:  606\n",
      "Loss: 967.7844232425749\n",
      "Training step:  607\n",
      "Loss: 967.7974842483529\n",
      "Training step:  608\n",
      "Loss: 967.7334332239088\n",
      "Training step:  609\n",
      "Loss: 967.7425021176175\n",
      "Training step:  610\n",
      "Loss: 967.6821999432716\n",
      "Training step:  611\n",
      "Loss: 967.6877365475191\n",
      "Training step:  612\n",
      "Loss: 967.6304077726713\n",
      "Training step:  613\n",
      "Loss: 967.6440252444559\n",
      "Training step:  614\n",
      "Loss: 967.5796697214402\n",
      "Training step:  615\n",
      "Loss: 967.5892971647946\n",
      "Training step:  616\n",
      "Loss: 967.5288498811823\n",
      "Training step:  617\n",
      "Loss: 967.534789177889\n",
      "Training step:  618\n",
      "Loss: 967.4780389377731\n",
      "Training step:  619\n",
      "Loss: 967.4912379356966\n",
      "Training step:  620\n",
      "Loss: 967.4275269489955\n",
      "Training step:  621\n",
      "Loss: 967.4367913265478\n",
      "Training step:  622\n",
      "Loss: 967.3769531103688\n",
      "Training step:  623\n",
      "Loss: 967.3825631155106\n",
      "Training step:  624\n",
      "Loss: 967.32564967694\n",
      "Training step:  625\n",
      "Loss: 967.3386348292277\n",
      "Training step:  626\n",
      "Loss: 967.275527264303\n",
      "Training step:  627\n",
      "Loss: 967.284432840653\n",
      "Training step:  628\n",
      "Loss: 967.2249711581744\n",
      "Training step:  629\n",
      "Loss: 967.2304394627628\n",
      "Training step:  630\n",
      "Loss: 967.1746066833641\n",
      "Training step:  631\n",
      "Loss: 967.1872775582708\n",
      "Training step:  632\n",
      "Loss: 967.1246103568888\n",
      "Training step:  633\n",
      "Loss: 967.1333483273205\n",
      "Training step:  634\n",
      "Loss: 967.0742943005007\n",
      "Training step:  635\n",
      "Loss: 967.0796262708972\n",
      "Training step:  636\n",
      "Loss: 967.0234438608055\n",
      "Training step:  637\n",
      "Loss: 967.0366749179996\n",
      "Training step:  638\n",
      "Loss: 966.9737105148665\n",
      "Training step:  639\n",
      "Loss: 966.9829944767147\n",
      "Training step:  640\n",
      "Loss: 966.9236149963353\n",
      "Training step:  641\n",
      "Loss: 966.9295228873108\n",
      "Training step:  642\n",
      "Loss: 966.8737082894946\n",
      "Training step:  643\n",
      "Loss: 966.8867350757902\n",
      "Training step:  644\n",
      "Loss: 966.8242039928018\n",
      "Training step:  645\n",
      "Loss: 966.8333243838309\n",
      "Training step:  646\n",
      "Loss: 966.7743461018156\n",
      "Training step:  647\n",
      "Loss: 966.7801211231316\n",
      "Training step:  648\n",
      "Loss: 966.7241814672279\n",
      "Training step:  649\n",
      "Loss: 966.7375332510865\n",
      "Training step:  650\n",
      "Loss: 966.6749361781109\n",
      "Training step:  651\n",
      "Loss: 966.6843738851992\n",
      "Training step:  652\n",
      "Loss: 966.6254800398294\n",
      "Training step:  653\n",
      "Loss: 966.6314248038195\n",
      "Training step:  654\n",
      "Loss: 966.5748421469937\n",
      "Training step:  655\n",
      "Loss: 966.5859664466602\n",
      "Training step:  656\n",
      "Loss: 966.5257126221377\n",
      "Training step:  657\n",
      "Loss: 966.5331411273215\n",
      "Training step:  658\n",
      "Loss: 966.476373230806\n",
      "Training step:  659\n",
      "Loss: 966.4878170948951\n",
      "Training step:  660\n",
      "Loss: 966.4274114705481\n",
      "Training step:  661\n",
      "Loss: 966.4351536555835\n",
      "Training step:  662\n",
      "Loss: 966.3782136177014\n",
      "Training step:  663\n",
      "Loss: 966.3826923241968\n",
      "Training step:  664\n",
      "Loss: 966.3280186513609\n",
      "Training step:  665\n",
      "Loss: 966.3405182653011\n",
      "Training step:  666\n",
      "Loss: 966.2793382474194\n",
      "Training step:  667\n",
      "Loss: 966.288080861802\n",
      "Training step:  668\n",
      "Loss: 966.2305155323012\n",
      "Training step:  669\n",
      "Loss: 966.2358494780924\n",
      "Training step:  670\n",
      "Loss: 966.1812156458327\n",
      "Training step:  671\n",
      "Loss: 966.1938522507126\n",
      "Training step:  672\n",
      "Loss: 966.1327829714174\n",
      "Training step:  673\n",
      "Loss: 966.1416664263621\n",
      "Training step:  674\n",
      "Loss: 966.0841797949234\n",
      "Training step:  675\n",
      "Loss: 966.0896850719224\n",
      "Training step:  676\n",
      "Loss: 966.035101903892\n",
      "Training step:  677\n",
      "Loss: 966.0478749367071\n",
      "Training step:  678\n",
      "Loss: 965.9869156844208\n",
      "Training step:  679\n",
      "Loss: 965.9959393520443\n",
      "Training step:  680\n",
      "Loss: 965.9383565591946\n",
      "Training step:  681\n",
      "Loss: 965.9442023745123\n",
      "Training step:  682\n",
      "Loss: 965.8894973128172\n",
      "Training step:  683\n",
      "Loss: 965.8996190271871\n",
      "Training step:  684\n",
      "Loss: 965.8414129829473\n",
      "Training step:  685\n",
      "Loss: 965.8480234886258\n",
      "Training step:  686\n",
      "Loss: 965.7926830353892\n",
      "Training step:  687\n",
      "Loss: 965.7965998842136\n",
      "Training step:  688\n",
      "Loss: 965.7399188279031\n",
      "Training step:  689\n",
      "Loss: 965.7452682716736\n",
      "Training step:  690\n",
      "Loss: 965.6913807083885\n",
      "Training step:  691\n",
      "Loss: 965.7026292482933\n",
      "Training step:  692\n",
      "Loss: 965.6438226766688\n",
      "Training step:  693\n",
      "Loss: 965.6512871496243\n",
      "Training step:  694\n",
      "Loss: 965.595955699326\n",
      "Training step:  695\n",
      "Loss: 965.6001444247414\n",
      "Training step:  696\n",
      "Loss: 965.547622694551\n",
      "Training step:  697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 965.5559990614026\n",
      "Training step:  698\n",
      "Loss: 965.5000523509412\n",
      "Training step:  699\n",
      "Loss: 965.5049970003953\n",
      "Training step:  700\n",
      "Loss: 965.4518473525582\n",
      "Training step:  701\n",
      "Loss: 965.4610114703231\n",
      "Training step:  702\n",
      "Loss: 965.4041759991201\n",
      "Training step:  703\n",
      "Loss: 965.4102205976588\n",
      "Training step:  704\n",
      "Loss: 965.3561057889702\n",
      "Training step:  705\n",
      "Loss: 965.3595301265192\n",
      "Training step:  706\n",
      "Loss: 965.303350573125\n",
      "Training step:  707\n",
      "Loss: 965.3089228130015\n",
      "Training step:  708\n",
      "Loss: 965.2556132937314\n",
      "Training step:  709\n",
      "Loss: 965.2651824505126\n",
      "Training step:  710\n",
      "Loss: 965.2085073384975\n",
      "Training step:  711\n",
      "Loss: 965.2146568076804\n",
      "Training step:  712\n",
      "Loss: 965.1607338956129\n",
      "Training step:  713\n",
      "Loss: 965.1642945686796\n",
      "Training step:  714\n",
      "Loss: 965.1089298037977\n",
      "Training step:  715\n",
      "Loss: 965.1139803562876\n",
      "Training step:  716\n",
      "Loss: 965.0581185233722\n",
      "Training step:  717\n",
      "Loss: 965.0637512487128\n",
      "Training step:  718\n",
      "Loss: 965.0072308151285\n",
      "Training step:  719\n",
      "Loss: 965.013604141329\n",
      "Training step:  720\n",
      "Loss: 964.9599101640163\n",
      "Training step:  721\n",
      "Loss: 964.9635652287698\n",
      "Training step:  722\n",
      "Loss: 964.9078234750127\n",
      "Training step:  723\n",
      "Loss: 964.9135769543941\n",
      "Training step:  724\n",
      "Loss: 964.8573307962852\n",
      "Training step:  725\n",
      "Loss: 964.8636591257675\n",
      "Training step:  726\n",
      "Loss: 964.806921716966\n",
      "Training step:  727\n",
      "Loss: 964.8138224801512\n",
      "Training step:  728\n",
      "Loss: 964.7598779531291\n",
      "Training step:  729\n",
      "Loss: 964.7640924281669\n",
      "Training step:  730\n",
      "Loss: 964.7087278188045\n",
      "Training step:  731\n",
      "Loss: 964.7143975080661\n",
      "Training step:  732\n",
      "Loss: 964.6583934656218\n",
      "Training step:  733\n",
      "Loss: 964.6647894967396\n",
      "Training step:  734\n",
      "Loss: 964.6082994281616\n",
      "Training step:  735\n",
      "Loss: 964.6152615916801\n",
      "Training step:  736\n",
      "Loss: 964.561543085883\n",
      "Training step:  737\n",
      "Loss: 964.565337026405\n",
      "Training step:  738\n",
      "Loss: 964.510214289519\n",
      "Training step:  739\n",
      "Loss: 964.5159583469649\n",
      "Training step:  740\n",
      "Loss: 964.4601962795805\n",
      "Training step:  741\n",
      "Loss: 964.4666585681384\n",
      "Training step:  742\n",
      "Loss: 964.4134847035749\n",
      "Training step:  743\n",
      "Loss: 964.4174730029193\n",
      "Training step:  744\n",
      "Loss: 964.362897615526\n",
      "Training step:  745\n",
      "Loss: 964.3683126232557\n",
      "Training step:  746\n",
      "Loss: 964.313111928327\n",
      "Training step:  747\n",
      "Loss: 964.3192397252794\n",
      "Training step:  748\n",
      "Loss: 964.2635632337701\n",
      "Training step:  749\n",
      "Loss: 964.270246860347\n",
      "Training step:  750\n",
      "Loss: 964.2139435335142\n",
      "Training step:  751\n",
      "Loss: 964.2213341208953\n",
      "Training step:  752\n",
      "Loss: 964.1677230853437\n",
      "Training step:  753\n",
      "Loss: 964.1725225457348\n",
      "Training step:  754\n",
      "Loss: 964.1175441869234\n",
      "Training step:  755\n",
      "Loss: 964.1237488672392\n",
      "Training step:  756\n",
      "Loss: 964.0681531824036\n",
      "Training step:  757\n",
      "Loss: 964.0750596719104\n",
      "Training step:  758\n",
      "Loss: 964.0189952638814\n",
      "Training step:  759\n",
      "Loss: 964.0264488912946\n",
      "Training step:  760\n",
      "Loss: 963.9730568411069\n",
      "Training step:  761\n",
      "Loss: 963.9779504331881\n",
      "Training step:  762\n",
      "Loss: 963.9226164712196\n",
      "Training step:  763\n",
      "Loss: 963.9294885857478\n",
      "Training step:  764\n",
      "Loss: 963.873685693539\n",
      "Training step:  765\n",
      "Loss: 963.8801150486663\n",
      "Training step:  766\n",
      "Loss: 963.8246931742934\n",
      "Training step:  767\n",
      "Loss: 963.8318003333884\n",
      "Training step:  768\n",
      "Loss: 963.7757691736147\n",
      "Training step:  769\n",
      "Loss: 963.7835651929419\n",
      "Training step:  770\n",
      "Loss: 963.7300180667497\n",
      "Training step:  771\n",
      "Loss: 963.735441015611\n",
      "Training step:  772\n",
      "Loss: 963.6799840099592\n",
      "Training step:  773\n",
      "Loss: 963.6833764930599\n",
      "Training step:  774\n",
      "Loss: 963.6299854247316\n",
      "Training step:  775\n",
      "Loss: 963.6353918125735\n",
      "Training step:  776\n",
      "Loss: 963.5808275101718\n",
      "Training step:  777\n",
      "Loss: 963.5874469108852\n",
      "Training step:  778\n",
      "Loss: 963.5324249272982\n",
      "Training step:  779\n",
      "Loss: 963.5395771033343\n",
      "Training step:  780\n",
      "Loss: 963.4871429171551\n",
      "Training step:  781\n",
      "Loss: 963.4918118135704\n",
      "Training step:  782\n",
      "Loss: 963.4380577947818\n",
      "Training step:  783\n",
      "Loss: 963.4440768546206\n",
      "Training step:  784\n",
      "Loss: 963.3897310942284\n",
      "Training step:  785\n",
      "Loss: 963.3964254471861\n",
      "Training step:  786\n",
      "Loss: 963.3416305961016\n",
      "Training step:  787\n",
      "Loss: 963.3488518016673\n",
      "Training step:  788\n",
      "Loss: 963.2964760746299\n",
      "Training step:  789\n",
      "Loss: 963.3013889015484\n",
      "Training step:  790\n",
      "Loss: 963.2477015498039\n",
      "Training step:  791\n",
      "Loss: 963.2539487775116\n",
      "Training step:  792\n",
      "Loss: 963.1996783683276\n",
      "Training step:  793\n",
      "Loss: 963.2056471382979\n",
      "Training step:  794\n",
      "Loss: 963.1510874017857\n",
      "Training step:  795\n",
      "Loss: 963.1583686093259\n",
      "Training step:  796\n",
      "Loss: 963.1032226538662\n",
      "Training step:  797\n",
      "Loss: 963.1111661017181\n",
      "Training step:  798\n",
      "Loss: 963.0585372912082\n",
      "Training step:  799\n",
      "Loss: 963.0640629871531\n",
      "Training step:  800\n",
      "Loss: 963.0096084422488\n",
      "Training step:  801\n",
      "Loss: 963.0160703557297\n",
      "Training step:  802\n",
      "Loss: 962.9619712718575\n",
      "Training step:  803\n",
      "Loss: 962.9690790674313\n",
      "Training step:  804\n",
      "Loss: 962.9144020799149\n",
      "Training step:  805\n",
      "Loss: 962.9221650187671\n",
      "Training step:  806\n",
      "Loss: 962.867053491281\n",
      "Training step:  807\n",
      "Loss: 962.8753274150404\n",
      "Training step:  808\n",
      "Loss: 962.8225540001727\n",
      "Training step:  809\n",
      "Loss: 962.8285868893662\n",
      "Training step:  810\n",
      "Loss: 962.774018817364\n",
      "Training step:  811\n",
      "Loss: 962.7809712617541\n",
      "Training step:  812\n",
      "Loss: 962.7267525154934\n",
      "Training step:  813\n",
      "Loss: 962.7343438989367\n",
      "Training step:  814\n",
      "Loss: 962.679556414116\n",
      "Training step:  815\n",
      "Loss: 962.6869613255874\n",
      "Training step:  816\n",
      "Loss: 962.6324361752063\n",
      "Training step:  817\n",
      "Loss: 962.6404813677316\n",
      "Training step:  818\n",
      "Loss: 962.5855285905424\n",
      "Training step:  819\n",
      "Loss: 962.593245178345\n",
      "Training step:  820\n",
      "Loss: 962.5385540040097\n",
      "Training step:  821\n",
      "Loss: 962.5460843550509\n",
      "Training step:  822\n",
      "Loss: 962.4917905716854\n",
      "Training step:  823\n",
      "Loss: 962.4998196180699\n",
      "Training step:  824\n",
      "Loss: 962.4449654938525\n",
      "Training step:  825\n",
      "Loss: 962.4488161077907\n",
      "Training step:  826\n",
      "Loss: 962.3971081796601\n",
      "Training step:  827\n",
      "Loss: 962.4026327385143\n",
      "Training step:  828\n",
      "Loss: 962.3492473405632\n",
      "Training step:  829\n",
      "Loss: 962.3565688212431\n",
      "Training step:  830\n",
      "Loss: 962.3027675982707\n",
      "Training step:  831\n",
      "Loss: 962.309771738779\n",
      "Training step:  832\n",
      "Loss: 962.2556079758792\n",
      "Training step:  833\n",
      "Loss: 962.2591087225882\n",
      "Training step:  834\n",
      "Loss: 962.2080612654449\n",
      "Training step:  835\n",
      "Loss: 962.2132132899575\n",
      "Training step:  836\n",
      "Loss: 962.1610153338883\n",
      "Training step:  837\n",
      "Loss: 962.1674161133993\n",
      "Training step:  838\n",
      "Loss: 962.1140633370602\n",
      "Training step:  839\n",
      "Loss: 962.1209043549533\n",
      "Training step:  840\n",
      "Loss: 962.0673279977964\n",
      "Training step:  841\n",
      "Loss: 962.071419262649\n",
      "Training step:  842\n",
      "Loss: 962.0200559825607\n",
      "Training step:  843\n",
      "Loss: 962.0258258564863\n",
      "Training step:  844\n",
      "Loss: 961.9734446145333\n",
      "Training step:  845\n",
      "Loss: 961.9794393168426\n",
      "Training step:  846\n",
      "Loss: 961.9267915338362\n",
      "Training step:  847\n",
      "Loss: 961.9340036543707\n",
      "Training step:  848\n",
      "Loss: 961.8802191588815\n",
      "Training step:  849\n",
      "Loss: 961.8829753019278\n",
      "Training step:  850\n",
      "Loss: 961.833273550198\n",
      "Training step:  851\n",
      "Loss: 961.8376216245753\n",
      "Training step:  852\n",
      "Loss: 961.7868001018339\n",
      "Training step:  853\n",
      "Loss: 961.7923698242502\n",
      "Training step:  854\n",
      "Loss: 961.7404192124054\n",
      "Training step:  855\n",
      "Loss: 961.7472052783183\n",
      "Training step:  856\n",
      "Loss: 961.6941306823152\n",
      "Training step:  857\n",
      "Loss: 961.6973377896121\n",
      "Training step:  858\n",
      "Loss: 961.6474522697077\n",
      "Training step:  859\n",
      "Loss: 961.6522808441032\n",
      "Training step:  860\n",
      "Loss: 961.6014044608994\n",
      "Training step:  861\n",
      "Loss: 961.6073094654655\n",
      "Training step:  862\n",
      "Loss: 961.5554454293629\n",
      "Training step:  863\n",
      "Loss: 961.5616464057747\n",
      "Training step:  864\n",
      "Loss: 961.5095658582387\n",
      "Training step:  865\n",
      "Loss: 961.5131071203544\n",
      "Training step:  866\n",
      "Loss: 961.4631648525166\n",
      "Training step:  867\n",
      "Loss: 961.4683378543435\n",
      "Training step:  868\n",
      "Loss: 961.4174082281284\n",
      "Training step:  869\n",
      "Loss: 961.4227999331217\n",
      "Training step:  870\n",
      "Loss: 961.3716114517866\n",
      "Training step:  871\n",
      "Loss: 961.3774156517285\n",
      "Training step:  872\n",
      "Loss: 961.3258857130098\n",
      "Training step:  873\n",
      "Loss: 961.3282181278897\n",
      "Training step:  874\n",
      "Loss: 961.2798020716931\n",
      "Training step:  875\n",
      "Loss: 961.2836965335908\n",
      "Training step:  876\n",
      "Loss: 961.2341839227141\n",
      "Training step:  877\n",
      "Loss: 961.239259410564\n",
      "Training step:  878\n",
      "Loss: 961.1887818976861\n",
      "Training step:  879\n",
      "Loss: 961.1949061035067\n",
      "Training step:  880\n",
      "Loss: 961.143467191969\n",
      "Training step:  881\n",
      "Loss: 961.1452200869708\n",
      "Training step:  882\n",
      "Loss: 961.0976817366342\n",
      "Training step:  883\n",
      "Loss: 961.1009552769789\n",
      "Training step:  884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 961.0523374750908\n",
      "Training step:  885\n",
      "Loss: 961.0567794990578\n",
      "Training step:  886\n",
      "Loss: 961.0070830772303\n",
      "Training step:  887\n",
      "Loss: 961.0126885110599\n",
      "Training step:  888\n",
      "Loss: 960.9619183499118\n",
      "Training step:  889\n",
      "Loss: 960.9633432315566\n",
      "Training step:  890\n",
      "Loss: 960.9164259294206\n",
      "Training step:  891\n",
      "Loss: 960.9193419848077\n",
      "Training step:  892\n",
      "Loss: 960.871358218928\n",
      "Training step:  893\n",
      "Loss: 960.8754299859885\n",
      "Training step:  894\n",
      "Loss: 960.8263797137176\n",
      "Training step:  895\n",
      "Loss: 960.8316021745654\n",
      "Training step:  896\n",
      "Loss: 960.7816125370805\n",
      "Training step:  897\n",
      "Loss: 960.783365506918\n",
      "Training step:  898\n",
      "Loss: 960.7363840961228\n",
      "Training step:  899\n",
      "Loss: 960.739647556555\n",
      "Training step:  900\n",
      "Loss: 960.6916015597012\n",
      "Training step:  901\n",
      "Loss: 960.696007052962\n",
      "Training step:  902\n",
      "Loss: 960.6470280271997\n",
      "Training step:  903\n",
      "Loss: 960.6516444628605\n",
      "Training step:  904\n",
      "Loss: 960.6024186816868\n",
      "Training step:  905\n",
      "Loss: 960.6046535460908\n",
      "Training step:  906\n",
      "Loss: 960.5579034208237\n",
      "Training step:  907\n",
      "Loss: 960.5611975733036\n",
      "Training step:  908\n",
      "Loss: 960.513401626037\n",
      "Training step:  909\n",
      "Loss: 960.5178247461457\n",
      "Training step:  910\n",
      "Loss: 960.4689877098618\n",
      "Training step:  911\n",
      "Loss: 960.4710643265545\n",
      "Training step:  912\n",
      "Loss: 960.424219169528\n",
      "Training step:  913\n",
      "Loss: 960.4278151284557\n",
      "Training step:  914\n",
      "Loss: 960.3800474782081\n",
      "Training step:  915\n",
      "Loss: 960.3846416538184\n",
      "Training step:  916\n",
      "Loss: 960.335960311689\n",
      "Training step:  917\n",
      "Loss: 960.3373451798875\n",
      "Training step:  918\n",
      "Loss: 960.2914190375702\n",
      "Training step:  919\n",
      "Loss: 960.2942772704931\n",
      "Training step:  920\n",
      "Loss: 960.2473229452603\n",
      "Training step:  921\n",
      "Loss: 960.251291524944\n",
      "Training step:  922\n",
      "Loss: 960.2033137693005\n",
      "Training step:  923\n",
      "Loss: 960.2049874791662\n",
      "Training step:  924\n",
      "Loss: 960.159418918854\n",
      "Training step:  925\n",
      "Loss: 960.1621144560087\n",
      "Training step:  926\n",
      "Loss: 960.1155266368532\n",
      "Training step:  927\n",
      "Loss: 960.1193232544086\n",
      "Training step:  928\n",
      "Loss: 960.0718368141987\n",
      "Training step:  929\n",
      "Loss: 960.0759100419175\n",
      "Training step:  930\n",
      "Loss: 960.0282235958988\n",
      "Training step:  931\n",
      "Loss: 960.0298957337633\n",
      "Training step:  932\n",
      "Loss: 959.9841436451283\n",
      "Training step:  933\n",
      "Loss: 959.9872964574979\n",
      "Training step:  934\n",
      "Loss: 959.940646490241\n",
      "Training step:  935\n",
      "Loss: 959.9440053507692\n",
      "Training step:  936\n",
      "Loss: 959.897117541557\n",
      "Training step:  937\n",
      "Loss: 959.9015491959993\n",
      "Training step:  938\n",
      "Loss: 959.8536625780812\n",
      "Training step:  939\n",
      "Loss: 959.8549199715686\n",
      "Training step:  940\n",
      "Loss: 959.8098564883774\n",
      "Training step:  941\n",
      "Loss: 959.8125706590897\n",
      "Training step:  942\n",
      "Loss: 959.7665078359555\n",
      "Training step:  943\n",
      "Loss: 959.7702980836592\n",
      "Training step:  944\n",
      "Loss: 959.7233571181405\n",
      "Training step:  945\n",
      "Loss: 959.7240707874469\n",
      "Training step:  946\n",
      "Loss: 959.67977277134\n",
      "Training step:  947\n",
      "Loss: 959.6819030692477\n",
      "Training step:  948\n",
      "Loss: 959.636616324401\n",
      "Training step:  949\n",
      "Loss: 959.6398143408406\n",
      "Training step:  950\n",
      "Loss: 959.5935445821578\n",
      "Training step:  951\n",
      "Loss: 959.5971261425079\n",
      "Training step:  952\n",
      "Loss: 959.5506612135136\n",
      "Training step:  953\n",
      "Loss: 959.5512022468763\n",
      "Training step:  954\n",
      "Loss: 959.5073466812423\n",
      "Training step:  955\n",
      "Loss: 959.5092871456204\n",
      "Training step:  956\n",
      "Loss: 959.4644555506342\n",
      "Training step:  957\n",
      "Loss: 959.4674518395394\n",
      "Training step:  958\n",
      "Loss: 959.4216485031611\n",
      "Training step:  959\n",
      "Loss: 959.4224698326775\n",
      "Training step:  960\n",
      "Loss: 959.3789484172906\n",
      "Training step:  961\n",
      "Loss: 959.3807446267627\n",
      "Training step:  962\n",
      "Loss: 959.3362554481837\n",
      "Training step:  963\n",
      "Loss: 959.3390986544719\n",
      "Training step:  964\n",
      "Loss: 959.29375640505\n",
      "Training step:  965\n",
      "Loss: 959.2968654986861\n",
      "Training step:  966\n",
      "Loss: 959.2513319365851\n",
      "Training step:  967\n",
      "Loss: 959.2521645484882\n",
      "Training step:  968\n",
      "Loss: 959.2084625123356\n",
      "Training step:  969\n",
      "Loss: 959.2107052584288\n",
      "Training step:  970\n",
      "Loss: 959.1661510116128\n",
      "Training step:  971\n",
      "Loss: 959.1693170482021\n",
      "Training step:  972\n",
      "Loss: 959.1239198587335\n",
      "Training step:  973\n",
      "Loss: 959.1233004385776\n",
      "Training step:  974\n",
      "Loss: 959.0807378777314\n",
      "Training step:  975\n",
      "Loss: 959.0820044706211\n",
      "Training step:  976\n",
      "Loss: 959.0384981814417\n",
      "Training step:  977\n",
      "Loss: 959.0407917377746\n",
      "Training step:  978\n",
      "Loss: 958.9963410416265\n",
      "Training step:  979\n",
      "Loss: 958.9996570996564\n",
      "Training step:  980\n",
      "Loss: 958.9543741028144\n",
      "Training step:  981\n",
      "Loss: 958.9539262342649\n",
      "Training step:  982\n",
      "Loss: 958.9114452787801\n",
      "Training step:  983\n",
      "Loss: 958.912884721584\n",
      "Training step:  984\n",
      "Loss: 958.8694704700156\n",
      "Training step:  985\n",
      "Loss: 958.8719249132353\n",
      "Training step:  986\n",
      "Loss: 958.8275776058607\n",
      "Training step:  987\n",
      "Loss: 958.8279369791037\n",
      "Training step:  988\n",
      "Loss: 958.7852287868948\n",
      "Training step:  989\n",
      "Loss: 958.7870942078289\n",
      "Training step:  990\n",
      "Loss: 958.7434570197537\n",
      "Training step:  991\n",
      "Loss: 958.7463281131201\n",
      "Training step:  992\n",
      "Loss: 958.7018725412034\n",
      "Training step:  993\n",
      "Loss: 958.7010580233465\n",
      "Training step:  994\n",
      "Loss: 958.6585060725577\n",
      "Training step:  995\n",
      "Loss: 958.6603985114061\n",
      "Training step:  996\n",
      "Loss: 958.6169290807607\n",
      "Training step:  997\n",
      "Loss: 958.6173821937164\n",
      "Training step:  998\n",
      "Loss: 958.5748986844001\n",
      "Training step:  999\n",
      "Loss: 958.5768490087818\n",
      "Training step:  1000\n",
      "Loss: 958.5334516544707\n",
      "Training step:  1001\n",
      "Loss: 958.53336075594\n",
      "Training step:  1002\n",
      "Loss: 958.4903397492357\n",
      "Training step:  1003\n",
      "Loss: 958.4929805277233\n",
      "Training step:  1004\n",
      "Loss: 958.4491337866531\n",
      "Training step:  1005\n",
      "Loss: 958.4481495887206\n",
      "Training step:  1006\n",
      "Loss: 958.4061708780733\n",
      "Training step:  1007\n",
      "Loss: 958.407852161013\n",
      "Training step:  1008\n",
      "Loss: 958.3649750220221\n",
      "Training step:  1009\n",
      "Loss: 958.3652450111042\n",
      "Training step:  1010\n",
      "Loss: 958.323330949699\n",
      "Training step:  1011\n",
      "Loss: 958.3250708698791\n",
      "Training step:  1012\n",
      "Loss: 958.2823662255024\n",
      "Training step:  1013\n",
      "Loss: 958.2820022328726\n",
      "Training step:  1014\n",
      "Loss: 958.2400397043731\n",
      "Training step:  1015\n",
      "Loss: 958.2419503168177\n",
      "Training step:  1016\n",
      "Loss: 958.1992050232803\n",
      "Training step:  1017\n",
      "Loss: 958.1990107086185\n",
      "Training step:  1018\n",
      "Loss: 958.1570055796572\n",
      "Training step:  1019\n",
      "Loss: 958.1590857622043\n",
      "Training step:  1020\n",
      "Loss: 958.1163005137038\n",
      "Training step:  1021\n",
      "Loss: 958.1148570863185\n",
      "Training step:  1022\n",
      "Loss: 958.0738664918738\n",
      "Training step:  1023\n",
      "Loss: 958.0750129225735\n",
      "Training step:  1024\n",
      "Loss: 958.0326509269601\n",
      "Training step:  1025\n",
      "Loss: 958.031572253432\n",
      "Training step:  1026\n",
      "Loss: 957.9907211655909\n",
      "Training step:  1027\n",
      "Loss: 957.9918532455396\n",
      "Training step:  1028\n",
      "Loss: 957.9496347334111\n",
      "Training step:  1029\n",
      "Loss: 957.9485504479362\n",
      "Training step:  1030\n",
      "Loss: 957.9074539311073\n",
      "Training step:  1031\n",
      "Loss: 957.9089678117214\n",
      "Training step:  1032\n",
      "Loss: 957.8666014687374\n",
      "Training step:  1033\n",
      "Loss: 957.8651553599894\n",
      "Training step:  1034\n",
      "Loss: 957.8245558784864\n",
      "Training step:  1035\n",
      "Loss: 957.825677307085\n",
      "Training step:  1036\n",
      "Loss: 957.783822909635\n",
      "Training step:  1037\n",
      "Loss: 957.7826484652271\n",
      "Training step:  1038\n",
      "Loss: 957.7422731846983\n",
      "Training step:  1039\n",
      "Loss: 957.7432813391848\n",
      "Training step:  1040\n",
      "Loss: 957.7016655029778\n",
      "Training step:  1041\n",
      "Loss: 957.700391613086\n",
      "Training step:  1042\n",
      "Loss: 957.6602433318687\n",
      "Training step:  1043\n",
      "Loss: 957.6611396797529\n",
      "Training step:  1044\n",
      "Loss: 957.6196623786797\n",
      "Training step:  1045\n",
      "Loss: 957.6177679627996\n",
      "Training step:  1046\n",
      "Loss: 957.5780096056624\n",
      "Training step:  1047\n",
      "Loss: 957.5786231124301\n",
      "Training step:  1048\n",
      "Loss: 957.5367742556401\n",
      "Training step:  1049\n",
      "Loss: 957.53536892575\n",
      "Training step:  1050\n",
      "Loss: 957.4952380688945\n",
      "Training step:  1051\n",
      "Loss: 957.496366429652\n",
      "Training step:  1052\n",
      "Loss: 957.4550131829255\n",
      "Training step:  1053\n",
      "Loss: 957.4538699112123\n",
      "Training step:  1054\n",
      "Loss: 957.4139580014586\n",
      "Training step:  1055\n",
      "Loss: 957.4149775489693\n",
      "Training step:  1056\n",
      "Loss: 957.3737602220084\n",
      "Training step:  1057\n",
      "Loss: 957.372615032311\n",
      "Training step:  1058\n",
      "Loss: 957.3328298036241\n",
      "Training step:  1059\n",
      "Loss: 957.3338397069867\n",
      "Training step:  1060\n",
      "Loss: 957.292853117791\n",
      "Training step:  1061\n",
      "Loss: 957.2916136076377\n",
      "Training step:  1062\n",
      "Loss: 957.252048239806\n",
      "Training step:  1063\n",
      "Loss: 957.252951851002\n",
      "Training step:  1064\n",
      "Loss: 957.2114384796325\n",
      "Training step:  1065\n",
      "Loss: 957.2090945181726\n",
      "Training step:  1066\n",
      "Loss: 957.1704251036996\n",
      "Training step:  1067\n",
      "Loss: 957.1705120181699\n",
      "Training step:  1068\n",
      "Loss: 957.1298181055374\n",
      "Training step:  1069\n",
      "Loss: 957.1274131961696\n",
      "Training step:  1070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 957.0889402511083\n",
      "Training step:  1071\n",
      "Loss: 957.0889494122205\n",
      "Training step:  1072\n",
      "Loss: 957.0485475820645\n",
      "Training step:  1073\n",
      "Loss: 957.0465254468846\n",
      "Training step:  1074\n",
      "Loss: 957.0077814110496\n",
      "Training step:  1075\n",
      "Loss: 957.0081965222693\n",
      "Training step:  1076\n",
      "Loss: 956.9674398563064\n",
      "Training step:  1077\n",
      "Loss: 956.9647757489902\n",
      "Training step:  1078\n",
      "Loss: 956.9268230924729\n",
      "Training step:  1079\n",
      "Loss: 956.9265337517853\n",
      "Training step:  1080\n",
      "Loss: 956.8865808930799\n",
      "Training step:  1081\n",
      "Loss: 956.8849631466987\n",
      "Training step:  1082\n",
      "Loss: 956.8463944306543\n",
      "Training step:  1083\n",
      "Loss: 956.8468602997777\n",
      "Training step:  1084\n",
      "Loss: 956.8063996963506\n",
      "Training step:  1085\n",
      "Loss: 956.8042861030914\n",
      "Training step:  1086\n",
      "Loss: 956.7663448260131\n",
      "Training step:  1087\n",
      "Loss: 956.7662779070047\n",
      "Training step:  1088\n",
      "Loss: 956.7263645356517\n",
      "Training step:  1089\n",
      "Loss: 956.7238597162466\n",
      "Training step:  1090\n",
      "Loss: 956.6864502419287\n",
      "Training step:  1091\n",
      "Loss: 956.6859490177494\n",
      "Training step:  1092\n",
      "Loss: 956.6465784671283\n",
      "Training step:  1093\n",
      "Loss: 956.6447727247347\n",
      "Training step:  1094\n",
      "Loss: 956.6067612920272\n",
      "Training step:  1095\n",
      "Loss: 956.604898763709\n",
      "Training step:  1096\n",
      "Loss: 956.567002694589\n",
      "Training step:  1097\n",
      "Loss: 956.5671828463128\n",
      "Training step:  1098\n",
      "Loss: 956.5274317285597\n",
      "Training step:  1099\n",
      "Loss: 956.5245302676485\n",
      "Training step:  1100\n",
      "Loss: 956.4874859966133\n",
      "Training step:  1101\n",
      "Loss: 956.4868957528392\n",
      "Training step:  1102\n",
      "Loss: 956.4479223107804\n",
      "Training step:  1103\n",
      "Loss: 956.4449688225577\n",
      "Training step:  1104\n",
      "Loss: 956.4081082833413\n",
      "Training step:  1105\n",
      "Loss: 956.4074501686705\n",
      "Training step:  1106\n",
      "Loss: 956.3687496942999\n",
      "Training step:  1107\n",
      "Loss: 956.366164043526\n",
      "Training step:  1108\n",
      "Loss: 956.3293761963656\n",
      "Training step:  1109\n",
      "Loss: 956.3287577034743\n",
      "Training step:  1110\n",
      "Loss: 956.2900601852559\n",
      "Training step:  1111\n",
      "Loss: 956.287092968133\n",
      "Training step:  1112\n",
      "Loss: 956.2504827630605\n",
      "Training step:  1113\n",
      "Loss: 956.2497982367041\n",
      "Training step:  1114\n",
      "Loss: 956.211370375379\n",
      "Training step:  1115\n",
      "Loss: 956.2082737732143\n",
      "Training step:  1116\n",
      "Loss: 956.1722542936291\n",
      "Training step:  1117\n",
      "Loss: 956.1710670219578\n",
      "Training step:  1118\n",
      "Loss: 956.1332458486341\n",
      "Training step:  1119\n",
      "Loss: 956.1312366364172\n",
      "Training step:  1120\n",
      "Loss: 956.0942102638841\n",
      "Training step:  1121\n",
      "Loss: 956.0921511038819\n",
      "Training step:  1122\n",
      "Loss: 956.0552351576106\n",
      "Training step:  1123\n",
      "Loss: 956.0531268756055\n",
      "Training step:  1124\n",
      "Loss: 956.01632093923\n",
      "Training step:  1125\n",
      "Loss: 956.0141638502274\n",
      "Training step:  1126\n",
      "Loss: 955.9775533283228\n",
      "Training step:  1127\n",
      "Loss: 955.9772643400236\n",
      "Training step:  1128\n",
      "Loss: 955.938878332957\n",
      "Training step:  1129\n",
      "Loss: 955.9356435814318\n",
      "Training step:  1130\n",
      "Loss: 955.8998452166147\n",
      "Training step:  1131\n",
      "Loss: 955.8988240498228\n",
      "Training step:  1132\n",
      "Loss: 955.8612650297463\n",
      "Training step:  1133\n",
      "Loss: 955.8589258718335\n",
      "Training step:  1134\n",
      "Loss: 955.8226455711387\n",
      "Training step:  1135\n",
      "Loss: 955.8202601505204\n",
      "Training step:  1136\n",
      "Loss: 955.7840874051817\n",
      "Training step:  1137\n",
      "Loss: 955.7836296088157\n",
      "Training step:  1138\n",
      "Loss: 955.7457085521537\n",
      "Training step:  1139\n",
      "Loss: 955.7423502124151\n",
      "Training step:  1140\n",
      "Loss: 955.7069745105842\n",
      "Training step:  1141\n",
      "Loss: 955.705796903637\n",
      "Training step:  1142\n",
      "Loss: 955.6686050299313\n",
      "Training step:  1143\n",
      "Loss: 955.6662090049416\n",
      "Training step:  1144\n",
      "Loss: 955.6302771990913\n",
      "Training step:  1145\n",
      "Loss: 955.627838942472\n",
      "Training step:  1146\n",
      "Loss: 955.5920129371358\n",
      "Training step:  1147\n",
      "Loss: 955.5895290006831\n",
      "Training step:  1148\n",
      "Loss: 955.5538083998262\n",
      "Training step:  1149\n",
      "Loss: 955.5532197324105\n",
      "Training step:  1150\n",
      "Loss: 955.5157810171246\n",
      "Training step:  1151\n",
      "Loss: 955.5123412475288\n",
      "Training step:  1152\n",
      "Loss: 955.4772573932065\n",
      "Training step:  1153\n",
      "Loss: 955.4758555887536\n",
      "Training step:  1154\n",
      "Loss: 955.4392844289978\n",
      "Training step:  1155\n",
      "Loss: 955.4356451230766\n",
      "Training step:  1156\n",
      "Loss: 955.4010234752822\n",
      "Training step:  1157\n",
      "Loss: 955.3995229923519\n",
      "Training step:  1158\n",
      "Loss: 955.3631204460441\n",
      "Training step:  1159\n",
      "Loss: 955.3604303072042\n",
      "Training step:  1160\n",
      "Loss: 955.3252575286688\n",
      "Training step:  1161\n",
      "Loss: 955.3225277903115\n",
      "Training step:  1162\n",
      "Loss: 955.2874577621828\n",
      "Training step:  1163\n",
      "Loss: 955.2846846219118\n",
      "Training step:  1164\n",
      "Loss: 955.2497169613399\n",
      "Training step:  1165\n",
      "Loss: 955.2487966803002\n",
      "Training step:  1166\n",
      "Loss: 955.2121498746766\n",
      "Training step:  1167\n",
      "Loss: 955.2084428856581\n",
      "Training step:  1168\n",
      "Loss: 955.1742425562406\n",
      "Training step:  1169\n",
      "Loss: 955.1726360021626\n",
      "Training step:  1170\n",
      "Loss: 955.136768208972\n",
      "Training step:  1171\n",
      "Loss: 955.1339109238853\n",
      "Training step:  1172\n",
      "Loss: 955.0992506842072\n",
      "Training step:  1173\n",
      "Loss: 955.0963565771413\n",
      "Training step:  1174\n",
      "Loss: 955.0617969392204\n",
      "Training step:  1175\n",
      "Loss: 955.0588610046013\n",
      "Training step:  1176\n",
      "Loss: 955.0244015950157\n",
      "Training step:  1177\n",
      "Loss: 955.0232855206502\n",
      "Training step:  1178\n",
      "Loss: 954.9871768567997\n",
      "Training step:  1179\n",
      "Loss: 954.9830572758252\n",
      "Training step:  1180\n",
      "Loss: 954.9496376459886\n",
      "Training step:  1181\n",
      "Loss: 954.9475517323598\n",
      "Training step:  1182\n",
      "Loss: 954.9124910623939\n",
      "Training step:  1183\n",
      "Loss: 954.9091996665705\n",
      "Training step:  1184\n",
      "Loss: 954.8753252133357\n",
      "Training step:  1185\n",
      "Loss: 954.8738225009166\n",
      "Training step:  1186\n",
      "Loss: 954.8383175193335\n",
      "Training step:  1187\n",
      "Loss: 954.8341316532113\n",
      "Training step:  1188\n",
      "Loss: 954.8009998218672\n",
      "Training step:  1189\n",
      "Loss: 954.7988346513579\n",
      "Training step:  1190\n",
      "Loss: 954.7640838171519\n",
      "Training step:  1191\n",
      "Loss: 954.7607215048707\n",
      "Training step:  1192\n",
      "Loss: 954.7271414508882\n",
      "Training step:  1193\n",
      "Loss: 954.7255536485563\n",
      "Training step:  1194\n",
      "Loss: 954.6903633468821\n",
      "Training step:  1195\n",
      "Loss: 954.6866023135607\n",
      "Training step:  1196\n",
      "Loss: 954.6535471736802\n",
      "Training step:  1197\n",
      "Loss: 954.6515235117548\n",
      "Training step:  1198\n",
      "Loss: 954.6167902791501\n",
      "Training step:  1199\n",
      "Loss: 954.6136415362303\n",
      "Training step:  1200\n",
      "Loss: 954.5800658528245\n",
      "Training step:  1201\n",
      "Loss: 954.5768846571136\n",
      "Training step:  1202\n",
      "Loss: 954.5434048561642\n",
      "Training step:  1203\n",
      "Loss: 954.5401852388997\n",
      "Training step:  1204\n",
      "Loss: 954.5068009679642\n",
      "Training step:  1205\n",
      "Loss: 954.5035431872055\n",
      "Training step:  1206\n",
      "Loss: 954.4702540953211\n",
      "Training step:  1207\n",
      "Loss: 954.466958407814\n",
      "Training step:  1208\n",
      "Loss: 954.4335494558062\n",
      "Training step:  1209\n",
      "Loss: 954.4304339127401\n",
      "Training step:  1210\n",
      "Loss: 954.3971906738681\n",
      "Training step:  1211\n",
      "Loss: 954.3939615652605\n",
      "Training step:  1212\n",
      "Loss: 954.3608886084515\n",
      "Training step:  1213\n",
      "Loss: 954.3593084518749\n",
      "Training step:  1214\n",
      "Loss: 954.3246709209343\n",
      "Training step:  1215\n",
      "Loss: 954.3197752124313\n",
      "Training step:  1216\n",
      "Loss: 954.2881728482951\n",
      "Training step:  1217\n",
      "Loss: 954.2851669093532\n",
      "Training step:  1218\n",
      "Loss: 954.2519411180552\n",
      "Training step:  1219\n",
      "Loss: 954.2478953339017\n",
      "Training step:  1220\n",
      "Loss: 954.2157916410858\n",
      "Training step:  1221\n",
      "Loss: 954.2134216567565\n",
      "Training step:  1222\n",
      "Loss: 954.1797721474351\n",
      "Training step:  1223\n",
      "Loss: 954.1757789361046\n",
      "Training step:  1224\n",
      "Loss: 954.1433153203152\n",
      "Training step:  1225\n",
      "Loss: 954.1414517114208\n",
      "Training step:  1226\n",
      "Loss: 954.1074182767662\n",
      "Training step:  1227\n",
      "Loss: 954.1030300481248\n",
      "Training step:  1228\n",
      "Loss: 954.0712333980956\n",
      "Training step:  1229\n",
      "Loss: 954.0687503492506\n",
      "Training step:  1230\n",
      "Loss: 954.0353516351885\n",
      "Training step:  1231\n",
      "Loss: 954.0318130963016\n",
      "Training step:  1232\n",
      "Loss: 953.999517235078\n",
      "Training step:  1233\n",
      "Loss: 953.9976585469828\n",
      "Training step:  1234\n",
      "Loss: 953.9638445027362\n",
      "Training step:  1235\n",
      "Loss: 953.9587836112554\n",
      "Training step:  1236\n",
      "Loss: 953.9279180343132\n",
      "Training step:  1237\n",
      "Loss: 953.9246780496446\n",
      "Training step:  1238\n",
      "Loss: 953.8922324526088\n",
      "Training step:  1239\n",
      "Loss: 953.8884066682165\n",
      "Training step:  1240\n",
      "Loss: 953.856622190931\n",
      "Training step:  1241\n",
      "Loss: 953.8544449917679\n",
      "Training step:  1242\n",
      "Loss: 953.8211603695637\n",
      "Training step:  1243\n",
      "Loss: 953.8169710659828\n",
      "Training step:  1244\n",
      "Loss: 953.7856729733776\n",
      "Training step:  1245\n",
      "Loss: 953.783096046393\n",
      "Training step:  1246\n",
      "Loss: 953.7502344062123\n",
      "Training step:  1247\n",
      "Loss: 953.7466168589191\n",
      "Training step:  1248\n",
      "Loss: 953.7148318351587\n",
      "Training step:  1249\n",
      "Loss: 953.71118782016\n",
      "Training step:  1250\n",
      "Loss: 953.6794911505808\n",
      "Training step:  1251\n",
      "Loss: 953.6758140621082\n",
      "Training step:  1252\n",
      "Loss: 953.6442054273647\n",
      "Training step:  1253\n",
      "Loss: 953.6421589351834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1254\n",
      "Loss: 953.6090754529469\n",
      "Training step:  1255\n",
      "Loss: 953.6039124203884\n",
      "Training step:  1256\n",
      "Loss: 953.5736862002768\n",
      "Training step:  1257\n",
      "Loss: 953.5703012361846\n",
      "Training step:  1258\n",
      "Loss: 953.5385460737807\n",
      "Training step:  1259\n",
      "Loss: 953.534180524074\n",
      "Training step:  1260\n",
      "Loss: 953.5032127793427\n",
      "Training step:  1261\n",
      "Loss: 953.50071284203\n",
      "Training step:  1262\n",
      "Loss: 953.4682830770554\n",
      "Training step:  1263\n",
      "Loss: 953.464237475676\n",
      "Training step:  1264\n",
      "Loss: 953.4333208473548\n",
      "Training step:  1265\n",
      "Loss: 953.4308710409473\n",
      "Training step:  1266\n",
      "Loss: 953.3985065442486\n",
      "Training step:  1267\n",
      "Loss: 953.3941063416105\n",
      "Training step:  1268\n",
      "Loss: 953.3633908172566\n",
      "Training step:  1269\n",
      "Loss: 953.3608358089492\n",
      "Training step:  1270\n",
      "Loss: 953.3286778469335\n",
      "Training step:  1271\n",
      "Loss: 953.3241929202511\n",
      "Training step:  1272\n",
      "Loss: 953.2939400745021\n",
      "Training step:  1273\n",
      "Loss: 953.2910052597443\n",
      "Training step:  1274\n",
      "Loss: 953.2593209444366\n",
      "Training step:  1275\n",
      "Loss: 953.2553203425224\n",
      "Training step:  1276\n",
      "Loss: 953.224667621897\n",
      "Training step:  1277\n",
      "Loss: 953.2206415489262\n",
      "Training step:  1278\n",
      "Loss: 953.1900728897582\n",
      "Training step:  1279\n",
      "Loss: 953.1860168076726\n",
      "Training step:  1280\n",
      "Loss: 953.1555319087502\n",
      "Training step:  1281\n",
      "Loss: 953.153042055677\n",
      "Training step:  1282\n",
      "Loss: 953.1211421601546\n",
      "Training step:  1283\n",
      "Loss: 953.1156693722716\n",
      "Training step:  1284\n",
      "Loss: 953.0865087571823\n",
      "Training step:  1285\n",
      "Loss: 953.082738747622\n",
      "Training step:  1286\n",
      "Loss: 953.0521109417906\n",
      "Training step:  1287\n",
      "Loss: 953.0477938066545\n",
      "Training step:  1288\n",
      "Loss: 953.0177804800692\n",
      "Training step:  1289\n",
      "Loss: 953.0150058470615\n",
      "Training step:  1290\n",
      "Loss: 952.9835943464958\n",
      "Training step:  1291\n",
      "Loss: 952.978944249089\n",
      "Training step:  1292\n",
      "Loss: 952.9491233994496\n",
      "Training step:  1293\n",
      "Loss: 952.9462502787626\n",
      "Training step:  1294\n",
      "Loss: 952.9150368713085\n",
      "Training step:  1295\n",
      "Loss: 952.909890572865\n",
      "Training step:  1296\n",
      "Loss: 952.8806957512553\n",
      "Training step:  1297\n",
      "Loss: 952.8772714802503\n",
      "Training step:  1298\n",
      "Loss: 952.8466282766537\n",
      "Training step:  1299\n",
      "Loss: 952.8422554263267\n",
      "Training step:  1300\n",
      "Loss: 952.8126071207705\n",
      "Training step:  1301\n",
      "Loss: 952.8097558012706\n",
      "Training step:  1302\n",
      "Loss: 952.7787334641789\n",
      "Training step:  1303\n",
      "Loss: 952.7740354608287\n",
      "Training step:  1304\n",
      "Loss: 952.7448293703831\n",
      "Training step:  1305\n",
      "Loss: 952.7416195039292\n",
      "Training step:  1306\n",
      "Loss: 952.7110475722196\n",
      "Training step:  1307\n",
      "Loss: 952.7068161887529\n",
      "Training step:  1308\n",
      "Loss: 952.6772276589212\n",
      "Training step:  1309\n",
      "Loss: 952.6729758560768\n",
      "Training step:  1310\n",
      "Loss: 952.6434670178545\n",
      "Training step:  1311\n",
      "Loss: 952.6391882064539\n",
      "Training step:  1312\n",
      "Loss: 952.609758777677\n",
      "Training step:  1313\n",
      "Loss: 952.6054531540548\n",
      "Training step:  1314\n",
      "Loss: 952.5761028537231\n",
      "Training step:  1315\n",
      "Loss: 952.5717706132091\n",
      "Training step:  1316\n",
      "Loss: 952.542499161485\n",
      "Training step:  1317\n",
      "Loss: 952.5396537530688\n",
      "Training step:  1318\n",
      "Loss: 952.5090395359861\n",
      "Training step:  1319\n",
      "Loss: 952.5033618230635\n",
      "Training step:  1320\n",
      "Loss: 952.475342490874\n",
      "Training step:  1321\n",
      "Loss: 952.4712876435864\n",
      "Training step:  1322\n",
      "Loss: 952.4418787575271\n",
      "Training step:  1323\n",
      "Loss: 952.4369343614862\n",
      "Training step:  1324\n",
      "Loss: 952.4082381306441\n",
      "Training step:  1325\n",
      "Loss: 952.4049953871643\n",
      "Training step:  1326\n",
      "Loss: 952.3749699318769\n",
      "Training step:  1327\n",
      "Loss: 952.3703206253051\n",
      "Training step:  1328\n",
      "Loss: 952.3414275052247\n",
      "Training step:  1329\n",
      "Loss: 952.3369984333056\n",
      "Training step:  1330\n",
      "Loss: 952.3081784284421\n",
      "Training step:  1331\n",
      "Loss: 952.3037241650372\n",
      "Training step:  1332\n",
      "Loss: 952.2750441472343\n",
      "Training step:  1333\n",
      "Loss: 952.271979510708\n",
      "Training step:  1334\n",
      "Loss: 952.2419883167393\n",
      "Training step:  1335\n",
      "Loss: 952.2361624448541\n",
      "Training step:  1336\n",
      "Loss: 952.2087092553443\n",
      "Training step:  1337\n",
      "Loss: 952.2044655435425\n",
      "Training step:  1338\n",
      "Loss: 952.1756500746519\n",
      "Training step:  1339\n",
      "Loss: 952.1705390394703\n",
      "Training step:  1340\n",
      "Loss: 952.142659603439\n",
      "Training step:  1341\n",
      "Loss: 952.1389614505579\n",
      "Training step:  1342\n",
      "Loss: 952.1097865130932\n",
      "Training step:  1343\n",
      "Loss: 952.105127705947\n",
      "Training step:  1344\n",
      "Loss: 952.0768841067724\n",
      "Training step:  1345\n",
      "Loss: 952.0722064408175\n",
      "Training step:  1346\n",
      "Loss: 952.044037655348\n",
      "Training step:  1347\n",
      "Loss: 952.0393363615144\n",
      "Training step:  1348\n",
      "Loss: 952.0112421278371\n",
      "Training step:  1349\n",
      "Loss: 952.0065173849056\n",
      "Training step:  1350\n",
      "Loss: 951.978497442149\n",
      "Training step:  1351\n",
      "Loss: 951.9751865472938\n",
      "Training step:  1352\n",
      "Loss: 951.9458895166758\n",
      "Training step:  1353\n",
      "Loss: 951.9398969193284\n",
      "Training step:  1354\n",
      "Loss: 951.9130661503242\n",
      "Training step:  1355\n",
      "Loss: 951.9086094572507\n",
      "Training step:  1356\n",
      "Loss: 951.8804565420392\n",
      "Training step:  1357\n",
      "Loss: 951.8751589662003\n",
      "Training step:  1358\n",
      "Loss: 951.8476831905825\n",
      "Training step:  1359\n",
      "Loss: 951.8440025150445\n",
      "Training step:  1360\n",
      "Loss: 951.81526214409\n",
      "Training step:  1361\n",
      "Loss: 951.8102517309433\n",
      "Training step:  1362\n",
      "Loss: 951.7825873328653\n",
      "Training step:  1363\n",
      "Loss: 951.7777839638393\n",
      "Training step:  1364\n",
      "Loss: 951.7501880371119\n",
      "Training step:  1365\n",
      "Loss: 951.7453625179563\n",
      "Training step:  1366\n",
      "Loss: 951.7178992394063\n",
      "Training step:  1367\n",
      "Loss: 951.7143954252641\n",
      "Training step:  1368\n",
      "Loss: 951.6856849513912\n",
      "Training step:  1369\n",
      "Loss: 951.6805075874064\n",
      "Training step:  1370\n",
      "Loss: 951.6534425797413\n",
      "Training step:  1371\n",
      "Loss: 951.6496206451782\n",
      "Training step:  1372\n",
      "Loss: 951.621316181103\n",
      "Training step:  1373\n",
      "Loss: 951.6165674164054\n",
      "Training step:  1374\n",
      "Loss: 951.5891535864989\n",
      "Training step:  1375\n",
      "Loss: 951.5839291057456\n",
      "Training step:  1376\n",
      "Loss: 951.5570526009103\n",
      "Training step:  1377\n",
      "Loss: 951.5531780982567\n",
      "Training step:  1378\n",
      "Loss: 951.5250729716555\n",
      "Training step:  1379\n",
      "Loss: 951.5202797356482\n",
      "Training step:  1380\n",
      "Loss: 951.4930573133764\n",
      "Training step:  1381\n",
      "Loss: 951.4877929020436\n",
      "Training step:  1382\n",
      "Loss: 951.4608776591027\n",
      "Training step:  1383\n",
      "Loss: 951.4571862233925\n",
      "Training step:  1384\n",
      "Loss: 951.4290502779173\n",
      "Training step:  1385\n",
      "Loss: 951.4233617899927\n",
      "Training step:  1386\n",
      "Loss: 951.3966768469697\n",
      "Training step:  1387\n",
      "Loss: 951.3928411240472\n",
      "Training step:  1388\n",
      "Loss: 951.3649434389419\n",
      "Training step:  1389\n",
      "Loss: 951.3598257815673\n",
      "Training step:  1390\n",
      "Loss: 951.3331798703365\n",
      "Training step:  1391\n",
      "Loss: 951.328041033765\n",
      "Training step:  1392\n",
      "Loss: 951.3012436700449\n",
      "Training step:  1393\n",
      "Loss: 951.2958576399687\n",
      "Training step:  1394\n",
      "Loss: 951.2692685365255\n",
      "Training step:  1395\n",
      "Loss: 951.2641723180889\n",
      "Training step:  1396\n",
      "Loss: 951.2376505117037\n",
      "Training step:  1397\n",
      "Loss: 951.2338769145681\n",
      "Training step:  1398\n",
      "Loss: 951.2061621242046\n",
      "Training step:  1399\n",
      "Loss: 951.1998878484936\n",
      "Training step:  1400\n",
      "Loss: 951.1723218575588\n",
      "Training step:  1401\n",
      "Loss: 951.1669106176399\n",
      "Training step:  1402\n",
      "Loss: 951.1405444836457\n",
      "Training step:  1403\n",
      "Loss: 951.1354159133925\n",
      "Training step:  1404\n",
      "Loss: 951.1091167434837\n",
      "Training step:  1405\n",
      "Loss: 951.103969179894\n",
      "Training step:  1406\n",
      "Loss: 951.0777376417251\n",
      "Training step:  1407\n",
      "Loss: 951.0725712384655\n",
      "Training step:  1408\n",
      "Loss: 951.0461023809395\n",
      "Training step:  1409\n",
      "Loss: 951.0404534982964\n",
      "Training step:  1410\n",
      "Loss: 951.014516874025\n",
      "Training step:  1411\n",
      "Loss: 951.0104591527498\n",
      "Training step:  1412\n",
      "Loss: 950.9833569274277\n",
      "Training step:  1413\n",
      "Loss: 950.9784191534076\n",
      "Training step:  1414\n",
      "Loss: 950.9522125907912\n",
      "Training step:  1415\n",
      "Loss: 950.9467737677354\n",
      "Training step:  1416\n",
      "Loss: 950.9205570129319\n",
      "Training step:  1417\n",
      "Loss: 950.9151797610676\n",
      "Training step:  1418\n",
      "Loss: 950.8892159366341\n",
      "Training step:  1419\n",
      "Loss: 950.8836322326185\n",
      "Training step:  1420\n",
      "Loss: 950.8560879447766\n",
      "Training step:  1421\n",
      "Loss: 950.8488286827034\n",
      "Training step:  1422\n",
      "Loss: 950.8228577610857\n",
      "Training step:  1423\n",
      "Loss: 950.8173385330962\n",
      "Training step:  1424\n",
      "Loss: 950.7916009599859\n",
      "Training step:  1425\n",
      "Loss: 950.7859323127005\n",
      "Training step:  1426\n",
      "Loss: 950.7603927452438\n",
      "Training step:  1427\n",
      "Loss: 950.7545754255226\n",
      "Training step:  1428\n",
      "Loss: 950.727275240141\n",
      "Training step:  1429\n",
      "Loss: 950.7214280084796\n",
      "Training step:  1430\n",
      "Loss: 950.6961648409026\n",
      "Training step:  1431\n",
      "Loss: 950.6905909892246\n",
      "Training step:  1432\n",
      "Loss: 950.6650990134389\n",
      "Training step:  1433\n",
      "Loss: 950.659376208119\n",
      "Training step:  1434\n",
      "Loss: 950.6340797650704\n",
      "Training step:  1435\n",
      "Loss: 950.6282104413714\n",
      "Training step:  1436\n",
      "Loss: 950.6011667483165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1437\n",
      "Loss: 950.5952696918445\n",
      "Training step:  1438\n",
      "Loss: 950.5685080404421\n",
      "Training step:  1439\n",
      "Loss: 950.5627175254392\n",
      "Training step:  1440\n",
      "Loss: 950.5376274488021\n",
      "Training step:  1441\n",
      "Loss: 950.5316928824315\n",
      "Training step:  1442\n",
      "Loss: 950.5048741374949\n",
      "Training step:  1443\n",
      "Loss: 950.4989151827095\n",
      "Training step:  1444\n",
      "Loss: 950.4723753178214\n",
      "Training step:  1445\n",
      "Loss: 950.4665205705888\n",
      "Training step:  1446\n",
      "Loss: 950.4416345899754\n",
      "Training step:  1447\n",
      "Loss: 950.4356363989231\n",
      "Training step:  1448\n",
      "Loss: 950.4092308254174\n",
      "Training step:  1449\n",
      "Loss: 950.4033448595148\n",
      "Training step:  1450\n",
      "Loss: 950.3785841270201\n",
      "Training step:  1451\n",
      "Loss: 950.3725548895488\n",
      "Training step:  1452\n",
      "Loss: 950.3460922106038\n",
      "Training step:  1453\n",
      "Loss: 950.3400417643976\n",
      "Training step:  1454\n",
      "Loss: 950.3138540802004\n",
      "Training step:  1455\n",
      "Loss: 950.3084130243587\n",
      "Training step:  1456\n",
      "Loss: 950.2836578194119\n",
      "Training step:  1457\n",
      "Loss: 950.2777624023548\n",
      "Training step:  1458\n",
      "Loss: 950.2531942963358\n",
      "Training step:  1459\n",
      "Loss: 950.2471586767857\n",
      "Training step:  1460\n",
      "Loss: 950.2209093005215\n",
      "Training step:  1461\n",
      "Loss: 950.2148521491833\n",
      "Training step:  1462\n",
      "Loss: 950.1887745427139\n",
      "Training step:  1463\n",
      "Loss: 950.1834353803574\n",
      "Training step:  1464\n",
      "Loss: 950.1584754969016\n",
      "Training step:  1465\n",
      "Loss: 950.1523284658556\n",
      "Training step:  1466\n",
      "Loss: 950.1265177744642\n",
      "Training step:  1467\n",
      "Loss: 950.1209822889891\n",
      "Training step:  1468\n",
      "Loss: 950.096317430742\n",
      "Training step:  1469\n",
      "Loss: 950.0899773018475\n",
      "Training step:  1470\n",
      "Loss: 950.0642665491104\n",
      "Training step:  1471\n",
      "Loss: 950.0587283420712\n",
      "Training step:  1472\n",
      "Loss: 950.0341575732979\n",
      "Training step:  1473\n",
      "Loss: 950.0278192944143\n",
      "Training step:  1474\n",
      "Loss: 950.0023890343147\n",
      "Training step:  1475\n",
      "Loss: 949.9966580001018\n",
      "Training step:  1476\n",
      "Loss: 949.9723780752064\n",
      "Training step:  1477\n",
      "Loss: 949.9664694757489\n",
      "Training step:  1478\n",
      "Loss: 949.9407775943945\n",
      "Training step:  1479\n",
      "Loss: 949.9354121105399\n",
      "Training step:  1480\n",
      "Loss: 949.9108409702969\n",
      "Training step:  1481\n",
      "Loss: 949.9046865251283\n",
      "Training step:  1482\n",
      "Loss: 949.8792754062953\n",
      "Training step:  1483\n",
      "Loss: 949.873719442784\n",
      "Training step:  1484\n",
      "Loss: 949.849436169711\n",
      "Training step:  1485\n",
      "Loss: 949.8430943990592\n",
      "Training step:  1486\n",
      "Loss: 949.8177805598676\n",
      "Training step:  1487\n",
      "Loss: 949.8119077420101\n",
      "Training step:  1488\n",
      "Loss: 949.7863773575186\n",
      "Training step:  1489\n",
      "Loss: 949.7806067345833\n",
      "Training step:  1490\n",
      "Loss: 949.7566314365267\n",
      "Training step:  1491\n",
      "Loss: 949.7501249904673\n",
      "Training step:  1492\n",
      "Loss: 949.7251195844901\n",
      "Training step:  1493\n",
      "Loss: 949.7196738485746\n",
      "Training step:  1494\n",
      "Loss: 949.6954982815644\n",
      "Training step:  1495\n",
      "Loss: 949.6892784680734\n",
      "Training step:  1496\n",
      "Loss: 949.6642701222929\n",
      "Training step:  1497\n",
      "Loss: 949.6586065714296\n",
      "Training step:  1498\n",
      "Loss: 949.6331146895504\n",
      "Training step:  1499\n",
      "Loss: 949.6261477539672\n",
      "Training step:  1500\n",
      "Loss: 949.6018560014219\n",
      "Training step:  1501\n",
      "Loss: 949.5958593212646\n",
      "Training step:  1502\n",
      "Loss: 949.5707869366452\n",
      "Training step:  1503\n",
      "Loss: 949.5648989904175\n",
      "Training step:  1504\n",
      "Loss: 949.5397804488149\n",
      "Training step:  1505\n",
      "Loss: 949.5336349282493\n",
      "Training step:  1506\n",
      "Loss: 949.5088245702319\n",
      "Training step:  1507\n",
      "Loss: 949.503516468857\n",
      "Training step:  1508\n",
      "Loss: 949.4797587632203\n",
      "Training step:  1509\n",
      "Loss: 949.4734393292292\n",
      "Training step:  1510\n",
      "Loss: 949.4486977223456\n",
      "Training step:  1511\n",
      "Loss: 949.4434113308147\n",
      "Training step:  1512\n",
      "Loss: 949.4194586163534\n",
      "Training step:  1513\n",
      "Loss: 949.4134189729856\n",
      "Training step:  1514\n",
      "Loss: 949.3886758733146\n",
      "Training step:  1515\n",
      "Loss: 949.3828525483867\n",
      "Training step:  1516\n",
      "Loss: 949.3580008446729\n",
      "Training step:  1517\n",
      "Loss: 949.3518787919417\n",
      "Training step:  1518\n",
      "Loss: 949.3273295141423\n",
      "Training step:  1519\n",
      "Loss: 949.3216741437578\n",
      "Training step:  1520\n",
      "Loss: 949.2982274124662\n",
      "Training step:  1521\n",
      "Loss: 949.2918738098882\n",
      "Training step:  1522\n",
      "Loss: 949.2676255288095\n",
      "Training step:  1523\n",
      "Loss: 949.2621083398114\n",
      "Training step:  1524\n",
      "Loss: 949.238653940785\n",
      "Training step:  1525\n",
      "Loss: 949.232397570401\n",
      "Training step:  1526\n",
      "Loss: 949.2079781377391\n",
      "Training step:  1527\n",
      "Loss: 949.2020797963595\n",
      "Training step:  1528\n",
      "Loss: 949.17753801017\n",
      "Training step:  1529\n",
      "Loss: 949.171392109543\n",
      "Training step:  1530\n",
      "Loss: 949.1471476245812\n",
      "Training step:  1531\n",
      "Loss: 949.1414601740457\n",
      "Training step:  1532\n",
      "Loss: 949.1183055361325\n",
      "Training step:  1533\n",
      "Loss: 949.1119338424678\n",
      "Training step:  1534\n",
      "Loss: 949.0878158058849\n",
      "Training step:  1535\n",
      "Loss: 949.081800756446\n",
      "Training step:  1536\n",
      "Loss: 949.0575621098908\n",
      "Training step:  1537\n",
      "Loss: 949.0517456886486\n",
      "Training step:  1538\n",
      "Loss: 949.0273573755488\n",
      "Training step:  1539\n",
      "Loss: 949.0201336347316\n",
      "Training step:  1540\n",
      "Loss: 948.9970679865233\n",
      "Training step:  1541\n",
      "Loss: 948.9907431880553\n",
      "Training step:  1542\n",
      "Loss: 948.966939758844\n",
      "Training step:  1543\n",
      "Loss: 948.9610811892421\n",
      "Training step:  1544\n",
      "Loss: 948.9369180848332\n",
      "Training step:  1545\n",
      "Loss: 948.9300325334426\n",
      "Training step:  1546\n",
      "Loss: 948.9067495602195\n",
      "Training step:  1547\n",
      "Loss: 948.9007907557126\n",
      "Training step:  1548\n",
      "Loss: 948.8767749815362\n",
      "Training step:  1549\n",
      "Loss: 948.8707918413469\n",
      "Training step:  1550\n",
      "Loss: 948.8468480570365\n",
      "Training step:  1551\n",
      "Loss: 948.8408395192348\n",
      "Training step:  1552\n",
      "Loss: 948.8169674631505\n",
      "Training step:  1553\n",
      "Loss: 948.8109337137723\n",
      "Training step:  1554\n",
      "Loss: 948.7871331253674\n",
      "Training step:  1555\n",
      "Loss: 948.7810743495277\n",
      "Training step:  1556\n",
      "Loss: 948.7573449693145\n",
      "Training step:  1557\n",
      "Loss: 948.751261351206\n",
      "Training step:  1558\n",
      "Loss: 948.7276029207452\n",
      "Training step:  1559\n",
      "Loss: 948.7219628696057\n",
      "Training step:  1560\n",
      "Loss: 948.699348522332\n",
      "Training step:  1561\n",
      "Loss: 948.693056158\n",
      "Training step:  1562\n",
      "Loss: 948.6696812812594\n",
      "Training step:  1563\n",
      "Loss: 948.6638419140364\n",
      "Training step:  1564\n",
      "Loss: 948.6401181512147\n",
      "Training step:  1565\n",
      "Loss: 948.6310880992434\n",
      "Training step:  1566\n",
      "Loss: 948.6106262789267\n",
      "Training step:  1567\n",
      "Loss: 948.6030428379238\n",
      "Training step:  1568\n",
      "Loss: 948.5808741273344\n",
      "Training step:  1569\n",
      "Loss: 948.5742540133616\n",
      "Training step:  1570\n",
      "Loss: 948.5513766677427\n",
      "Training step:  1571\n",
      "Loss: 948.5455372725571\n",
      "Training step:  1572\n",
      "Loss: 948.5219934976492\n",
      "Training step:  1573\n",
      "Loss: 948.5134861753226\n",
      "Training step:  1574\n",
      "Loss: 948.4925994524599\n",
      "Training step:  1575\n",
      "Loss: 948.4851132877304\n",
      "Training step:  1576\n",
      "Loss: 948.4630486521772\n",
      "Training step:  1577\n",
      "Loss: 948.4565039868253\n",
      "Training step:  1578\n",
      "Loss: 948.433733948861\n",
      "Training step:  1579\n",
      "Loss: 948.4276853630929\n",
      "Training step:  1580\n",
      "Loss: 948.4044868375629\n",
      "Training step:  1581\n",
      "Loss: 948.3966935532794\n",
      "Training step:  1582\n",
      "Loss: 948.3752036144133\n",
      "Training step:  1583\n",
      "Loss: 948.3681939425028\n",
      "Training step:  1584\n",
      "Loss: 948.3460063686779\n",
      "Training step:  1585\n",
      "Loss: 948.3397623490947\n",
      "Training step:  1586\n",
      "Loss: 948.3169218219673\n",
      "Training step:  1587\n",
      "Loss: 948.3108020213165\n",
      "Training step:  1588\n",
      "Loss: 948.2878515408559\n",
      "Training step:  1589\n",
      "Loss: 948.2817080756868\n",
      "Training step:  1590\n",
      "Loss: 948.2588251459434\n",
      "Training step:  1591\n",
      "Loss: 948.2526592565389\n",
      "Training step:  1592\n",
      "Loss: 948.2298436349917\n",
      "Training step:  1593\n",
      "Loss: 948.2236554908849\n",
      "Training step:  1594\n",
      "Loss: 948.2009069359907\n",
      "Training step:  1595\n",
      "Loss: 948.1951406624371\n",
      "Training step:  1596\n",
      "Loss: 948.1720187214968\n",
      "Training step:  1597\n",
      "Loss: 948.1632077272152\n",
      "Training step:  1598\n",
      "Loss: 948.1432021391311\n",
      "Training step:  1599\n",
      "Loss: 948.1358320571289\n",
      "Training step:  1600\n",
      "Loss: 948.1141992501816\n",
      "Training step:  1601\n",
      "Loss: 948.1077351283707\n",
      "Training step:  1602\n",
      "Loss: 948.0854212162387\n",
      "Training step:  1603\n",
      "Loss: 948.0793866344053\n",
      "Training step:  1604\n",
      "Loss: 948.0567033747444\n",
      "Training step:  1605\n",
      "Loss: 948.0481677268923\n",
      "Training step:  1606\n",
      "Loss: 948.028022188984\n",
      "Training step:  1607\n",
      "Loss: 948.0204605417332\n",
      "Training step:  1608\n",
      "Loss: 947.9993385206417\n",
      "Training step:  1609\n",
      "Loss: 947.9925176432305\n",
      "Training step:  1610\n",
      "Loss: 947.9707248099758\n",
      "Training step:  1611\n",
      "Loss: 947.9646410799577\n",
      "Training step:  1612\n",
      "Loss: 947.942180487356\n",
      "Training step:  1613\n",
      "Loss: 947.933829916975\n",
      "Training step:  1614\n",
      "Loss: 947.9136486976656\n",
      "Training step:  1615\n",
      "Loss: 947.9059808522089\n",
      "Training step:  1616\n",
      "Loss: 947.8851370762558\n",
      "Training step:  1617\n",
      "Loss: 947.8782012758946\n",
      "Training step:  1618\n",
      "Loss: 947.8566944579604\n",
      "Training step:  1619\n",
      "Loss: 947.8504875069193\n",
      "Training step:  1620\n",
      "Loss: 947.8283601058461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1621\n",
      "Loss: 947.8204725623824\n",
      "Training step:  1622\n",
      "Loss: 947.7999568059721\n",
      "Training step:  1623\n",
      "Loss: 947.7928107588998\n",
      "Training step:  1624\n",
      "Loss: 947.7716351633726\n",
      "Training step:  1625\n",
      "Loss: 947.7652119894443\n",
      "Training step:  1626\n",
      "Loss: 947.7434208673253\n",
      "Training step:  1627\n",
      "Loss: 947.7371186372457\n",
      "Training step:  1628\n",
      "Loss: 947.7152237782183\n",
      "Training step:  1629\n",
      "Loss: 947.7072983875305\n",
      "Training step:  1630\n",
      "Loss: 947.6869955565863\n",
      "Training step:  1631\n",
      "Loss: 947.6797984154825\n",
      "Training step:  1632\n",
      "Loss: 947.6588441796549\n",
      "Training step:  1633\n",
      "Loss: 947.6523616883533\n",
      "Training step:  1634\n",
      "Loss: 947.6307606620892\n",
      "Training step:  1635\n",
      "Loss: 947.6246880459172\n",
      "Training step:  1636\n",
      "Loss: 947.6027729719617\n",
      "Training step:  1637\n",
      "Loss: 947.594468524878\n",
      "Training step:  1638\n",
      "Loss: 947.5747550872328\n",
      "Training step:  1639\n",
      "Loss: 947.5671153668425\n",
      "Training step:  1640\n",
      "Loss: 947.5467605048568\n",
      "Training step:  1641\n",
      "Loss: 947.5398278885099\n",
      "Training step:  1642\n",
      "Loss: 947.5188332488607\n",
      "Training step:  1643\n",
      "Loss: 947.5126046500891\n",
      "Training step:  1644\n",
      "Loss: 947.4909731459528\n",
      "Training step:  1645\n",
      "Loss: 947.4829296781826\n",
      "Training step:  1646\n",
      "Loss: 947.463097799543\n",
      "Training step:  1647\n",
      "Loss: 947.4557501590668\n",
      "Training step:  1648\n",
      "Loss: 947.4352831054715\n",
      "Training step:  1649\n",
      "Loss: 947.4286340275484\n",
      "Training step:  1650\n",
      "Loss: 947.4075351749786\n",
      "Training step:  1651\n",
      "Loss: 947.4015816093379\n",
      "Training step:  1652\n",
      "Loss: 947.3798910118816\n",
      "Training step:  1653\n",
      "Loss: 947.3710998603402\n",
      "Training step:  1654\n",
      "Loss: 947.3522827942842\n",
      "Training step:  1655\n",
      "Loss: 947.3448191190587\n",
      "Training step:  1656\n",
      "Loss: 947.3246388132226\n",
      "Training step:  1657\n",
      "Loss: 947.3178614279034\n",
      "Training step:  1658\n",
      "Loss: 947.29705662367\n",
      "Training step:  1659\n",
      "Loss: 947.290966944859\n",
      "Training step:  1660\n",
      "Loss: 947.2695775877597\n",
      "Training step:  1661\n",
      "Loss: 947.2615369465427\n",
      "Training step:  1662\n",
      "Loss: 947.2421742755391\n",
      "Training step:  1663\n",
      "Loss: 947.2346764247532\n",
      "Training step:  1664\n",
      "Loss: 947.214693772623\n",
      "Training step:  1665\n",
      "Loss: 947.2078787656185\n",
      "Training step:  1666\n",
      "Loss: 947.1872789542665\n",
      "Training step:  1667\n",
      "Loss: 947.1811438104414\n",
      "Training step:  1668\n",
      "Loss: 947.1598913120391\n",
      "Training step:  1669\n",
      "Loss: 947.1517079017831\n",
      "Training step:  1670\n",
      "Loss: 947.1325414223563\n",
      "Training step:  1671\n",
      "Loss: 947.1250013000367\n",
      "Training step:  1672\n",
      "Loss: 947.1052224150965\n",
      "Training step:  1673\n",
      "Loss: 947.0983573687507\n",
      "Training step:  1674\n",
      "Loss: 947.0779685662176\n",
      "Training step:  1675\n",
      "Loss: 947.071775649522\n",
      "Training step:  1676\n",
      "Loss: 947.0508158154623\n",
      "Training step:  1677\n",
      "Loss: 947.0430646310859\n",
      "Training step:  1678\n",
      "Loss: 947.0237239459157\n",
      "Training step:  1679\n",
      "Loss: 947.0165282410654\n",
      "Training step:  1680\n",
      "Loss: 946.9965825878693\n",
      "Training step:  1681\n",
      "Loss: 946.9900537072705\n",
      "Training step:  1682\n",
      "Loss: 946.9695058419029\n",
      "Training step:  1683\n",
      "Loss: 946.9633602616559\n",
      "Training step:  1684\n",
      "Loss: 946.9425200282574\n",
      "Training step:  1685\n",
      "Loss: 946.9348281844889\n",
      "Training step:  1686\n",
      "Loss: 946.9155881160339\n",
      "Training step:  1687\n",
      "Loss: 946.9084511816548\n",
      "Training step:  1688\n",
      "Loss: 946.8886133879404\n",
      "Training step:  1689\n",
      "Loss: 946.8821355401942\n",
      "Training step:  1690\n",
      "Loss: 946.861702744804\n",
      "Training step:  1691\n",
      "Loss: 946.8556033258772\n",
      "Training step:  1692\n",
      "Loss: 946.8348816025391\n",
      "Training step:  1693\n",
      "Loss: 946.8267204585842\n",
      "Training step:  1694\n",
      "Loss: 946.8080213762884\n",
      "Training step:  1695\n",
      "Loss: 946.8004834301889\n",
      "Training step:  1696\n",
      "Loss: 946.7811973730642\n",
      "Training step:  1697\n",
      "Loss: 946.774311547714\n",
      "Training step:  1698\n",
      "Loss: 946.7544369538856\n",
      "Training step:  1699\n",
      "Loss: 946.7482004037373\n",
      "Training step:  1700\n",
      "Loss: 946.7277399566113\n",
      "Training step:  1701\n",
      "Loss: 946.7200314603522\n",
      "Training step:  1702\n",
      "Loss: 946.7010016581067\n",
      "Training step:  1703\n",
      "Loss: 946.6939715201032\n",
      "Training step:  1704\n",
      "Loss: 946.6743565496075\n",
      "Training step:  1705\n",
      "Loss: 946.6679703043199\n",
      "Training step:  1706\n",
      "Loss: 946.6478086520389\n",
      "Training step:  1707\n",
      "Loss: 946.6400863145282\n",
      "Training step:  1708\n",
      "Loss: 946.6211943414158\n",
      "Training step:  1709\n",
      "Loss: 946.6141414592241\n",
      "Training step:  1710\n",
      "Loss: 946.5946696272505\n",
      "Training step:  1711\n",
      "Loss: 946.5882551225095\n",
      "Training step:  1712\n",
      "Loss: 946.5682418018997\n",
      "Training step:  1713\n",
      "Loss: 946.5607128493646\n",
      "Training step:  1714\n",
      "Loss: 946.5418646999537\n",
      "Training step:  1715\n",
      "Loss: 946.5348843753176\n",
      "Training step:  1716\n",
      "Loss: 946.5154631232238\n",
      "Training step:  1717\n",
      "Loss: 946.5091155673407\n",
      "Training step:  1718\n",
      "Loss: 946.489157632231\n",
      "Training step:  1719\n",
      "Loss: 946.481493593958\n",
      "Training step:  1720\n",
      "Loss: 946.462781638225\n",
      "Training step:  1721\n",
      "Loss: 946.4557797603594\n",
      "Training step:  1722\n",
      "Loss: 946.4364993563344\n",
      "Training step:  1723\n",
      "Loss: 946.4301248262678\n",
      "Training step:  1724\n",
      "Loss: 946.4102789773906\n",
      "Training step:  1725\n",
      "Loss: 946.4025024104324\n",
      "Training step:  1726\n",
      "Loss: 946.3841639950662\n",
      "Training step:  1727\n",
      "Loss: 946.3767692389202\n",
      "Training step:  1728\n",
      "Loss: 946.3580153356422\n",
      "Training step:  1729\n",
      "Loss: 946.3512212216857\n",
      "Training step:  1730\n",
      "Loss: 946.3319062976738\n",
      "Training step:  1731\n",
      "Loss: 946.3254715387158\n",
      "Training step:  1732\n",
      "Loss: 946.3057836544374\n",
      "Training step:  1733\n",
      "Loss: 946.2980295737246\n",
      "Training step:  1734\n",
      "Loss: 946.2796928095686\n",
      "Training step:  1735\n",
      "Loss: 946.272581117969\n",
      "Training step:  1736\n",
      "Loss: 946.2536855558449\n",
      "Training step:  1737\n",
      "Loss: 946.2471888372754\n",
      "Training step:  1738\n",
      "Loss: 946.2277719515586\n",
      "Training step:  1739\n",
      "Loss: 946.2213799040958\n",
      "Training step:  1740\n",
      "Loss: 946.2018755878089\n",
      "Training step:  1741\n",
      "Loss: 946.1941009614383\n",
      "Training step:  1742\n",
      "Loss: 946.1759446422343\n",
      "Training step:  1743\n",
      "Loss: 946.1688017662688\n",
      "Training step:  1744\n",
      "Loss: 946.1500937770597\n",
      "Training step:  1745\n",
      "Loss: 946.1435588690251\n",
      "Training step:  1746\n",
      "Loss: 946.1243360450829\n",
      "Training step:  1747\n",
      "Loss: 946.1181179990493\n",
      "Training step:  1748\n",
      "Loss: 946.0986293376473\n",
      "Training step:  1749\n",
      "Loss: 946.0903468968982\n",
      "Training step:  1750\n",
      "Loss: 946.0729080390844\n",
      "Training step:  1751\n",
      "Loss: 946.0651758636709\n",
      "Training step:  1752\n",
      "Loss: 946.0471951299766\n",
      "Training step:  1753\n",
      "Loss: 946.0400648274493\n",
      "Training step:  1754\n",
      "Loss: 946.0215423048161\n",
      "Training step:  1755\n",
      "Loss: 946.0150112511794\n",
      "Training step:  1756\n",
      "Loss: 945.9959494118245\n",
      "Training step:  1757\n",
      "Loss: 945.9884034294959\n",
      "Training step:  1758\n",
      "Loss: 945.970432880872\n",
      "Training step:  1759\n",
      "Loss: 945.9634074181379\n",
      "Training step:  1760\n",
      "Loss: 945.9449000498486\n",
      "Training step:  1761\n",
      "Loss: 945.9384685215668\n",
      "Training step:  1762\n",
      "Loss: 945.9194586147835\n",
      "Training step:  1763\n",
      "Loss: 945.911665850505\n",
      "Training step:  1764\n",
      "Loss: 945.893960902702\n",
      "Training step:  1765\n",
      "Loss: 945.8867767160164\n",
      "Training step:  1766\n",
      "Loss: 945.8685373331683\n",
      "Training step:  1767\n",
      "Loss: 945.861942202078\n",
      "Training step:  1768\n",
      "Loss: 945.843204387268\n",
      "Training step:  1769\n",
      "Loss: 945.8367114749113\n",
      "Training step:  1770\n",
      "Loss: 945.8178897354294\n",
      "Training step:  1771\n",
      "Loss: 945.8103926549021\n",
      "Training step:  1772\n",
      "Loss: 945.7926397771827\n",
      "Training step:  1773\n",
      "Loss: 945.7856567025391\n",
      "Training step:  1774\n",
      "Loss: 945.7673781451269\n",
      "Training step:  1775\n",
      "Loss: 945.7609770773674\n",
      "Training step:  1776\n",
      "Loss: 945.7421752406367\n",
      "Training step:  1777\n",
      "Loss: 945.7344660220097\n",
      "Training step:  1778\n",
      "Loss: 945.7169416098466\n",
      "Training step:  1779\n",
      "Loss: 945.7098360226663\n",
      "Training step:  1780\n",
      "Loss: 945.6917891105187\n",
      "Training step:  1781\n",
      "Loss: 945.6852607016527\n",
      "Training step:  1782\n",
      "Loss: 945.66672557261\n",
      "Training step:  1783\n",
      "Loss: 945.659008356088\n",
      "Training step:  1784\n",
      "Loss: 945.6416069035208\n",
      "Training step:  1785\n",
      "Loss: 945.6344872708332\n",
      "Training step:  1786\n",
      "Loss: 945.6165680539295\n",
      "Training step:  1787\n",
      "Loss: 945.6100206527495\n",
      "Training step:  1788\n",
      "Loss: 945.5916178633682\n",
      "Training step:  1789\n",
      "Loss: 945.5853692578397\n",
      "Training step:  1790\n",
      "Loss: 945.566716783374\n",
      "Training step:  1791\n",
      "Loss: 945.5585258367495\n",
      "Training step:  1792\n",
      "Loss: 945.5417986235958\n",
      "Training step:  1793\n",
      "Loss: 945.5341296803692\n",
      "Training step:  1794\n",
      "Loss: 945.5168938967144\n",
      "Training step:  1795\n",
      "Loss: 945.5097914442973\n",
      "Training step:  1796\n",
      "Loss: 945.4920467602248\n",
      "Training step:  1797\n",
      "Loss: 945.4855083298557\n",
      "Training step:  1798\n",
      "Loss: 945.4672570696786\n",
      "Training step:  1799\n",
      "Loss: 945.4597632627987\n",
      "Training step:  1800\n",
      "Loss: 945.4425372446511\n",
      "Training step:  1801\n",
      "Loss: 945.4355364603983\n",
      "Training step:  1802\n",
      "Loss: 945.4178062156836\n",
      "Training step:  1803\n",
      "Loss: 945.4113644499572\n",
      "Training step:  1804\n",
      "Loss: 945.3931621920625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1805\n",
      "Loss: 945.385439337245\n",
      "Training step:  1806\n",
      "Loss: 945.3684626640727\n",
      "Training step:  1807\n",
      "Loss: 945.3613159027491\n",
      "Training step:  1808\n",
      "Loss: 945.3438376369013\n",
      "Training step:  1809\n",
      "Loss: 945.337245299962\n",
      "Training step:  1810\n",
      "Loss: 945.3192988815499\n",
      "Training step:  1811\n",
      "Loss: 945.3128032525688\n",
      "Training step:  1812\n",
      "Loss: 945.2947780613905\n",
      "Training step:  1813\n",
      "Loss: 945.2873372279136\n",
      "Training step:  1814\n",
      "Loss: 945.2703162217795\n",
      "Training step:  1815\n",
      "Loss: 945.2633625445002\n",
      "Training step:  1816\n",
      "Loss: 945.2458477895611\n",
      "Training step:  1817\n",
      "Loss: 945.2394419006458\n",
      "Training step:  1818\n",
      "Loss: 945.2214356536185\n",
      "Training step:  1819\n",
      "Loss: 945.213361739219\n",
      "Training step:  1820\n",
      "Loss: 945.196818246038\n",
      "Training step:  1821\n",
      "Loss: 945.1894789572431\n",
      "Training step:  1822\n",
      "Loss: 945.1724481185782\n",
      "Training step:  1823\n",
      "Loss: 945.165652477834\n",
      "Training step:  1824\n",
      "Loss: 945.1481339679707\n",
      "Training step:  1825\n",
      "Loss: 945.141879605517\n",
      "Training step:  1826\n",
      "Loss: 945.1239044656915\n",
      "Training step:  1827\n",
      "Loss: 945.1151457339422\n",
      "Training step:  1828\n",
      "Loss: 945.0995389866254\n",
      "Training step:  1829\n",
      "Loss: 945.0919533354132\n",
      "Training step:  1830\n",
      "Loss: 945.0753108587478\n",
      "Training step:  1831\n",
      "Loss: 945.068260595848\n",
      "Training step:  1832\n",
      "Loss: 945.0511358660622\n",
      "Training step:  1833\n",
      "Loss: 945.0446210540807\n",
      "Training step:  1834\n",
      "Loss: 945.0270162756453\n",
      "Training step:  1835\n",
      "Loss: 945.0193033337081\n",
      "Training step:  1836\n",
      "Loss: 945.0028694688552\n",
      "Training step:  1837\n",
      "Loss: 944.9957114521973\n",
      "Training step:  1838\n",
      "Loss: 944.9787991035365\n",
      "Training step:  1839\n",
      "Loss: 944.972172093512\n",
      "Training step:  1840\n",
      "Loss: 944.954811998001\n",
      "Training step:  1841\n",
      "Loss: 944.9472680587496\n",
      "Training step:  1842\n",
      "Loss: 944.930871146663\n",
      "Training step:  1843\n",
      "Loss: 944.9237829295766\n",
      "Training step:  1844\n",
      "Loss: 944.9069122580738\n",
      "Training step:  1845\n",
      "Loss: 944.9003503789797\n",
      "Training step:  1846\n",
      "Loss: 944.8830359428957\n",
      "Training step:  1847\n",
      "Loss: 944.8753896728076\n",
      "Training step:  1848\n",
      "Loss: 944.8591044361772\n",
      "Training step:  1849\n",
      "Loss: 944.8520081099838\n",
      "Training step:  1850\n",
      "Loss: 944.83525379691\n",
      "Training step:  1851\n",
      "Loss: 944.8286792956653\n",
      "Training step:  1852\n",
      "Loss: 944.811485444863\n",
      "Training step:  1853\n",
      "Loss: 944.8040053470854\n",
      "Training step:  1854\n",
      "Loss: 944.7877575500615\n",
      "Training step:  1855\n",
      "Loss: 944.7807304180182\n",
      "Training step:  1856\n",
      "Loss: 944.7640173454985\n",
      "Training step:  1857\n",
      "Loss: 944.7575074498735\n",
      "Training step:  1858\n",
      "Loss: 944.7403587509909\n",
      "Training step:  1859\n",
      "Loss: 944.7329456478889\n",
      "Training step:  1860\n",
      "Loss: 944.7167348018312\n",
      "Training step:  1861\n",
      "Loss: 944.7097763893297\n",
      "Training step:  1862\n",
      "Loss: 944.6931045088347\n",
      "Training step:  1863\n",
      "Loss: 944.6866587840201\n",
      "Training step:  1864\n",
      "Loss: 944.6695551541487\n",
      "Training step:  1865\n",
      "Loss: 944.661773699016\n",
      "Training step:  1866\n",
      "Loss: 944.6457613435127\n",
      "Training step:  1867\n",
      "Loss: 944.6386986364803\n",
      "Training step:  1868\n",
      "Loss: 944.6222344258198\n",
      "Training step:  1869\n",
      "Loss: 944.6156801533732\n",
      "Training step:  1870\n",
      "Loss: 944.5987609549475\n",
      "Training step:  1871\n",
      "Loss: 944.5913501086461\n",
      "Training step:  1872\n",
      "Loss: 944.5752496660405\n",
      "Training step:  1873\n",
      "Loss: 944.5683895831877\n",
      "Training step:  1874\n",
      "Loss: 944.5518623757962\n",
      "Training step:  1875\n",
      "Loss: 944.5454783229072\n",
      "Training step:  1876\n",
      "Loss: 944.5285268365377\n",
      "Training step:  1877\n",
      "Loss: 944.5205837356555\n",
      "Training step:  1878\n",
      "Loss: 944.5049680100767\n",
      "Training step:  1879\n",
      "Loss: 944.497702663001\n",
      "Training step:  1880\n",
      "Loss: 944.4816464916839\n",
      "Training step:  1881\n",
      "Loss: 944.4748811792209\n",
      "Training step:  1882\n",
      "Loss: 944.4583777950613\n",
      "Training step:  1883\n",
      "Loss: 944.4521103389636\n",
      "Training step:  1884\n",
      "Loss: 944.4351880627034\n",
      "Training step:  1885\n",
      "Loss: 944.4269212599593\n",
      "Training step:  1886\n",
      "Loss: 944.4116712810455\n",
      "Training step:  1887\n",
      "Loss: 944.404163653307\n",
      "Training step:  1888\n",
      "Loss: 944.3882889598184\n",
      "Training step:  1889\n",
      "Loss: 944.3814769586328\n",
      "Training step:  1890\n",
      "Loss: 944.3651605242287\n",
      "Training step:  1891\n",
      "Loss: 944.358840749255\n",
      "Training step:  1892\n",
      "Loss: 944.3421105470525\n",
      "Training step:  1893\n",
      "Loss: 944.3338188714737\n",
      "Training step:  1894\n",
      "Loss: 944.3187386063291\n",
      "Training step:  1895\n",
      "Loss: 944.3111938535305\n",
      "Training step:  1896\n",
      "Loss: 944.2954974378763\n",
      "Training step:  1897\n",
      "Loss: 944.288640343638\n",
      "Training step:  1898\n",
      "Loss: 944.2725084149721\n",
      "Training step:  1899\n",
      "Loss: 944.2661379805869\n",
      "Training step:  1900\n",
      "Loss: 944.2495712512527\n",
      "Training step:  1901\n",
      "Loss: 944.2415545527207\n",
      "Training step:  1902\n",
      "Loss: 944.2264451718345\n",
      "Training step:  1903\n",
      "Loss: 944.2190734436213\n",
      "Training step:  1904\n",
      "Loss: 944.2033519814017\n",
      "Training step:  1905\n",
      "Loss: 944.1966597256229\n",
      "Training step:  1906\n",
      "Loss: 944.1805327914908\n",
      "Training step:  1907\n",
      "Loss: 944.1730104891209\n",
      "Training step:  1908\n",
      "Loss: 944.1575640748675\n",
      "Training step:  1909\n",
      "Loss: 944.1506519561752\n",
      "Training step:  1910\n",
      "Loss: 944.1347804407969\n",
      "Training step:  1911\n",
      "Loss: 944.1283467361272\n",
      "Training step:  1912\n",
      "Loss: 944.1120731245792\n",
      "Training step:  1913\n",
      "Loss: 944.1040866953889\n",
      "Training step:  1914\n",
      "Loss: 944.0891541762824\n",
      "Training step:  1915\n",
      "Loss: 944.0818026717719\n",
      "Training step:  1916\n",
      "Loss: 944.0662699567314\n",
      "Training step:  1917\n",
      "Loss: 944.0595861730234\n",
      "Training step:  1918\n",
      "Loss: 944.0436315720513\n",
      "Training step:  1919\n",
      "Loss: 944.0361568430638\n",
      "Training step:  1920\n",
      "Loss: 944.0208694610271\n",
      "Training step:  1921\n",
      "Loss: 944.013996179075\n",
      "Training step:  1922\n",
      "Loss: 943.998292602824\n",
      "Training step:  1923\n",
      "Loss: 943.9918894943467\n",
      "Training step:  1924\n",
      "Loss: 943.9757909130386\n",
      "Training step:  1925\n",
      "Loss: 943.9678602973155\n",
      "Training step:  1926\n",
      "Loss: 943.9529450515477\n",
      "Training step:  1927\n",
      "Loss: 943.9457808033465\n",
      "Training step:  1928\n",
      "Loss: 943.9302759360131\n",
      "Training step:  1929\n",
      "Loss: 943.9237676138522\n",
      "Training step:  1930\n",
      "Loss: 943.9078725710217\n",
      "Training step:  1931\n",
      "Loss: 943.9003005688851\n",
      "Training step:  1932\n",
      "Loss: 943.8852322493284\n",
      "Training step:  1933\n",
      "Loss: 943.8783331975212\n",
      "Training step:  1934\n",
      "Loss: 943.8628572559168\n",
      "Training step:  1935\n",
      "Loss: 943.8564203744944\n",
      "Training step:  1936\n",
      "Loss: 943.8405564074858\n",
      "Training step:  1937\n",
      "Loss: 943.8329128081842\n",
      "Training step:  1938\n",
      "Loss: 943.8180254192237\n",
      "Training step:  1939\n",
      "Loss: 943.8110373046673\n",
      "Training step:  1940\n",
      "Loss: 943.7955681342237\n",
      "Training step:  1941\n",
      "Loss: 943.7892243672848\n",
      "Training step:  1942\n",
      "Loss: 943.7733715242979\n",
      "Training step:  1943\n",
      "Loss: 943.7655352199771\n",
      "Training step:  1944\n",
      "Loss: 943.7508336821527\n",
      "Training step:  1945\n",
      "Loss: 943.7437495002182\n",
      "Training step:  1946\n",
      "Loss: 943.7284729913451\n",
      "Training step:  1947\n",
      "Loss: 943.7220277171996\n",
      "Training step:  1948\n",
      "Loss: 943.7063734107207\n",
      "Training step:  1949\n",
      "Loss: 943.6988882433626\n",
      "Training step:  1950\n",
      "Loss: 943.6841269814861\n",
      "Training step:  1951\n",
      "Loss: 943.6772073241777\n",
      "Training step:  1952\n",
      "Loss: 943.661875316592\n",
      "Training step:  1953\n",
      "Loss: 943.6555887883111\n",
      "Training step:  1954\n",
      "Loss: 943.6398809846087\n",
      "Training step:  1955\n",
      "Loss: 943.6313366793814\n",
      "Training step:  1956\n",
      "Loss: 943.6175189409217\n",
      "Training step:  1957\n",
      "Loss: 943.609906650922\n",
      "Training step:  1958\n",
      "Loss: 943.5953091362614\n",
      "Training step:  1959\n",
      "Loss: 943.5883639854381\n",
      "Training step:  1960\n",
      "Loss: 943.5731943796934\n",
      "Training step:  1961\n",
      "Loss: 943.565691167128\n",
      "Training step:  1962\n",
      "Loss: 943.5511439036507\n",
      "Training step:  1963\n",
      "Loss: 943.5442036659401\n",
      "Training step:  1964\n",
      "Loss: 943.5290957353752\n",
      "Training step:  1965\n",
      "Loss: 943.5225940022555\n",
      "Training step:  1966\n",
      "Loss: 943.5072725282462\n",
      "Training step:  1967\n",
      "Loss: 943.4994997801844\n",
      "Training step:  1968\n",
      "Loss: 943.4851345638317\n",
      "Training step:  1969\n",
      "Loss: 943.4780998210769\n",
      "Training step:  1970\n",
      "Loss: 943.4631796641113\n",
      "Training step:  1971\n",
      "Loss: 943.4567619113059\n",
      "Training step:  1972\n",
      "Loss: 943.4414789402665\n",
      "Training step:  1973\n",
      "Loss: 943.4336382562626\n",
      "Training step:  1974\n",
      "Loss: 943.4194502759917\n",
      "Training step:  1975\n",
      "Loss: 943.4123259264612\n",
      "Training step:  1976\n",
      "Loss: 943.3975899144901\n",
      "Training step:  1977\n",
      "Loss: 943.3910773458987\n",
      "Training step:  1978\n",
      "Loss: 943.3759841120485\n",
      "Training step:  1979\n",
      "Loss: 943.3684806661793\n",
      "Training step:  1980\n",
      "Loss: 943.3541136536603\n",
      "Training step:  1981\n",
      "Loss: 943.3472780743563\n",
      "Training step:  1982\n",
      "Loss: 943.3323661492827\n",
      "Training step:  1983\n",
      "Loss: 943.3249870256557\n",
      "Training step:  1984\n",
      "Loss: 943.3105555725899\n",
      "Training step:  1985\n",
      "Loss: 943.3038538458994\n",
      "Training step:  1986\n",
      "Loss: 943.2888799514216\n",
      "Training step:  1987\n",
      "Loss: 943.2813984611352\n",
      "Training step:  1988\n",
      "Loss: 943.2671425123007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1989\n",
      "Loss: 943.260319455428\n",
      "Training step:  1990\n",
      "Loss: 943.2455258889772\n",
      "Training step:  1991\n",
      "Loss: 943.2381673649436\n",
      "Training step:  1992\n",
      "Loss: 943.2238477927889\n",
      "Training step:  1993\n",
      "Loss: 943.2171573358205\n",
      "Training step:  1994\n",
      "Loss: 943.202324722948\n",
      "Training step:  1995\n",
      "Loss: 943.194710318763\n",
      "Training step:  1996\n",
      "Loss: 943.1806445107549\n",
      "Training step:  1997\n",
      "Loss: 943.1737491483707\n",
      "Training step:  1998\n",
      "Loss: 943.159154118673\n",
      "Training step:  1999\n",
      "Loss: 943.1528510094947\n",
      "Training step:  2000\n",
      "Loss: 943.1379103098486\n",
      "Training step:  2001\n",
      "Loss: 943.1290505517127\n",
      "Training step:  2002\n",
      "Loss: 943.1162369655855\n",
      "Training step:  2003\n",
      "Loss: 943.1085349541274\n",
      "Training step:  2004\n",
      "Loss: 943.0945949944061\n",
      "Training step:  2005\n",
      "Loss: 943.0877000539065\n",
      "Training step:  2006\n",
      "Loss: 943.073235343337\n",
      "Training step:  2007\n",
      "Loss: 943.0667533921732\n",
      "Training step:  2008\n",
      "Loss: 943.0519511230464\n",
      "Training step:  2009\n",
      "Loss: 943.0423917399879\n",
      "Training step:  2010\n",
      "Loss: 943.0304738365937\n",
      "Training step:  2011\n",
      "Loss: 943.0218668305846\n",
      "Training step:  2012\n",
      "Loss: 943.0085693327392\n",
      "Training step:  2013\n",
      "Loss: 943.0011120090854\n",
      "Training step:  2014\n",
      "Loss: 942.9871859254906\n",
      "Training step:  2015\n",
      "Loss: 942.9804309407239\n",
      "Training step:  2016\n",
      "Loss: 942.9660109944956\n",
      "Training step:  2017\n",
      "Loss: 942.9585876945125\n",
      "Training step:  2018\n",
      "Loss: 942.9447606186342\n",
      "Training step:  2019\n",
      "Loss: 942.9379660686591\n",
      "Training step:  2020\n",
      "Loss: 942.9236274634864\n",
      "Training step:  2021\n",
      "Loss: 942.9163226736315\n",
      "Training step:  2022\n",
      "Loss: 942.9024349147076\n",
      "Training step:  2023\n",
      "Loss: 942.8957684144806\n",
      "Training step:  2024\n",
      "Loss: 942.8813926200413\n",
      "Training step:  2025\n",
      "Loss: 942.8739723258136\n",
      "Training step:  2026\n",
      "Loss: 942.8602717653303\n",
      "Training step:  2027\n",
      "Loss: 942.8534699661508\n",
      "Training step:  2028\n",
      "Loss: 942.8392862255158\n",
      "Training step:  2029\n",
      "Loss: 942.8328621775938\n",
      "Training step:  2030\n",
      "Loss: 942.8183517862045\n",
      "Training step:  2031\n",
      "Loss: 942.8098703204555\n",
      "Training step:  2032\n",
      "Loss: 942.7971156656898\n",
      "Training step:  2033\n",
      "Loss: 942.7896522118813\n",
      "Training step:  2034\n",
      "Loss: 942.7760521856569\n",
      "Training step:  2035\n",
      "Loss: 942.7692718354665\n",
      "Training step:  2036\n",
      "Loss: 942.7551735332689\n",
      "Training step:  2037\n",
      "Loss: 942.747894150572\n",
      "Training step:  2038\n",
      "Loss: 942.7342349448833\n",
      "Training step:  2039\n",
      "Loss: 942.7275802943755\n",
      "Training step:  2040\n",
      "Loss: 942.713446016137\n",
      "Training step:  2041\n",
      "Loss: 942.70605416248\n",
      "Training step:  2042\n",
      "Loss: 942.692577827915\n",
      "Training step:  2043\n",
      "Loss: 942.6857917182618\n",
      "Training step:  2044\n",
      "Loss: 942.671823944586\n",
      "Training step:  2045\n",
      "Loss: 942.6654281054015\n",
      "Training step:  2046\n",
      "Loss: 942.6511415391035\n",
      "Training step:  2047\n",
      "Loss: 942.6418547641766\n",
      "Training step:  2048\n",
      "Loss: 942.6302254700279\n",
      "Training step:  2049\n",
      "Loss: 942.6218989805614\n",
      "Training step:  2050\n",
      "Loss: 942.6089670898028\n",
      "Training step:  2051\n",
      "Loss: 942.601720875115\n",
      "Training step:  2052\n",
      "Loss: 942.5881997903367\n",
      "Training step:  2053\n",
      "Loss: 942.5816178839463\n",
      "Training step:  2054\n",
      "Loss: 942.5676318194112\n",
      "Training step:  2055\n",
      "Loss: 942.560078624449\n",
      "Training step:  2056\n",
      "Loss: 942.5468771409002\n",
      "Training step:  2057\n",
      "Loss: 942.5400175992095\n",
      "Training step:  2058\n",
      "Loss: 942.5262262617416\n",
      "Training step:  2059\n",
      "Loss: 942.518999852853\n",
      "Training step:  2060\n",
      "Loss: 942.5056329190252\n",
      "Training step:  2061\n",
      "Loss: 942.4990111035521\n",
      "Training step:  2062\n",
      "Loss: 942.4851858733865\n",
      "Training step:  2063\n",
      "Loss: 942.4778512064682\n",
      "Training step:  2064\n",
      "Loss: 942.4646614123819\n",
      "Training step:  2065\n",
      "Loss: 942.4579132056089\n",
      "Training step:  2066\n",
      "Loss: 942.4441605235262\n",
      "Training step:  2067\n",
      "Loss: 942.4368200241429\n",
      "Training step:  2068\n",
      "Loss: 942.4236991595319\n",
      "Training step:  2069\n",
      "Loss: 942.4169393941689\n",
      "Training step:  2070\n",
      "Loss: 942.4032590762905\n",
      "Training step:  2071\n",
      "Loss: 942.3959129763695\n",
      "Training step:  2072\n",
      "Loss: 942.3827415925267\n",
      "Training step:  2073\n",
      "Loss: 942.3760978587612\n",
      "Training step:  2074\n",
      "Loss: 942.3623696866002\n",
      "Training step:  2075\n",
      "Loss: 942.3548945146003\n",
      "Training step:  2076\n",
      "Loss: 942.341851624226\n",
      "Training step:  2077\n",
      "Loss: 942.3351300352865\n",
      "Training step:  2078\n",
      "Loss: 942.3215346906109\n",
      "Training step:  2079\n",
      "Loss: 942.3141147283156\n",
      "Training step:  2080\n",
      "Loss: 942.3010740846885\n",
      "Training step:  2081\n",
      "Loss: 942.2944125374692\n",
      "Training step:  2082\n",
      "Loss: 942.2808025017961\n",
      "Training step:  2083\n",
      "Loss: 942.2734579981378\n",
      "Training step:  2084\n",
      "Loss: 942.2604725211095\n",
      "Training step:  2085\n",
      "Loss: 942.2538135281968\n",
      "Training step:  2086\n",
      "Loss: 942.2402630227438\n",
      "Training step:  2087\n",
      "Loss: 942.2328093868039\n",
      "Training step:  2088\n",
      "Loss: 942.2199311675647\n",
      "Training step:  2089\n",
      "Loss: 942.2132165005451\n",
      "Training step:  2090\n",
      "Loss: 942.199777391351\n",
      "Training step:  2091\n",
      "Loss: 942.1925131890742\n",
      "Training step:  2092\n",
      "Loss: 942.1795667941885\n",
      "Training step:  2093\n",
      "Loss: 942.172985613858\n",
      "Training step:  2094\n",
      "Loss: 942.1595001452731\n",
      "Training step:  2095\n",
      "Loss: 942.1519981507317\n",
      "Training step:  2096\n",
      "Loss: 942.1392983385506\n",
      "Training step:  2097\n",
      "Loss: 942.1325125745379\n",
      "Training step:  2098\n",
      "Loss: 942.1192607507843\n",
      "Training step:  2099\n",
      "Loss: 942.1129444330222\n",
      "Training step:  2100\n",
      "Loss: 942.0993002433756\n",
      "Training step:  2101\n",
      "Loss: 942.0894416733828\n",
      "Training step:  2102\n",
      "Loss: 942.0797740279803\n",
      "Training step:  2103\n",
      "Loss: 942.0703440236067\n",
      "Training step:  2104\n",
      "Loss: 942.059005254417\n",
      "Training step:  2105\n",
      "Loss: 942.0512283664657\n",
      "Training step:  2106\n",
      "Loss: 942.038756867411\n",
      "Training step:  2107\n",
      "Loss: 942.031883976907\n",
      "Training step:  2108\n",
      "Loss: 942.0188299786549\n",
      "Training step:  2109\n",
      "Loss: 942.0124651468276\n",
      "Training step:  2110\n",
      "Loss: 941.9990173273752\n",
      "Training step:  2111\n",
      "Loss: 941.989806757095\n",
      "Training step:  2112\n",
      "Loss: 941.979202514478\n",
      "Training step:  2113\n",
      "Loss: 941.9706827754932\n",
      "Training step:  2114\n",
      "Loss: 941.9589080732216\n",
      "Training step:  2115\n",
      "Loss: 941.9516230223123\n",
      "Training step:  2116\n",
      "Loss: 941.9389951510893\n",
      "Training step:  2117\n",
      "Loss: 941.9324358335085\n",
      "Training step:  2118\n",
      "Loss: 941.9192889327384\n",
      "Training step:  2119\n",
      "Loss: 941.9118359621498\n",
      "Training step:  2120\n",
      "Loss: 941.899376359247\n",
      "Training step:  2121\n",
      "Loss: 941.8926964075021\n",
      "Training step:  2122\n",
      "Loss: 941.8797233663955\n",
      "Training step:  2123\n",
      "Loss: 941.8724976952819\n",
      "Training step:  2124\n",
      "Loss: 941.8599922230894\n",
      "Training step:  2125\n",
      "Loss: 941.8534216045322\n",
      "Training step:  2126\n",
      "Loss: 941.8404045570636\n",
      "Training step:  2127\n",
      "Loss: 941.8330606094001\n",
      "Training step:  2128\n",
      "Loss: 941.8206056207114\n",
      "Training step:  2129\n",
      "Loss: 941.8140398195033\n",
      "Training step:  2130\n",
      "Loss: 941.8010764797884\n",
      "Training step:  2131\n",
      "Loss: 941.7937435643948\n",
      "Training step:  2132\n",
      "Loss: 941.7813380164953\n",
      "Training step:  2133\n",
      "Loss: 941.7747771575166\n",
      "Training step:  2134\n",
      "Loss: 941.7618491009758\n",
      "Training step:  2135\n",
      "Loss: 941.7545441940491\n",
      "Training step:  2136\n",
      "Loss: 941.7421702243037\n",
      "Training step:  2137\n",
      "Loss: 941.7356332819244\n",
      "Training step:  2138\n",
      "Loss: 941.72275829491\n",
      "Training step:  2139\n",
      "Loss: 941.7154645199761\n",
      "Training step:  2140\n",
      "Loss: 941.703139508908\n",
      "Training step:  2141\n",
      "Loss: 941.6966076979212\n",
      "Training step:  2142\n",
      "Loss: 941.6837855854474\n",
      "Training step:  2143\n",
      "Loss: 941.6765030157472\n",
      "Training step:  2144\n",
      "Loss: 941.6642266988621\n",
      "Training step:  2145\n",
      "Loss: 941.6577001395918\n",
      "Training step:  2146\n",
      "Loss: 941.6449306099086\n",
      "Training step:  2147\n",
      "Loss: 941.6378701226004\n",
      "Training step:  2148\n",
      "Loss: 941.6255508749426\n",
      "Training step:  2149\n",
      "Loss: 941.6191303520121\n",
      "Training step:  2150\n",
      "Loss: 941.6063188278202\n",
      "Training step:  2151\n",
      "Loss: 941.5988943247078\n",
      "Training step:  2152\n",
      "Loss: 941.5868255674512\n",
      "Training step:  2153\n",
      "Loss: 941.5801907220351\n",
      "Training step:  2154\n",
      "Loss: 941.5676211124554\n",
      "Training step:  2155\n",
      "Loss: 941.5604893804755\n",
      "Training step:  2156\n",
      "Loss: 941.5482307339702\n",
      "Training step:  2157\n",
      "Loss: 941.5418611321545\n",
      "Training step:  2158\n",
      "Loss: 941.5291162960798\n",
      "Training step:  2159\n",
      "Loss: 941.5216203431035\n",
      "Training step:  2160\n",
      "Loss: 941.5097479694308\n",
      "Training step:  2161\n",
      "Loss: 941.5030168856674\n",
      "Training step:  2162\n",
      "Loss: 941.4905490016727\n",
      "Training step:  2163\n",
      "Loss: 941.4834347722896\n",
      "Training step:  2164\n",
      "Loss: 941.4712738523772\n",
      "Training step:  2165\n",
      "Loss: 941.4649167090879\n",
      "Training step:  2166\n",
      "Loss: 941.4522763131266\n",
      "Training step:  2167\n",
      "Loss: 941.4441984996223\n",
      "Training step:  2168\n",
      "Loss: 941.4329699815775\n",
      "Training step:  2169\n",
      "Loss: 941.4258670929594\n",
      "Training step:  2170\n",
      "Loss: 941.4137292717448\n",
      "Training step:  2171\n",
      "Loss: 941.4074343445424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  2172\n",
      "Loss: 941.3948208697055\n",
      "Training step:  2173\n",
      "Loss: 941.3861048495902\n",
      "Training step:  2174\n",
      "Loss: 941.375832192807\n",
      "Training step:  2175\n",
      "Loss: 941.3678436389141\n",
      "Training step:  2176\n",
      "Loss: 941.3565056224821\n",
      "Training step:  2177\n",
      "Loss: 941.3494186058941\n",
      "Training step:  2178\n",
      "Loss: 941.3373767912623\n",
      "Training step:  2179\n",
      "Loss: 941.3310886165624\n",
      "Training step:  2180\n",
      "Loss: 941.318579045479\n",
      "Training step:  2181\n",
      "Loss: 941.3104801258955\n",
      "Training step:  2182\n",
      "Loss: 941.2994909869052\n",
      "Training step:  2183\n",
      "Loss: 941.2923267047123\n",
      "Training step:  2184\n",
      "Loss: 941.2804483717854\n",
      "Training step:  2185\n",
      "Loss: 941.2740763844622\n",
      "Training step:  2186\n",
      "Loss: 941.2617188965027\n",
      "Training step:  2187\n",
      "Loss: 941.2532986391412\n",
      "Training step:  2188\n",
      "Loss: 941.2428303654209\n",
      "Training step:  2189\n",
      "Loss: 941.2352796733268\n",
      "Training step:  2190\n",
      "Loss: 941.223819512423\n",
      "Training step:  2191\n",
      "Loss: 941.2170703693996\n",
      "Training step:  2192\n",
      "Loss: 941.2050440730442\n",
      "Training step:  2193\n",
      "Loss: 941.1986275566663\n",
      "Training step:  2194\n",
      "Loss: 941.1863402396757\n",
      "Training step:  2195\n",
      "Loss: 941.1788527369612\n",
      "Training step:  2196\n",
      "Loss: 941.1675661634007\n",
      "Training step:  2197\n",
      "Loss: 941.1607158229536\n",
      "Training step:  2198\n",
      "Loss: 941.1487458833759\n",
      "Training step:  2199\n",
      "Loss: 941.1416692976351\n",
      "Training step:  2200\n",
      "Loss: 941.1299865720399\n",
      "Training step:  2201\n",
      "Loss: 941.1236252517149\n",
      "Training step:  2202\n",
      "Loss: 941.1113804328461\n",
      "Training step:  2203\n",
      "Loss: 941.1027661347144\n",
      "Training step:  2204\n",
      "Loss: 941.0928461961131\n",
      "Training step:  2205\n",
      "Loss: 941.0848818147732\n",
      "Training step:  2206\n",
      "Loss: 941.074006261261\n",
      "Training step:  2207\n",
      "Loss: 941.0670511065697\n",
      "Training step:  2208\n",
      "Loss: 941.0553131941922\n",
      "Training step:  2209\n",
      "Loss: 941.0489933870299\n",
      "Training step:  2210\n",
      "Loss: 941.0368342141941\n",
      "Training step:  2211\n",
      "Loss: 941.0287359542001\n",
      "Training step:  2212\n",
      "Loss: 941.0182069933159\n",
      "Training step:  2213\n",
      "Loss: 941.0110744204666\n",
      "Training step:  2214\n",
      "Loss: 940.9995835128617\n",
      "Training step:  2215\n",
      "Loss: 940.9932101225455\n",
      "Training step:  2216\n",
      "Loss: 940.9811704119327\n",
      "Training step:  2217\n",
      "Loss: 940.9733723721943\n",
      "Training step:  2218\n",
      "Loss: 940.9625625770843\n",
      "Training step:  2219\n",
      "Loss: 940.9554979567982\n",
      "Training step:  2220\n",
      "Loss: 940.9440282261465\n",
      "Training step:  2221\n",
      "Loss: 940.9377149148273\n",
      "Training step:  2222\n",
      "Loss: 940.9257012678523\n",
      "Training step:  2223\n",
      "Loss: 940.9171017643315\n",
      "Training step:  2224\n",
      "Loss: 940.9074763906393\n",
      "Training step:  2225\n",
      "Loss: 940.8994560937647\n",
      "Training step:  2226\n",
      "Loss: 940.8887067990569\n",
      "Training step:  2227\n",
      "Loss: 940.8816866917804\n",
      "Training step:  2228\n",
      "Loss: 940.8702832394275\n",
      "Training step:  2229\n",
      "Loss: 940.8640056570159\n",
      "Training step:  2230\n",
      "Loss: 940.8520809743662\n",
      "Training step:  2231\n",
      "Loss: 940.844261561059\n",
      "Training step:  2232\n",
      "Loss: 940.8336851010185\n",
      "Training step:  2233\n",
      "Loss: 940.8267606168852\n",
      "Training step:  2234\n",
      "Loss: 940.8153576628258\n",
      "Training step:  2235\n",
      "Loss: 940.8090433323229\n",
      "Training step:  2236\n",
      "Loss: 940.7972221086452\n",
      "Training step:  2237\n",
      "Loss: 940.7891365270095\n",
      "Training step:  2238\n",
      "Loss: 940.7789983849951\n",
      "Training step:  2239\n",
      "Loss: 940.7717753040727\n",
      "Training step:  2240\n",
      "Loss: 940.7607153238295\n",
      "Training step:  2241\n",
      "Loss: 940.7542294043125\n",
      "Training step:  2242\n",
      "Loss: 940.7425298732476\n",
      "Training step:  2243\n",
      "Loss: 940.7355822705886\n",
      "Training step:  2244\n",
      "Loss: 940.7243819769385\n",
      "Training step:  2245\n",
      "Loss: 940.718103768831\n",
      "Training step:  2246\n",
      "Loss: 940.7063810393321\n",
      "Training step:  2247\n",
      "Loss: 940.6987303654417\n",
      "Training step:  2248\n",
      "Loss: 940.688185988112\n",
      "Training step:  2249\n",
      "Loss: 940.6812466647674\n",
      "Training step:  2250\n",
      "Loss: 940.6700704759238\n",
      "Training step:  2251\n",
      "Loss: 940.6638501081457\n",
      "Training step:  2252\n",
      "Loss: 940.6521557927977\n",
      "Training step:  2253\n",
      "Loss: 940.6431843695257\n",
      "Training step:  2254\n",
      "Loss: 940.6346976783732\n",
      "Training step:  2255\n",
      "Loss: 940.6261223181592\n",
      "Training step:  2256\n",
      "Loss: 940.6162347155066\n",
      "Training step:  2257\n",
      "Loss: 940.6089726020956\n",
      "Training step:  2258\n",
      "Loss: 940.5981891138549\n",
      "Training step:  2259\n",
      "Loss: 940.5916476869041\n",
      "Training step:  2260\n",
      "Loss: 940.5802414869424\n",
      "Training step:  2261\n",
      "Loss: 940.5732962504454\n",
      "Training step:  2262\n",
      "Loss: 940.5623403586914\n",
      "Training step:  2263\n",
      "Loss: 940.5560405857474\n",
      "Training step:  2264\n",
      "Loss: 940.5444660098809\n",
      "Training step:  2265\n",
      "Loss: 940.5359012734204\n",
      "Training step:  2266\n",
      "Loss: 940.526930868592\n",
      "Training step:  2267\n",
      "Loss: 940.5187302407745\n",
      "Training step:  2268\n",
      "Loss: 940.5087443200082\n",
      "Training step:  2269\n",
      "Loss: 940.5017547018215\n",
      "Training step:  2270\n",
      "Loss: 940.4908858491563\n",
      "Training step:  2271\n",
      "Loss: 940.4845963678729\n",
      "Training step:  2272\n",
      "Loss: 940.4731161791425\n",
      "Training step:  2273\n",
      "Loss: 940.4654053991914\n",
      "Training step:  2274\n",
      "Loss: 940.4553653822774\n",
      "Training step:  2275\n",
      "Loss: 940.4484058479405\n",
      "Training step:  2276\n",
      "Loss: 940.4375956330807\n",
      "Training step:  2277\n",
      "Loss: 940.4313287141179\n",
      "Training step:  2278\n",
      "Loss: 940.4199126250455\n",
      "Training step:  2279\n",
      "Loss: 940.4113072446786\n",
      "Training step:  2280\n",
      "Loss: 940.4026389279736\n",
      "Training step:  2281\n",
      "Loss: 940.3946319164666\n",
      "Training step:  2282\n",
      "Loss: 940.384665907932\n",
      "Training step:  2283\n",
      "Loss: 940.3777233531564\n",
      "Training step:  2284\n",
      "Loss: 940.3669975805299\n",
      "Training step:  2285\n",
      "Loss: 940.3607407790812\n",
      "Training step:  2286\n",
      "Loss: 940.3494303834298\n",
      "Training step:  2287\n",
      "Loss: 940.3417104681123\n",
      "Training step:  2288\n",
      "Loss: 940.3318293154838\n",
      "Training step:  2289\n",
      "Loss: 940.3248775629763\n",
      "Training step:  2290\n",
      "Loss: 940.3142429104944\n",
      "Training step:  2291\n",
      "Loss: 940.3079702992567\n",
      "Training step:  2292\n",
      "Loss: 940.2967422698628\n",
      "Training step:  2293\n",
      "Loss: 940.2882276533918\n",
      "Training step:  2294\n",
      "Loss: 940.2796193107547\n",
      "Training step:  2295\n",
      "Loss: 940.2717320881067\n",
      "Training step:  2296\n",
      "Loss: 940.2618525327618\n",
      "Training step:  2297\n",
      "Loss: 940.2550021824965\n",
      "Training step:  2298\n",
      "Loss: 940.2443784200348\n",
      "Training step:  2299\n",
      "Loss: 940.238197700746\n",
      "Training step:  2300\n",
      "Loss: 940.2269877181478\n",
      "Training step:  2301\n",
      "Loss: 940.2183142394566\n",
      "Training step:  2302\n",
      "Loss: 940.2100850097814\n",
      "Training step:  2303\n",
      "Loss: 940.2018446853493\n",
      "Training step:  2304\n",
      "Loss: 940.1923604871564\n",
      "Training step:  2305\n",
      "Loss: 940.1852787466139\n",
      "Training step:  2306\n",
      "Loss: 940.174963414438\n",
      "Training step:  2307\n",
      "Loss: 940.1685506375757\n",
      "Training step:  2308\n",
      "Loss: 940.1576557157641\n",
      "Training step:  2309\n",
      "Loss: 940.1508091622964\n",
      "Training step:  2310\n",
      "Loss: 940.140390747219\n",
      "Training step:  2311\n",
      "Loss: 940.1341429373958\n",
      "Training step:  2312\n",
      "Loss: 940.1231485990587\n",
      "Training step:  2313\n",
      "Loss: 940.1158976969156\n",
      "Training step:  2314\n",
      "Loss: 940.1058535437127\n",
      "Training step:  2315\n",
      "Loss: 940.0992475688172\n",
      "Training step:  2316\n",
      "Loss: 940.0886339861217\n",
      "Training step:  2317\n",
      "Loss: 940.0824150819576\n",
      "Training step:  2318\n",
      "Loss: 940.0714731920906\n",
      "Training step:  2319\n",
      "Loss: 940.0634515268089\n",
      "Training step:  2320\n",
      "Loss: 940.0544646649187\n",
      "Training step:  2321\n",
      "Loss: 940.0470115743188\n",
      "Training step:  2322\n",
      "Loss: 940.0370859840572\n",
      "Training step:  2323\n",
      "Loss: 940.0304481784443\n",
      "Training step:  2324\n",
      "Loss: 940.0199620983874\n",
      "Training step:  2325\n",
      "Loss: 940.0137099269829\n",
      "Training step:  2326\n",
      "Loss: 940.002899385254\n",
      "Training step:  2327\n",
      "Loss: 939.9958565356208\n",
      "Training step:  2328\n",
      "Loss: 939.9857641522041\n",
      "Training step:  2329\n",
      "Loss: 939.9793934170497\n",
      "Training step:  2330\n",
      "Loss: 939.9687412854347\n",
      "Training step:  2331\n",
      "Loss: 939.9620026744248\n",
      "Training step:  2332\n",
      "Loss: 939.9517565499318\n",
      "Training step:  2333\n",
      "Loss: 939.9456056547365\n",
      "Training step:  2334\n",
      "Loss: 939.9348023061566\n",
      "Training step:  2335\n",
      "Loss: 939.9267821295055\n",
      "Training step:  2336\n",
      "Loss: 939.9180533979356\n",
      "Training step:  2337\n",
      "Loss: 939.9105034702186\n",
      "Training step:  2338\n",
      "Loss: 939.9008592605223\n",
      "Training step:  2339\n",
      "Loss: 939.8941122492266\n",
      "Training step:  2340\n",
      "Loss: 939.8839253913562\n",
      "Training step:  2341\n",
      "Loss: 939.8778086756613\n",
      "Training step:  2342\n",
      "Loss: 939.8670712476076\n",
      "Training step:  2343\n",
      "Loss: 939.8597807059036\n",
      "Training step:  2344\n",
      "Loss: 939.8501951546249\n",
      "Training step:  2345\n",
      "Loss: 939.8434669458929\n",
      "Training step:  2346\n",
      "Loss: 939.833333464799\n",
      "Training step:  2347\n",
      "Loss: 939.8271360931686\n",
      "Training step:  2348\n",
      "Loss: 939.8165525961684\n",
      "Training step:  2349\n",
      "Loss: 939.8095893012787\n",
      "Training step:  2350\n",
      "Loss: 939.7996977337713\n",
      "Training step:  2351\n",
      "Loss: 939.7933876482982\n",
      "Training step:  2352\n",
      "Loss: 939.7829559710408\n",
      "Training step:  2353\n",
      "Loss: 939.7762883876984\n",
      "Training step:  2354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 939.766240155953\n",
      "Training step:  2355\n",
      "Loss: 939.7600509638236\n",
      "Training step:  2356\n",
      "Loss: 939.7495579786971\n",
      "Training step:  2357\n",
      "Loss: 939.7427134692342\n",
      "Training step:  2358\n",
      "Loss: 939.7327946564927\n",
      "Training step:  2359\n",
      "Loss: 939.7266161922902\n",
      "Training step:  2360\n",
      "Loss: 939.7161624787445\n",
      "Training step:  2361\n",
      "Loss: 939.7093052963818\n",
      "Training step:  2362\n",
      "Loss: 939.6994522011963\n",
      "Training step:  2363\n",
      "Loss: 939.6932518971041\n",
      "Training step:  2364\n",
      "Loss: 939.6828679402075\n",
      "Training step:  2365\n",
      "Loss: 939.6763055940806\n",
      "Training step:  2366\n",
      "Loss: 939.6662984648447\n",
      "Training step:  2367\n",
      "Loss: 939.6602158681658\n",
      "Training step:  2368\n",
      "Loss: 939.649771993103\n",
      "Training step:  2369\n",
      "Loss: 939.642293049687\n",
      "Training step:  2370\n",
      "Loss: 939.6332590411143\n",
      "Training step:  2371\n",
      "Loss: 939.6263989310709\n",
      "Training step:  2372\n",
      "Loss: 939.616585886672\n",
      "Training step:  2373\n",
      "Loss: 939.610466794664\n",
      "Training step:  2374\n",
      "Loss: 939.6001305336878\n",
      "Training step:  2375\n",
      "Loss: 939.5933416773646\n",
      "Training step:  2376\n",
      "Loss: 939.583593172797\n",
      "Training step:  2377\n",
      "Loss: 939.5774530222327\n",
      "Training step:  2378\n",
      "Loss: 939.5671852529614\n",
      "Training step:  2379\n",
      "Loss: 939.5605200040621\n",
      "Training step:  2380\n",
      "Loss: 939.5506882489009\n",
      "Training step:  2381\n",
      "Loss: 939.544590841387\n",
      "Training step:  2382\n",
      "Loss: 939.534331813754\n",
      "Training step:  2383\n",
      "Loss: 939.5275997695828\n",
      "Training step:  2384\n",
      "Loss: 939.517891743059\n",
      "Training step:  2385\n",
      "Loss: 939.5118058937974\n",
      "Training step:  2386\n",
      "Loss: 939.5015849187387\n",
      "Training step:  2387\n",
      "Loss: 939.4948170234006\n",
      "Training step:  2388\n",
      "Loss: 939.4851995371504\n",
      "Training step:  2389\n",
      "Loss: 939.4790640537205\n",
      "Training step:  2390\n",
      "Loss: 939.4689377364715\n",
      "Training step:  2391\n",
      "Loss: 939.4624530723717\n",
      "Training step:  2392\n",
      "Loss: 939.4526893562148\n",
      "Training step:  2393\n",
      "Loss: 939.4466675064755\n",
      "Training step:  2394\n",
      "Loss: 939.4364837409465\n",
      "Training step:  2395\n",
      "Loss: 939.4288137101099\n",
      "Training step:  2396\n",
      "Loss: 939.4204236521366\n",
      "Training step:  2397\n",
      "Loss: 939.4132391901111\n",
      "Training step:  2398\n",
      "Loss: 939.4039711144284\n",
      "Training step:  2399\n",
      "Loss: 939.3975643130655\n",
      "Training step:  2400\n",
      "Loss: 939.387801622572\n",
      "Training step:  2401\n",
      "Loss: 939.3817392476983\n",
      "Training step:  2402\n",
      "Loss: 939.3716870730666\n",
      "Training step:  2403\n",
      "Loss: 939.3650827224286\n",
      "Training step:  2404\n",
      "Loss: 939.3554878822142\n",
      "Training step:  2405\n",
      "Loss: 939.3494264314542\n",
      "Training step:  2406\n",
      "Loss: 939.3394218254753\n",
      "Training step:  2407\n",
      "Loss: 939.3328912749176\n",
      "Training step:  2408\n",
      "Loss: 939.3232666635558\n",
      "Training step:  2409\n",
      "Loss: 939.3172877002044\n",
      "Training step:  2410\n",
      "Loss: 939.3072546755684\n",
      "Training step:  2411\n",
      "Loss: 939.299882116572\n",
      "Training step:  2412\n",
      "Loss: 939.2912761472088\n",
      "Training step:  2413\n",
      "Loss: 939.2844479108776\n",
      "Training step:  2414\n",
      "Loss: 939.275112258051\n",
      "Training step:  2415\n",
      "Loss: 939.2689827853543\n",
      "Training step:  2416\n",
      "Loss: 939.2591608614778\n",
      "Training step:  2417\n",
      "Loss: 939.2527036667337\n",
      "Training step:  2418\n",
      "Loss: 939.2431224510449\n",
      "Training step:  2419\n",
      "Loss: 939.2370876819673\n",
      "Training step:  2420\n",
      "Loss: 939.2272258274082\n",
      "Training step:  2421\n",
      "Loss: 939.2206144065426\n",
      "Training step:  2422\n",
      "Loss: 939.2112502105465\n",
      "Training step:  2423\n",
      "Loss: 939.2052487580331\n",
      "Training step:  2424\n",
      "Loss: 939.195402916707\n",
      "Training step:  2425\n",
      "Loss: 939.1887813803214\n",
      "Training step:  2426\n",
      "Loss: 939.1794774759128\n",
      "Training step:  2427\n",
      "Loss: 939.1734578479026\n",
      "Training step:  2428\n",
      "Loss: 939.1636513691391\n",
      "Training step:  2429\n",
      "Loss: 939.1572637587581\n",
      "Training step:  2430\n",
      "Loss: 939.1476760626996\n",
      "Training step:  2431\n",
      "Loss: 939.1417945608714\n",
      "Training step:  2432\n",
      "Loss: 939.1319247216022\n",
      "Training step:  2433\n",
      "Loss: 939.1253056819057\n",
      "Training step:  2434\n",
      "Loss: 939.1160636074782\n",
      "Training step:  2435\n",
      "Loss: 939.1100628379958\n",
      "Training step:  2436\n",
      "Loss: 939.1003508797044\n",
      "Training step:  2437\n",
      "Loss: 939.0940324991739\n",
      "Training step:  2438\n",
      "Loss: 939.084552782063\n",
      "Training step:  2439\n",
      "Loss: 939.0786443378175\n",
      "Training step:  2440\n",
      "Loss: 939.0688939931231\n",
      "Training step:  2441\n",
      "Loss: 939.0624971884671\n",
      "Training step:  2442\n",
      "Loss: 939.0531491927994\n",
      "Training step:  2443\n",
      "Loss: 939.0472721951776\n",
      "Training step:  2444\n",
      "Loss: 939.0375394160936\n",
      "Training step:  2445\n",
      "Loss: 939.0310263870539\n",
      "Training step:  2446\n",
      "Loss: 939.0218541257074\n",
      "Training step:  2447\n",
      "Loss: 939.0159209352806\n",
      "Training step:  2448\n",
      "Loss: 939.0062868315646\n",
      "Training step:  2449\n",
      "Loss: 939.0000351283953\n",
      "Training step:  2450\n",
      "Loss: 938.9906293024441\n",
      "Training step:  2451\n",
      "Loss: 938.984785241338\n",
      "Training step:  2452\n",
      "Loss: 938.9751136188239\n",
      "Training step:  2453\n",
      "Loss: 938.9681774558113\n",
      "Training step:  2454\n",
      "Loss: 938.9595600359451\n",
      "Training step:  2455\n",
      "Loss: 938.9531011768357\n",
      "Training step:  2456\n",
      "Loss: 938.9439259188492\n",
      "Training step:  2457\n",
      "Loss: 938.9380295345898\n",
      "Training step:  2458\n",
      "Loss: 938.9284788299087\n",
      "Training step:  2459\n",
      "Loss: 938.9220352265195\n",
      "Training step:  2460\n",
      "Loss: 938.9129124671623\n",
      "Training step:  2461\n",
      "Loss: 938.9070052272974\n",
      "Training step:  2462\n",
      "Loss: 938.897509361865\n",
      "Training step:  2463\n",
      "Loss: 938.8912705522223\n",
      "Training step:  2464\n",
      "Loss: 938.8820159175928\n",
      "Training step:  2465\n",
      "Loss: 938.8761761028986\n",
      "Training step:  2466\n",
      "Loss: 938.8666624971906\n",
      "Training step:  2467\n",
      "Loss: 938.8601027787189\n",
      "Training step:  2468\n",
      "Loss: 938.8512078531355\n",
      "Training step:  2469\n",
      "Loss: 938.8452265190087\n",
      "Training step:  2470\n",
      "Loss: 938.8357824637748\n",
      "Training step:  2471\n",
      "Loss: 938.8294904220504\n",
      "Training step:  2472\n",
      "Loss: 938.8203865674485\n",
      "Training step:  2473\n",
      "Loss: 938.8144784113009\n",
      "Training step:  2474\n",
      "Loss: 938.8051127469204\n",
      "Training step:  2475\n",
      "Loss: 938.7989076467894\n",
      "Training step:  2476\n",
      "Loss: 938.7897593180326\n",
      "Training step:  2477\n",
      "Loss: 938.7839450042135\n",
      "Training step:  2478\n",
      "Loss: 938.7745433516986\n",
      "Training step:  2479\n",
      "Loss: 938.768096675999\n",
      "Training step:  2480\n",
      "Loss: 938.759218537724\n",
      "Training step:  2481\n",
      "Loss: 938.7533591972388\n",
      "Training step:  2482\n",
      "Loss: 938.7440370745579\n",
      "Training step:  2483\n",
      "Loss: 938.7378821050384\n",
      "Training step:  2484\n",
      "Loss: 938.7287747355352\n",
      "Training step:  2485\n",
      "Loss: 938.7230090656602\n",
      "Training step:  2486\n",
      "Loss: 938.7136515403707\n",
      "Training step:  2487\n",
      "Loss: 938.706655703523\n",
      "Training step:  2488\n",
      "Loss: 938.6985657382784\n",
      "Training step:  2489\n",
      "Loss: 938.6919983487622\n",
      "Training step:  2490\n",
      "Loss: 938.6832825067553\n",
      "Training step:  2491\n",
      "Loss: 938.6773620054529\n",
      "Training step:  2492\n",
      "Loss: 938.6681102787693\n",
      "Training step:  2493\n",
      "Loss: 938.6618054269459\n",
      "Training step:  2494\n",
      "Loss: 938.6529732497223\n",
      "Training step:  2495\n",
      "Loss: 938.647142837207\n",
      "Training step:  2496\n",
      "Loss: 938.6378571639264\n",
      "Training step:  2497\n",
      "Loss: 938.6303205357458\n",
      "Training step:  2498\n",
      "Loss: 938.6228332852362\n",
      "Training step:  2499\n",
      "Loss: 938.6157698481494\n",
      "Training step:  2500\n",
      "Loss: 938.6075668420715\n",
      "Training step:  2501\n",
      "Loss: 938.6013130087471\n",
      "Training step:  2502\n",
      "Loss: 938.5924670940609\n",
      "Training step:  2503\n",
      "Loss: 938.5867198583935\n",
      "Training step:  2504\n",
      "Loss: 938.5774605735065\n",
      "Training step:  2505\n",
      "Loss: 938.5700714760172\n",
      "Training step:  2506\n",
      "Loss: 938.5626959570536\n",
      "Training step:  2507\n",
      "Loss: 938.555636804847\n",
      "Training step:  2508\n",
      "Loss: 938.5475178189165\n",
      "Training step:  2509\n",
      "Loss: 938.5412620952742\n",
      "Training step:  2510\n",
      "Loss: 938.5325068060331\n",
      "Training step:  2511\n",
      "Loss: 938.5267708843733\n",
      "Training step:  2512\n",
      "Loss: 938.517589882146\n",
      "Training step:  2513\n",
      "Loss: 938.5101016717622\n",
      "Training step:  2514\n",
      "Loss: 938.5029578359341\n",
      "Training step:  2515\n",
      "Loss: 938.4957176091518\n",
      "Training step:  2516\n",
      "Loss: 938.4878426561337\n",
      "Training step:  2517\n",
      "Loss: 938.4813996062477\n",
      "Training step:  2518\n",
      "Loss: 938.4728952435736\n",
      "Training step:  2519\n",
      "Loss: 938.4670526537905\n",
      "Training step:  2520\n",
      "Loss: 938.4580550189715\n",
      "Training step:  2521\n",
      "Loss: 938.4517973626549\n",
      "Training step:  2522\n",
      "Loss: 938.4432330510413\n",
      "Training step:  2523\n",
      "Loss: 938.4374254929875\n",
      "Training step:  2524\n",
      "Loss: 938.4284262406079\n",
      "Training step:  2525\n",
      "Loss: 938.4220536355474\n",
      "Training step:  2526\n",
      "Loss: 938.4136653457057\n",
      "Training step:  2527\n",
      "Loss: 938.4077893768809\n",
      "Training step:  2528\n",
      "Loss: 938.3988970763941\n",
      "Training step:  2529\n",
      "Loss: 938.3927167843357\n",
      "Training step:  2530\n",
      "Loss: 938.3841600927767\n",
      "Training step:  2531\n",
      "Loss: 938.378437498562\n",
      "Training step:  2532\n",
      "Loss: 938.3693795682219\n",
      "Training step:  2533\n",
      "Loss: 938.3621348302634\n",
      "Training step:  2534\n",
      "Loss: 938.3549629336361\n",
      "Training step:  2535\n",
      "Loss: 938.3479736284961\n",
      "Training step:  2536\n",
      "Loss: 938.3401266460168\n",
      "Training step:  2537\n",
      "Loss: 938.3338690753803\n",
      "Training step:  2538\n",
      "Loss: 938.3254119159185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  2539\n",
      "Loss: 938.3197355005785\n",
      "Training step:  2540\n",
      "Loss: 938.3108001593012\n",
      "Training step:  2541\n",
      "Loss: 938.3045538633652\n",
      "Training step:  2542\n",
      "Loss: 938.2962152382094\n",
      "Training step:  2543\n",
      "Loss: 938.2904543687938\n",
      "Training step:  2544\n",
      "Loss: 938.2816237635478\n",
      "Training step:  2545\n",
      "Loss: 938.2755868420606\n",
      "Training step:  2546\n",
      "Loss: 938.2670612749463\n",
      "Training step:  2547\n",
      "Loss: 938.2613668713907\n",
      "Training step:  2548\n",
      "Loss: 938.2525206709043\n",
      "Training step:  2549\n",
      "Loss: 938.2463608906418\n",
      "Training step:  2550\n",
      "Loss: 938.2380148729616\n",
      "Training step:  2551\n",
      "Loss: 938.2323528375098\n",
      "Training step:  2552\n",
      "Loss: 938.2235207960091\n",
      "Training step:  2553\n",
      "Loss: 938.2169236869684\n",
      "Training step:  2554\n",
      "Loss: 938.2091212287987\n",
      "Training step:  2555\n",
      "Loss: 938.2030175237164\n",
      "Training step:  2556\n",
      "Loss: 938.1946228346737\n",
      "Training step:  2557\n",
      "Loss: 938.1890040940674\n",
      "Training step:  2558\n",
      "Loss: 938.1801961943934\n",
      "Training step:  2559\n",
      "Loss: 938.1729878866829\n",
      "Training step:  2560\n",
      "Loss: 938.1658733559296\n",
      "Training step:  2561\n",
      "Loss: 938.1590714855179\n",
      "Training step:  2562\n",
      "Loss: 938.1513116023854\n",
      "Training step:  2563\n",
      "Loss: 938.1452445377004\n",
      "Training step:  2564\n",
      "Loss: 938.1368978473182\n",
      "Training step:  2565\n",
      "Loss: 938.1312935853338\n",
      "Training step:  2566\n",
      "Loss: 938.1225404839505\n",
      "Training step:  2567\n",
      "Loss: 938.1161764568603\n",
      "Training step:  2568\n",
      "Loss: 938.1082798464306\n",
      "Training step:  2569\n",
      "Loss: 938.1023136884363\n",
      "Training step:  2570\n",
      "Loss: 938.0939435082552\n",
      "Training step:  2571\n",
      "Loss: 938.0883452878228\n",
      "Training step:  2572\n",
      "Loss: 938.0796658636476\n",
      "Training step:  2573\n",
      "Loss: 938.0727897147573\n",
      "Training step:  2574\n",
      "Loss: 938.0655809562852\n",
      "Training step:  2575\n",
      "Loss: 938.059084314299\n",
      "Training step:  2576\n",
      "Loss: 938.0512341717481\n",
      "Training step:  2577\n",
      "Loss: 938.0452982118939\n",
      "Training step:  2578\n",
      "Loss: 938.0369801517679\n",
      "Training step:  2579\n",
      "Loss: 938.0314088958737\n",
      "Training step:  2580\n",
      "Loss: 938.0227852975007\n",
      "Training step:  2581\n",
      "Loss: 938.0166914006033\n",
      "Training step:  2582\n",
      "Loss: 938.0086302491576\n",
      "Training step:  2583\n",
      "Loss: 938.0029978105044\n",
      "Training step:  2584\n",
      "Loss: 937.9944733019448\n",
      "Training step:  2585\n",
      "Loss: 937.9885303742476\n",
      "Training step:  2586\n",
      "Loss: 937.9803439854179\n",
      "Training step:  2587\n",
      "Loss: 937.9747196628122\n",
      "Training step:  2588\n",
      "Loss: 937.9662312774462\n",
      "Training step:  2589\n",
      "Loss: 937.960343569659\n",
      "Training step:  2590\n",
      "Loss: 937.952141079912\n",
      "Training step:  2591\n",
      "Loss: 937.9465772748223\n",
      "Training step:  2592\n",
      "Loss: 937.9380746643894\n",
      "Training step:  2593\n",
      "Loss: 937.9319923783871\n",
      "Training step:  2594\n",
      "Loss: 937.9240501062728\n",
      "Training step:  2595\n",
      "Loss: 937.9184164948649\n",
      "Training step:  2596\n",
      "Loss: 937.9100190694145\n",
      "Training step:  2597\n",
      "Loss: 937.9041298144548\n",
      "Training step:  2598\n",
      "Loss: 937.8960148909047\n",
      "Training step:  2599\n",
      "Loss: 937.8904429170532\n",
      "Training step:  2600\n",
      "Loss: 937.8820314146024\n",
      "Training step:  2601\n",
      "Loss: 937.8760304565071\n",
      "Training step:  2602\n",
      "Loss: 937.8680820647547\n",
      "Training step:  2603\n",
      "Loss: 937.8624711748865\n",
      "Training step:  2604\n",
      "Loss: 937.8541369441067\n",
      "Training step:  2605\n",
      "Loss: 937.8483512760407\n",
      "Training step:  2606\n",
      "Loss: 937.8402118730554\n",
      "Training step:  2607\n",
      "Loss: 937.8347515982115\n",
      "Training step:  2608\n",
      "Loss: 937.8263192813247\n",
      "Training step:  2609\n",
      "Loss: 937.8193075724381\n",
      "Training step:  2610\n",
      "Loss: 937.812549744647\n",
      "Training step:  2611\n",
      "Loss: 937.8058978117841\n",
      "Training step:  2612\n",
      "Loss: 937.7985123841245\n",
      "Training step:  2613\n",
      "Loss: 937.7925498858115\n",
      "Training step:  2614\n",
      "Loss: 937.7846201989161\n",
      "Training step:  2615\n",
      "Loss: 937.7791069083099\n",
      "Training step:  2616\n",
      "Loss: 937.7707983602409\n",
      "Training step:  2617\n",
      "Loss: 937.7648969165027\n",
      "Training step:  2618\n",
      "Loss: 937.757012349165\n",
      "Training step:  2619\n",
      "Loss: 937.7514940715524\n",
      "Training step:  2620\n",
      "Loss: 937.7432328833075\n",
      "Training step:  2621\n",
      "Loss: 937.7373531997293\n",
      "Training step:  2622\n",
      "Loss: 937.7294872289762\n",
      "Training step:  2623\n",
      "Loss: 937.7239927691556\n",
      "Training step:  2624\n",
      "Loss: 937.715752443617\n",
      "Training step:  2625\n",
      "Loss: 937.7099431946997\n",
      "Training step:  2626\n",
      "Loss: 937.7020419188368\n",
      "Training step:  2627\n",
      "Loss: 937.6965332285716\n",
      "Training step:  2628\n",
      "Loss: 937.6883475734029\n",
      "Training step:  2629\n",
      "Loss: 937.6825910107016\n",
      "Training step:  2630\n",
      "Loss: 937.6746748958083\n",
      "Training step:  2631\n",
      "Loss: 937.6692240929082\n",
      "Training step:  2632\n",
      "Loss: 937.6610253666674\n",
      "Training step:  2633\n",
      "Loss: 937.654958469926\n",
      "Training step:  2634\n",
      "Loss: 937.6474105604424\n",
      "Training step:  2635\n",
      "Loss: 937.6417565418924\n",
      "Training step:  2636\n",
      "Loss: 937.6337796185611\n",
      "Training step:  2637\n",
      "Loss: 937.6280971982767\n",
      "Training step:  2638\n",
      "Loss: 937.6201865689299\n",
      "Training step:  2639\n",
      "Loss: 937.6148114779497\n",
      "Training step:  2640\n",
      "Loss: 937.6066216909342\n",
      "Training step:  2641\n",
      "Loss: 937.5999416678034\n",
      "Training step:  2642\n",
      "Loss: 937.5932405130008\n",
      "Training step:  2643\n",
      "Loss: 937.5868714365912\n",
      "Training step:  2644\n",
      "Loss: 937.5795679501606\n",
      "Training step:  2645\n",
      "Loss: 937.5737433751056\n",
      "Training step:  2646\n",
      "Loss: 937.5660169628702\n",
      "Training step:  2647\n",
      "Loss: 937.5606024052948\n",
      "Training step:  2648\n",
      "Loss: 937.5525290285431\n",
      "Training step:  2649\n",
      "Loss: 937.5467369425747\n",
      "Training step:  2650\n",
      "Loss: 937.5390679665609\n",
      "Training step:  2651\n",
      "Loss: 937.5336492592534\n",
      "Training step:  2652\n",
      "Loss: 937.5256213193101\n",
      "Training step:  2653\n",
      "Loss: 937.5198979014675\n",
      "Training step:  2654\n",
      "Loss: 937.5121952823865\n",
      "Training step:  2655\n",
      "Loss: 937.5067627645791\n",
      "Training step:  2656\n",
      "Loss: 937.4987874819899\n",
      "Training step:  2657\n",
      "Loss: 937.4931150562702\n",
      "Training step:  2658\n",
      "Loss: 937.4853984243363\n",
      "Training step:  2659\n",
      "Loss: 937.4800220320211\n",
      "Training step:  2660\n",
      "Loss: 937.4720344327178\n",
      "Training step:  2661\n",
      "Loss: 937.4658155881401\n",
      "Training step:  2662\n",
      "Loss: 937.4587693015744\n",
      "Training step:  2663\n",
      "Loss: 937.4529483308638\n",
      "Training step:  2664\n",
      "Loss: 937.4453986685787\n",
      "Training step:  2665\n",
      "Loss: 937.4399923740345\n",
      "Training step:  2666\n",
      "Loss: 937.4320911718047\n",
      "Training step:  2667\n",
      "Loss: 937.4264311822329\n",
      "Training step:  2668\n",
      "Loss: 937.4188038961415\n",
      "Training step:  2669\n",
      "Loss: 937.4134324367427\n",
      "Training step:  2670\n",
      "Loss: 937.4055381967127\n",
      "Training step:  2671\n",
      "Loss: 937.3998359787548\n",
      "Training step:  2672\n",
      "Loss: 937.3922959311909\n",
      "Training step:  2673\n",
      "Loss: 937.386870870248\n",
      "Training step:  2674\n",
      "Loss: 937.3790653799919\n",
      "Training step:  2675\n",
      "Loss: 937.373484047232\n",
      "Training step:  2676\n",
      "Loss: 937.3658543750661\n",
      "Training step:  2677\n",
      "Loss: 937.3605658206337\n",
      "Training step:  2678\n",
      "Loss: 937.3526724705068\n",
      "Training step:  2679\n",
      "Loss: 937.345995590759\n",
      "Training step:  2680\n",
      "Loss: 937.3393495593932\n",
      "Training step:  2681\n",
      "Loss: 937.3332824370343\n",
      "Training step:  2682\n",
      "Loss: 937.3260689438922\n",
      "Training step:  2683\n",
      "Loss: 937.3205156865524\n",
      "Training step:  2684\n",
      "Loss: 937.3129026208678\n",
      "Training step:  2685\n",
      "Loss: 937.3076487962247\n",
      "Training step:  2686\n",
      "Loss: 937.2997886011259\n",
      "Training step:  2687\n",
      "Loss: 937.294076455075\n",
      "Training step:  2688\n",
      "Loss: 937.2867215267039\n",
      "Training step:  2689\n",
      "Loss: 937.2813908759329\n",
      "Training step:  2690\n",
      "Loss: 937.2736406654182\n",
      "Training step:  2691\n",
      "Loss: 937.2681484703251\n",
      "Training step:  2692\n",
      "Loss: 937.2605904743579\n",
      "Training step:  2693\n",
      "Loss: 937.2553755955216\n",
      "Training step:  2694\n",
      "Loss: 937.2475602477481\n",
      "Training step:  2695\n",
      "Loss: 937.2419933319887\n",
      "Training step:  2696\n",
      "Loss: 937.2345559231492\n",
      "Training step:  2697\n",
      "Loss: 937.2293382828406\n",
      "Training step:  2698\n",
      "Loss: 937.221565962982\n",
      "Training step:  2699\n",
      "Loss: 937.2160626785553\n",
      "Training step:  2700\n",
      "Loss: 937.2085944498738\n",
      "Training step:  2701\n",
      "Loss: 937.2033646610631\n",
      "Training step:  2702\n",
      "Loss: 937.1956421061285\n",
      "Training step:  2703\n",
      "Loss: 937.1901599971253\n",
      "Training step:  2704\n",
      "Loss: 937.1827086762423\n",
      "Training step:  2705\n",
      "Loss: 937.1775005332487\n",
      "Training step:  2706\n",
      "Loss: 937.1697799508646\n",
      "Training step:  2707\n",
      "Loss: 937.1643267569775\n",
      "Training step:  2708\n",
      "Loss: 937.1568855135358\n",
      "Training step:  2709\n",
      "Loss: 937.1517042095579\n",
      "Training step:  2710\n",
      "Loss: 937.1440117214025\n",
      "Training step:  2711\n",
      "Loss: 937.1385675003058\n",
      "Training step:  2712\n",
      "Loss: 937.1311559381082\n",
      "Training step:  2713\n",
      "Loss: 937.1259824884623\n",
      "Training step:  2714\n",
      "Loss: 937.1183211844932\n",
      "Training step:  2715\n",
      "Loss: 937.1128695489093\n",
      "Training step:  2716\n",
      "Loss: 937.105505247896\n",
      "Training step:  2717\n",
      "Loss: 937.1003207690683\n",
      "Training step:  2718\n",
      "Loss: 937.0927081939788\n",
      "Training step:  2719\n",
      "Loss: 937.0872655411233\n",
      "Training step:  2720\n",
      "Loss: 937.0799305640659\n",
      "Training step:  2721\n",
      "Loss: 937.0747540801458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  2722\n",
      "Loss: 937.0671723143462\n",
      "Training step:  2723\n",
      "Loss: 937.0617506614132\n",
      "Training step:  2724\n",
      "Loss: 937.0544322546606\n",
      "Training step:  2725\n",
      "Loss: 937.0492771828305\n",
      "Training step:  2726\n",
      "Loss: 937.0417134826454\n",
      "Training step:  2727\n",
      "Loss: 937.0361506944067\n",
      "Training step:  2728\n",
      "Loss: 937.0290016562143\n",
      "Training step:  2729\n",
      "Loss: 937.0237828308653\n",
      "Training step:  2730\n",
      "Loss: 937.0163146939768\n",
      "Training step:  2731\n",
      "Loss: 937.0109554053295\n",
      "Training step:  2732\n",
      "Loss: 937.0036493294925\n",
      "Training step:  2733\n",
      "Loss: 936.9985577456457\n",
      "Training step:  2734\n",
      "Loss: 936.9910093714491\n",
      "Training step:  2735\n",
      "Loss: 936.9848520544876\n",
      "Training step:  2736\n",
      "Loss: 936.9784549565362\n",
      "Training step:  2737\n",
      "Loss: 936.9726056766366\n",
      "Training step:  2738\n",
      "Loss: 936.9657388213332\n",
      "Training step:  2739\n",
      "Loss: 936.9603579482053\n",
      "Training step:  2740\n",
      "Loss: 936.9531245107249\n",
      "Training step:  2741\n",
      "Loss: 936.948016641881\n",
      "Training step:  2742\n",
      "Loss: 936.9405560466355\n",
      "Training step:  2743\n",
      "Loss: 936.9350199897319\n",
      "Training step:  2744\n",
      "Loss: 936.9280244733769\n",
      "Training step:  2745\n",
      "Loss: 936.9228500354415\n",
      "Training step:  2746\n",
      "Loss: 936.9154910714007\n",
      "Training step:  2747\n",
      "Loss: 936.9101766029659\n",
      "Training step:  2748\n",
      "Loss: 936.9029759527649\n",
      "Training step:  2749\n",
      "Loss: 936.8979251543747\n",
      "Training step:  2750\n",
      "Loss: 936.8904879715242\n",
      "Training step:  2751\n",
      "Loss: 936.8842557399315\n",
      "Training step:  2752\n",
      "Loss: 936.8780591326074\n",
      "Training step:  2753\n",
      "Loss: 936.872149876431\n",
      "Training step:  2754\n",
      "Loss: 936.8654824024915\n",
      "Training step:  2755\n",
      "Loss: 936.8600312530551\n",
      "Training step:  2756\n",
      "Loss: 936.8530062356817\n",
      "Training step:  2757\n",
      "Loss: 936.8479042397884\n",
      "Training step:  2758\n",
      "Loss: 936.8405851066909\n",
      "Training step:  2759\n",
      "Loss: 936.835070527475\n",
      "Training step:  2760\n",
      "Loss: 936.8282055489854\n",
      "Training step:  2761\n",
      "Loss: 936.8230376230679\n",
      "Training step:  2762\n",
      "Loss: 936.8158177687934\n",
      "Training step:  2763\n",
      "Loss: 936.810587194152\n",
      "Training step:  2764\n",
      "Loss: 936.8034513224716\n",
      "Training step:  2765\n",
      "Loss: 936.7981847883117\n",
      "Training step:  2766\n",
      "Loss: 936.7911042537345\n",
      "Training step:  2767\n",
      "Loss: 936.7860938107217\n",
      "Training step:  2768\n",
      "Loss: 936.7787681623626\n",
      "Training step:  2769\n",
      "Loss: 936.7730626686999\n",
      "Training step:  2770\n",
      "Loss: 936.766459479158\n",
      "Training step:  2771\n",
      "Loss: 936.761088444641\n",
      "Training step:  2772\n",
      "Loss: 936.7541372503141\n",
      "Training step:  2773\n",
      "Loss: 936.7490420160791\n",
      "Training step:  2774\n",
      "Loss: 936.7418625440199\n",
      "Training step:  2775\n",
      "Loss: 936.736574153975\n",
      "Training step:  2776\n",
      "Loss: 936.729612156542\n",
      "Training step:  2777\n",
      "Loss: 936.7245661456348\n",
      "Training step:  2778\n",
      "Loss: 936.717377294265\n",
      "Training step:  2779\n",
      "Loss: 936.7120439161182\n",
      "Training step:  2780\n",
      "Loss: 936.7051681111676\n",
      "Training step:  2781\n",
      "Loss: 936.700067842115\n",
      "Training step:  2782\n",
      "Loss: 936.6929664544514\n",
      "Training step:  2783\n",
      "Loss: 936.6877377652321\n",
      "Training step:  2784\n",
      "Loss: 936.6807865511272\n",
      "Training step:  2785\n",
      "Loss: 936.6758044326875\n",
      "Training step:  2786\n",
      "Loss: 936.6686291392323\n",
      "Training step:  2787\n",
      "Loss: 936.6631367424197\n",
      "Training step:  2788\n",
      "Loss: 936.6565007267045\n",
      "Training step:  2789\n",
      "Loss: 936.6513372345485\n",
      "Training step:  2790\n",
      "Loss: 936.6443615575398\n",
      "Training step:  2791\n",
      "Loss: 936.6391755399947\n",
      "Training step:  2792\n",
      "Loss: 936.6322532147407\n",
      "Training step:  2793\n",
      "Loss: 936.6273130476819\n",
      "Training step:  2794\n",
      "Loss: 936.6201693585706\n",
      "Training step:  2795\n",
      "Loss: 936.6147439909232\n",
      "Training step:  2796\n",
      "Loss: 936.6081048386964\n",
      "Training step:  2797\n",
      "Loss: 936.6030194801865\n",
      "Training step:  2798\n",
      "Loss: 936.5960444653897\n",
      "Training step:  2799\n",
      "Loss: 936.5909188816909\n",
      "Training step:  2800\n",
      "Loss: 936.5840079480275\n",
      "Training step:  2801\n",
      "Loss: 936.5788485653212\n",
      "Training step:  2802\n",
      "Loss: 936.5719902340257\n",
      "Training step:  2803\n",
      "Loss: 936.5670727969932\n",
      "Training step:  2804\n",
      "Loss: 936.5599964091505\n",
      "Training step:  2805\n",
      "Loss: 936.5546616434084\n",
      "Training step:  2806\n",
      "Loss: 936.5480116930715\n",
      "Training step:  2807\n",
      "Loss: 936.5429783885235\n",
      "Training step:  2808\n",
      "Loss: 936.536044436404\n",
      "Training step:  2809\n",
      "Loss: 936.5309683358315\n",
      "Training step:  2810\n",
      "Loss: 936.5240975920132\n",
      "Training step:  2811\n",
      "Loss: 936.5189882292734\n",
      "Training step:  2812\n",
      "Loss: 936.5121693847259\n",
      "Training step:  2813\n",
      "Loss: 936.5073006458816\n",
      "Training step:  2814\n",
      "Loss: 936.5002670384486\n",
      "Training step:  2815\n",
      "Loss: 936.494361679929\n",
      "Training step:  2816\n",
      "Loss: 936.4883777637499\n",
      "Training step:  2817\n",
      "Loss: 936.4827963351514\n",
      "Training step:  2818\n",
      "Loss: 936.4763484690593\n",
      "Training step:  2819\n",
      "Loss: 936.4712439733249\n",
      "Training step:  2820\n",
      "Loss: 936.4644692630501\n",
      "Training step:  2821\n",
      "Loss: 936.4596073374422\n",
      "Training step:  2822\n",
      "Loss: 936.4526375880112\n",
      "Training step:  2823\n",
      "Loss: 936.4474152715671\n",
      "Training step:  2824\n",
      "Loss: 936.4408318230969\n",
      "Training step:  2825\n",
      "Loss: 936.435884370468\n",
      "Training step:  2826\n",
      "Loss: 936.4290245120183\n",
      "Training step:  2827\n",
      "Loss: 936.4239771575537\n",
      "Training step:  2828\n",
      "Loss: 936.417239586105\n",
      "Training step:  2829\n",
      "Loss: 936.4124248153029\n",
      "Training step:  2830\n",
      "Loss: 936.4054776229926\n",
      "Training step:  2831\n",
      "Loss: 936.4002132056239\n",
      "Training step:  2832\n",
      "Loss: 936.3937303931696\n",
      "Training step:  2833\n",
      "Loss: 936.3887971165332\n",
      "Training step:  2834\n",
      "Loss: 936.3819959385045\n",
      "Training step:  2835\n",
      "Loss: 936.3768872213321\n",
      "Training step:  2836\n",
      "Loss: 936.3702851838217\n",
      "Training step:  2837\n",
      "Loss: 936.3653980319443\n",
      "Training step:  2838\n",
      "Loss: 936.3585887569943\n",
      "Training step:  2839\n",
      "Loss: 936.3534895331806\n",
      "Training step:  2840\n",
      "Loss: 936.3469128947844\n",
      "Training step:  2841\n",
      "Loss: 936.342034541232\n",
      "Training step:  2842\n",
      "Loss: 936.335251908488\n",
      "Training step:  2843\n",
      "Loss: 936.3301623450586\n",
      "Training step:  2844\n",
      "Loss: 936.3236109812236\n",
      "Training step:  2845\n",
      "Loss: 936.3187414496768\n",
      "Training step:  2846\n",
      "Loss: 936.3119853272347\n",
      "Training step:  2847\n",
      "Loss: 936.3069054415932\n",
      "Training step:  2848\n",
      "Loss: 936.3003792285565\n",
      "Training step:  2849\n",
      "Loss: 936.295518542187\n",
      "Training step:  2850\n",
      "Loss: 936.2887887989735\n",
      "Training step:  2851\n",
      "Loss: 936.2837503612739\n",
      "Training step:  2852\n",
      "Loss: 936.2772151763052\n",
      "Training step:  2853\n",
      "Loss: 936.2723996628781\n",
      "Training step:  2854\n",
      "Loss: 936.2656622194661\n",
      "Training step:  2855\n",
      "Loss: 936.2605505308752\n",
      "Training step:  2856\n",
      "Loss: 936.2541091735419\n",
      "Training step:  2857\n",
      "Loss: 936.2492282031844\n",
      "Training step:  2858\n",
      "Loss: 936.2425853588677\n",
      "Training step:  2859\n",
      "Loss: 936.2375985438871\n",
      "Training step:  2860\n",
      "Loss: 936.2310798418346\n",
      "Training step:  2861\n",
      "Loss: 936.2263165660141\n",
      "Training step:  2862\n",
      "Loss: 936.2195980755663\n",
      "Training step:  2863\n",
      "Loss: 936.2139761786524\n",
      "Training step:  2864\n",
      "Loss: 936.2080682859695\n",
      "Training step:  2865\n",
      "Loss: 936.2028384075372\n",
      "Training step:  2866\n",
      "Loss: 936.1965643536299\n",
      "Training step:  2867\n",
      "Loss: 936.1916948980894\n",
      "Training step:  2868\n",
      "Loss: 936.1851182014005\n",
      "Training step:  2869\n",
      "Loss: 936.180166962944\n",
      "Training step:  2870\n",
      "Loss: 936.1736998842313\n",
      "Training step:  2871\n",
      "Loss: 936.1689528504949\n",
      "Training step:  2872\n",
      "Loss: 936.162299093405\n",
      "Training step:  2873\n",
      "Loss: 936.1573009976979\n",
      "Training step:  2874\n",
      "Loss: 936.1509198617862\n",
      "Training step:  2875\n",
      "Loss: 936.1461270218314\n",
      "Training step:  2876\n",
      "Loss: 936.1395501891195\n",
      "Training step:  2877\n",
      "Loss: 936.1346304338018\n",
      "Training step:  2878\n",
      "Loss: 936.1282000560016\n",
      "Training step:  2879\n",
      "Loss: 936.1234955565295\n",
      "Training step:  2880\n",
      "Loss: 936.1168707662519\n",
      "Training step:  2881\n",
      "Loss: 936.1118797737468\n",
      "Training step:  2882\n",
      "Loss: 936.1055397631148\n",
      "Training step:  2883\n",
      "Loss: 936.1007725952668\n",
      "Training step:  2884\n",
      "Loss: 936.0942391532436\n",
      "Training step:  2885\n",
      "Loss: 936.0893072422862\n",
      "Training step:  2886\n",
      "Loss: 936.0829589064342\n",
      "Training step:  2887\n",
      "Loss: 936.0782352373376\n",
      "Training step:  2888\n",
      "Loss: 936.0716947676328\n",
      "Training step:  2889\n",
      "Loss: 936.0667263889347\n",
      "Training step:  2890\n",
      "Loss: 936.060430730111\n",
      "Training step:  2891\n",
      "Loss: 936.0556853914429\n",
      "Training step:  2892\n",
      "Loss: 936.0491986953234\n",
      "Training step:  2893\n",
      "Loss: 936.0442983099471\n",
      "Training step:  2894\n",
      "Loss: 936.0379847792738\n",
      "Training step:  2895\n",
      "Loss: 936.0332929393059\n",
      "Training step:  2896\n",
      "Loss: 936.0267895955045\n",
      "Training step:  2897\n",
      "Loss: 936.0218861014163\n",
      "Training step:  2898\n",
      "Loss: 936.0156099679804\n",
      "Training step:  2899\n",
      "Loss: 936.0109125880108\n",
      "Training step:  2900\n",
      "Loss: 936.0044477616101\n",
      "Training step:  2901\n",
      "Loss: 935.9995539272101\n",
      "Training step:  2902\n",
      "Loss: 935.9933015132941\n",
      "Training step:  2903\n",
      "Loss: 935.9886130885532\n",
      "Training step:  2904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 935.9821731152574\n",
      "Training step:  2905\n",
      "Loss: 935.9773183035956\n",
      "Training step:  2906\n",
      "Loss: 935.9710581228827\n",
      "Training step:  2907\n",
      "Loss: 935.9664121713159\n",
      "Training step:  2908\n",
      "Loss: 935.9599656047588\n",
      "Training step:  2909\n",
      "Loss: 935.9546266577511\n",
      "Training step:  2910\n",
      "Loss: 935.9488252961693\n",
      "Training step:  2911\n",
      "Loss: 935.9438022770039\n",
      "Training step:  2912\n",
      "Loss: 935.9376593618433\n",
      "Training step:  2913\n",
      "Loss: 935.9329357622898\n",
      "Training step:  2914\n",
      "Loss: 935.9266069762216\n",
      "Training step:  2915\n",
      "Loss: 935.921813710483\n",
      "Training step:  2916\n",
      "Loss: 935.9155743334453\n",
      "Training step:  2917\n",
      "Loss: 935.9109876597479\n",
      "Training step:  2918\n",
      "Loss: 935.904564741388\n",
      "Training step:  2919\n",
      "Loss: 935.8993544615204\n",
      "Training step:  2920\n",
      "Loss: 935.8935576522961\n",
      "Training step:  2921\n",
      "Loss: 935.8886166043924\n",
      "Training step:  2922\n",
      "Loss: 935.8825476492607\n",
      "Training step:  2923\n",
      "Loss: 935.8778287283897\n",
      "Training step:  2924\n",
      "Loss: 935.8715776835926\n",
      "Training step:  2925\n",
      "Loss: 935.8668244327324\n",
      "Training step:  2926\n",
      "Loss: 935.8606270216584\n",
      "Training step:  2927\n",
      "Loss: 935.8558376469103\n",
      "Training step:  2928\n",
      "Loss: 935.8496936551815\n",
      "Training step:  2929\n",
      "Loss: 935.8451055159387\n",
      "Training step:  2930\n",
      "Loss: 935.8387812359755\n",
      "Training step:  2931\n",
      "Loss: 935.8338972253085\n",
      "Training step:  2932\n",
      "Loss: 935.8278264366551\n",
      "Training step:  2933\n",
      "Loss: 935.823193021745\n",
      "Training step:  2934\n",
      "Loss: 935.8169425938669\n",
      "Training step:  2935\n",
      "Loss: 935.8121236566982\n",
      "Training step:  2936\n",
      "Loss: 935.806079220031\n",
      "Training step:  2937\n",
      "Loss: 935.8014508578843\n",
      "Training step:  2938\n",
      "Loss: 935.7952282147351\n",
      "Training step:  2939\n",
      "Loss: 935.7904467585936\n",
      "Training step:  2940\n",
      "Loss: 935.7843951384712\n",
      "Training step:  2941\n",
      "Loss: 935.7798077689471\n",
      "Training step:  2942\n",
      "Loss: 935.7735790581165\n",
      "Training step:  2943\n",
      "Loss: 935.7687957108202\n",
      "Training step:  2944\n",
      "Loss: 935.7627793420259\n",
      "Training step:  2945\n",
      "Loss: 935.7581875550014\n",
      "Training step:  2946\n",
      "Loss: 935.7519951416523\n",
      "Training step:  2947\n",
      "Loss: 935.747248899606\n",
      "Training step:  2948\n",
      "Loss: 935.7412255384592\n",
      "Training step:  2949\n",
      "Loss: 935.7366743379273\n",
      "Training step:  2950\n",
      "Loss: 935.7304760347387\n",
      "Training step:  2951\n",
      "Loss: 935.725591666505\n",
      "Training step:  2952\n",
      "Loss: 935.7196905359872\n",
      "Training step:  2953\n",
      "Loss: 935.7150375945419\n",
      "Training step:  2954\n",
      "Loss: 935.7089648279133\n",
      "Training step:  2955\n",
      "Loss: 935.7042879308065\n",
      "Training step:  2956\n",
      "Loss: 935.6982576362961\n",
      "Training step:  2957\n",
      "Loss: 935.6935551105903\n",
      "Training step:  2958\n",
      "Loss: 935.6875671230717\n",
      "Training step:  2959\n",
      "Loss: 935.6830589065519\n",
      "Training step:  2960\n",
      "Loss: 935.6768986266235\n",
      "Training step:  2961\n",
      "Loss: 935.6718299915503\n",
      "Training step:  2962\n",
      "Loss: 935.6661813497974\n",
      "Training step:  2963\n",
      "Loss: 935.6614240524302\n",
      "Training step:  2964\n",
      "Loss: 935.6555187994014\n",
      "Training step:  2965\n",
      "Loss: 935.6509686379052\n",
      "Training step:  2966\n",
      "Loss: 935.6448925720133\n",
      "Training step:  2967\n",
      "Loss: 935.6401668306835\n",
      "Training step:  2968\n",
      "Loss: 935.6342264266457\n",
      "Training step:  2969\n",
      "Loss: 935.6297382948275\n",
      "Training step:  2970\n",
      "Loss: 935.6236355939092\n",
      "Training step:  2971\n",
      "Loss: 935.6189278957718\n",
      "Training step:  2972\n",
      "Loss: 935.6130612081391\n",
      "Training step:  2973\n",
      "Loss: 935.6085350386514\n",
      "Training step:  2974\n",
      "Loss: 935.6024995952071\n",
      "Training step:  2975\n",
      "Loss: 935.5978280851433\n",
      "Training step:  2976\n",
      "Loss: 935.591954900092\n",
      "Training step:  2977\n",
      "Loss: 935.5874681036655\n",
      "Training step:  2978\n",
      "Loss: 935.5814272203392\n",
      "Training step:  2979\n",
      "Loss: 935.5767918130967\n",
      "Training step:  2980\n",
      "Loss: 935.5709122813599\n",
      "Training step:  2981\n",
      "Loss: 935.5664645986345\n",
      "Training step:  2982\n",
      "Loss: 935.560418419771\n",
      "Training step:  2983\n",
      "Loss: 935.5554029159956\n",
      "Training step:  2984\n",
      "Loss: 935.5498166539754\n",
      "Training step:  2985\n",
      "Loss: 935.5451688970148\n",
      "Training step:  2986\n",
      "Loss: 935.5393319843806\n",
      "Training step:  2987\n",
      "Loss: 935.5348747391856\n",
      "Training step:  2988\n",
      "Loss: 935.5288811715726\n",
      "Training step:  2989\n",
      "Loss: 935.5242146455432\n",
      "Training step:  2990\n",
      "Loss: 935.5183911423226\n",
      "Training step:  2991\n",
      "Loss: 935.5139610359873\n",
      "Training step:  2992\n",
      "Loss: 935.5079729355388\n",
      "Training step:  2993\n",
      "Loss: 935.5033318754868\n",
      "Training step:  2994\n",
      "Loss: 935.4975139689343\n",
      "Training step:  2995\n",
      "Loss: 935.4931019703662\n",
      "Training step:  2996\n",
      "Loss: 935.4871277869818\n",
      "Training step:  2997\n",
      "Loss: 935.4823967105461\n",
      "Training step:  2998\n",
      "Loss: 935.4767110452256\n",
      "Training step:  2999\n",
      "Loss: 935.4721953177789\n",
      "Training step:  3000\n",
      "Loss: 935.4663489629836\n",
      "Training step:  3001\n",
      "Loss: 935.4618030712479\n",
      "Training step:  3002\n",
      "Loss: 935.4560049119184\n",
      "Training step:  3003\n",
      "Loss: 935.4514353668156\n",
      "Training step:  3004\n",
      "Loss: 935.4456769077985\n",
      "Training step:  3005\n",
      "Loss: 935.4412884482332\n",
      "Training step:  3006\n",
      "Loss: 935.4353692849782\n",
      "Training step:  3007\n",
      "Loss: 935.4307267728166\n",
      "Training step:  3008\n",
      "Loss: 935.4250228180034\n",
      "Training step:  3009\n",
      "Loss: 935.4206072509612\n",
      "Training step:  3010\n",
      "Loss: 935.4147431906064\n",
      "Training step:  3011\n",
      "Loss: 935.4101600758185\n",
      "Training step:  3012\n",
      "Loss: 935.4044803043533\n",
      "Training step:  3013\n",
      "Loss: 935.4000702802506\n",
      "Training step:  3014\n",
      "Loss: 935.3942316806128\n",
      "Training step:  3015\n",
      "Loss: 935.3896831844081\n",
      "Training step:  3016\n",
      "Loss: 935.3839976436067\n",
      "Training step:  3017\n",
      "Loss: 935.3796252565098\n",
      "Training step:  3018\n",
      "Loss: 935.3737818838775\n",
      "Training step:  3019\n",
      "Loss: 935.3692430860743\n",
      "Training step:  3020\n",
      "Loss: 935.3635783937132\n",
      "Training step:  3021\n",
      "Loss: 935.3592151231965\n",
      "Training step:  3022\n",
      "Loss: 935.3533935499427\n",
      "Training step:  3023\n",
      "Loss: 935.3486674582074\n",
      "Training step:  3024\n",
      "Loss: 935.3431899389853\n",
      "Training step:  3025\n",
      "Loss: 935.3387400487516\n",
      "Training step:  3026\n",
      "Loss: 935.3330276831383\n",
      "Training step:  3027\n",
      "Loss: 935.3285490968223\n",
      "Training step:  3028\n",
      "Loss: 935.3228831983639\n",
      "Training step:  3029\n",
      "Loss: 935.3183742785662\n",
      "Training step:  3030\n",
      "Loss: 935.3127546630506\n",
      "Training step:  3031\n",
      "Loss: 935.3084195649195\n",
      "Training step:  3032\n",
      "Loss: 935.3026454314288\n",
      "Training step:  3033\n",
      "Loss: 935.2981103960115\n",
      "Training step:  3034\n",
      "Loss: 935.292495894484\n",
      "Training step:  3035\n",
      "Loss: 935.2881868287576\n",
      "Training step:  3036\n",
      "Loss: 935.2824181879862\n",
      "Training step:  3037\n",
      "Loss: 935.2775691596986\n",
      "Training step:  3038\n",
      "Loss: 935.2722327799218\n",
      "Training step:  3039\n",
      "Loss: 935.2677094796807\n",
      "Training step:  3040\n",
      "Loss: 935.2621298852339\n",
      "Training step:  3041\n",
      "Loss: 935.2578203963997\n",
      "Training step:  3042\n",
      "Loss: 935.2520855813405\n",
      "Training step:  3043\n",
      "Loss: 935.2475907177288\n",
      "Training step:  3044\n",
      "Loss: 935.2420285991947\n",
      "Training step:  3045\n",
      "Loss: 935.2377301799236\n",
      "Training step:  3046\n",
      "Loss: 935.2320240156091\n",
      "Training step:  3047\n",
      "Loss: 935.2275409278392\n",
      "Training step:  3048\n",
      "Loss: 935.2219973468032\n",
      "Training step:  3049\n",
      "Loss: 935.2177182059723\n",
      "Training step:  3050\n",
      "Loss: 935.2120236691553\n",
      "Training step:  3051\n",
      "Loss: 935.2075026006597\n",
      "Training step:  3052\n",
      "Loss: 935.2020150547133\n",
      "Training step:  3053\n",
      "Loss: 935.1977057629879\n",
      "Training step:  3054\n",
      "Loss: 935.1920689663791\n",
      "Training step:  3055\n",
      "Loss: 935.1876296518494\n",
      "Training step:  3056\n",
      "Loss: 935.1821372263737\n",
      "Training step:  3057\n",
      "Loss: 935.1778639519721\n",
      "Training step:  3058\n",
      "Loss: 935.1722229711982\n",
      "Training step:  3059\n",
      "Loss: 935.1678167466757\n",
      "Training step:  3060\n",
      "Loss: 935.1623193317729\n",
      "Training step:  3061\n",
      "Loss: 935.1578914627019\n",
      "Training step:  3062\n",
      "Loss: 935.1524306690701\n",
      "Training step:  3063\n",
      "Loss: 935.1481685994215\n",
      "Training step:  3064\n",
      "Loss: 935.1425605898014\n",
      "Training step:  3065\n",
      "Loss: 935.1381414533319\n",
      "Training step:  3066\n",
      "Loss: 935.1326670536489\n",
      "Training step:  3067\n",
      "Loss: 935.1282539678839\n",
      "Training step:  3068\n",
      "Loss: 935.1228228632607\n",
      "Training step:  3069\n",
      "Loss: 935.1185739081468\n",
      "Training step:  3070\n",
      "Loss: 935.1129969174982\n",
      "Training step:  3071\n",
      "Loss: 935.1086184015574\n",
      "Training step:  3072\n",
      "Loss: 935.1031824764593\n",
      "Training step:  3073\n",
      "Loss: 935.0989688507686\n",
      "Training step:  3074\n",
      "Loss: 935.093387956151\n",
      "Training step:  3075\n",
      "Loss: 935.0885623398292\n",
      "Training step:  3076\n",
      "Loss: 935.0834403273979\n",
      "Training step:  3077\n",
      "Loss: 935.0789763452052\n",
      "Training step:  3078\n",
      "Loss: 935.0735943919257\n",
      "Training step:  3079\n",
      "Loss: 935.0693557709277\n",
      "Training step:  3080\n",
      "Loss: 935.0638368926653\n",
      "Training step:  3081\n",
      "Loss: 935.0594935200094\n",
      "Training step:  3082\n",
      "Loss: 935.0540969747843\n",
      "Training step:  3083\n",
      "Loss: 935.0499042505134\n",
      "Training step:  3084\n",
      "Loss: 935.0443722978827\n",
      "Training step:  3085\n",
      "Loss: 935.0400223741341\n",
      "Training step:  3086\n",
      "Loss: 935.0346628884754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  3087\n",
      "Loss: 935.0304683885425\n",
      "Training step:  3088\n",
      "Loss: 935.0249669605739\n",
      "Training step:  3089\n",
      "Loss: 935.0206267034985\n",
      "Training step:  3090\n",
      "Loss: 935.0152865568241\n",
      "Training step:  3091\n",
      "Loss: 935.0111011884762\n",
      "Training step:  3092\n",
      "Loss: 935.0056199561923\n",
      "Training step:  3093\n",
      "Loss: 935.0012893331957\n",
      "Training step:  3094\n",
      "Loss: 934.9959684393244\n",
      "Training step:  3095\n",
      "Loss: 934.9917922042725\n",
      "Training step:  3096\n",
      "Loss: 934.986331076411\n",
      "Training step:  3097\n",
      "Loss: 934.9820007907829\n",
      "Training step:  3098\n",
      "Loss: 934.9766590422184\n",
      "Training step:  3099\n",
      "Loss: 934.9725280182776\n",
      "Training step:  3100\n",
      "Loss: 934.9670529320442\n",
      "Training step:  3101\n",
      "Loss: 934.9625920568496\n",
      "Training step:  3102\n",
      "Loss: 934.9574119942979\n",
      "Training step:  3103\n",
      "Loss: 934.9531874530943\n",
      "Training step:  3104\n",
      "Loss: 934.9478281635028\n",
      "Training step:  3105\n",
      "Loss: 934.9435770831248\n",
      "Training step:  3106\n",
      "Loss: 934.938259496853\n",
      "Training step:  3107\n",
      "Loss: 934.9339888769508\n",
      "Training step:  3108\n",
      "Loss: 934.9287057183403\n",
      "Training step:  3109\n",
      "Loss: 934.9245920459521\n",
      "Training step:  3110\n",
      "Loss: 934.9191716375942\n",
      "Training step:  3111\n",
      "Loss: 934.9146758222981\n",
      "Training step:  3112\n",
      "Loss: 934.9095510270298\n",
      "Training step:  3113\n",
      "Loss: 934.905337353013\n",
      "Training step:  3114\n",
      "Loss: 934.9000351919567\n",
      "Training step:  3115\n",
      "Loss: 934.8957744868815\n",
      "Training step:  3116\n",
      "Loss: 934.8905394150686\n",
      "Training step:  3117\n",
      "Loss: 934.8864231665285\n",
      "Training step:  3118\n",
      "Loss: 934.8810594891257\n",
      "Training step:  3119\n",
      "Loss: 934.876770283882\n",
      "Training step:  3120\n",
      "Loss: 934.8715472617786\n",
      "Training step:  3121\n",
      "Loss: 934.8674476584708\n",
      "Training step:  3122\n",
      "Loss: 934.862096448041\n",
      "Training step:  3123\n",
      "Loss: 934.8578323309112\n",
      "Training step:  3124\n",
      "Loss: 934.8526262467934\n",
      "Training step:  3125\n",
      "Loss: 934.8485447978422\n",
      "Training step:  3126\n",
      "Loss: 934.8432045800612\n",
      "Training step:  3127\n",
      "Loss: 934.8388520660799\n",
      "Training step:  3128\n",
      "Loss: 934.8337586734215\n",
      "Training step:  3129\n",
      "Loss: 934.8295831059904\n",
      "Training step:  3130\n",
      "Loss: 934.8243588047163\n",
      "Training step:  3131\n",
      "Loss: 934.8201589944097\n",
      "Training step:  3132\n",
      "Loss: 934.814974891554\n",
      "Training step:  3133\n",
      "Loss: 934.8107563651517\n",
      "Training step:  3134\n",
      "Loss: 934.8055723541447\n",
      "Training step:  3135\n",
      "Loss: 934.8013617464493\n",
      "Training step:  3136\n",
      "Loss: 934.7962171070785\n",
      "Training step:  3137\n",
      "Loss: 934.7921558605547\n",
      "Training step:  3138\n",
      "Loss: 934.786879660475\n",
      "Training step:  3139\n",
      "Loss: 934.7826564785117\n",
      "Training step:  3140\n",
      "Loss: 934.7775221029036\n",
      "Training step:  3141\n",
      "Loss: 934.7734787975136\n",
      "Training step:  3142\n",
      "Loss: 934.7682134531123\n",
      "Training step:  3143\n",
      "Loss: 934.7639230768763\n",
      "Training step:  3144\n",
      "Loss: 934.7588777954819\n",
      "Training step:  3145\n",
      "Loss: 934.7547654034171\n",
      "Training step:  3146\n",
      "Loss: 934.7495916212755\n",
      "Training step:  3147\n",
      "Loss: 934.7454535443804\n",
      "Training step:  3148\n",
      "Loss: 934.7403191084098\n",
      "Training step:  3149\n",
      "Loss: 934.7361563467873\n",
      "Training step:  3150\n",
      "Loss: 934.7310611026821\n",
      "Training step:  3151\n",
      "Loss: 934.7270466108242\n",
      "Training step:  3152\n",
      "Loss: 934.7218225897909\n",
      "Training step:  3153\n",
      "Loss: 934.7173786987482\n",
      "Training step:  3154\n",
      "Loss: 934.7124877223171\n",
      "Training step:  3155\n",
      "Loss: 934.7083255905192\n",
      "Training step:  3156\n",
      "Loss: 934.7032640319613\n",
      "Training step:  3157\n",
      "Loss: 934.699246809332\n",
      "Training step:  3158\n",
      "Loss: 934.6940558496777\n",
      "Training step:  3159\n",
      "Loss: 934.6898450468532\n",
      "Training step:  3160\n",
      "Loss: 934.6848289373762\n",
      "Training step:  3161\n",
      "Loss: 934.6807902932147\n",
      "Training step:  3162\n",
      "Loss: 934.6756541970288\n",
      "Training step:  3163\n",
      "Loss: 934.6715538000105\n",
      "Training step:  3164\n",
      "Loss: 934.6664929958218\n",
      "Training step:  3165\n",
      "Loss: 934.662368260836\n",
      "Training step:  3166\n",
      "Loss: 934.6573457830578\n",
      "Training step:  3167\n",
      "Loss: 934.6533635410062\n",
      "Training step:  3168\n",
      "Loss: 934.6482153721062\n",
      "Training step:  3169\n",
      "Loss: 934.6440708210419\n",
      "Training step:  3170\n",
      "Loss: 934.6390670746097\n",
      "Training step:  3171\n",
      "Loss: 934.6350927088716\n",
      "Training step:  3172\n",
      "Loss: 934.6299641805896\n",
      "Training step:  3173\n",
      "Loss: 934.6258366559866\n",
      "Training step:  3174\n",
      "Loss: 934.6208295799876\n",
      "Training step:  3175\n",
      "Loss: 934.6168807222273\n",
      "Training step:  3176\n",
      "Loss: 934.6117551814215\n",
      "Training step:  3177\n",
      "Loss: 934.6075124639802\n",
      "Training step:  3178\n",
      "Loss: 934.6025879332594\n",
      "Training step:  3179\n",
      "Loss: 934.5985825123087\n",
      "Training step:  3180\n",
      "Loss: 934.5935357231615\n",
      "Training step:  3181\n",
      "Loss: 934.589505570256\n",
      "Training step:  3182\n",
      "Loss: 934.5844963487649\n",
      "Training step:  3183\n",
      "Loss: 934.5804428989035\n",
      "Training step:  3184\n",
      "Loss: 934.5754710982576\n",
      "Training step:  3185\n",
      "Loss: 934.5714007126825\n",
      "Training step:  3186\n",
      "Loss: 934.5664598555251\n",
      "Training step:  3187\n",
      "Loss: 934.5625282745426\n",
      "Training step:  3188\n",
      "Loss: 934.55746549237\n",
      "Training step:  3189\n",
      "Loss: 934.5533972761865\n",
      "Training step:  3190\n",
      "Loss: 934.5484520017068\n",
      "Training step:  3191\n",
      "Loss: 934.5443899537421\n",
      "Training step:  3192\n",
      "Loss: 934.5394812811428\n",
      "Training step:  3193\n",
      "Loss: 934.5355561259476\n",
      "Training step:  3194\n",
      "Loss: 934.5305266244889\n",
      "Training step:  3195\n",
      "Loss: 934.5264540219677\n",
      "Training step:  3196\n",
      "Loss: 934.5215550602923\n",
      "Training step:  3197\n",
      "Loss: 934.5176470726747\n",
      "Training step:  3198\n",
      "Loss: 934.5126279862931\n",
      "Training step:  3199\n",
      "Loss: 934.508526647454\n",
      "Training step:  3200\n",
      "Loss: 934.5036435761483\n",
      "Training step:  3201\n",
      "Loss: 934.4997396371391\n",
      "Training step:  3202\n",
      "Loss: 934.4947433008676\n",
      "Training step:  3203\n",
      "Loss: 934.4906924579466\n",
      "Training step:  3204\n",
      "Loss: 934.4858123183652\n",
      "Training step:  3205\n",
      "Loss: 934.4817794966198\n",
      "Training step:  3206\n",
      "Loss: 934.476934955389\n",
      "Training step:  3207\n",
      "Loss: 934.4730367163713\n",
      "Training step:  3208\n",
      "Loss: 934.468073881127\n",
      "Training step:  3209\n",
      "Loss: 934.4640314288571\n",
      "Training step:  3210\n",
      "Loss: 934.4591965261374\n",
      "Training step:  3211\n",
      "Loss: 934.4553152856295\n",
      "Training step:  3212\n",
      "Loss: 934.4503627381539\n",
      "Training step:  3213\n",
      "Loss: 934.4462439287046\n",
      "Training step:  3214\n",
      "Loss: 934.4414369266052\n",
      "Training step:  3215\n",
      "Loss: 934.4375447445719\n",
      "Training step:  3216\n",
      "Loss: 934.4326281936108\n",
      "Training step:  3217\n",
      "Loss: 934.4286336252667\n",
      "Training step:  3218\n",
      "Loss: 934.4238311121276\n",
      "Training step:  3219\n",
      "Loss: 934.4199689783756\n",
      "Training step:  3220\n",
      "Loss: 934.4150503202417\n",
      "Training step:  3221\n",
      "Loss: 934.4110573301323\n",
      "Training step:  3222\n",
      "Loss: 934.4062508063213\n",
      "Training step:  3223\n",
      "Loss: 934.4022636759928\n",
      "Training step:  3224\n",
      "Loss: 934.3974921827167\n",
      "Training step:  3225\n",
      "Loss: 934.3936367613221\n",
      "Training step:  3226\n",
      "Loss: 934.3887501680779\n",
      "Training step:  3227\n",
      "Loss: 934.3847717105073\n",
      "Training step:  3228\n",
      "Loss: 934.3799905366978\n",
      "Training step:  3229\n",
      "Loss: 934.3760176424953\n",
      "Training step:  3230\n",
      "Loss: 934.3712712321703\n",
      "Training step:  3231\n",
      "Loss: 934.3674287846878\n",
      "Training step:  3232\n",
      "Loss: 934.3625683185996\n",
      "Training step:  3233\n",
      "Loss: 934.3586244435194\n",
      "Training step:  3234\n",
      "Loss: 934.3538754088975\n",
      "Training step:  3235\n",
      "Loss: 934.3499154342175\n",
      "Training step:  3236\n",
      "Loss: 934.3451778982442\n",
      "Training step:  3237\n",
      "Loss: 934.3413595312701\n",
      "Training step:  3238\n",
      "Loss: 934.3365148311383\n",
      "Training step:  3239\n",
      "Loss: 934.3325567617427\n",
      "Training step:  3240\n",
      "Loss: 934.3278048981881\n",
      "Training step:  3241\n",
      "Loss: 934.3238811009545\n",
      "Training step:  3242\n",
      "Loss: 934.319163263518\n",
      "Training step:  3243\n",
      "Loss: 934.3152242647369\n",
      "Training step:  3244\n",
      "Loss: 934.3105177419588\n",
      "Training step:  3245\n",
      "Loss: 934.3067186158432\n",
      "Training step:  3246\n",
      "Loss: 934.301906307396\n",
      "Training step:  3247\n",
      "Loss: 934.2979269322408\n",
      "Training step:  3248\n",
      "Loss: 934.2932015325648\n",
      "Training step:  3249\n",
      "Loss: 934.289303498209\n",
      "Training step:  3250\n",
      "Loss: 934.2846116409937\n",
      "Training step:  3251\n",
      "Loss: 934.2808357085902\n",
      "Training step:  3252\n",
      "Loss: 934.27603898897\n",
      "Training step:  3253\n",
      "Loss: 934.2720893655596\n",
      "Training step:  3254\n",
      "Loss: 934.267405027608\n",
      "Training step:  3255\n",
      "Loss: 934.2635045054363\n",
      "Training step:  3256\n",
      "Loss: 934.2588369206388\n",
      "Training step:  3257\n",
      "Loss: 934.2550736083894\n",
      "Training step:  3258\n",
      "Loss: 934.2503022624455\n",
      "Training step:  3259\n",
      "Loss: 934.2463162894126\n",
      "Training step:  3260\n",
      "Loss: 934.2416801770719\n",
      "Training step:  3261\n",
      "Loss: 934.2379071623656\n",
      "Training step:  3262\n",
      "Loss: 934.2331697985975\n",
      "Training step:  3263\n",
      "Loss: 934.2292766778673\n",
      "Training step:  3264\n",
      "Loss: 934.2246276842119\n",
      "Training step:  3265\n",
      "Loss: 934.220755846331\n",
      "Training step:  3266\n",
      "Loss: 934.216123484603\n",
      "Training step:  3267\n",
      "Loss: 934.2123874422001\n",
      "Training step:  3268\n",
      "Loss: 934.2076529480676\n",
      "Training step:  3269\n",
      "Loss: 934.2037754287379\n",
      "Training step:  3270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 934.1991308625204\n",
      "Training step:  3271\n",
      "Loss: 934.1952934055494\n",
      "Training step:  3272\n",
      "Loss: 934.1906646357733\n",
      "Training step:  3273\n",
      "Loss: 934.1868235075927\n",
      "Training step:  3274\n",
      "Loss: 934.1822111954585\n",
      "Training step:  3275\n",
      "Loss: 934.1783664307573\n",
      "Training step:  3276\n",
      "Loss: 934.1737705219443\n",
      "Training step:  3277\n",
      "Loss: 934.1700596481624\n",
      "Training step:  3278\n",
      "Loss: 934.1653632250229\n",
      "Training step:  3279\n",
      "Loss: 934.1614354210678\n",
      "Training step:  3280\n",
      "Loss: 934.1568699260938\n",
      "Training step:  3281\n",
      "Loss: 934.1531555517544\n",
      "Training step:  3282\n",
      "Loss: 934.148486791952\n",
      "Training step:  3283\n",
      "Loss: 934.1446357673009\n",
      "Training step:  3284\n",
      "Loss: 934.1400543867766\n",
      "Training step:  3285\n",
      "Loss: 934.136241951075\n",
      "Training step:  3286\n",
      "Loss: 934.1316765822343\n",
      "Training step:  3287\n",
      "Loss: 934.1278606407672\n",
      "Training step:  3288\n",
      "Loss: 934.1232853362717\n",
      "Training step:  3289\n",
      "Loss: 934.119492227861\n",
      "Training step:  3290\n",
      "Loss: 934.1149326328946\n",
      "Training step:  3291\n",
      "Loss: 934.1111360470784\n",
      "Training step:  3292\n",
      "Loss: 934.1065925417186\n",
      "Training step:  3293\n",
      "Loss: 934.1029268436101\n",
      "Training step:  3294\n",
      "Loss: 934.0982853496754\n",
      "Training step:  3295\n",
      "Loss: 934.0944499357134\n",
      "Training step:  3296\n",
      "Loss: 934.0899196710918\n",
      "Training step:  3297\n",
      "Loss: 934.0861314301143\n",
      "Training step:  3298\n",
      "Loss: 934.0816169753253\n",
      "Training step:  3299\n",
      "Loss: 934.0779583101291\n",
      "Training step:  3300\n",
      "Loss: 934.0733468101231\n",
      "Training step:  3301\n",
      "Loss: 934.0695530300814\n",
      "Training step:  3302\n",
      "Loss: 934.0650380402878\n",
      "Training step:  3303\n",
      "Loss: 934.0612716739976\n",
      "Training step:  3304\n",
      "Loss: 934.0567725098932\n",
      "Training step:  3305\n",
      "Loss: 934.0530028233902\n",
      "Training step:  3306\n",
      "Loss: 934.0485194579609\n",
      "Training step:  3307\n",
      "Loss: 934.0448779676507\n",
      "Training step:  3308\n",
      "Loss: 934.0402987896999\n",
      "Training step:  3309\n",
      "Loss: 934.0364920738973\n",
      "Training step:  3310\n",
      "Loss: 934.0319921619225\n",
      "Training step:  3311\n",
      "Loss: 934.0282536267704\n",
      "Training step:  3312\n",
      "Loss: 934.0237761361096\n",
      "Training step:  3313\n",
      "Loss: 934.020034311667\n",
      "Training step:  3314\n",
      "Loss: 934.0155472387008\n",
      "Training step:  3315\n",
      "Loss: 934.0118275025897\n",
      "Training step:  3316\n",
      "Loss: 934.0073557869985\n",
      "Training step:  3317\n",
      "Loss: 934.0036328267263\n",
      "Training step:  3318\n",
      "Loss: 933.9991767001497\n",
      "Training step:  3319\n",
      "Loss: 933.995450547764\n",
      "Training step:  3320\n",
      "Loss: 933.9910099591921\n",
      "Training step:  3321\n",
      "Loss: 933.987414401969\n",
      "Training step:  3322\n",
      "Loss: 933.9828750051984\n",
      "Training step:  3323\n",
      "Loss: 933.9790672792232\n",
      "Training step:  3324\n",
      "Loss: 933.9746597201922\n",
      "Training step:  3325\n",
      "Loss: 933.9710514776082\n",
      "Training step:  3326\n",
      "Loss: 933.9665475696008\n",
      "Training step:  3327\n",
      "Loss: 933.9628120856069\n",
      "Training step:  3328\n",
      "Loss: 933.9584000621016\n",
      "Training step:  3329\n",
      "Loss: 933.9548174519022\n",
      "Training step:  3330\n",
      "Loss: 933.9503135958461\n",
      "Training step:  3331\n",
      "Loss: 933.9465027660661\n",
      "Training step:  3332\n",
      "Loss: 933.9421275075103\n",
      "Training step:  3333\n",
      "Loss: 933.9385010909617\n",
      "Training step:  3334\n",
      "Loss: 933.9340653388181\n",
      "Training step:  3335\n",
      "Loss: 933.9303806426777\n",
      "Training step:  3336\n",
      "Loss: 933.925995420083\n",
      "Training step:  3337\n",
      "Loss: 933.9223077660881\n",
      "Training step:  3338\n",
      "Loss: 933.9179377296786\n",
      "Training step:  3339\n",
      "Loss: 933.9142520555663\n",
      "Training step:  3340\n",
      "Loss: 933.9098921789372\n",
      "Training step:  3341\n",
      "Loss: 933.9062035245115\n",
      "Training step:  3342\n",
      "Loss: 933.901828454228\n",
      "Training step:  3343\n",
      "Loss: 933.8981604814082\n",
      "Training step:  3344\n",
      "Loss: 933.8938068838298\n",
      "Training step:  3345\n",
      "Loss: 933.8901292865642\n",
      "Training step:  3346\n",
      "Loss: 933.885797573598\n",
      "Training step:  3347\n",
      "Loss: 933.8822409789058\n",
      "Training step:  3348\n",
      "Loss: 933.8778194135141\n",
      "Training step:  3349\n",
      "Loss: 933.8740096025813\n",
      "Training step:  3350\n",
      "Loss: 933.86970597504\n",
      "Training step:  3351\n",
      "Loss: 933.8661451195021\n",
      "Training step:  3352\n",
      "Loss: 933.8617496332464\n",
      "Training step:  3353\n",
      "Loss: 933.8581003559235\n",
      "Training step:  3354\n",
      "Loss: 933.8537579325443\n",
      "Training step:  3355\n",
      "Loss: 933.8501291027419\n",
      "Training step:  3356\n",
      "Loss: 933.8458021437532\n",
      "Training step:  3357\n",
      "Loss: 933.8421699532198\n",
      "Training step:  3358\n",
      "Loss: 933.8378583907064\n",
      "Training step:  3359\n",
      "Loss: 933.8342294881488\n",
      "Training step:  3360\n",
      "Loss: 933.82993267098\n",
      "Training step:  3361\n",
      "Loss: 933.82630098911\n",
      "Training step:  3362\n",
      "Loss: 933.821989479833\n",
      "Training step:  3363\n",
      "Loss: 933.8183779720223\n",
      "Training step:  3364\n",
      "Loss: 933.8140874188787\n",
      "Training step:  3365\n",
      "Loss: 933.8104732237614\n",
      "Training step:  3366\n",
      "Loss: 933.8061973463736\n",
      "Training step:  3367\n",
      "Loss: 933.8027001286888\n",
      "Training step:  3368\n",
      "Loss: 933.7983373119285\n",
      "Training step:  3369\n",
      "Loss: 933.7946418465499\n",
      "Training step:  3370\n",
      "Loss: 933.7904041384387\n",
      "Training step:  3371\n",
      "Loss: 933.7868931730445\n",
      "Training step:  3372\n",
      "Loss: 933.7825665958634\n",
      "Training step:  3373\n",
      "Loss: 933.7789287040911\n",
      "Training step:  3374\n",
      "Loss: 933.7746765685607\n",
      "Training step:  3375\n",
      "Loss: 933.771075974078\n",
      "Training step:  3376\n",
      "Loss: 933.7668392804544\n",
      "Training step:  3377\n",
      "Loss: 933.7633603668575\n",
      "Training step:  3378\n",
      "Loss: 933.7590380486018\n",
      "Training step:  3379\n",
      "Loss: 933.7553699380015\n",
      "Training step:  3380\n",
      "Loss: 933.7511386822149\n",
      "Training step:  3381\n",
      "Loss: 933.7475528734325\n",
      "Training step:  3382\n",
      "Loss: 933.7433140004558\n",
      "Training step:  3383\n",
      "Loss: 933.739730967972\n",
      "Training step:  3384\n",
      "Loss: 933.7355071204587\n",
      "Training step:  3385\n",
      "Loss: 933.731937732204\n",
      "Training step:  3386\n",
      "Loss: 933.7277342739272\n",
      "Training step:  3387\n",
      "Loss: 933.7242780398356\n",
      "Training step:  3388\n",
      "Loss: 933.7199767020488\n",
      "Training step:  3389\n",
      "Loss: 933.716295569351\n",
      "Training step:  3390\n",
      "Loss: 933.7121290217087\n",
      "Training step:  3391\n",
      "Loss: 933.7086538425366\n",
      "Training step:  3392\n",
      "Loss: 933.7043922073636\n",
      "Training step:  3393\n",
      "Loss: 933.7008480821921\n",
      "Training step:  3394\n",
      "Loss: 933.6966368250551\n",
      "Training step:  3395\n",
      "Loss: 933.6930727009053\n",
      "Training step:  3396\n",
      "Loss: 933.6888853785684\n",
      "Training step:  3397\n",
      "Loss: 933.685349360026\n",
      "Training step:  3398\n",
      "Loss: 933.6811818807645\n",
      "Training step:  3399\n",
      "Loss: 933.6777508750326\n",
      "Training step:  3400\n",
      "Loss: 933.673493621748\n",
      "Training step:  3401\n",
      "Loss: 933.6698619960218\n",
      "Training step:  3402\n",
      "Loss: 933.6657275602917\n",
      "Training step:  3403\n",
      "Loss: 933.6622891964741\n",
      "Training step:  3404\n",
      "Loss: 933.6580609017873\n",
      "Training step:  3405\n",
      "Loss: 933.6545150929388\n",
      "Training step:  3406\n",
      "Loss: 933.6503586715942\n",
      "Training step:  3407\n",
      "Loss: 933.6468492546575\n",
      "Training step:  3408\n",
      "Loss: 933.6427069566071\n",
      "Training step:  3409\n",
      "Loss: 933.6391946814115\n",
      "Training step:  3410\n",
      "Loss: 933.6350668093625\n",
      "Training step:  3411\n",
      "Loss: 933.6316699273532\n",
      "Training step:  3412\n",
      "Loss: 933.6274476665282\n",
      "Training step:  3413\n",
      "Loss: 933.6237109491075\n",
      "Training step:  3414\n",
      "Loss: 933.619640427959\n",
      "Training step:  3415\n",
      "Loss: 933.6161684141899\n",
      "Training step:  3416\n",
      "Loss: 933.612035664832\n",
      "Training step:  3417\n",
      "Loss: 933.6085038671398\n",
      "Training step:  3418\n",
      "Loss: 933.6044115736668\n",
      "Training step:  3419\n",
      "Loss: 933.6010173844462\n",
      "Training step:  3420\n",
      "Loss: 933.5968376206923\n",
      "Training step:  3421\n",
      "Loss: 933.5932016348934\n",
      "Training step:  3422\n",
      "Loss: 933.5891819409472\n",
      "Training step:  3423\n",
      "Loss: 933.5857336623654\n",
      "Training step:  3424\n",
      "Loss: 933.5816254661822\n",
      "Training step:  3425\n",
      "Loss: 933.5781310888858\n",
      "Training step:  3426\n",
      "Loss: 933.5740549064361\n",
      "Training step:  3427\n",
      "Loss: 933.5705793693746\n",
      "Training step:  3428\n",
      "Loss: 933.5665223788515\n",
      "Training step:  3429\n",
      "Loss: 933.5631475235717\n",
      "Training step:  3430\n",
      "Loss: 933.5590047680406\n",
      "Training step:  3431\n",
      "Loss: 933.5554967718105\n",
      "Training step:  3432\n",
      "Loss: 933.5514521634681\n",
      "Training step:  3433\n",
      "Loss: 933.5479785465768\n",
      "Training step:  3434\n",
      "Loss: 933.543939398676\n",
      "Training step:  3435\n",
      "Loss: 933.5404717556331\n",
      "Training step:  3436\n",
      "Loss: 933.5364465029335\n",
      "Training step:  3437\n",
      "Loss: 933.5330834907239\n",
      "Training step:  3438\n",
      "Loss: 933.5289734888112\n",
      "Training step:  3439\n",
      "Loss: 933.5254797651645\n",
      "Training step:  3440\n",
      "Loss: 933.5214454976897\n",
      "Training step:  3441\n",
      "Loss: 933.5179698911799\n",
      "Training step:  3442\n",
      "Loss: 933.513957535461\n",
      "Training step:  3443\n",
      "Loss: 933.5105082133349\n",
      "Training step:  3444\n",
      "Loss: 933.5065146603098\n",
      "Training step:  3445\n",
      "Loss: 933.5031631722317\n",
      "Training step:  3446\n",
      "Loss: 933.4990804141127\n",
      "Training step:  3447\n",
      "Loss: 933.4956068869055\n",
      "Training step:  3448\n",
      "Loss: 933.4916065467538\n",
      "Training step:  3449\n",
      "Loss: 933.4881784089058\n",
      "Training step:  3450\n",
      "Loss: 933.4841916733991\n",
      "Training step:  3451\n",
      "Loss: 933.4808666154859\n",
      "Training step:  3452\n",
      "Loss: 933.4767969673624\n",
      "Training step:  3453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 933.4732967573531\n",
      "Training step:  3454\n",
      "Loss: 933.4693172816445\n",
      "Training step:  3455\n",
      "Loss: 933.4660065068256\n",
      "Training step:  3456\n",
      "Loss: 933.4619445663305\n",
      "Training step:  3457\n",
      "Loss: 933.4584385585672\n",
      "Training step:  3458\n",
      "Loss: 933.4544898261655\n",
      "Training step:  3459\n",
      "Loss: 933.4511727902085\n",
      "Training step:  3460\n",
      "Loss: 933.4471381593299\n",
      "Training step:  3461\n",
      "Loss: 933.4437219027334\n",
      "Training step:  3462\n",
      "Loss: 933.4397617804749\n",
      "Training step:  3463\n",
      "Loss: 933.4363704174333\n",
      "Training step:  3464\n",
      "Loss: 933.4324160067263\n",
      "Training step:  3465\n",
      "Loss: 933.4290304748104\n",
      "Training step:  3466\n",
      "Loss: 933.4250894595687\n",
      "Training step:  3467\n",
      "Loss: 933.421804711518\n",
      "Training step:  3468\n",
      "Loss: 933.4177827980011\n",
      "Training step:  3469\n",
      "Loss: 933.4142511262723\n",
      "Training step:  3470\n",
      "Loss: 933.4103702310243\n",
      "Training step:  3471\n",
      "Loss: 933.4070219755608\n",
      "Training step:  3472\n",
      "Loss: 933.4030819068042\n",
      "Training step:  3473\n",
      "Loss: 933.3996897018875\n",
      "Training step:  3474\n",
      "Loss: 933.3957711634396\n",
      "Training step:  3475\n",
      "Loss: 933.3923694230983\n",
      "Training step:  3476\n",
      "Loss: 933.3884802736153\n",
      "Training step:  3477\n",
      "Loss: 933.3851952901368\n",
      "Training step:  3478\n",
      "Loss: 933.3812262184931\n",
      "Training step:  3479\n",
      "Loss: 933.3778396242705\n",
      "Training step:  3480\n",
      "Loss: 933.3739258139107\n",
      "Training step:  3481\n",
      "Loss: 933.3705536141864\n",
      "Training step:  3482\n",
      "Loss: 933.3666791690677\n",
      "Training step:  3483\n",
      "Loss: 933.3634103699991\n",
      "Training step:  3484\n",
      "Loss: 933.3594568327903\n",
      "Training step:  3485\n",
      "Loss: 933.3560961146686\n",
      "Training step:  3486\n",
      "Loss: 933.3522127936685\n",
      "Training step:  3487\n",
      "Loss: 933.3489764468873\n",
      "Training step:  3488\n",
      "Loss: 933.3450146326562\n",
      "Training step:  3489\n",
      "Loss: 933.341526568733\n",
      "Training step:  3490\n",
      "Loss: 933.3377027061651\n",
      "Training step:  3491\n",
      "Loss: 933.3344258921568\n",
      "Training step:  3492\n",
      "Loss: 933.3305210677604\n",
      "Training step:  3493\n",
      "Loss: 933.3272024429576\n",
      "Training step:  3494\n",
      "Loss: 933.3233458625118\n",
      "Training step:  3495\n",
      "Loss: 933.3201100324075\n",
      "Training step:  3496\n",
      "Loss: 933.3161888912273\n",
      "Training step:  3497\n",
      "Loss: 933.3128866330137\n",
      "Training step:  3498\n",
      "Loss: 933.3090082521983\n",
      "Training step:  3499\n",
      "Loss: 933.3056965014475\n",
      "Training step:  3500\n",
      "Loss: 933.3018465831444\n",
      "Training step:  3501\n",
      "Loss: 933.2985181868479\n",
      "Training step:  3502\n",
      "Loss: 933.2946693612391\n",
      "Training step:  3503\n",
      "Loss: 933.2913512546046\n",
      "Training step:  3504\n",
      "Loss: 933.2875339508383\n",
      "Training step:  3505\n",
      "Loss: 933.28432460368\n",
      "Training step:  3506\n",
      "Loss: 933.2804307308315\n",
      "Training step:  3507\n",
      "Loss: 933.2770981644485\n",
      "Training step:  3508\n",
      "Loss: 933.2732800017734\n",
      "Training step:  3509\n",
      "Loss: 933.2699964325524\n",
      "Training step:  3510\n",
      "Loss: 933.2661907875627\n",
      "Training step:  3511\n",
      "Loss: 933.2629052071946\n",
      "Training step:  3512\n",
      "Loss: 933.259112277088\n",
      "Training step:  3513\n",
      "Loss: 933.2559205480255\n",
      "Training step:  3514\n",
      "Loss: 933.252052213595\n",
      "Training step:  3515\n",
      "Loss: 933.2487444853429\n",
      "Training step:  3516\n",
      "Loss: 933.2449438413283\n",
      "Training step:  3517\n",
      "Loss: 933.2416520885533\n",
      "Training step:  3518\n",
      "Loss: 933.2378714956278\n",
      "Training step:  3519\n",
      "Loss: 933.2346035366501\n",
      "Training step:  3520\n",
      "Loss: 933.2308399751546\n",
      "Training step:  3521\n",
      "Loss: 933.2276598064464\n",
      "Training step:  3522\n",
      "Loss: 933.2238217452965\n",
      "Training step:  3523\n",
      "Loss: 933.2205274499314\n",
      "Training step:  3524\n",
      "Loss: 933.2167358677591\n",
      "Training step:  3525\n",
      "Loss: 933.2134783812736\n",
      "Training step:  3526\n",
      "Loss: 933.2097236350697\n",
      "Training step:  3527\n",
      "Loss: 933.2065660500954\n",
      "Training step:  3528\n",
      "Loss: 933.2027373854113\n",
      "Training step:  3529\n",
      "Loss: 933.199429076272\n",
      "Training step:  3530\n",
      "Loss: 933.1956750024526\n",
      "Training step:  3531\n",
      "Loss: 933.1924431468011\n",
      "Training step:  3532\n",
      "Loss: 933.1887015183025\n",
      "Training step:  3533\n",
      "Loss: 933.1854678057439\n",
      "Training step:  3534\n",
      "Loss: 933.1817311900242\n",
      "Training step:  3535\n",
      "Loss: 933.1785030262545\n",
      "Training step:  3536\n",
      "Loss: 933.1747787061769\n",
      "Training step:  3537\n",
      "Loss: 933.1716413976645\n",
      "Training step:  3538\n",
      "Loss: 933.1678443717751\n",
      "Training step:  3539\n",
      "Loss: 933.1646108754375\n",
      "Training step:  3540\n",
      "Loss: 933.1608880817136\n",
      "Training step:  3541\n",
      "Loss: 933.1576771456895\n",
      "Training step:  3542\n",
      "Loss: 933.1539667418541\n",
      "Training step:  3543\n",
      "Loss: 933.1507540202608\n",
      "Training step:  3544\n",
      "Loss: 933.1470485902\n",
      "Training step:  3545\n",
      "Loss: 933.1438413793666\n",
      "Training step:  3546\n",
      "Loss: 933.1401526555139\n",
      "Training step:  3547\n",
      "Loss: 933.1370299820741\n",
      "Training step:  3548\n",
      "Loss: 933.133269675649\n",
      "Training step:  3549\n",
      "Loss: 933.1300596969568\n",
      "Training step:  3550\n",
      "Loss: 933.126357930911\n",
      "Training step:  3551\n",
      "Loss: 933.1231464335148\n",
      "Training step:  3552\n",
      "Loss: 933.1194459220483\n",
      "Training step:  3553\n",
      "Loss: 933.1162314517103\n",
      "Training step:  3554\n",
      "Loss: 933.1125492933469\n",
      "Training step:  3555\n",
      "Loss: 933.1093710200538\n",
      "Training step:  3556\n",
      "Loss: 933.1057045206043\n",
      "Training step:  3557\n",
      "Loss: 933.1026101290549\n",
      "Training step:  3558\n",
      "Loss: 933.0988731480911\n",
      "Training step:  3559\n",
      "Loss: 933.0956340215621\n",
      "Training step:  3560\n",
      "Loss: 933.0919680703504\n",
      "Training step:  3561\n",
      "Loss: 933.0888030155924\n",
      "Training step:  3562\n",
      "Loss: 933.0851540625068\n",
      "Training step:  3563\n",
      "Loss: 933.08207242231\n",
      "Training step:  3564\n",
      "Loss: 933.0783536340631\n",
      "Training step:  3565\n",
      "Loss: 933.0751267102285\n",
      "Training step:  3566\n",
      "Loss: 933.0714810219091\n",
      "Training step:  3567\n",
      "Loss: 933.068326163374\n",
      "Training step:  3568\n",
      "Loss: 933.064686118881\n",
      "Training step:  3569\n",
      "Loss: 933.0615366686798\n",
      "Training step:  3570\n",
      "Loss: 933.0579084530174\n",
      "Training step:  3571\n",
      "Loss: 933.054845268528\n",
      "Training step:  3572\n",
      "Loss: 933.0511480351535\n",
      "Training step:  3573\n",
      "Loss: 933.0479786026949\n",
      "Training step:  3574\n",
      "Loss: 933.0443333284192\n",
      "Training step:  3575\n",
      "Loss: 933.0411892018361\n",
      "Training step:  3576\n",
      "Loss: 933.037568906129\n",
      "Training step:  3577\n",
      "Loss: 933.034440462326\n",
      "Training step:  3578\n",
      "Loss: 933.030835976966\n",
      "Training step:  3579\n",
      "Loss: 933.0277887415962\n",
      "Training step:  3580\n",
      "Loss: 933.0241161191841\n",
      "Training step:  3581\n",
      "Loss: 933.0209356238698\n",
      "Training step:  3582\n",
      "Loss: 933.0173253757067\n",
      "Training step:  3583\n",
      "Loss: 933.0141863332732\n",
      "Training step:  3584\n",
      "Loss: 933.0105947356184\n",
      "Training step:  3585\n",
      "Loss: 933.0074777603346\n",
      "Training step:  3586\n",
      "Loss: 933.003902029108\n",
      "Training step:  3587\n",
      "Loss: 933.0008647570421\n",
      "Training step:  3588\n",
      "Loss: 932.9972217125841\n",
      "Training step:  3589\n",
      "Loss: 932.9941042217085\n",
      "Training step:  3590\n",
      "Loss: 932.9905215340412\n",
      "Training step:  3591\n",
      "Loss: 932.9873955665478\n",
      "Training step:  3592\n",
      "Loss: 932.9838124328031\n",
      "Training step:  3593\n",
      "Loss: 932.9806978299483\n",
      "Training step:  3594\n",
      "Loss: 932.9771489126784\n",
      "Training step:  3595\n",
      "Loss: 932.9741235065715\n",
      "Training step:  3596\n",
      "Loss: 932.9705079774449\n",
      "Training step:  3597\n",
      "Loss: 932.9673978556114\n",
      "Training step:  3598\n",
      "Loss: 932.9638067169918\n",
      "Training step:  3599\n",
      "Loss: 932.9607186624822\n",
      "Training step:  3600\n",
      "Loss: 932.9571792745503\n",
      "Training step:  3601\n",
      "Loss: 932.9541743381991\n",
      "Training step:  3602\n",
      "Loss: 932.9505690676898\n",
      "Training step:  3603\n",
      "Loss: 932.9474772634882\n",
      "Training step:  3604\n",
      "Loss: 932.9439327152807\n",
      "Training step:  3605\n",
      "Loss: 932.9408393275519\n",
      "Training step:  3606\n",
      "Loss: 932.9372833487586\n",
      "Training step:  3607\n",
      "Loss: 932.9342118918097\n",
      "Training step:  3608\n",
      "Loss: 932.930699725112\n",
      "Training step:  3609\n",
      "Loss: 932.9277056456139\n",
      "Training step:  3610\n",
      "Loss: 932.9241284020554\n",
      "Training step:  3611\n",
      "Loss: 932.9210571607941\n",
      "Training step:  3612\n",
      "Loss: 932.9175315405791\n",
      "Training step:  3613\n",
      "Loss: 932.9144589269351\n",
      "Training step:  3614\n",
      "Loss: 932.910932677142\n",
      "Training step:  3615\n",
      "Loss: 932.9078711409246\n",
      "Training step:  3616\n",
      "Loss: 932.9043887029171\n",
      "Training step:  3617\n",
      "Loss: 932.9014026881711\n",
      "Training step:  3618\n",
      "Loss: 932.8978559580579\n",
      "Training step:  3619\n",
      "Loss: 932.8947947439272\n",
      "Training step:  3620\n",
      "Loss: 932.8912617804398\n",
      "Training step:  3621\n",
      "Loss: 932.8882365394749\n",
      "Training step:  3622\n",
      "Loss: 932.8847460698091\n",
      "Training step:  3623\n",
      "Loss: 932.8817160279503\n",
      "Training step:  3624\n",
      "Loss: 932.8782366802461\n",
      "Training step:  3625\n",
      "Loss: 932.8752053654825\n",
      "Training step:  3626\n",
      "Loss: 932.871730658611\n",
      "Training step:  3627\n",
      "Loss: 932.8687045293218\n",
      "Training step:  3628\n",
      "Loss: 932.8652449195507\n",
      "Training step:  3629\n",
      "Loss: 932.8622942400089\n",
      "Training step:  3630\n",
      "Loss: 932.8587715293529\n",
      "Training step:  3631\n",
      "Loss: 932.8557456251591\n",
      "Training step:  3632\n",
      "Loss: 932.8522727692246\n",
      "Training step:  3633\n",
      "Loss: 932.8492455536422\n",
      "Training step:  3634\n",
      "Loss: 932.8457471187395\n",
      "Training step:  3635\n",
      "Loss: 932.8427395032567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  3636\n",
      "Loss: 932.8392959482782\n",
      "Training step:  3637\n",
      "Loss: 932.8362871565879\n",
      "Training step:  3638\n",
      "Loss: 932.8328545281031\n",
      "Training step:  3639\n",
      "Loss: 932.8299242116253\n",
      "Training step:  3640\n",
      "Loss: 932.8264294257743\n",
      "Training step:  3641\n",
      "Loss: 932.8233253513687\n",
      "Training step:  3642\n",
      "Loss: 932.8198345722542\n",
      "Training step:  3643\n",
      "Loss: 932.8168483909186\n",
      "Training step:  3644\n",
      "Loss: 932.8133982808899\n",
      "Training step:  3645\n",
      "Loss: 932.8104063061195\n",
      "Training step:  3646\n",
      "Loss: 932.8069734562583\n",
      "Training step:  3647\n",
      "Loss: 932.8039747033861\n",
      "Training step:  3648\n",
      "Loss: 932.800552049012\n",
      "Training step:  3649\n",
      "Loss: 932.7975528404309\n",
      "Training step:  3650\n",
      "Loss: 932.7941259114042\n",
      "Training step:  3651\n",
      "Loss: 932.7911357805688\n",
      "Training step:  3652\n",
      "Loss: 932.7877460455528\n",
      "Training step:  3653\n",
      "Loss: 932.7848380055792\n",
      "Training step:  3654\n",
      "Loss: 932.7813874373708\n",
      "Training step:  3655\n",
      "Loss: 932.7783612752298\n",
      "Training step:  3656\n",
      "Loss: 932.7749360627042\n",
      "Training step:  3657\n",
      "Loss: 932.7719615813681\n",
      "Training step:  3658\n",
      "Loss: 932.7685739677752\n",
      "Training step:  3659\n",
      "Loss: 932.765614576597\n",
      "Training step:  3660\n",
      "Loss: 932.7622353338063\n",
      "Training step:  3661\n",
      "Loss: 932.7592771484304\n",
      "Training step:  3662\n",
      "Loss: 932.7559123969563\n",
      "Training step:  3663\n",
      "Loss: 932.7530259689715\n",
      "Training step:  3664\n",
      "Loss: 932.7496013309963\n",
      "Training step:  3665\n",
      "Loss: 932.7466366271327\n",
      "Training step:  3666\n",
      "Loss: 932.7432424498635\n",
      "Training step:  3667\n",
      "Loss: 932.7403008898381\n",
      "Training step:  3668\n",
      "Loss: 932.7369374350172\n",
      "Training step:  3669\n",
      "Loss: 932.734001211133\n",
      "Training step:  3670\n",
      "Loss: 932.7306520794225\n",
      "Training step:  3671\n",
      "Loss: 932.7277110460732\n",
      "Training step:  3672\n",
      "Loss: 932.7243569594319\n",
      "Training step:  3673\n",
      "Loss: 932.721430366323\n",
      "Training step:  3674\n",
      "Loss: 932.7180903924382\n",
      "Training step:  3675\n",
      "Loss: 932.7151590311415\n",
      "Training step:  3676\n",
      "Loss: 932.7118179328407\n",
      "Training step:  3677\n",
      "Loss: 932.7088971792929\n",
      "Training step:  3678\n",
      "Loss: 932.7055701692483\n",
      "Training step:  3679\n",
      "Loss: 932.7026446940858\n",
      "Training step:  3680\n",
      "Loss: 932.6992839063377\n",
      "Training step:  3681\n",
      "Loss: 932.6963478679561\n",
      "Training step:  3682\n",
      "Loss: 932.6929850768701\n",
      "Training step:  3683\n",
      "Loss: 932.6900424639807\n",
      "Training step:  3684\n",
      "Loss: 932.6866962862566\n",
      "Training step:  3685\n",
      "Loss: 932.6837771467797\n",
      "Training step:  3686\n",
      "Loss: 932.6804672718885\n",
      "Training step:  3687\n",
      "Loss: 932.6776359625266\n",
      "Training step:  3688\n",
      "Loss: 932.674268344261\n",
      "Training step:  3689\n",
      "Loss: 932.6712501976107\n",
      "Training step:  3690\n",
      "Loss: 932.6679261605094\n",
      "Training step:  3691\n",
      "Loss: 932.6650086313683\n",
      "Training step:  3692\n",
      "Loss: 932.6616676234685\n",
      "Training step:  3693\n",
      "Loss: 932.658759026184\n",
      "Training step:  3694\n",
      "Loss: 932.6554360758763\n",
      "Training step:  3695\n",
      "Loss: 932.6525372991367\n",
      "Training step:  3696\n",
      "Loss: 932.6492540994154\n",
      "Training step:  3697\n",
      "Loss: 932.6463589400455\n",
      "Training step:  3698\n",
      "Loss: 932.6430841015712\n",
      "Training step:  3699\n",
      "Loss: 932.6401992520251\n",
      "Training step:  3700\n",
      "Loss: 932.63692907465\n",
      "Training step:  3701\n",
      "Loss: 932.6340487837341\n",
      "Training step:  3702\n",
      "Loss: 932.6307833005845\n",
      "Training step:  3703\n",
      "Loss: 932.6278982243388\n",
      "Training step:  3704\n",
      "Loss: 932.6246271976795\n",
      "Training step:  3705\n",
      "Loss: 932.6217363079505\n",
      "Training step:  3706\n",
      "Loss: 932.618479835407\n",
      "Training step:  3707\n",
      "Loss: 932.6156135413714\n",
      "Training step:  3708\n",
      "Loss: 932.612370604956\n",
      "Training step:  3709\n",
      "Loss: 932.6095715455049\n",
      "Training step:  3710\n",
      "Loss: 932.6062728204851\n",
      "Training step:  3711\n",
      "Loss: 932.6033643081759\n",
      "Training step:  3712\n",
      "Loss: 932.600053326371\n",
      "Training step:  3713\n",
      "Loss: 932.596954286602\n",
      "Training step:  3714\n",
      "Loss: 932.5938463771016\n",
      "Training step:  3715\n",
      "Loss: 932.5909050138958\n",
      "Training step:  3716\n",
      "Loss: 932.5876465098436\n",
      "Training step:  3717\n",
      "Loss: 932.5847874254873\n",
      "Training step:  3718\n",
      "Loss: 932.5815642013374\n",
      "Training step:  3719\n",
      "Loss: 932.5786944187233\n",
      "Training step:  3720\n",
      "Loss: 932.57545537685\n",
      "Training step:  3721\n",
      "Loss: 932.5726023823556\n",
      "Training step:  3722\n",
      "Loss: 932.5693288162654\n",
      "Training step:  3723\n",
      "Loss: 932.5664516165301\n",
      "Training step:  3724\n",
      "Loss: 932.5631920861814\n",
      "Training step:  3725\n",
      "Loss: 932.5603603544345\n",
      "Training step:  3726\n",
      "Loss: 932.5571463019273\n",
      "Training step:  3727\n",
      "Loss: 932.554303621547\n",
      "Training step:  3728\n",
      "Loss: 932.5510963363789\n",
      "Training step:  3729\n",
      "Loss: 932.5482563707454\n",
      "Training step:  3730\n",
      "Loss: 932.5450724550523\n",
      "Training step:  3731\n",
      "Loss: 932.5423115147754\n",
      "Training step:  3732\n",
      "Loss: 932.5390738199367\n",
      "Training step:  3733\n",
      "Loss: 932.536248566384\n",
      "Training step:  3734\n",
      "Loss: 932.5330516162787\n",
      "Training step:  3735\n",
      "Loss: 932.5302284601281\n",
      "Training step:  3736\n",
      "Loss: 932.5270546082027\n",
      "Training step:  3737\n",
      "Loss: 932.5242413254391\n",
      "Training step:  3738\n",
      "Loss: 932.5210720426289\n",
      "Training step:  3739\n",
      "Loss: 932.5182632074536\n",
      "Training step:  3740\n",
      "Loss: 932.5150930500115\n",
      "Training step:  3741\n",
      "Loss: 932.5122852651027\n",
      "Training step:  3742\n",
      "Loss: 932.5091284628468\n",
      "Training step:  3743\n",
      "Loss: 932.5063250689548\n",
      "Training step:  3744\n",
      "Loss: 932.5031674154932\n",
      "Training step:  3745\n",
      "Loss: 932.5003738565952\n",
      "Training step:  3746\n",
      "Loss: 932.4972206749347\n",
      "Training step:  3747\n",
      "Loss: 932.4944227895625\n",
      "Training step:  3748\n",
      "Loss: 932.4912698903738\n",
      "Training step:  3749\n",
      "Loss: 932.4884660735897\n",
      "Training step:  3750\n",
      "Loss: 932.4852578552619\n",
      "Training step:  3751\n",
      "Loss: 932.4822426964527\n",
      "Training step:  3752\n",
      "Loss: 932.479200323927\n",
      "Training step:  3753\n",
      "Loss: 932.4763396296651\n",
      "Training step:  3754\n",
      "Loss: 932.4731663566916\n",
      "Training step:  3755\n",
      "Loss: 932.4703776344091\n",
      "Training step:  3756\n",
      "Loss: 932.4672036428245\n",
      "Training step:  3757\n",
      "Loss: 932.4644136444506\n",
      "Training step:  3758\n",
      "Loss: 932.4612266058563\n",
      "Training step:  3759\n",
      "Loss: 932.4583376103337\n",
      "Training step:  3760\n",
      "Loss: 932.455229900768\n",
      "Training step:  3761\n",
      "Loss: 932.4525102242574\n",
      "Training step:  3762\n",
      "Loss: 932.4493624519575\n",
      "Training step:  3763\n",
      "Loss: 932.4466140539919\n",
      "Training step:  3764\n",
      "Loss: 932.4434856680798\n",
      "Training step:  3765\n",
      "Loss: 932.4407273883039\n",
      "Training step:  3766\n",
      "Loss: 932.4375562398955\n",
      "Training step:  3767\n",
      "Loss: 932.4346382587144\n",
      "Training step:  3768\n",
      "Loss: 932.4315981141636\n",
      "Training step:  3769\n",
      "Loss: 932.4288331175185\n",
      "Training step:  3770\n",
      "Loss: 932.4256801643662\n",
      "Training step:  3771\n",
      "Loss: 932.4229474784607\n",
      "Training step:  3772\n",
      "Loss: 932.4198416492785\n",
      "Training step:  3773\n",
      "Loss: 932.41709592545\n",
      "Training step:  3774\n",
      "Loss: 932.4139617375062\n",
      "Training step:  3775\n",
      "Loss: 932.4112428020277\n",
      "Training step:  3776\n",
      "Loss: 932.408140410457\n",
      "Training step:  3777\n",
      "Loss: 932.4054087363409\n",
      "Training step:  3778\n",
      "Loss: 932.4022790054125\n",
      "Training step:  3779\n",
      "Loss: 932.3994845816948\n",
      "Training step:  3780\n",
      "Loss: 932.3963901358354\n",
      "Training step:  3781\n",
      "Loss: 932.3936651457774\n",
      "Training step:  3782\n",
      "Loss: 932.3905509219607\n",
      "Training step:  3783\n",
      "Loss: 932.3878168644766\n",
      "Training step:  3784\n",
      "Loss: 932.3847020971996\n",
      "Training step:  3785\n",
      "Loss: 932.3818981533741\n",
      "Training step:  3786\n",
      "Loss: 932.3788173161231\n",
      "Training step:  3787\n",
      "Loss: 932.3761040462284\n",
      "Training step:  3788\n",
      "Loss: 932.3729995557377\n",
      "Training step:  3789\n",
      "Loss: 932.3702846955033\n",
      "Training step:  3790\n",
      "Loss: 932.3671883896724\n",
      "Training step:  3791\n",
      "Loss: 932.3644690304\n",
      "Training step:  3792\n",
      "Loss: 932.3613748781854\n",
      "Training step:  3793\n",
      "Loss: 932.3585996836779\n",
      "Training step:  3794\n",
      "Loss: 932.3555254245556\n",
      "Training step:  3795\n",
      "Loss: 932.3528419650601\n",
      "Training step:  3796\n",
      "Loss: 932.349747773598\n",
      "Training step:  3797\n",
      "Loss: 932.3468783676238\n",
      "Training step:  3798\n",
      "Loss: 932.3439150652465\n",
      "Training step:  3799\n",
      "Loss: 932.3411832337435\n",
      "Training step:  3800\n",
      "Loss: 932.3381099171513\n",
      "Training step:  3801\n",
      "Loss: 932.3353723447334\n",
      "Training step:  3802\n",
      "Loss: 932.332322390616\n",
      "Training step:  3803\n",
      "Loss: 932.3296399013004\n",
      "Training step:  3804\n",
      "Loss: 932.3265635671107\n",
      "Training step:  3805\n",
      "Loss: 932.3237975047914\n",
      "Training step:  3806\n",
      "Loss: 932.3207706874304\n",
      "Training step:  3807\n",
      "Loss: 932.3180750022343\n",
      "Training step:  3808\n",
      "Loss: 932.3150399028484\n",
      "Training step:  3809\n",
      "Loss: 932.3123685904021\n",
      "Training step:  3810\n",
      "Loss: 932.3093179487441\n",
      "Training step:  3811\n",
      "Loss: 932.3065400416615\n",
      "Training step:  3812\n",
      "Loss: 932.3035535549071\n",
      "Training step:  3813\n",
      "Loss: 932.3009342462566\n",
      "Training step:  3814\n",
      "Loss: 932.2979102097776\n",
      "Training step:  3815\n",
      "Loss: 932.295263693433\n",
      "Training step:  3816\n",
      "Loss: 932.292218448526\n",
      "Training step:  3817\n",
      "Loss: 932.2894224965141\n",
      "Training step:  3818\n",
      "Loss: 932.286486734329\n",
      "Training step:  3819\n",
      "Loss: 932.2838301879792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  3820\n",
      "Loss: 932.2808046852603\n",
      "Training step:  3821\n",
      "Loss: 932.2781380880917\n",
      "Training step:  3822\n",
      "Loss: 932.2751205330312\n",
      "Training step:  3823\n",
      "Loss: 932.2724917129756\n",
      "Training step:  3824\n",
      "Loss: 932.2695045259541\n",
      "Training step:  3825\n",
      "Loss: 932.266863939621\n",
      "Training step:  3826\n",
      "Loss: 932.2638506589489\n",
      "Training step:  3827\n",
      "Loss: 932.2610855943431\n",
      "Training step:  3828\n",
      "Loss: 932.2581607859822\n",
      "Training step:  3829\n",
      "Loss: 932.2555373563604\n",
      "Training step:  3830\n",
      "Loss: 932.2525271397096\n",
      "Training step:  3831\n",
      "Loss: 932.2498021483627\n",
      "Training step:  3832\n",
      "Loss: 932.2468479089282\n",
      "Training step:  3833\n",
      "Loss: 932.2442020842869\n",
      "Training step:  3834\n",
      "Loss: 932.2412232577279\n",
      "Training step:  3835\n",
      "Loss: 932.2386092014416\n",
      "Training step:  3836\n",
      "Loss: 932.235611679876\n",
      "Training step:  3837\n",
      "Loss: 932.2328177574458\n",
      "Training step:  3838\n",
      "Loss: 932.2299556012164\n",
      "Training step:  3839\n",
      "Loss: 932.2272870850911\n",
      "Training step:  3840\n",
      "Loss: 932.2243197544415\n",
      "Training step:  3841\n",
      "Loss: 932.2217069451032\n",
      "Training step:  3842\n",
      "Loss: 932.2187367533896\n",
      "Training step:  3843\n",
      "Loss: 932.2161436902361\n",
      "Training step:  3844\n",
      "Loss: 932.2131525943859\n",
      "Training step:  3845\n",
      "Loss: 932.2103744532661\n",
      "Training step:  3846\n",
      "Loss: 932.2075332858553\n",
      "Training step:  3847\n",
      "Loss: 932.2048756469828\n",
      "Training step:  3848\n",
      "Loss: 932.2019292403086\n",
      "Training step:  3849\n",
      "Loss: 932.1993359464954\n",
      "Training step:  3850\n",
      "Loss: 932.1963749973336\n",
      "Training step:  3851\n",
      "Loss: 932.1937651748619\n",
      "Training step:  3852\n",
      "Loss: 932.1908233948066\n",
      "Training step:  3853\n",
      "Loss: 932.1882467660889\n",
      "Training step:  3854\n",
      "Loss: 932.1852867881736\n",
      "Training step:  3855\n",
      "Loss: 932.1825081570493\n",
      "Training step:  3856\n",
      "Loss: 932.1797272816804\n",
      "Training step:  3857\n",
      "Loss: 932.1770630684373\n",
      "Training step:  3858\n",
      "Loss: 932.1741566062838\n",
      "Training step:  3859\n",
      "Loss: 932.171625747514\n",
      "Training step:  3860\n",
      "Loss: 932.1686511052137\n",
      "Training step:  3861\n",
      "Loss: 932.1658570709376\n",
      "Training step:  3862\n",
      "Loss: 932.1631925612359\n",
      "Training step:  3863\n",
      "Loss: 932.160294333008\n",
      "Training step:  3864\n",
      "Loss: 932.1577563079488\n",
      "Training step:  3865\n",
      "Loss: 932.1547975109717\n",
      "Training step:  3866\n",
      "Loss: 932.1520248519982\n",
      "Training step:  3867\n",
      "Loss: 932.1493478632481\n",
      "Training step:  3868\n",
      "Loss: 932.1465888470748\n",
      "Training step:  3869\n",
      "Loss: 932.143789573131\n",
      "Training step:  3870\n",
      "Loss: 932.1411981272853\n",
      "Training step:  3871\n",
      "Loss: 932.1383071832718\n",
      "Training step:  3872\n",
      "Loss: 932.1357435832916\n",
      "Training step:  3873\n",
      "Loss: 932.1328465321202\n",
      "Training step:  3874\n",
      "Loss: 932.1303060374636\n",
      "Training step:  3875\n",
      "Loss: 932.1273892457792\n",
      "Training step:  3876\n",
      "Loss: 932.124793436565\n",
      "Training step:  3877\n",
      "Loss: 932.1219205468384\n",
      "Training step:  3878\n",
      "Loss: 932.1193793337255\n",
      "Training step:  3879\n",
      "Loss: 932.116484529456\n",
      "Training step:  3880\n",
      "Loss: 932.1139664596161\n",
      "Training step:  3881\n",
      "Loss: 932.11106197604\n",
      "Training step:  3882\n",
      "Loss: 932.108405376868\n",
      "Training step:  3883\n",
      "Loss: 932.1056312793286\n",
      "Training step:  3884\n",
      "Loss: 932.103071242797\n",
      "Training step:  3885\n",
      "Loss: 932.1002050439378\n",
      "Training step:  3886\n",
      "Loss: 932.0976857003817\n",
      "Training step:  3887\n",
      "Loss: 932.0948065108919\n",
      "Training step:  3888\n",
      "Loss: 932.0922786257634\n",
      "Training step:  3889\n",
      "Loss: 932.0894100129419\n",
      "Training step:  3890\n",
      "Loss: 932.0868917906156\n",
      "Training step:  3891\n",
      "Loss: 932.0840241279647\n",
      "Training step:  3892\n",
      "Loss: 932.0814571227896\n",
      "Training step:  3893\n",
      "Loss: 932.0786302892524\n",
      "Training step:  3894\n",
      "Loss: 932.0761075847624\n",
      "Training step:  3895\n",
      "Loss: 932.0732596506891\n",
      "Training step:  3896\n",
      "Loss: 932.0707597110713\n",
      "Training step:  3897\n",
      "Loss: 932.0678983737598\n",
      "Training step:  3898\n",
      "Loss: 932.0652073137878\n",
      "Training step:  3899\n",
      "Loss: 932.0625114624484\n",
      "Training step:  3900\n",
      "Loss: 932.0599239231196\n",
      "Training step:  3901\n",
      "Loss: 932.0571199202302\n",
      "Training step:  3902\n",
      "Loss: 932.0546046961359\n",
      "Training step:  3903\n",
      "Loss: 932.0517740116425\n",
      "Training step:  3904\n",
      "Loss: 932.0492802994198\n",
      "Training step:  3905\n",
      "Loss: 932.0464477498871\n",
      "Training step:  3906\n",
      "Loss: 932.0439575420044\n",
      "Training step:  3907\n",
      "Loss: 932.0411259532216\n",
      "Training step:  3908\n",
      "Loss: 932.0385953366632\n",
      "Training step:  3909\n",
      "Loss: 932.0357961752709\n",
      "Training step:  3910\n",
      "Loss: 932.0333101166029\n",
      "Training step:  3911\n",
      "Loss: 932.0304899878569\n",
      "Training step:  3912\n",
      "Loss: 932.02798699044\n",
      "Training step:  3913\n",
      "Loss: 932.0251842903964\n",
      "Training step:  3914\n",
      "Loss: 932.0227141822894\n",
      "Training step:  3915\n",
      "Loss: 932.019898975908\n",
      "Training step:  3916\n",
      "Loss: 932.0172583662447\n",
      "Training step:  3917\n",
      "Loss: 932.0145897142356\n",
      "Training step:  3918\n",
      "Loss: 932.0120474001394\n",
      "Training step:  3919\n",
      "Loss: 932.0092736038251\n",
      "Training step:  3920\n",
      "Loss: 932.0068006904534\n",
      "Training step:  3921\n",
      "Loss: 932.004003884461\n",
      "Training step:  3922\n",
      "Loss: 932.0015343691052\n",
      "Training step:  3923\n",
      "Loss: 931.9987488355549\n",
      "Training step:  3924\n",
      "Loss: 931.9963004963588\n",
      "Training step:  3925\n",
      "Loss: 931.9935025506206\n",
      "Training step:  3926\n",
      "Loss: 931.9908878958173\n",
      "Training step:  3927\n",
      "Loss: 931.9882329446588\n",
      "Training step:  3928\n",
      "Loss: 931.9857190826633\n",
      "Training step:  3929\n",
      "Loss: 931.9829690749735\n",
      "Training step:  3930\n",
      "Loss: 931.9805112651718\n",
      "Training step:  3931\n",
      "Loss: 931.9777412694757\n",
      "Training step:  3932\n",
      "Loss: 931.9753050171911\n",
      "Training step:  3933\n",
      "Loss: 931.9725261388114\n",
      "Training step:  3934\n",
      "Loss: 931.9699533318545\n",
      "Training step:  3935\n",
      "Loss: 931.9672886579132\n",
      "Training step:  3936\n",
      "Loss: 931.9648199016938\n",
      "Training step:  3937\n",
      "Loss: 931.9620726610028\n",
      "Training step:  3938\n",
      "Loss: 931.9596392835367\n",
      "Training step:  3939\n",
      "Loss: 931.956880244346\n",
      "Training step:  3940\n",
      "Loss: 931.9544392257494\n",
      "Training step:  3941\n",
      "Loss: 931.9516867161782\n",
      "Training step:  3942\n",
      "Loss: 931.949261575105\n",
      "Training step:  3943\n",
      "Loss: 931.9465068225461\n",
      "Training step:  3944\n",
      "Loss: 931.9440230465391\n",
      "Training step:  3945\n",
      "Loss: 931.9413119199152\n",
      "Training step:  3946\n",
      "Loss: 931.9388770298027\n",
      "Training step:  3947\n",
      "Loss: 931.9361408090674\n",
      "Training step:  3948\n",
      "Loss: 931.9337151156127\n",
      "Training step:  3949\n",
      "Loss: 931.9309842156582\n",
      "Training step:  3950\n",
      "Loss: 931.9285686202898\n",
      "Training step:  3951\n",
      "Loss: 931.9258355222737\n",
      "Training step:  3952\n",
      "Loss: 931.9233460163437\n",
      "Training step:  3953\n",
      "Loss: 931.9206658675236\n",
      "Training step:  3954\n",
      "Loss: 931.9182294991309\n",
      "Training step:  3955\n",
      "Loss: 931.9155227969959\n",
      "Training step:  3956\n",
      "Loss: 931.9131191830019\n",
      "Training step:  3957\n",
      "Loss: 931.910398055975\n",
      "Training step:  3958\n",
      "Loss: 931.9079145487108\n",
      "Training step:  3959\n",
      "Loss: 931.9052523232307\n",
      "Training step:  3960\n",
      "Loss: 931.9028308339297\n",
      "Training step:  3961\n",
      "Loss: 931.900132919186\n",
      "Training step:  3962\n",
      "Loss: 931.8977438049418\n",
      "Training step:  3963\n",
      "Loss: 931.8950344118686\n",
      "Training step:  3964\n",
      "Loss: 931.8924777511611\n",
      "Training step:  3965\n",
      "Loss: 931.8899075867988\n",
      "Training step:  3966\n",
      "Loss: 931.8874452790755\n",
      "Training step:  3967\n",
      "Loss: 931.8847788813254\n",
      "Training step:  3968\n",
      "Loss: 931.8823824101013\n",
      "Training step:  3969\n",
      "Loss: 931.8796948806265\n",
      "Training step:  3970\n",
      "Loss: 931.8773020581617\n",
      "Training step:  3971\n",
      "Loss: 931.874616093939\n",
      "Training step:  3972\n",
      "Loss: 931.8722490446065\n",
      "Training step:  3973\n",
      "Loss: 931.8695548905448\n",
      "Training step:  3974\n",
      "Loss: 931.8670785933691\n",
      "Training step:  3975\n",
      "Loss: 931.8644637529839\n",
      "Training step:  3976\n",
      "Loss: 931.8621045027453\n",
      "Training step:  3977\n",
      "Loss: 931.8594155566595\n",
      "Training step:  3978\n",
      "Loss: 931.8569136915296\n",
      "Training step:  3979\n",
      "Loss: 931.8543468936786\n",
      "Training step:  3980\n",
      "Loss: 931.8519397861505\n",
      "Training step:  3981\n",
      "Loss: 931.8492945107527\n",
      "Training step:  3982\n",
      "Loss: 931.8469297430213\n",
      "Training step:  3983\n",
      "Loss: 931.8442640768837\n",
      "Training step:  3984\n",
      "Loss: 931.8419148555714\n",
      "Training step:  3985\n",
      "Loss: 931.8392478010749\n",
      "Training step:  3986\n",
      "Loss: 931.8368919790503\n",
      "Training step:  3987\n",
      "Loss: 931.8342303603764\n",
      "Training step:  3988\n",
      "Loss: 931.8318797231614\n",
      "Training step:  3989\n",
      "Loss: 931.8292205523492\n",
      "Training step:  3990\n",
      "Loss: 931.8268132725467\n",
      "Training step:  3991\n",
      "Loss: 931.8242033989023\n",
      "Training step:  3992\n",
      "Loss: 931.821839929792\n",
      "Training step:  3993\n",
      "Loss: 931.8192071251331\n",
      "Training step:  3994\n",
      "Loss: 931.8168724004751\n",
      "Training step:  3995\n",
      "Loss: 931.8142288134319\n",
      "Training step:  3996\n",
      "Loss: 931.8117633429545\n",
      "Training step:  3997\n",
      "Loss: 931.8092259854261\n",
      "Training step:  3998\n",
      "Loss: 931.8068577551998\n",
      "Training step:  3999\n",
      "Loss: 931.8042442425589\n",
      "Training step:  4000\n",
      "Loss: 931.8019113605034\n",
      "Training step:  4001\n",
      "Loss: 931.799278708607\n",
      "Training step:  4002\n",
      "Loss: 931.7969324068949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  4003\n",
      "Loss: 931.7943194963393\n",
      "Training step:  4004\n",
      "Loss: 931.7920019374557\n",
      "Training step:  4005\n",
      "Loss: 931.7893785276493\n",
      "Training step:  4006\n",
      "Loss: 931.786928560086\n",
      "Training step:  4007\n",
      "Loss: 931.7844058848133\n",
      "Training step:  4008\n",
      "Loss: 931.7820600541577\n",
      "Training step:  4009\n",
      "Loss: 931.779463611615\n",
      "Training step:  4010\n",
      "Loss: 931.7771502701742\n",
      "Training step:  4011\n",
      "Loss: 931.7745382726306\n",
      "Training step:  4012\n",
      "Loss: 931.7721722297123\n",
      "Training step:  4013\n",
      "Loss: 931.7696111303129\n",
      "Training step:  4014\n",
      "Loss: 931.7672795854462\n",
      "Training step:  4015\n",
      "Loss: 931.7646944942227\n",
      "Training step:  4016\n",
      "Loss: 931.7623930446615\n",
      "Training step:  4017\n",
      "Loss: 931.7597975918663\n",
      "Training step:  4018\n",
      "Loss: 931.7573932144085\n",
      "Training step:  4019\n",
      "Loss: 931.7548741688356\n",
      "Training step:  4020\n",
      "Loss: 931.7525747965003\n",
      "Training step:  4021\n",
      "Loss: 931.7499853744459\n",
      "Training step:  4022\n",
      "Loss: 931.747680751757\n",
      "Training step:  4023\n",
      "Loss: 931.7451017388232\n",
      "Training step:  4024\n",
      "Loss: 931.7428112565907\n",
      "Training step:  4025\n",
      "Loss: 931.7402305878201\n",
      "Training step:  4026\n",
      "Loss: 931.7378425467477\n",
      "Training step:  4027\n",
      "Loss: 931.7353407153142\n",
      "Training step:  4028\n",
      "Loss: 931.7330514190521\n",
      "Training step:  4029\n",
      "Loss: 931.7304770384128\n",
      "Training step:  4030\n",
      "Loss: 931.7281908460378\n",
      "Training step:  4031\n",
      "Loss: 931.725622415782\n",
      "Training step:  4032\n",
      "Loss: 931.7233504104682\n",
      "Training step:  4033\n",
      "Loss: 931.7207835976423\n",
      "Training step:  4034\n",
      "Loss: 931.7184451573762\n",
      "Training step:  4035\n",
      "Loss: 931.7159309345516\n",
      "Training step:  4036\n",
      "Loss: 931.7136847732436\n",
      "Training step:  4037\n",
      "Loss: 931.711110382376\n",
      "Training step:  4038\n",
      "Loss: 931.7086609346064\n",
      "Training step:  4039\n",
      "Loss: 931.7063254968881\n",
      "Training step:  4040\n",
      "Loss: 931.7037939492986\n",
      "Training step:  4041\n",
      "Loss: 931.7015145309106\n",
      "Training step:  4042\n",
      "Loss: 931.6989680624648\n",
      "Training step:  4043\n",
      "Loss: 931.6967141155582\n",
      "Training step:  4044\n",
      "Loss: 931.6941639402655\n",
      "Training step:  4045\n",
      "Loss: 931.6918477112059\n",
      "Training step:  4046\n",
      "Loss: 931.6893583159534\n",
      "Training step:  4047\n",
      "Loss: 931.6871248185729\n",
      "Training step:  4048\n",
      "Loss: 931.6845765038992\n",
      "Training step:  4049\n",
      "Loss: 931.6821465771325\n",
      "Training step:  4050\n",
      "Loss: 931.6798301841726\n",
      "Training step:  4051\n",
      "Loss: 931.6774084883483\n",
      "Training step:  4052\n",
      "Loss: 931.674982738331\n",
      "Training step:  4053\n",
      "Loss: 931.6726947046592\n",
      "Training step:  4054\n",
      "Loss: 931.6702003272114\n",
      "Training step:  4055\n",
      "Loss: 931.6679491342117\n",
      "Training step:  4056\n",
      "Loss: 931.6654335608338\n",
      "Training step:  4057\n",
      "Loss: 931.6631997438898\n",
      "Training step:  4058\n",
      "Loss: 931.6606782799344\n",
      "Training step:  4059\n",
      "Loss: 931.6584391961383\n",
      "Training step:  4060\n",
      "Loss: 931.6559275366221\n",
      "Training step:  4061\n",
      "Loss: 931.6537020569117\n",
      "Training step:  4062\n",
      "Loss: 931.6511841664508\n",
      "Training step:  4063\n",
      "Loss: 931.6488555914278\n",
      "Training step:  4064\n",
      "Loss: 931.646439386083\n",
      "Training step:  4065\n",
      "Loss: 931.6441881900914\n",
      "Training step:  4066\n",
      "Loss: 931.6417022848939\n",
      "Training step:  4067\n",
      "Loss: 931.6394827620475\n",
      "Training step:  4068\n",
      "Loss: 931.6369826864876\n",
      "Training step:  4069\n",
      "Loss: 931.6347580502842\n",
      "Training step:  4070\n",
      "Loss: 931.6322676515645\n",
      "Training step:  4071\n",
      "Loss: 931.6300563988536\n",
      "Training step:  4072\n",
      "Loss: 931.6275598833613\n",
      "Training step:  4073\n",
      "Loss: 931.6252178096698\n",
      "Training step:  4074\n",
      "Loss: 931.6228368766856\n",
      "Training step:  4075\n",
      "Loss: 931.6205788569329\n",
      "Training step:  4076\n",
      "Loss: 931.6181238318742\n",
      "Training step:  4077\n",
      "Loss: 931.615911158319\n",
      "Training step:  4078\n",
      "Loss: 931.6134358629207\n",
      "Training step:  4079\n",
      "Loss: 931.6112387067059\n",
      "Training step:  4080\n",
      "Loss: 931.6087590717927\n",
      "Training step:  4081\n",
      "Loss: 931.6064695963128\n",
      "Training step:  4082\n",
      "Loss: 931.6040768377502\n",
      "Training step:  4083\n",
      "Loss: 931.6018668944116\n",
      "Training step:  4084\n",
      "Loss: 931.5994077145037\n",
      "Training step:  4085\n",
      "Loss: 931.5972248703799\n",
      "Training step:  4086\n",
      "Loss: 931.5947519587536\n",
      "Training step:  4087\n",
      "Loss: 931.592420817627\n",
      "Training step:  4088\n",
      "Loss: 931.5900934782707\n",
      "Training step:  4089\n",
      "Loss: 931.5878206298516\n",
      "Training step:  4090\n",
      "Loss: 931.5854144122243\n",
      "Training step:  4091\n",
      "Loss: 931.5832464879578\n",
      "Training step:  4092\n",
      "Loss: 931.5807807411122\n",
      "Training step:  4093\n",
      "Loss: 931.5785051324145\n",
      "Training step:  4094\n",
      "Loss: 931.5761455499247\n",
      "Training step:  4095\n",
      "Loss: 931.5739306660549\n",
      "Training step:  4096\n",
      "Loss: 931.5715141850179\n",
      "Training step:  4097\n",
      "Loss: 931.5693290583038\n",
      "Training step:  4098\n",
      "Loss: 931.5668962208679\n",
      "Training step:  4099\n",
      "Loss: 931.5647147097967\n",
      "Training step:  4100\n",
      "Loss: 931.5622857483339\n",
      "Training step:  4101\n",
      "Loss: 931.5600994286209\n",
      "Training step:  4102\n",
      "Loss: 931.5576806282634\n",
      "Training step:  4103\n",
      "Loss: 931.5555088576139\n",
      "Training step:  4104\n",
      "Loss: 931.5530842705375\n",
      "Training step:  4105\n",
      "Loss: 931.5508263860414\n",
      "Training step:  4106\n",
      "Loss: 931.5484855380045\n",
      "Training step:  4107\n",
      "Loss: 931.5463045192563\n",
      "Training step:  4108\n",
      "Loss: 931.5438997798561\n",
      "Training step:  4109\n",
      "Loss: 931.5417450276599\n",
      "Training step:  4110\n",
      "Loss: 931.5393270689334\n",
      "Training step:  4111\n",
      "Loss: 931.537037394253\n",
      "Training step:  4112\n",
      "Loss: 931.5347343429435\n",
      "Training step:  4113\n",
      "Loss: 931.5325234766306\n",
      "Training step:  4114\n",
      "Loss: 931.5301510630094\n",
      "Training step:  4115\n",
      "Loss: 931.5279848566053\n",
      "Training step:  4116\n",
      "Loss: 931.5255934667747\n",
      "Training step:  4117\n",
      "Loss: 931.5234515302475\n",
      "Training step:  4118\n",
      "Loss: 931.5210471063757\n",
      "Training step:  4119\n",
      "Loss: 931.5188912114487\n",
      "Training step:  4120\n",
      "Loss: 931.5165037121861\n",
      "Training step:  4121\n",
      "Loss: 931.5143722559118\n",
      "Training step:  4122\n",
      "Loss: 931.5119718406927\n",
      "Training step:  4123\n",
      "Loss: 931.5097134721003\n",
      "Training step:  4124\n",
      "Loss: 931.5074319937941\n",
      "Training step:  4125\n",
      "Loss: 931.5052298079661\n",
      "Training step:  4126\n",
      "Loss: 931.5028898687036\n",
      "Training step:  4127\n",
      "Loss: 931.5007778194718\n",
      "Training step:  4128\n",
      "Loss: 931.4983808436369\n",
      "Training step:  4129\n",
      "Loss: 931.4960998006084\n",
      "Training step:  4130\n",
      "Loss: 931.4939063937416\n",
      "Training step:  4131\n",
      "Loss: 931.4916440730043\n",
      "Training step:  4132\n",
      "Loss: 931.4893534161652\n",
      "Training step:  4133\n",
      "Loss: 931.4872043001335\n",
      "Training step:  4134\n",
      "Loss: 931.4848517397049\n",
      "Training step:  4135\n",
      "Loss: 931.4827248816385\n",
      "Training step:  4136\n",
      "Loss: 931.4803647990315\n",
      "Training step:  4137\n",
      "Loss: 931.4782469074074\n",
      "Training step:  4138\n",
      "Loss: 931.4758853969536\n",
      "Training step:  4139\n",
      "Loss: 931.4737763563103\n",
      "Training step:  4140\n",
      "Loss: 931.4714106728413\n",
      "Training step:  4141\n",
      "Loss: 931.4692467025736\n",
      "Training step:  4142\n",
      "Loss: 931.4669327069228\n",
      "Training step:  4143\n",
      "Loss: 931.464838138925\n",
      "Training step:  4144\n",
      "Loss: 931.462476537171\n",
      "Training step:  4145\n",
      "Loss: 931.4602648219364\n",
      "Training step:  4146\n",
      "Loss: 931.4580172613142\n",
      "Training step:  4147\n",
      "Loss: 931.45586565174\n",
      "Training step:  4148\n",
      "Loss: 931.4535512548606\n",
      "Training step:  4149\n",
      "Loss: 931.4514412516012\n",
      "Training step:  4150\n",
      "Loss: 931.4491086421192\n",
      "Training step:  4151\n",
      "Loss: 931.4470179545008\n",
      "Training step:  4152\n",
      "Loss: 931.4446764968975\n",
      "Training step:  4153\n",
      "Loss: 931.4425650940408\n",
      "Training step:  4154\n",
      "Loss: 931.4402473294759\n",
      "Training step:  4155\n",
      "Loss: 931.4381587586527\n",
      "Training step:  4156\n",
      "Loss: 931.4358288102081\n",
      "Training step:  4157\n",
      "Loss: 931.4337110346429\n",
      "Training step:  4158\n",
      "Loss: 931.4314074654567\n",
      "Training step:  4159\n",
      "Loss: 931.4293175443906\n",
      "Training step:  4160\n",
      "Loss: 931.4269991590534\n",
      "Training step:  4161\n",
      "Loss: 931.4249180638027\n",
      "Training step:  4162\n",
      "Loss: 931.4225979702823\n",
      "Training step:  4163\n",
      "Loss: 931.4204178050279\n",
      "Training step:  4164\n",
      "Loss: 931.4181866264348\n",
      "Training step:  4165\n",
      "Loss: 931.4160824302069\n",
      "Training step:  4166\n",
      "Loss: 931.4137919913014\n",
      "Training step:  4167\n",
      "Loss: 931.4117150495409\n",
      "Training step:  4168\n",
      "Loss: 931.4094100324314\n",
      "Training step:  4169\n",
      "Loss: 931.4073417680032\n",
      "Training step:  4170\n",
      "Loss: 931.4050377158866\n",
      "Training step:  4171\n",
      "Loss: 931.4028944711764\n",
      "Training step:  4172\n",
      "Loss: 931.4006599766375\n",
      "Training step:  4173\n",
      "Loss: 931.3985898952599\n",
      "Training step:  4174\n",
      "Loss: 931.396296951263\n",
      "Training step:  4175\n",
      "Loss: 931.3942311984823\n",
      "Training step:  4176\n",
      "Loss: 931.3919414579613\n",
      "Training step:  4177\n",
      "Loss: 931.389881747673\n",
      "Training step:  4178\n",
      "Loss: 931.387592646101\n",
      "Training step:  4179\n",
      "Loss: 931.3854974841104\n",
      "Training step:  4180\n",
      "Loss: 931.3832447000618\n",
      "Training step:  4181\n",
      "Loss: 931.3811780158177\n",
      "Training step:  4182\n",
      "Loss: 931.3789017716166\n",
      "Training step:  4183\n",
      "Loss: 931.376860423964\n",
      "Training step:  4184\n",
      "Loss: 931.3745752397052\n",
      "Training step:  4185\n",
      "Loss: 931.3724266324894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  4186\n",
      "Loss: 931.3702317806391\n",
      "Training step:  4187\n",
      "Loss: 931.3681594916526\n",
      "Training step:  4188\n",
      "Loss: 931.3659018563727\n",
      "Training step:  4189\n",
      "Loss: 931.3638632691349\n",
      "Training step:  4190\n",
      "Loss: 931.3615940085781\n",
      "Training step:  4191\n",
      "Loss: 931.3595565442823\n",
      "Training step:  4192\n",
      "Loss: 931.3572904264346\n",
      "Training step:  4193\n",
      "Loss: 931.3552539786655\n",
      "Training step:  4194\n",
      "Loss: 931.3529933782173\n",
      "Training step:  4195\n",
      "Loss: 931.3509650149817\n",
      "Training step:  4196\n",
      "Loss: 931.3487028709875\n",
      "Training step:  4197\n",
      "Loss: 931.3465805900286\n",
      "Training step:  4198\n",
      "Loss: 931.3443971776269\n",
      "Training step:  4199\n",
      "Loss: 931.3423462430827\n",
      "Training step:  4200\n",
      "Loss: 931.3401157789675\n",
      "Training step:  4201\n",
      "Loss: 931.3380882798074\n",
      "Training step:  4202\n",
      "Loss: 931.335846524649\n",
      "Training step:  4203\n",
      "Loss: 931.3338201453525\n",
      "Training step:  4204\n",
      "Loss: 931.331581504258\n",
      "Training step:  4205\n",
      "Loss: 931.3295632255948\n",
      "Training step:  4206\n",
      "Loss: 931.3273169886517\n",
      "Training step:  4207\n",
      "Loss: 931.325205677809\n",
      "Training step:  4208\n",
      "Loss: 931.3230438723125\n",
      "Training step:  4209\n",
      "Loss: 931.3210086508974\n",
      "Training step:  4210\n",
      "Loss: 931.3187916306173\n",
      "Training step:  4211\n",
      "Loss: 931.3167820834426\n",
      "Training step:  4212\n",
      "Loss: 931.3145515018324\n",
      "Training step:  4213\n",
      "Loss: 931.312550269543\n",
      "Training step:  4214\n",
      "Loss: 931.3103206920283\n",
      "Training step:  4215\n",
      "Loss: 931.3082909830388\n",
      "Training step:  4216\n",
      "Loss: 931.3060877711157\n",
      "Training step:  4217\n",
      "Loss: 931.3040832642151\n",
      "Training step:  4218\n",
      "Loss: 931.3018666436055\n",
      "Training step:  4219\n",
      "Loss: 931.2998659332764\n",
      "Training step:  4220\n",
      "Loss: 931.2976524111003\n",
      "Training step:  4221\n",
      "Loss: 931.2956595857851\n",
      "Training step:  4222\n",
      "Loss: 931.2934470674195\n",
      "Training step:  4223\n",
      "Loss: 931.2914120060476\n",
      "Training step:  4224\n",
      "Loss: 931.2892301779078\n",
      "Training step:  4225\n",
      "Loss: 931.2872321586476\n",
      "Training step:  4226\n",
      "Loss: 931.285034111407\n",
      "Training step:  4227\n",
      "Loss: 931.2830534774172\n",
      "Training step:  4228\n",
      "Loss: 931.2808477039605\n",
      "Training step:  4229\n",
      "Loss: 931.2787647117258\n",
      "Training step:  4230\n",
      "Loss: 931.276647481949\n",
      "Training step:  4231\n",
      "Loss: 931.2746312357506\n",
      "Training step:  4232\n",
      "Loss: 931.272456603214\n",
      "Training step:  4233\n",
      "Loss: 931.2704732364826\n",
      "Training step:  4234\n",
      "Loss: 931.2682878063081\n",
      "Training step:  4235\n",
      "Loss: 931.2663145987503\n",
      "Training step:  4236\n",
      "Loss: 931.2641260198988\n",
      "Training step:  4237\n",
      "Loss: 931.2621460047695\n",
      "Training step:  4238\n",
      "Loss: 931.2599685230915\n",
      "Training step:  4239\n",
      "Loss: 931.2579959038616\n",
      "Training step:  4240\n",
      "Loss: 931.255817061435\n",
      "Training step:  4241\n",
      "Loss: 931.2538251520049\n",
      "Training step:  4242\n",
      "Loss: 931.2516654671451\n",
      "Training step:  4243\n",
      "Loss: 931.2496988515775\n",
      "Training step:  4244\n",
      "Loss: 931.2475287320748\n",
      "Training step:  4245\n",
      "Loss: 931.2455675804231\n",
      "Training step:  4246\n",
      "Loss: 931.2433961069079\n",
      "Training step:  4247\n",
      "Loss: 931.2413487342495\n",
      "Training step:  4248\n",
      "Loss: 931.2392412960784\n",
      "Training step:  4249\n",
      "Loss: 931.2372693711094\n",
      "Training step:  4250\n",
      "Loss: 931.2351184780952\n",
      "Training step:  4251\n",
      "Loss: 931.2331645740132\n",
      "Training step:  4252\n",
      "Loss: 931.2310040055993\n",
      "Training step:  4253\n",
      "Loss: 931.2290259574206\n",
      "Training step:  4254\n",
      "Loss: 931.2268899865653\n",
      "Training step:  4255\n",
      "Loss: 931.2249360826528\n",
      "Training step:  4256\n",
      "Loss: 931.2227876023028\n",
      "Training step:  4257\n",
      "Loss: 931.2208415713287\n",
      "Training step:  4258\n",
      "Loss: 931.2186940912185\n",
      "Training step:  4259\n",
      "Loss: 931.2167205496471\n",
      "Training step:  4260\n",
      "Loss: 931.2145936685837\n",
      "Training step:  4261\n",
      "Loss: 931.2126492328167\n",
      "Training step:  4262\n",
      "Loss: 931.2105120653499\n",
      "Training step:  4263\n",
      "Loss: 931.2085688591653\n",
      "Training step:  4264\n",
      "Loss: 931.2064346671369\n",
      "Training step:  4265\n",
      "Loss: 931.2044989399596\n",
      "Training step:  4266\n",
      "Loss: 931.2023634948181\n",
      "Training step:  4267\n",
      "Loss: 931.2003399198164\n",
      "Training step:  4268\n",
      "Loss: 931.1982715907579\n",
      "Training step:  4269\n",
      "Loss: 931.1963174398451\n",
      "Training step:  4270\n",
      "Loss: 931.1942081381326\n",
      "Training step:  4271\n",
      "Loss: 931.1922760046765\n",
      "Training step:  4272\n",
      "Loss: 931.1901566387181\n",
      "Training step:  4273\n",
      "Loss: 931.1882341574897\n",
      "Training step:  4274\n",
      "Loss: 931.1861118928284\n",
      "Training step:  4275\n",
      "Loss: 931.1841274521945\n",
      "Training step:  4276\n",
      "Loss: 931.1820464693591\n",
      "Training step:  4277\n",
      "Loss: 931.1801457424485\n",
      "Training step:  4278\n",
      "Loss: 931.1780163472775\n",
      "Training step:  4279\n",
      "Loss: 931.1759793107791\n",
      "Training step:  4280\n",
      "Loss: 931.1740052197068\n",
      "Training step:  4281\n",
      "Loss: 931.1719228983179\n",
      "Training step:  4282\n",
      "Loss: 931.1699848436656\n",
      "Training step:  4283\n",
      "Loss: 931.1678816536629\n",
      "Training step:  4284\n",
      "Loss: 931.1659731841037\n",
      "Training step:  4285\n",
      "Loss: 931.1638677243333\n",
      "Training step:  4286\n",
      "Loss: 931.1619520089874\n",
      "Training step:  4287\n",
      "Loss: 931.1598584088981\n",
      "Training step:  4288\n",
      "Loss: 931.1579591593484\n",
      "Training step:  4289\n",
      "Loss: 931.1558564821601\n",
      "Training step:  4290\n",
      "Loss: 931.1538765362632\n",
      "Training step:  4291\n",
      "Loss: 931.1518426162062\n",
      "Training step:  4292\n",
      "Loss: 931.1499299297718\n",
      "Training step:  4293\n",
      "Loss: 931.1478486264286\n",
      "Training step:  4294\n",
      "Loss: 931.1459570462576\n",
      "Training step:  4295\n",
      "Loss: 931.1438660887304\n",
      "Training step:  4296\n",
      "Loss: 931.1419684685532\n",
      "Training step:  4297\n",
      "Loss: 931.1398878028087\n",
      "Training step:  4298\n",
      "Loss: 931.1380052599688\n",
      "Training step:  4299\n",
      "Loss: 931.1359178449464\n",
      "Training step:  4300\n",
      "Loss: 931.1339719491119\n",
      "Training step:  4301\n",
      "Loss: 931.1319366236633\n",
      "Training step:  4302\n",
      "Loss: 931.1300601377723\n",
      "Training step:  4303\n",
      "Loss: 931.1279790088233\n",
      "Training step:  4304\n",
      "Loss: 931.126093758708\n",
      "Training step:  4305\n",
      "Loss: 931.1240233551295\n",
      "Training step:  4306\n",
      "Loss: 931.1221462704116\n",
      "Training step:  4307\n",
      "Loss: 931.1200747772505\n",
      "Training step:  4308\n",
      "Loss: 931.1181753243552\n",
      "Training step:  4309\n",
      "Loss: 931.1161268529523\n",
      "Training step:  4310\n",
      "Loss: 931.114249481616\n",
      "Training step:  4311\n",
      "Loss: 931.1121896649375\n",
      "Training step:  4312\n",
      "Loss: 931.1103197640582\n",
      "Training step:  4313\n",
      "Loss: 931.1082610017196\n",
      "Training step:  4314\n",
      "Loss: 931.1063960822773\n",
      "Training step:  4315\n",
      "Loss: 931.1043362423252\n",
      "Training step:  4316\n",
      "Loss: 931.1023748737665\n",
      "Training step:  4317\n",
      "Loss: 931.1004053312636\n",
      "Training step:  4318\n",
      "Loss: 931.0984939937663\n",
      "Training step:  4319\n",
      "Loss: 931.0964712423522\n",
      "Training step:  4320\n",
      "Loss: 931.0946052721735\n",
      "Training step:  4321\n",
      "Loss: 931.0925630715047\n",
      "Training step:  4322\n",
      "Loss: 931.0907083434118\n",
      "Training step:  4323\n",
      "Loss: 931.0886635491154\n",
      "Training step:  4324\n",
      "Loss: 931.0867905267058\n",
      "Training step:  4325\n",
      "Loss: 931.0847621791324\n",
      "Training step:  4326\n",
      "Loss: 931.0829119778787\n",
      "Training step:  4327\n",
      "Loss: 931.0808744494434\n",
      "Training step:  4328\n",
      "Loss: 931.0789939406438\n",
      "Training step:  4329\n",
      "Loss: 931.0769814450289\n",
      "Training step:  4330\n",
      "Loss: 931.0751286604839\n",
      "Training step:  4331\n",
      "Loss: 931.0731026596692\n",
      "Training step:  4332\n",
      "Loss: 931.0712609901268\n",
      "Training step:  4333\n",
      "Loss: 931.0692324384736\n",
      "Training step:  4334\n",
      "Loss: 931.0673530061531\n",
      "Training step:  4335\n",
      "Loss: 931.065348432644\n",
      "Training step:  4336\n",
      "Loss: 931.0635052392711\n",
      "Training step:  4337\n",
      "Loss: 931.061489269251\n",
      "Training step:  4338\n",
      "Loss: 931.0596511961168\n",
      "Training step:  4339\n",
      "Loss: 931.0576342229426\n",
      "Training step:  4340\n",
      "Loss: 931.0557961831207\n",
      "Training step:  4341\n",
      "Loss: 931.053785138477\n",
      "Training step:  4342\n",
      "Loss: 931.0519538606651\n",
      "Training step:  4343\n",
      "Loss: 931.049941852716\n",
      "Training step:  4344\n",
      "Loss: 931.0480404972675\n",
      "Training step:  4345\n",
      "Loss: 931.0460847247559\n",
      "Training step:  4346\n",
      "Loss: 931.0442489943994\n",
      "Training step:  4347\n",
      "Loss: 931.0422505294692\n",
      "Training step:  4348\n",
      "Loss: 931.0404269126274\n",
      "Training step:  4349\n",
      "Loss: 931.0384259935902\n",
      "Training step:  4350\n",
      "Loss: 931.0365969576798\n",
      "Training step:  4351\n",
      "Loss: 931.0346043826144\n",
      "Training step:  4352\n",
      "Loss: 931.0327905843515\n",
      "Training step:  4353\n",
      "Loss: 931.0307918497208\n",
      "Training step:  4354\n",
      "Loss: 931.0288871285272\n",
      "Training step:  4355\n",
      "Loss: 931.0269691902386\n",
      "Training step:  4356\n",
      "Loss: 931.0251149298738\n",
      "Training step:  4357\n",
      "Loss: 931.023147196544\n",
      "Training step:  4358\n",
      "Loss: 931.0213289618125\n",
      "Training step:  4359\n",
      "Loss: 931.0193483995216\n",
      "Training step:  4360\n",
      "Loss: 931.0175447251577\n",
      "Training step:  4361\n",
      "Loss: 931.0155580645636\n",
      "Training step:  4362\n",
      "Loss: 931.0137418535752\n",
      "Training step:  4363\n",
      "Loss: 931.0117706696747\n",
      "Training step:  4364\n",
      "Loss: 931.0099691009464\n",
      "Training step:  4365\n",
      "Loss: 931.0079919258383\n",
      "Training step:  4366\n",
      "Loss: 931.0061617892854\n",
      "Training step:  4367\n",
      "Loss: 931.0042040132981\n",
      "Training step:  4368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 931.0024022053004\n",
      "Training step:  4369\n",
      "Loss: 931.0004341039694\n",
      "Training step:  4370\n",
      "Loss: 930.99863925339\n",
      "Training step:  4371\n",
      "Loss: 930.9966722222829\n",
      "Training step:  4372\n",
      "Loss: 930.9948784601752\n",
      "Training step:  4373\n",
      "Loss: 930.9929141763992\n",
      "Training step:  4374\n",
      "Loss: 930.9911036605905\n",
      "Training step:  4375\n",
      "Loss: 930.9891520044748\n",
      "Training step:  4376\n",
      "Loss: 930.9873645113698\n",
      "Training step:  4377\n",
      "Loss: 930.9854069966146\n",
      "Training step:  4378\n",
      "Loss: 930.9836242257469\n",
      "Training step:  4379\n",
      "Loss: 930.9816658567297\n",
      "Training step:  4380\n",
      "Loss: 930.9797913053072\n",
      "Training step:  4381\n",
      "Loss: 930.9779209906992\n",
      "Training step:  4382\n",
      "Loss: 930.9760868372094\n",
      "Training step:  4383\n",
      "Loss: 930.974161183766\n",
      "Training step:  4384\n",
      "Loss: 930.972378475535\n",
      "Training step:  4385\n",
      "Loss: 930.9704376334804\n",
      "Training step:  4386\n",
      "Loss: 930.9686670135626\n",
      "Training step:  4387\n",
      "Loss: 930.9667203678707\n",
      "Training step:  4388\n",
      "Loss: 930.9649288265707\n",
      "Training step:  4389\n",
      "Loss: 930.9630019164061\n",
      "Training step:  4390\n",
      "Loss: 930.9612307235734\n",
      "Training step:  4391\n",
      "Loss: 930.9592938124912\n",
      "Training step:  4392\n",
      "Loss: 930.957525745835\n",
      "Training step:  4393\n",
      "Loss: 930.9555915491678\n",
      "Training step:  4394\n",
      "Loss: 930.9537979328461\n",
      "Training step:  4395\n",
      "Loss: 930.951882292219\n",
      "Training step:  4396\n",
      "Loss: 930.950115969078\n",
      "Training step:  4397\n",
      "Loss: 930.9481924575261\n",
      "Training step:  4398\n",
      "Loss: 930.9464379373285\n",
      "Training step:  4399\n",
      "Loss: 930.9445087492909\n",
      "Training step:  4400\n",
      "Loss: 930.9426679335327\n",
      "Training step:  4401\n",
      "Loss: 930.9408151473056\n",
      "Training step:  4402\n",
      "Loss: 930.9390220554811\n",
      "Training step:  4403\n",
      "Loss: 930.9371148997111\n",
      "Training step:  4404\n",
      "Loss: 930.9353622472919\n",
      "Training step:  4405\n",
      "Loss: 930.9334469297188\n",
      "Training step:  4406\n",
      "Loss: 930.931695593269\n",
      "Training step:  4407\n",
      "Loss: 930.9297829396103\n",
      "Training step:  4408\n",
      "Loss: 930.9280379394768\n",
      "Training step:  4409\n",
      "Loss: 930.926124541376\n",
      "Training step:  4410\n",
      "Loss: 930.9243310121806\n",
      "Training step:  4411\n",
      "Loss: 930.9224581517086\n",
      "Training step:  4412\n",
      "Loss: 930.920724613654\n",
      "Training step:  4413\n",
      "Loss: 930.9188135097112\n",
      "Training step:  4414\n",
      "Loss: 930.917064059501\n",
      "Training step:  4415\n",
      "Loss: 930.9151707145422\n",
      "Training step:  4416\n",
      "Loss: 930.9134347072762\n",
      "Training step:  4417\n",
      "Loss: 930.9115341117689\n",
      "Training step:  4418\n",
      "Loss: 930.9097633721005\n",
      "Training step:  4419\n",
      "Loss: 930.9078882298818\n",
      "Training step:  4420\n",
      "Loss: 930.9061532298692\n",
      "Training step:  4421\n",
      "Loss: 930.9042637481356\n",
      "Training step:  4422\n",
      "Loss: 930.9025401907255\n",
      "Training step:  4423\n",
      "Loss: 930.9006452797845\n",
      "Training step:  4424\n",
      "Loss: 930.8988469943238\n",
      "Training step:  4425\n",
      "Loss: 930.8970147642721\n",
      "Training step:  4426\n",
      "Loss: 930.895270001461\n",
      "Training step:  4427\n",
      "Loss: 930.8933958627717\n",
      "Training step:  4428\n",
      "Loss: 930.8916749779859\n",
      "Training step:  4429\n",
      "Loss: 930.8897930974867\n",
      "Training step:  4430\n",
      "Loss: 930.8880734418591\n",
      "Training step:  4431\n",
      "Loss: 930.8861942009681\n",
      "Training step:  4432\n",
      "Loss: 930.8844807518304\n",
      "Training step:  4433\n",
      "Loss: 930.8826026125852\n",
      "Training step:  4434\n",
      "Loss: 930.8808802465458\n",
      "Training step:  4435\n",
      "Loss: 930.8790137414685\n",
      "Training step:  4436\n",
      "Loss: 930.8773048228247\n",
      "Training step:  4437\n",
      "Loss: 930.8754313069453\n",
      "Training step:  4438\n",
      "Loss: 930.8736433592318\n",
      "Training step:  4439\n",
      "Loss: 930.8718457103797\n",
      "Training step:  4440\n",
      "Loss: 930.8700913548657\n",
      "Training step:  4441\n",
      "Loss: 930.8682479721015\n",
      "Training step:  4442\n",
      "Loss: 930.8665401428382\n",
      "Training step:  4443\n",
      "Loss: 930.8646826302196\n",
      "Training step:  4444\n",
      "Loss: 930.8629824284138\n",
      "Training step:  4445\n",
      "Loss: 930.861122975568\n",
      "Training step:  4446\n",
      "Loss: 930.8593883633525\n",
      "Training step:  4447\n",
      "Loss: 930.8575467342537\n",
      "Training step:  4448\n",
      "Loss: 930.8558489807467\n",
      "Training step:  4449\n",
      "Loss: 930.8539957491106\n",
      "Training step:  4450\n",
      "Loss: 930.8523042145961\n",
      "Training step:  4451\n",
      "Loss: 930.8504503649177\n",
      "Training step:  4452\n",
      "Loss: 930.8487095179354\n",
      "Training step:  4453\n",
      "Loss: 930.8468945623131\n",
      "Training step:  4454\n",
      "Loss: 930.8452084585005\n",
      "Training step:  4455\n",
      "Loss: 930.8433633463565\n",
      "Training step:  4456\n",
      "Loss: 930.8416517502535\n",
      "Training step:  4457\n",
      "Loss: 930.8398225046349\n",
      "Training step:  4458\n",
      "Loss: 930.8381340048973\n",
      "Training step:  4459\n",
      "Loss: 930.8362978749394\n",
      "Training step:  4460\n",
      "Loss: 930.8346155903977\n",
      "Training step:  4461\n",
      "Loss: 930.8327788661785\n",
      "Training step:  4462\n",
      "Loss: 930.8310830412843\n",
      "Training step:  4463\n",
      "Loss: 930.8292605859245\n",
      "Training step:  4464\n",
      "Loss: 930.8275812974147\n",
      "Training step:  4465\n",
      "Loss: 930.8257521565492\n",
      "Training step:  4466\n",
      "Loss: 930.8240199103925\n",
      "Training step:  4467\n",
      "Loss: 930.822231464784\n",
      "Training step:  4468\n",
      "Loss: 930.8205579754137\n",
      "Training step:  4469\n",
      "Loss: 930.8187349231415\n",
      "Training step:  4470\n",
      "Loss: 930.817062863491\n",
      "Training step:  4471\n",
      "Loss: 930.8152420417205\n",
      "Training step:  4472\n",
      "Loss: 930.8135758703434\n",
      "Training step:  4473\n",
      "Loss: 930.8117561429674\n",
      "Training step:  4474\n",
      "Loss: 930.8100892550164\n",
      "Training step:  4475\n",
      "Loss: 930.8082738717244\n",
      "Training step:  4476\n",
      "Loss: 930.8066128080039\n",
      "Training step:  4477\n",
      "Loss: 930.8047985410316\n",
      "Training step:  4478\n",
      "Loss: 930.8030640269483\n",
      "Training step:  4479\n",
      "Loss: 930.8013141371869\n",
      "Training step:  4480\n",
      "Loss: 930.7996245701547\n",
      "Training step:  4481\n",
      "Loss: 930.7978334925793\n",
      "Training step:  4482\n",
      "Loss: 930.7961728823915\n",
      "Training step:  4483\n",
      "Loss: 930.7943713689107\n",
      "Training step:  4484\n",
      "Loss: 930.7927198482683\n",
      "Training step:  4485\n",
      "Loss: 930.7909165818656\n",
      "Training step:  4486\n",
      "Loss: 930.7892387327488\n",
      "Training step:  4487\n",
      "Loss: 930.78745493601\n",
      "Training step:  4488\n",
      "Loss: 930.7858004920089\n",
      "Training step:  4489\n",
      "Loss: 930.7840083064644\n",
      "Training step:  4490\n",
      "Loss: 930.7823660069998\n",
      "Training step:  4491\n",
      "Loss: 930.7805690389006\n",
      "Training step:  4492\n",
      "Loss: 930.7788609886044\n",
      "Training step:  4493\n",
      "Loss: 930.7771199562811\n",
      "Training step:  4494\n",
      "Loss: 930.7754601375538\n",
      "Training step:  4495\n",
      "Loss: 930.7736858379617\n",
      "Training step:  4496\n",
      "Loss: 930.7720423007961\n",
      "Training step:  4497\n",
      "Loss: 930.770261194905\n",
      "Training step:  4498\n",
      "Loss: 930.7686280084121\n",
      "Training step:  4499\n",
      "Loss: 930.7668421887217\n",
      "Training step:  4500\n",
      "Loss: 930.7651822251729\n",
      "Training step:  4501\n",
      "Loss: 930.76341287372\n",
      "Training step:  4502\n",
      "Loss: 930.761778095587\n",
      "Training step:  4503\n",
      "Loss: 930.7600014380639\n",
      "Training step:  4504\n",
      "Loss: 930.7583602748882\n",
      "Training step:  4505\n",
      "Loss: 930.7565955481074\n",
      "Training step:  4506\n",
      "Loss: 930.7549663570518\n",
      "Training step:  4507\n",
      "Loss: 930.75319544365\n",
      "Training step:  4508\n",
      "Loss: 930.751545064193\n",
      "Training step:  4509\n",
      "Loss: 930.7497900479323\n",
      "Training step:  4510\n",
      "Loss: 930.7481607024706\n",
      "Training step:  4511\n",
      "Loss: 930.7463996848\n",
      "Training step:  4512\n",
      "Loss: 930.7447821337566\n",
      "Training step:  4513\n",
      "Loss: 930.7430165308747\n",
      "Training step:  4514\n",
      "Loss: 930.7413457061109\n",
      "Training step:  4515\n",
      "Loss: 930.7396242689988\n",
      "Training step:  4516\n",
      "Loss: 930.7380033387169\n",
      "Training step:  4517\n",
      "Loss: 930.7362505514824\n",
      "Training step:  4518\n",
      "Loss: 930.7346396773573\n",
      "Training step:  4519\n",
      "Loss: 930.7328823489793\n",
      "Training step:  4520\n",
      "Loss: 930.7312638616128\n",
      "Training step:  4521\n",
      "Loss: 930.7295169417716\n",
      "Training step:  4522\n",
      "Loss: 930.7279103857477\n",
      "Training step:  4523\n",
      "Loss: 930.7261589879431\n",
      "Training step:  4524\n",
      "Loss: 930.7244945458525\n",
      "Training step:  4525\n",
      "Loss: 930.7227904257044\n",
      "Training step:  4526\n",
      "Loss: 930.7211751906965\n",
      "Training step:  4527\n",
      "Loss: 930.7194390877947\n",
      "Training step:  4528\n",
      "Loss: 930.7178362192794\n",
      "Training step:  4529\n",
      "Loss: 930.7160941564271\n",
      "Training step:  4530\n",
      "Loss: 930.7144941318938\n",
      "Training step:  4531\n",
      "Loss: 930.7127545169928\n",
      "Training step:  4532\n",
      "Loss: 930.7111599784287\n",
      "Training step:  4533\n",
      "Loss: 930.7094214872762\n",
      "Training step:  4534\n",
      "Loss: 930.7077775202337\n",
      "Training step:  4535\n",
      "Loss: 930.7060792918453\n",
      "Training step:  4536\n",
      "Loss: 930.7044848746307\n",
      "Training step:  4537\n",
      "Loss: 930.7027545031689\n",
      "Training step:  4538\n",
      "Loss: 930.7011711030832\n",
      "Training step:  4539\n",
      "Loss: 930.699436355267\n",
      "Training step:  4540\n",
      "Loss: 930.6977807138372\n",
      "Training step:  4541\n",
      "Loss: 930.6961137854565\n",
      "Training step:  4542\n",
      "Loss: 930.6944892838483\n",
      "Training step:  4543\n",
      "Loss: 930.6927827774475\n",
      "Training step:  4544\n",
      "Loss: 930.691193110722\n",
      "Training step:  4545\n",
      "Loss: 930.6894773049725\n",
      "Training step:  4546\n",
      "Loss: 930.6878960518882\n",
      "Training step:  4547\n",
      "Loss: 930.6861787586961\n",
      "Training step:  4548\n",
      "Loss: 930.6845972122454\n",
      "Training step:  4549\n",
      "Loss: 930.6828837162756\n",
      "Training step:  4550\n",
      "Loss: 930.6813075265721\n",
      "Training step:  4551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 930.6795900245149\n",
      "Training step:  4552\n",
      "Loss: 930.6779670450105\n",
      "Training step:  4553\n",
      "Loss: 930.6762936580877\n",
      "Training step:  4554\n",
      "Loss: 930.6747130271397\n",
      "Training step:  4555\n",
      "Loss: 930.6730124488379\n",
      "Training step:  4556\n",
      "Loss: 930.6714433371643\n",
      "Training step:  4557\n",
      "Loss: 930.6697385465147\n",
      "Training step:  4558\n",
      "Loss: 930.6681178165882\n",
      "Training step:  4559\n",
      "Loss: 930.6664584864507\n",
      "Training step:  4560\n",
      "Loss: 930.6648811243739\n",
      "Training step:  4561\n",
      "Loss: 930.6631912067891\n",
      "Training step:  4562\n",
      "Loss: 930.6616256042965\n",
      "Training step:  4563\n",
      "Loss: 930.659931529762\n",
      "Training step:  4564\n",
      "Loss: 930.6583725757164\n",
      "Training step:  4565\n",
      "Loss: 930.6566770808524\n",
      "Training step:  4566\n",
      "Loss: 930.6550937657594\n",
      "Training step:  4567\n",
      "Loss: 930.6534199213265\n",
      "Training step:  4568\n",
      "Loss: 930.6518558580352\n",
      "Training step:  4569\n",
      "Loss: 930.6501733179465\n",
      "Training step:  4570\n",
      "Loss: 930.6486201957191\n",
      "Training step:  4571\n",
      "Loss: 930.6469335566792\n",
      "Training step:  4572\n",
      "Loss: 930.6453266829159\n",
      "Training step:  4573\n",
      "Loss: 930.6436833555239\n",
      "Training step:  4574\n",
      "Loss: 930.6421236110541\n",
      "Training step:  4575\n",
      "Loss: 930.6404492249919\n",
      "Training step:  4576\n",
      "Loss: 930.6389018970135\n",
      "Training step:  4577\n",
      "Loss: 930.6372234689096\n",
      "Training step:  4578\n",
      "Loss: 930.6356774214898\n",
      "Training step:  4579\n",
      "Loss: 930.6340013439212\n",
      "Training step:  4580\n",
      "Loss: 930.6324605069607\n",
      "Training step:  4581\n",
      "Loss: 930.630784134885\n",
      "Training step:  4582\n",
      "Loss: 930.6292023860217\n",
      "Training step:  4583\n",
      "Loss: 930.6275589489213\n",
      "Training step:  4584\n",
      "Loss: 930.6260238759569\n",
      "Training step:  4585\n",
      "Loss: 930.6243536096455\n",
      "Training step:  4586\n",
      "Loss: 930.6228186444732\n",
      "Training step:  4587\n",
      "Loss: 930.6211507376922\n",
      "Training step:  4588\n",
      "Loss: 930.6196209157972\n",
      "Training step:  4589\n",
      "Loss: 930.6179541302545\n",
      "Training step:  4590\n",
      "Loss: 930.6163729684174\n",
      "Training step:  4591\n",
      "Loss: 930.6147510045964\n",
      "Training step:  4592\n",
      "Loss: 930.6132123968674\n",
      "Training step:  4593\n",
      "Loss: 930.6115572859178\n",
      "Training step:  4594\n",
      "Loss: 930.6100339595649\n",
      "Training step:  4595\n",
      "Loss: 930.6083749363293\n",
      "Training step:  4596\n",
      "Loss: 930.6067993610953\n",
      "Training step:  4597\n",
      "Loss: 930.6051868822242\n",
      "Training step:  4598\n",
      "Loss: 930.6036449206275\n",
      "Training step:  4599\n",
      "Loss: 930.6019970536096\n",
      "Training step:  4600\n",
      "Loss: 930.6004683447253\n",
      "Training step:  4601\n",
      "Loss: 930.5988183995107\n",
      "Training step:  4602\n",
      "Loss: 930.5972958062532\n",
      "Training step:  4603\n",
      "Loss: 930.5956535453568\n",
      "Training step:  4604\n",
      "Loss: 930.5941410551121\n",
      "Training step:  4605\n",
      "Loss: 930.5924949598256\n",
      "Training step:  4606\n",
      "Loss: 930.5909343134995\n",
      "Training step:  4607\n",
      "Loss: 930.589330446605\n",
      "Training step:  4608\n",
      "Loss: 930.5878112441212\n",
      "Training step:  4609\n",
      "Loss: 930.5861787831607\n",
      "Training step:  4610\n",
      "Loss: 930.5846701888642\n",
      "Training step:  4611\n",
      "Loss: 930.5830339366042\n",
      "Training step:  4612\n",
      "Loss: 930.5815160818998\n",
      "Training step:  4613\n",
      "Loss: 930.5798858727754\n",
      "Training step:  4614\n",
      "Loss: 930.5783847974426\n",
      "Training step:  4615\n",
      "Loss: 930.5767507927663\n",
      "Training step:  4616\n",
      "Loss: 930.5751937672995\n",
      "Training step:  4617\n",
      "Loss: 930.5736106155625\n",
      "Training step:  4618\n",
      "Loss: 930.5720912868338\n",
      "Training step:  4619\n",
      "Loss: 930.5704738738059\n",
      "Training step:  4620\n",
      "Loss: 930.5689733927586\n",
      "Training step:  4621\n",
      "Loss: 930.5673510576306\n",
      "Training step:  4622\n",
      "Loss: 930.5658556979902\n",
      "Training step:  4623\n",
      "Loss: 930.5642331554549\n",
      "Training step:  4624\n",
      "Loss: 930.5627028967308\n",
      "Training step:  4625\n",
      "Loss: 930.5611109823618\n",
      "Training step:  4626\n",
      "Loss: 930.5596036643393\n",
      "Training step:  4627\n",
      "Loss: 930.557994040755\n",
      "Training step:  4628\n",
      "Loss: 930.5565002737587\n",
      "Training step:  4629\n",
      "Loss: 930.554891230407\n",
      "Training step:  4630\n",
      "Loss: 930.5534035581775\n",
      "Training step:  4631\n",
      "Loss: 930.5517933337384\n",
      "Training step:  4632\n",
      "Loss: 930.5502933227826\n",
      "Training step:  4633\n",
      "Loss: 930.548692324776\n",
      "Training step:  4634\n",
      "Loss: 930.5472081544613\n",
      "Training step:  4635\n",
      "Loss: 930.545603597059\n",
      "Training step:  4636\n",
      "Loss: 930.544116245691\n",
      "Training step:  4637\n",
      "Loss: 930.542514680402\n",
      "Training step:  4638\n",
      "Loss: 930.5410212015755\n",
      "Training step:  4639\n",
      "Loss: 930.5394274694432\n",
      "Training step:  4640\n",
      "Loss: 930.5379498571734\n",
      "Training step:  4641\n",
      "Loss: 930.536352653982\n",
      "Training step:  4642\n",
      "Loss: 930.5348600562368\n",
      "Training step:  4643\n",
      "Loss: 930.5332721253102\n",
      "Training step:  4644\n",
      "Loss: 930.5317977568978\n",
      "Training step:  4645\n",
      "Loss: 930.5302022359446\n",
      "Training step:  4646\n",
      "Loss: 930.5286745663365\n",
      "Training step:  4647\n",
      "Loss: 930.5271302461384\n",
      "Training step:  4648\n",
      "Loss: 930.5256386815238\n",
      "Training step:  4649\n",
      "Loss: 930.5240590797705\n",
      "Training step:  4650\n",
      "Loss: 930.5225897708888\n",
      "Training step:  4651\n",
      "Loss: 930.5210053605006\n",
      "Training step:  4652\n",
      "Loss: 930.5195433529664\n",
      "Training step:  4653\n",
      "Loss: 930.5179578288211\n",
      "Training step:  4654\n",
      "Loss: 930.5164677126311\n",
      "Training step:  4655\n",
      "Loss: 930.5149033624036\n",
      "Training step:  4656\n",
      "Loss: 930.513434612778\n",
      "Training step:  4657\n",
      "Loss: 930.5118601548453\n",
      "Training step:  4658\n",
      "Loss: 930.5104040972631\n",
      "Training step:  4659\n",
      "Loss: 930.5088262272727\n",
      "Training step:  4660\n",
      "Loss: 930.5073671416532\n",
      "Training step:  4661\n",
      "Loss: 930.5057930513293\n",
      "Training step:  4662\n",
      "Loss: 930.5043295560969\n",
      "Training step:  4663\n",
      "Loss: 930.502763680611\n",
      "Training step:  4664\n",
      "Loss: 930.5013126478109\n",
      "Training step:  4665\n",
      "Loss: 930.4997434676101\n",
      "Training step:  4666\n",
      "Loss: 930.4982551260233\n",
      "Training step:  4667\n",
      "Loss: 930.4967153006605\n",
      "Training step:  4668\n",
      "Loss: 930.4952677645852\n",
      "Training step:  4669\n",
      "Loss: 930.4937047004347\n",
      "Training step:  4670\n",
      "Loss: 930.492264445344\n",
      "Training step:  4671\n",
      "Loss: 930.490697998496\n",
      "Training step:  4672\n",
      "Loss: 930.4891899330527\n",
      "Training step:  4673\n",
      "Loss: 930.4877004385586\n",
      "Training step:  4674\n",
      "Loss: 930.4861934465648\n",
      "Training step:  4675\n",
      "Loss: 930.4846645424215\n",
      "Training step:  4676\n",
      "Loss: 930.4832129506593\n",
      "Training step:  4677\n",
      "Loss: 930.4816617303682\n",
      "Training step:  4678\n",
      "Loss: 930.4802207602565\n",
      "Training step:  4679\n",
      "Loss: 930.4786683774546\n",
      "Training step:  4680\n",
      "Loss: 930.4772281797426\n",
      "Training step:  4681\n",
      "Loss: 930.475680143545\n",
      "Training step:  4682\n",
      "Loss: 930.4742370318054\n",
      "Training step:  4683\n",
      "Loss: 930.4726956277983\n",
      "Training step:  4684\n",
      "Loss: 930.4712647764236\n",
      "Training step:  4685\n",
      "Loss: 930.4697201620451\n",
      "Training step:  4686\n",
      "Loss: 930.4682552198263\n",
      "Training step:  4687\n",
      "Loss: 930.4667387818585\n",
      "Training step:  4688\n",
      "Loss: 930.4652956137203\n",
      "Training step:  4689\n",
      "Loss: 930.4637667619415\n",
      "Training step:  4690\n",
      "Loss: 930.462337511289\n",
      "Training step:  4691\n",
      "Loss: 930.4608015055081\n",
      "Training step:  4692\n",
      "Loss: 930.4593722246159\n",
      "Training step:  4693\n",
      "Loss: 930.4578398220126\n",
      "Training step:  4694\n",
      "Loss: 930.4564176315668\n",
      "Training step:  4695\n",
      "Loss: 930.454886403784\n",
      "Training step:  4696\n",
      "Loss: 930.453467590596\n",
      "Training step:  4697\n",
      "Loss: 930.451936277308\n",
      "Training step:  4698\n",
      "Loss: 930.4504641729715\n",
      "Training step:  4699\n",
      "Loss: 930.4489834329914\n",
      "Training step:  4700\n",
      "Loss: 930.4475418905694\n",
      "Training step:  4701\n",
      "Loss: 930.44602870899\n",
      "Training step:  4702\n",
      "Loss: 930.44461142239\n",
      "Training step:  4703\n",
      "Loss: 930.4430898155958\n",
      "Training step:  4704\n",
      "Loss: 930.4416771199644\n",
      "Training step:  4705\n",
      "Loss: 930.4401558244037\n",
      "Training step:  4706\n",
      "Loss: 930.4387113874553\n",
      "Training step:  4707\n",
      "Loss: 930.4372188026381\n",
      "Training step:  4708\n",
      "Loss: 930.4357953701905\n",
      "Training step:  4709\n",
      "Loss: 930.4342901078139\n",
      "Training step:  4710\n",
      "Loss: 930.4328795102929\n",
      "Training step:  4711\n",
      "Loss: 930.4313675464236\n",
      "Training step:  4712\n",
      "Loss: 930.4299610805219\n",
      "Training step:  4713\n",
      "Loss: 930.4284497506542\n",
      "Training step:  4714\n",
      "Loss: 930.4270492675407\n",
      "Training step:  4715\n",
      "Loss: 930.4255400828349\n",
      "Training step:  4716\n",
      "Loss: 930.4241268100221\n",
      "Training step:  4717\n",
      "Loss: 930.422628110011\n",
      "Training step:  4718\n",
      "Loss: 930.421228527685\n",
      "Training step:  4719\n",
      "Loss: 930.4197232254963\n",
      "Training step:  4720\n",
      "Loss: 930.4183196447564\n",
      "Training step:  4721\n",
      "Loss: 930.4168196297826\n",
      "Training step:  4722\n",
      "Loss: 930.4154262273834\n",
      "Training step:  4723\n",
      "Loss: 930.4139248170658\n",
      "Training step:  4724\n",
      "Loss: 930.412488503798\n",
      "Training step:  4725\n",
      "Loss: 930.411029567253\n",
      "Training step:  4726\n",
      "Loss: 930.4096243226206\n",
      "Training step:  4727\n",
      "Loss: 930.4081398094816\n",
      "Training step:  4728\n",
      "Loss: 930.4067485478477\n",
      "Training step:  4729\n",
      "Loss: 930.4052573255219\n",
      "Training step:  4730\n",
      "Loss: 930.4038705587037\n",
      "Training step:  4731\n",
      "Loss: 930.4023796755754\n",
      "Training step:  4732\n",
      "Loss: 930.4009758841228\n",
      "Training step:  4733\n",
      "Loss: 930.3995002954399\n",
      "Training step:  4734\n",
      "Loss: 930.3981129888624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  4735\n",
      "Loss: 930.3966291567641\n",
      "Training step:  4736\n",
      "Loss: 930.3952431656122\n",
      "Training step:  4737\n",
      "Loss: 930.3937632878848\n",
      "Training step:  4738\n",
      "Loss: 930.3923839862761\n",
      "Training step:  4739\n",
      "Loss: 930.3909017164813\n",
      "Training step:  4740\n",
      "Loss: 930.389475273106\n",
      "Training step:  4741\n",
      "Loss: 930.3880422327178\n",
      "Training step:  4742\n",
      "Loss: 930.3866418311414\n",
      "Training step:  4743\n",
      "Loss: 930.3851783489977\n",
      "Training step:  4744\n",
      "Loss: 930.3838011895002\n",
      "Training step:  4745\n",
      "Loss: 930.3823298480056\n",
      "Training step:  4746\n",
      "Loss: 930.3809532856122\n",
      "Training step:  4747\n",
      "Loss: 930.3794849416716\n",
      "Training step:  4748\n",
      "Loss: 930.3781172138758\n",
      "Training step:  4749\n",
      "Loss: 930.3766456930011\n",
      "Training step:  4750\n",
      "Loss: 930.3752363932892\n",
      "Training step:  4751\n",
      "Loss: 930.373804445513\n",
      "Training step:  4752\n",
      "Loss: 930.3724281702024\n",
      "Training step:  4753\n",
      "Loss: 930.3709681884555\n",
      "Training step:  4754\n",
      "Loss: 930.36960672844\n",
      "Training step:  4755\n",
      "Loss: 930.3681439316695\n",
      "Training step:  4756\n",
      "Loss: 930.366783665\n",
      "Training step:  4757\n",
      "Loss: 930.3653240455099\n",
      "Training step:  4758\n",
      "Loss: 930.3639548649014\n",
      "Training step:  4759\n",
      "Loss: 930.3625018114897\n",
      "Training step:  4760\n",
      "Loss: 930.3611460728393\n",
      "Training step:  4761\n",
      "Loss: 930.3596879241458\n",
      "Training step:  4762\n",
      "Loss: 930.3582982548284\n",
      "Training step:  4763\n",
      "Loss: 930.3568707392062\n",
      "Training step:  4764\n",
      "Loss: 930.355515290746\n",
      "Training step:  4765\n",
      "Loss: 930.3540644665236\n",
      "Training step:  4766\n",
      "Loss: 930.3527156758428\n",
      "Training step:  4767\n",
      "Loss: 930.3512655670457\n",
      "Training step:  4768\n",
      "Loss: 930.3498884335947\n",
      "Training step:  4769\n",
      "Loss: 930.3484623116484\n",
      "Training step:  4770\n",
      "Loss: 930.3471042921583\n",
      "Training step:  4771\n",
      "Loss: 930.3456672261825\n",
      "Training step:  4772\n",
      "Loss: 930.3443201442752\n",
      "Training step:  4773\n",
      "Loss: 930.3428781083791\n",
      "Training step:  4774\n",
      "Loss: 930.341536676756\n",
      "Training step:  4775\n",
      "Loss: 930.3400934672874\n",
      "Training step:  4776\n",
      "Loss: 930.3387085191057\n",
      "Training step:  4777\n",
      "Loss: 930.3373087277814\n",
      "Training step:  4778\n",
      "Loss: 930.3359521522175\n",
      "Training step:  4779\n",
      "Loss: 930.3345231863666\n",
      "Training step:  4780\n",
      "Loss: 930.3331812133894\n",
      "Training step:  4781\n",
      "Loss: 930.3317496270146\n",
      "Training step:  4782\n",
      "Loss: 930.3304142725303\n",
      "Training step:  4783\n",
      "Loss: 930.3289815504851\n",
      "Training step:  4784\n",
      "Loss: 930.3276159600226\n",
      "Training step:  4785\n",
      "Loss: 930.3262124437841\n",
      "Training step:  4786\n",
      "Loss: 930.3248780372887\n",
      "Training step:  4787\n",
      "Loss: 930.3234518658318\n",
      "Training step:  4788\n",
      "Loss: 930.3221219926103\n",
      "Training step:  4789\n",
      "Loss: 930.3206962076372\n",
      "Training step:  4790\n",
      "Loss: 930.3193523514477\n",
      "Training step:  4791\n",
      "Loss: 930.3179413929436\n",
      "Training step:  4792\n",
      "Loss: 930.3166103647851\n",
      "Training step:  4793\n",
      "Loss: 930.3151924716552\n",
      "Training step:  4794\n",
      "Loss: 930.3138719456769\n",
      "Training step:  4795\n",
      "Loss: 930.3124514966129\n",
      "Training step:  4796\n",
      "Loss: 930.3110813239132\n",
      "Training step:  4797\n",
      "Loss: 930.3097112268482\n",
      "Training step:  4798\n",
      "Loss: 930.3083619974275\n",
      "Training step:  4799\n",
      "Loss: 930.3069641565453\n",
      "Training step:  4800\n",
      "Loss: 930.3056367662837\n",
      "Training step:  4801\n",
      "Loss: 930.3042309590094\n",
      "Training step:  4802\n",
      "Loss: 930.3029108223793\n",
      "Training step:  4803\n",
      "Loss: 930.3015035165577\n",
      "Training step:  4804\n",
      "Loss: 930.3001871271209\n",
      "Training step:  4805\n",
      "Loss: 930.2987804279887\n",
      "Training step:  4806\n",
      "Loss: 930.2974693261756\n",
      "Training step:  4807\n",
      "Loss: 930.2960615542398\n",
      "Training step:  4808\n",
      "Loss: 930.294712504149\n",
      "Training step:  4809\n",
      "Loss: 930.2933418116551\n",
      "Training step:  4810\n",
      "Loss: 930.2920207376346\n",
      "Training step:  4811\n",
      "Loss: 930.2906258967879\n",
      "Training step:  4812\n",
      "Loss: 930.2893184644784\n",
      "Training step:  4813\n",
      "Loss: 930.2879180022279\n",
      "Training step:  4814\n",
      "Loss: 930.2865981385074\n",
      "Training step:  4815\n",
      "Loss: 930.285209827857\n",
      "Training step:  4816\n",
      "Loss: 930.2839036830336\n",
      "Training step:  4817\n",
      "Loss: 930.2825097774877\n",
      "Training step:  4818\n",
      "Loss: 930.2812100331402\n",
      "Training step:  4819\n",
      "Loss: 930.2798150819536\n",
      "Training step:  4820\n",
      "Loss: 930.2784790167141\n",
      "Training step:  4821\n",
      "Loss: 930.2771197781212\n",
      "Training step:  4822\n",
      "Loss: 930.2758112609215\n",
      "Training step:  4823\n",
      "Loss: 930.274430543504\n",
      "Training step:  4824\n",
      "Loss: 930.2731328735556\n",
      "Training step:  4825\n",
      "Loss: 930.2717476205291\n",
      "Training step:  4826\n",
      "Loss: 930.2704552569483\n",
      "Training step:  4827\n",
      "Loss: 930.2690689914301\n",
      "Training step:  4828\n",
      "Loss: 930.2677402884304\n",
      "Training step:  4829\n",
      "Loss: 930.2663901433585\n",
      "Training step:  4830\n",
      "Loss: 930.2650880883535\n",
      "Training step:  4831\n",
      "Loss: 930.2637144459874\n",
      "Training step:  4832\n",
      "Loss: 930.2624257027011\n",
      "Training step:  4833\n",
      "Loss: 930.2610466187635\n",
      "Training step:  4834\n",
      "Loss: 930.2597591795386\n",
      "Training step:  4835\n",
      "Loss: 930.2583830343223\n",
      "Training step:  4836\n",
      "Loss: 930.2570637636794\n",
      "Training step:  4837\n",
      "Loss: 930.2557198685524\n",
      "Training step:  4838\n",
      "Loss: 930.2544277813971\n",
      "Training step:  4839\n",
      "Loss: 930.2530632785345\n",
      "Training step:  4840\n",
      "Loss: 930.251781077026\n",
      "Training step:  4841\n",
      "Loss: 930.2504121566291\n",
      "Training step:  4842\n",
      "Loss: 930.2491303594068\n",
      "Training step:  4843\n",
      "Loss: 930.2477653200823\n",
      "Training step:  4844\n",
      "Loss: 930.2464884760901\n",
      "Training step:  4845\n",
      "Loss: 930.2451224749133\n",
      "Training step:  4846\n",
      "Loss: 930.2438179692073\n",
      "Training step:  4847\n",
      "Loss: 930.2424784174759\n",
      "Training step:  4848\n",
      "Loss: 930.2411901447751\n",
      "Training step:  4849\n",
      "Loss: 930.2398382300408\n",
      "Training step:  4850\n",
      "Loss: 930.2385641799883\n",
      "Training step:  4851\n",
      "Loss: 930.2372068033977\n",
      "Training step:  4852\n",
      "Loss: 930.2359396555204\n",
      "Training step:  4853\n",
      "Loss: 930.2345817639855\n",
      "Training step:  4854\n",
      "Loss: 930.2332944073974\n",
      "Training step:  4855\n",
      "Loss: 930.2319540623771\n",
      "Training step:  4856\n",
      "Loss: 930.2306808896035\n",
      "Training step:  4857\n",
      "Loss: 930.229333295504\n",
      "Training step:  4858\n",
      "Loss: 930.2280697843325\n",
      "Training step:  4859\n",
      "Loss: 930.2267179366382\n",
      "Training step:  4860\n",
      "Loss: 930.2254136000284\n",
      "Training step:  4861\n",
      "Loss: 930.2241067438762\n",
      "Training step:  4862\n",
      "Loss: 930.2228213009631\n",
      "Training step:  4863\n",
      "Loss: 930.2214890614376\n",
      "Training step:  4864\n",
      "Loss: 930.220223108305\n",
      "Training step:  4865\n",
      "Loss: 930.2188845232552\n",
      "Training step:  4866\n",
      "Loss: 930.217627180436\n",
      "Training step:  4867\n",
      "Loss: 930.2162843720288\n",
      "Training step:  4868\n",
      "Loss: 930.2150202977581\n",
      "Training step:  4869\n",
      "Loss: 930.2136870953909\n",
      "Training step:  4870\n",
      "Loss: 930.2124322917724\n",
      "Training step:  4871\n",
      "Loss: 930.2110949230828\n",
      "Training step:  4872\n",
      "Loss: 930.2098322799674\n",
      "Training step:  4873\n",
      "Loss: 930.2085056835107\n",
      "Training step:  4874\n",
      "Loss: 930.2072517610025\n",
      "Training step:  4875\n",
      "Loss: 930.2059201406712\n",
      "Training step:  4876\n",
      "Loss: 930.2046721587341\n",
      "Training step:  4877\n",
      "Loss: 930.2033396618456\n",
      "Training step:  4878\n",
      "Loss: 930.2020588346132\n",
      "Training step:  4879\n",
      "Loss: 930.200755971004\n",
      "Training step:  4880\n",
      "Loss: 930.199499194867\n",
      "Training step:  4881\n",
      "Loss: 930.1981746649609\n",
      "Training step:  4882\n",
      "Loss: 930.196931628285\n",
      "Training step:  4883\n",
      "Loss: 930.1956055090743\n",
      "Training step:  4884\n",
      "Loss: 930.1943656754897\n",
      "Training step:  4885\n",
      "Loss: 930.1930403858837\n",
      "Training step:  4886\n",
      "Loss: 930.1917780453572\n",
      "Training step:  4887\n",
      "Loss: 930.1904744099355\n",
      "Training step:  4888\n",
      "Loss: 930.1892251147412\n",
      "Training step:  4889\n",
      "Loss: 930.1879142606524\n",
      "Training step:  4890\n",
      "Loss: 930.1866760657053\n",
      "Training step:  4891\n",
      "Loss: 930.1853601557951\n",
      "Training step:  4892\n",
      "Loss: 930.184127435515\n",
      "Training step:  4893\n",
      "Loss: 930.1828103446368\n",
      "Training step:  4894\n",
      "Loss: 930.1815489716055\n",
      "Training step:  4895\n",
      "Loss: 930.1802604794558\n",
      "Training step:  4896\n",
      "Loss: 930.1790247942507\n",
      "Training step:  4897\n",
      "Loss: 930.1777174227769\n",
      "Training step:  4898\n",
      "Loss: 930.1764902288974\n",
      "Training step:  4899\n",
      "Loss: 930.1751788966725\n",
      "Training step:  4900\n",
      "Loss: 930.1739241842099\n",
      "Training step:  4901\n",
      "Loss: 930.1726405287817\n",
      "Training step:  4902\n",
      "Loss: 930.1714113162305\n",
      "Training step:  4903\n",
      "Loss: 930.1701088715809\n",
      "Training step:  4904\n",
      "Loss: 930.1688880408088\n",
      "Training step:  4905\n",
      "Loss: 930.1675816648956\n",
      "Training step:  4906\n",
      "Loss: 930.1663278696464\n",
      "Training step:  4907\n",
      "Loss: 930.1650518390436\n",
      "Training step:  4908\n",
      "Loss: 930.1638210662069\n",
      "Training step:  4909\n",
      "Loss: 930.1625243139106\n",
      "Training step:  4910\n",
      "Loss: 930.1613043855307\n",
      "Training step:  4911\n",
      "Loss: 930.1600058540613\n",
      "Training step:  4912\n",
      "Loss: 930.1587827618558\n",
      "Training step:  4913\n",
      "Loss: 930.1574931612118\n",
      "Training step:  4914\n",
      "Loss: 930.1562781277189\n",
      "Training step:  4915\n",
      "Loss: 930.1549838383114\n",
      "Training step:  4916\n",
      "Loss: 930.1537596578854\n",
      "Training step:  4917\n",
      "Loss: 930.152474429419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  4918\n",
      "Loss: 930.1512624037636\n",
      "Training step:  4919\n",
      "Loss: 930.1499733237403\n",
      "Training step:  4920\n",
      "Loss: 930.1487644353019\n",
      "Training step:  4921\n",
      "Loss: 930.1474753341096\n",
      "Training step:  4922\n",
      "Loss: 930.1462482087405\n",
      "Training step:  4923\n",
      "Loss: 930.1449789656218\n",
      "Training step:  4924\n",
      "Loss: 930.1437629478868\n",
      "Training step:  4925\n",
      "Loss: 930.1424874002811\n",
      "Training step:  4926\n",
      "Loss: 930.1412813628156\n",
      "Training step:  4927\n",
      "Loss: 930.1400010635405\n",
      "Training step:  4928\n",
      "Loss: 930.1388029148955\n",
      "Training step:  4929\n",
      "Loss: 930.1375188516946\n",
      "Training step:  4930\n",
      "Loss: 930.1362728486865\n",
      "Training step:  4931\n",
      "Loss: 930.1350572903132\n",
      "Training step:  4932\n",
      "Loss: 930.1337952382084\n",
      "Training step:  4933\n",
      "Loss: 930.132550318183\n",
      "Training step:  4934\n",
      "Loss: 930.1313309764557\n",
      "Training step:  4935\n",
      "Loss: 930.1300653010865\n",
      "Training step:  4936\n",
      "Loss: 930.1288598285793\n",
      "Training step:  4937\n",
      "Loss: 930.1275930623023\n",
      "Training step:  4938\n",
      "Loss: 930.1263943632906\n",
      "Training step:  4939\n",
      "Loss: 930.1251289012682\n",
      "Training step:  4940\n",
      "Loss: 930.1239378371116\n",
      "Training step:  4941\n",
      "Loss: 930.1226666449759\n",
      "Training step:  4942\n",
      "Loss: 930.121444960492\n",
      "Training step:  4943\n",
      "Loss: 930.1202063507722\n",
      "Training step:  4944\n",
      "Loss: 930.1190079377163\n",
      "Training step:  4945\n",
      "Loss: 930.1177518733007\n",
      "Training step:  4946\n",
      "Loss: 930.1165619736472\n",
      "Training step:  4947\n",
      "Loss: 930.1153022899629\n",
      "Training step:  4948\n",
      "Loss: 930.1141200802228\n",
      "Training step:  4949\n",
      "Loss: 930.1128585506709\n",
      "Training step:  4950\n",
      "Loss: 930.1116646142409\n",
      "Training step:  4951\n",
      "Loss: 930.1104140275304\n",
      "Training step:  4952\n",
      "Loss: 930.1092296703946\n",
      "Training step:  4953\n",
      "Loss: 930.1079746993562\n",
      "Training step:  4954\n",
      "Loss: 930.1067957430562\n",
      "Training step:  4955\n",
      "Loss: 930.1055401067813\n",
      "Training step:  4956\n",
      "Loss: 930.1043399985334\n",
      "Training step:  4957\n",
      "Loss: 930.1031071336813\n",
      "Training step:  4958\n",
      "Loss: 930.1019163407029\n",
      "Training step:  4959\n",
      "Loss: 930.1006732485861\n",
      "Training step:  4960\n",
      "Loss: 930.0994958362405\n",
      "Training step:  4961\n",
      "Loss: 930.0982491486312\n",
      "Training step:  4962\n",
      "Loss: 930.0970792859038\n",
      "Training step:  4963\n",
      "Loss: 930.0958290632406\n",
      "Training step:  4964\n",
      "Loss: 930.0946172867997\n",
      "Training step:  4965\n",
      "Loss: 930.0934181144559\n",
      "Training step:  4966\n",
      "Loss: 930.0922140323844\n",
      "Training step:  4967\n",
      "Loss: 930.0909936807569\n",
      "Training step:  4968\n",
      "Loss: 930.0898208780022\n",
      "Training step:  4969\n",
      "Loss: 930.088583415496\n",
      "Training step:  4970\n",
      "Loss: 930.0874157803665\n",
      "Training step:  4971\n",
      "Loss: 930.0861773768371\n",
      "Training step:  4972\n",
      "Loss: 930.0850105547175\n",
      "Training step:  4973\n",
      "Loss: 930.0837745498786\n",
      "Training step:  4974\n",
      "Loss: 930.0826104627348\n",
      "Training step:  4975\n",
      "Loss: 930.0813752341709\n",
      "Training step:  4976\n",
      "Loss: 930.0801943380502\n",
      "Training step:  4977\n",
      "Loss: 930.0789775343309\n",
      "Training step:  4978\n",
      "Loss: 930.0778070369289\n",
      "Training step:  4979\n",
      "Loss: 930.0765839645492\n",
      "Training step:  4980\n",
      "Loss: 930.0754222657529\n",
      "Training step:  4981\n",
      "Loss: 930.0741957877907\n",
      "Training step:  4982\n",
      "Loss: 930.0730414456677\n",
      "Training step:  4983\n",
      "Loss: 930.07181156019\n",
      "Training step:  4984\n",
      "Loss: 930.0706174501089\n",
      "Training step:  4985\n",
      "Loss: 930.0694346787852\n",
      "Training step:  4986\n",
      "Loss: 930.068250519163\n",
      "Training step:  4987\n",
      "Loss: 930.0670471210851\n",
      "Training step:  4988\n",
      "Loss: 930.0658801490137\n",
      "Training step:  4989\n",
      "Loss: 930.0646687892529\n",
      "Training step:  4990\n",
      "Loss: 930.0635136335675\n",
      "Training step:  4991\n",
      "Loss: 930.0622973274542\n",
      "Training step:  4992\n",
      "Loss: 930.0611463836085\n",
      "Training step:  4993\n",
      "Loss: 930.0599306008415\n",
      "Training step:  4994\n",
      "Loss: 930.0587867767275\n",
      "Training step:  4995\n",
      "Loss: 930.05756766288\n",
      "Training step:  4996\n",
      "Loss: 930.0563823055568\n",
      "Training step:  4997\n",
      "Loss: 930.055220230123\n",
      "Training step:  4998\n",
      "Loss: 930.0540323048872\n",
      "Training step:  4999\n",
      "Loss: 930.0528470631017\n",
      "Training step:  5000\n",
      "Loss: 930.0516914896824\n",
      "Training step:  5001\n",
      "Loss: 930.050490541884\n",
      "Training step:  5002\n",
      "Loss: 930.0493452257872\n",
      "Training step:  5003\n",
      "Loss: 930.0481409964162\n",
      "Training step:  5004\n",
      "Loss: 930.0470013738766\n",
      "Training step:  5005\n",
      "Loss: 930.0457952751783\n",
      "Training step:  5006\n",
      "Loss: 930.0446555255107\n",
      "Training step:  5007\n",
      "Loss: 930.0434533267569\n",
      "Training step:  5008\n",
      "Loss: 930.0423176192506\n",
      "Training step:  5009\n",
      "Loss: 930.0411148609562\n",
      "Training step:  5010\n",
      "Loss: 930.039960484494\n",
      "Training step:  5011\n",
      "Loss: 930.0387753979949\n",
      "Training step:  5012\n",
      "Loss: 930.037632798446\n",
      "Training step:  5013\n",
      "Loss: 930.0364416524772\n",
      "Training step:  5014\n",
      "Loss: 930.0353084143621\n",
      "Training step:  5015\n",
      "Loss: 930.0341132155389\n",
      "Training step:  5016\n",
      "Loss: 930.0329846827052\n",
      "Training step:  5017\n",
      "Loss: 930.0317886496347\n",
      "Training step:  5018\n",
      "Loss: 930.0306583240119\n",
      "Training step:  5019\n",
      "Loss: 930.0294664659957\n",
      "Training step:  5020\n",
      "Loss: 930.0283412509997\n",
      "Training step:  5021\n",
      "Loss: 930.0271488622623\n",
      "Training step:  5022\n",
      "Loss: 930.0260054257093\n",
      "Training step:  5023\n",
      "Loss: 930.0248325640777\n",
      "Training step:  5024\n",
      "Loss: 930.0236981948948\n",
      "Training step:  5025\n",
      "Loss: 930.0225196352723\n",
      "Training step:  5026\n",
      "Loss: 930.0213944805571\n",
      "Training step:  5027\n",
      "Loss: 930.0202119670693\n",
      "Training step:  5028\n",
      "Loss: 930.0190937473112\n",
      "Training step:  5029\n",
      "Loss: 930.017908106138\n",
      "Training step:  5030\n",
      "Loss: 930.0167627580636\n",
      "Training step:  5031\n",
      "Loss: 930.0156029219434\n",
      "Training step:  5032\n",
      "Loss: 930.0144800911951\n",
      "Training step:  5033\n",
      "Loss: 930.0133044023997\n",
      "Training step:  5034\n",
      "Loss: 930.0121870278087\n",
      "Training step:  5035\n",
      "Loss: 930.0110098572574\n",
      "Training step:  5036\n",
      "Loss: 930.0099000413908\n",
      "Training step:  5037\n",
      "Loss: 930.0087198081126\n",
      "Training step:  5038\n",
      "Loss: 930.0075811561496\n",
      "Training step:  5039\n",
      "Loss: 930.0064317567009\n",
      "Training step:  5040\n",
      "Loss: 930.0053105009883\n",
      "Training step:  5041\n",
      "Loss: 930.0041424158466\n",
      "Training step:  5042\n",
      "Loss: 930.0030292746288\n",
      "Training step:  5043\n",
      "Loss: 930.0018617560845\n",
      "Training step:  5044\n",
      "Loss: 930.0007557674738\n",
      "Training step:  5045\n",
      "Loss: 929.9995852139292\n",
      "Training step:  5046\n",
      "Loss: 929.9984673273121\n",
      "Training step:  5047\n",
      "Loss: 929.997308581819\n",
      "Training step:  5048\n",
      "Loss: 929.996201023886\n",
      "Training step:  5049\n",
      "Loss: 929.9950378220421\n",
      "Training step:  5050\n",
      "Loss: 929.9939377373046\n",
      "Training step:  5051\n",
      "Loss: 929.9927715348211\n",
      "Training step:  5052\n",
      "Loss: 929.9916430887799\n",
      "Training step:  5053\n",
      "Loss: 929.9905037038623\n",
      "Training step:  5054\n",
      "Loss: 929.989396970932\n",
      "Training step:  5055\n",
      "Loss: 929.9882424454527\n",
      "Training step:  5056\n",
      "Loss: 929.987144223275\n",
      "Training step:  5057\n",
      "Loss: 929.9859852628931\n",
      "Training step:  5058\n",
      "Loss: 929.9848922060353\n",
      "Training step:  5059\n",
      "Loss: 929.9837325116406\n",
      "Training step:  5060\n",
      "Loss: 929.9826112260998\n",
      "Training step:  5061\n",
      "Loss: 929.9814821167964\n",
      "Training step:  5062\n",
      "Loss: 929.9803770728074\n",
      "Training step:  5063\n",
      "Loss: 929.979229960302\n",
      "Training step:  5064\n",
      "Loss: 929.9781376179103\n",
      "Training step:  5065\n",
      "Loss: 929.976986770394\n",
      "Training step:  5066\n",
      "Loss: 929.9758975476001\n",
      "Training step:  5067\n",
      "Loss: 929.9747472658534\n",
      "Training step:  5068\n",
      "Loss: 929.9736619018194\n",
      "Training step:  5069\n",
      "Loss: 929.9725111827598\n",
      "Training step:  5070\n",
      "Loss: 929.9714026197503\n",
      "Training step:  5071\n",
      "Loss: 929.9702761881616\n",
      "Training step:  5072\n",
      "Loss: 929.9691755926696\n",
      "Training step:  5073\n",
      "Loss: 929.9680407113782\n",
      "Training step:  5074\n",
      "Loss: 929.9669524338617\n",
      "Training step:  5075\n",
      "Loss: 929.9658133597936\n",
      "Training step:  5076\n",
      "Loss: 929.964732327615\n",
      "Training step:  5077\n",
      "Loss: 929.9635904144237\n",
      "Training step:  5078\n",
      "Loss: 929.9625120268038\n",
      "Training step:  5079\n",
      "Loss: 929.9613709523663\n",
      "Training step:  5080\n",
      "Loss: 929.9602829757333\n",
      "Training step:  5081\n",
      "Loss: 929.9591513410122\n",
      "Training step:  5082\n",
      "Loss: 929.9580726418935\n",
      "Training step:  5083\n",
      "Loss: 929.9569375029132\n",
      "Training step:  5084\n",
      "Loss: 929.955865943367\n",
      "Training step:  5085\n",
      "Loss: 929.9547280027062\n",
      "Training step:  5086\n",
      "Loss: 929.953621374368\n",
      "Training step:  5087\n",
      "Loss: 929.9525287853186\n",
      "Training step:  5088\n",
      "Loss: 929.9514260934332\n",
      "Training step:  5089\n",
      "Loss: 929.9503153974631\n",
      "Training step:  5090\n",
      "Loss: 929.9492375421723\n",
      "Training step:  5091\n",
      "Loss: 929.948114576019\n",
      "Training step:  5092\n",
      "Loss: 929.9470443250253\n",
      "Training step:  5093\n",
      "Loss: 929.9459171852502\n",
      "Training step:  5094\n",
      "Loss: 929.9448526851328\n",
      "Training step:  5095\n",
      "Loss: 929.9437240146622\n",
      "Training step:  5096\n",
      "Loss: 929.9426397283166\n",
      "Training step:  5097\n",
      "Loss: 929.9415328301997\n",
      "Training step:  5098\n",
      "Loss: 929.9404559008719\n",
      "Training step:  5099\n",
      "Loss: 929.9393408538167\n",
      "Training step:  5100\n",
      "Loss: 929.9382749453812\n",
      "Training step:  5101\n",
      "Loss: 929.9371564888188\n",
      "Training step:  5102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 929.9360975549686\n",
      "Training step:  5103\n",
      "Loss: 929.9349763796748\n",
      "Training step:  5104\n",
      "Loss: 929.9338977562419\n",
      "Training step:  5105\n",
      "Loss: 929.9327965978599\n",
      "Training step:  5106\n",
      "Loss: 929.9317270058434\n",
      "Training step:  5107\n",
      "Loss: 929.9306208577283\n",
      "Training step:  5108\n",
      "Loss: 929.9295595282098\n",
      "Training step:  5109\n",
      "Loss: 929.9284493249761\n",
      "Training step:  5110\n",
      "Loss: 929.9273949214584\n",
      "Training step:  5111\n",
      "Loss: 929.9262820433842\n",
      "Training step:  5112\n",
      "Loss: 929.9252280276263\n",
      "Training step:  5113\n",
      "Loss: 929.9241181606311\n",
      "Training step:  5114\n",
      "Loss: 929.9230677387721\n",
      "Training step:  5115\n",
      "Loss: 929.921957515736\n",
      "Training step:  5116\n",
      "Loss: 929.9208922589859\n",
      "Training step:  5117\n",
      "Loss: 929.9197980025924\n",
      "Training step:  5118\n",
      "Loss: 929.9187411963057\n",
      "Training step:  5119\n",
      "Loss: 929.9176419946617\n",
      "Training step:  5120\n",
      "Loss: 929.9165924825182\n",
      "Training step:  5121\n",
      "Loss: 929.9154900540343\n",
      "Training step:  5122\n",
      "Loss: 929.9144473344093\n",
      "Training step:  5123\n",
      "Loss: 929.9133422918611\n",
      "Training step:  5124\n",
      "Loss: 929.9122687299687\n",
      "Training step:  5125\n",
      "Loss: 929.9112002235422\n",
      "Training step:  5126\n",
      "Loss: 929.9101357088812\n",
      "Training step:  5127\n",
      "Loss: 929.9090513945595\n",
      "Training step:  5128\n",
      "Loss: 929.9080003234187\n",
      "Training step:  5129\n",
      "Loss: 929.9069112164952\n",
      "Training step:  5130\n",
      "Loss: 929.9058681471099\n",
      "Training step:  5131\n",
      "Loss: 929.9047757538896\n",
      "Training step:  5132\n",
      "Loss: 929.9037387477144\n",
      "Training step:  5133\n",
      "Loss: 929.9026437916772\n",
      "Training step:  5134\n",
      "Loss: 929.9016063584253\n",
      "Training step:  5135\n",
      "Loss: 929.9005145480332\n",
      "Training step:  5136\n",
      "Loss: 929.8994812041454\n",
      "Training step:  5137\n",
      "Loss: 929.8983890770344\n",
      "Training step:  5138\n",
      "Loss: 929.8973370537677\n",
      "Training step:  5139\n",
      "Loss: 929.8962657159123\n",
      "Training step:  5140\n",
      "Loss: 929.8952201727137\n",
      "Training step:  5141\n",
      "Loss: 929.8941412346429\n",
      "Training step:  5142\n",
      "Loss: 929.893106886995\n",
      "Training step:  5143\n",
      "Loss: 929.8920241453919\n",
      "Training step:  5144\n",
      "Loss: 929.8909964187458\n",
      "Training step:  5145\n",
      "Loss: 929.8899111713242\n",
      "Training step:  5146\n",
      "Loss: 929.8888837851165\n",
      "Training step:  5147\n",
      "Loss: 929.8878014403209\n",
      "Training step:  5148\n",
      "Loss: 929.8867775646938\n",
      "Training step:  5149\n",
      "Loss: 929.88569492142\n",
      "Training step:  5150\n",
      "Loss: 929.884648757691\n",
      "Training step:  5151\n",
      "Loss: 929.883590353206\n",
      "Training step:  5152\n",
      "Loss: 929.88255826721\n",
      "Training step:  5153\n",
      "Loss: 929.88148715306\n",
      "Training step:  5154\n",
      "Loss: 929.8804640266467\n",
      "Training step:  5155\n",
      "Loss: 929.8793891839897\n",
      "Training step:  5156\n",
      "Loss: 929.878370284153\n",
      "Training step:  5157\n",
      "Loss: 929.8772951621407\n",
      "Training step:  5158\n",
      "Loss: 929.8762723942222\n",
      "Training step:  5159\n",
      "Loss: 929.8752034667356\n",
      "Training step:  5160\n",
      "Loss: 929.8741869701365\n",
      "Training step:  5161\n",
      "Loss: 929.8731150549131\n",
      "Training step:  5162\n",
      "Loss: 929.8720854727012\n",
      "Training step:  5163\n",
      "Loss: 929.8710285021443\n",
      "Training step:  5164\n",
      "Loss: 929.8700067748177\n",
      "Training step:  5165\n",
      "Loss: 929.8689452575268\n",
      "Training step:  5166\n",
      "Loss: 929.8679311378343\n",
      "Training step:  5167\n",
      "Loss: 929.866866550578\n",
      "Training step:  5168\n",
      "Loss: 929.8658582084223\n",
      "Training step:  5169\n",
      "Loss: 929.8647912348728\n",
      "Training step:  5170\n",
      "Loss: 929.8637522938932\n",
      "Training step:  5171\n",
      "Loss: 929.8627249466731\n",
      "Training step:  5172\n",
      "Loss: 929.86169012041\n",
      "Training step:  5173\n",
      "Loss: 929.8606468751973\n",
      "Training step:  5174\n",
      "Loss: 929.8596244149865\n",
      "Training step:  5175\n",
      "Loss: 929.858575648983\n",
      "Training step:  5176\n",
      "Loss: 929.8575637491524\n",
      "Training step:  5177\n",
      "Loss: 929.8565114674536\n",
      "Training step:  5178\n",
      "Loss: 929.855504803352\n",
      "Training step:  5179\n",
      "Loss: 929.8544512690892\n",
      "Training step:  5180\n",
      "Loss: 929.8534491618317\n",
      "Training step:  5181\n",
      "Loss: 929.8523943749121\n",
      "Training step:  5182\n",
      "Loss: 929.8513839092665\n",
      "Training step:  5183\n",
      "Loss: 929.8503371282171\n",
      "Training step:  5184\n",
      "Loss: 929.8493359723418\n",
      "Training step:  5185\n",
      "Loss: 929.848285532057\n",
      "Training step:  5186\n",
      "Loss: 929.8472887818622\n",
      "Training step:  5187\n",
      "Loss: 929.8462378701411\n",
      "Training step:  5188\n",
      "Loss: 929.8452255682464\n",
      "Training step:  5189\n",
      "Loss: 929.844191343187\n",
      "Training step:  5190\n",
      "Loss: 929.8431864761676\n",
      "Training step:  5191\n",
      "Loss: 929.8421466137637\n",
      "Training step:  5192\n",
      "Loss: 929.8411505984978\n",
      "Training step:  5193\n",
      "Loss: 929.8401077825516\n",
      "Training step:  5194\n",
      "Loss: 929.8391173576933\n",
      "Training step:  5195\n",
      "Loss: 929.8380722733648\n",
      "Training step:  5196\n",
      "Loss: 929.837063376138\n",
      "Training step:  5197\n",
      "Loss: 929.8360377571694\n",
      "Training step:  5198\n",
      "Loss: 929.8350359826944\n",
      "Training step:  5199\n",
      "Loss: 929.8340034800251\n",
      "Training step:  5200\n",
      "Loss: 929.8330120266598\n",
      "Training step:  5201\n",
      "Loss: 929.8319760922097\n",
      "Training step:  5202\n",
      "Loss: 929.8309907719711\n",
      "Training step:  5203\n",
      "Loss: 929.8299525984947\n",
      "Training step:  5204\n",
      "Loss: 929.8289669391725\n",
      "Training step:  5205\n",
      "Loss: 929.8279322412861\n",
      "Training step:  5206\n",
      "Loss: 929.8269498023964\n",
      "Training step:  5207\n",
      "Loss: 929.8259148921903\n",
      "Training step:  5208\n",
      "Loss: 929.8249146258818\n",
      "Training step:  5209\n",
      "Loss: 929.8238990597305\n",
      "Training step:  5210\n",
      "Loss: 929.8229050819266\n",
      "Training step:  5211\n",
      "Loss: 929.8218827705698\n",
      "Training step:  5212\n",
      "Loss: 929.8208989682167\n",
      "Training step:  5213\n",
      "Loss: 929.8198733241412\n",
      "Training step:  5214\n",
      "Loss: 929.818895583062\n",
      "Training step:  5215\n",
      "Loss: 929.8178677627097\n",
      "Training step:  5216\n",
      "Loss: 929.8168888039885\n",
      "Training step:  5217\n",
      "Loss: 929.8158648677785\n",
      "Training step:  5218\n",
      "Loss: 929.8148916323742\n",
      "Training step:  5219\n",
      "Loss: 929.8138655388523\n",
      "Training step:  5220\n",
      "Loss: 929.8128638738236\n",
      "Training step:  5221\n",
      "Loss: 929.8118724556181\n",
      "Training step:  5222\n",
      "Loss: 929.8108735513757\n",
      "Training step:  5223\n",
      "Loss: 929.8098658728996\n",
      "Training step:  5224\n",
      "Loss: 929.8088811457145\n",
      "Training step:  5225\n",
      "Loss: 929.8078682807452\n",
      "Training step:  5226\n",
      "Loss: 929.8068947671378\n",
      "Training step:  5227\n",
      "Loss: 929.8058799381147\n",
      "Training step:  5228\n",
      "Loss: 929.8049111925795\n",
      "Training step:  5229\n",
      "Loss: 929.8038952430633\n",
      "Training step:  5230\n",
      "Loss: 929.8029280256002\n",
      "Training step:  5231\n",
      "Loss: 929.8019136213593\n",
      "Training step:  5232\n",
      "Loss: 929.8009488667736\n",
      "Training step:  5233\n",
      "Loss: 929.7999350057858\n",
      "Training step:  5234\n",
      "Loss: 929.7989559468376\n",
      "Training step:  5235\n",
      "Loss: 929.7979582271445\n",
      "Training step:  5236\n",
      "Loss: 929.7969853996407\n",
      "Training step:  5237\n",
      "Loss: 929.7959837321495\n",
      "Training step:  5238\n",
      "Loss: 929.7950178454977\n",
      "Training step:  5239\n",
      "Loss: 929.7940129821683\n",
      "Training step:  5240\n",
      "Loss: 929.7930529514355\n",
      "Training step:  5241\n",
      "Loss: 929.7920460286932\n",
      "Training step:  5242\n",
      "Loss: 929.7910884971037\n",
      "Training step:  5243\n",
      "Loss: 929.790082120627\n",
      "Training step:  5244\n",
      "Loss: 929.7891049096595\n",
      "Training step:  5245\n",
      "Loss: 929.7881181407614\n",
      "Training step:  5246\n",
      "Loss: 929.7871482948774\n",
      "Training step:  5247\n",
      "Loss: 929.7861551181534\n",
      "Training step:  5248\n",
      "Loss: 929.7851949791419\n",
      "Training step:  5249\n",
      "Loss: 929.7841984816803\n",
      "Training step:  5250\n",
      "Loss: 929.7832434880029\n",
      "Training step:  5251\n",
      "Loss: 929.7822455118956\n",
      "Training step:  5252\n",
      "Loss: 929.7812962080844\n",
      "Training step:  5253\n",
      "Loss: 929.7802962147595\n",
      "Training step:  5254\n",
      "Loss: 929.779325629942\n",
      "Training step:  5255\n",
      "Loss: 929.7783490262289\n",
      "Training step:  5256\n",
      "Loss: 929.7773913649984\n",
      "Training step:  5257\n",
      "Loss: 929.7764039533819\n",
      "Training step:  5258\n",
      "Loss: 929.775452847263\n",
      "Training step:  5259\n",
      "Loss: 929.7744623444365\n",
      "Training step:  5260\n",
      "Loss: 929.7735153144052\n",
      "Training step:  5261\n",
      "Loss: 929.7725244645901\n",
      "Training step:  5262\n",
      "Loss: 929.7715825084767\n",
      "Training step:  5263\n",
      "Loss: 929.7705896797185\n",
      "Training step:  5264\n",
      "Loss: 929.7696189960169\n",
      "Training step:  5265\n",
      "Loss: 929.7686669395434\n",
      "Training step:  5266\n",
      "Loss: 929.7676896336112\n",
      "Training step:  5267\n",
      "Loss: 929.7667215972831\n",
      "Training step:  5268\n",
      "Loss: 929.7657670780442\n",
      "Training step:  5269\n",
      "Loss: 929.7647885361795\n",
      "Training step:  5270\n",
      "Loss: 929.7638415843084\n",
      "Training step:  5271\n",
      "Loss: 929.7628631604633\n",
      "Training step:  5272\n",
      "Loss: 929.7619227598556\n",
      "Training step:  5273\n",
      "Loss: 929.7609423377568\n",
      "Training step:  5274\n",
      "Loss: 929.7600059796341\n",
      "Training step:  5275\n",
      "Loss: 929.7590245630889\n",
      "Training step:  5276\n",
      "Loss: 929.7580862183909\n",
      "Training step:  5277\n",
      "Loss: 929.7571093240089\n",
      "Training step:  5278\n",
      "Loss: 929.756176204475\n",
      "Training step:  5279\n",
      "Loss: 929.7551973996214\n",
      "Training step:  5280\n",
      "Loss: 929.7542521062637\n",
      "Training step:  5281\n",
      "Loss: 929.7532868751896\n",
      "Training step:  5282\n",
      "Loss: 929.7523474198517\n",
      "Training step:  5283\n",
      "Loss: 929.7513791371393\n",
      "Training step:  5284\n",
      "Loss: 929.7504461882896\n",
      "Training step:  5285\n",
      "Loss: 929.7494749573299\n",
      "Training step:  5286\n",
      "Loss: 929.7485475087053\n",
      "Training step:  5287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 929.7475743877895\n",
      "Training step:  5288\n",
      "Loss: 929.7466413443107\n",
      "Training step:  5289\n",
      "Loss: 929.7456762927293\n",
      "Training step:  5290\n",
      "Loss: 929.7447486981206\n",
      "Training step:  5291\n",
      "Loss: 929.7437812186912\n",
      "Training step:  5292\n",
      "Loss: 929.7428585577006\n",
      "Training step:  5293\n",
      "Loss: 929.7418892149657\n",
      "Training step:  5294\n",
      "Loss: 929.7409438832447\n",
      "Training step:  5295\n",
      "Loss: 929.7400008789633\n",
      "Training step:  5296\n",
      "Loss: 929.7390648893294\n",
      "Training step:  5297\n",
      "Loss: 929.738109634553\n",
      "Training step:  5298\n",
      "Loss: 929.7371829256728\n",
      "Training step:  5299\n",
      "Loss: 929.7362249648796\n",
      "Training step:  5300\n",
      "Loss: 929.7353043001395\n",
      "Training step:  5301\n",
      "Loss: 929.7343434734203\n",
      "Training step:  5302\n",
      "Loss: 929.7334265791733\n",
      "Training step:  5303\n",
      "Loss: 929.7324654720377\n",
      "Training step:  5304\n",
      "Loss: 929.7315439827033\n",
      "Training step:  5305\n",
      "Loss: 929.7305898107595\n",
      "Training step:  5306\n",
      "Loss: 929.7296737864109\n",
      "Training step:  5307\n",
      "Loss: 929.7287167849589\n",
      "Training step:  5308\n",
      "Loss: 929.7278036013759\n",
      "Training step:  5309\n",
      "Loss: 929.7268471558784\n",
      "Training step:  5310\n",
      "Loss: 929.7259348866729\n",
      "Training step:  5311\n",
      "Loss: 929.7249798492883\n",
      "Training step:  5312\n",
      "Loss: 929.72406896636\n",
      "Training step:  5313\n",
      "Loss: 929.7231153348822\n",
      "Training step:  5314\n",
      "Loss: 929.7222044725534\n",
      "Training step:  5315\n",
      "Loss: 929.7212536244947\n",
      "Training step:  5316\n",
      "Loss: 929.7203460697377\n",
      "Training step:  5317\n",
      "Loss: 929.719394685132\n",
      "Training step:  5318\n",
      "Loss: 929.7184760884411\n",
      "Training step:  5319\n",
      "Loss: 929.7175375191905\n",
      "Training step:  5320\n",
      "Loss: 929.7166251751792\n",
      "Training step:  5321\n",
      "Loss: 929.7156831975595\n",
      "Training step:  5322\n",
      "Loss: 929.7147770370982\n",
      "Training step:  5323\n",
      "Loss: 929.7138323159219\n",
      "Training step:  5324\n",
      "Loss: 929.712931392007\n",
      "Training step:  5325\n",
      "Loss: 929.7119849254138\n",
      "Training step:  5326\n",
      "Loss: 929.7110593504729\n",
      "Training step:  5327\n",
      "Loss: 929.7101426424772\n",
      "Training step:  5328\n",
      "Loss: 929.709222745227\n",
      "Training step:  5329\n",
      "Loss: 929.708294151925\n",
      "Training step:  5330\n",
      "Loss: 929.7073838113421\n",
      "Training step:  5331\n",
      "Loss: 929.7064509922535\n",
      "Training step:  5332\n",
      "Loss: 929.7055491546802\n",
      "Training step:  5333\n",
      "Loss: 929.7046141438075\n",
      "Training step:  5334\n",
      "Loss: 929.7037170074256\n",
      "Training step:  5335\n",
      "Loss: 929.7027802845815\n",
      "Training step:  5336\n",
      "Loss: 929.7018845485818\n",
      "Training step:  5337\n",
      "Loss: 929.7009492471359\n",
      "Training step:  5338\n",
      "Loss: 929.7000548779599\n",
      "Training step:  5339\n",
      "Loss: 929.6991205342234\n",
      "Training step:  5340\n",
      "Loss: 929.6982275274946\n",
      "Training step:  5341\n",
      "Loss: 929.6972945592049\n",
      "Training step:  5342\n",
      "Loss: 929.6964029090735\n",
      "Training step:  5343\n",
      "Loss: 929.6954713142101\n",
      "Training step:  5344\n",
      "Loss: 929.6945797162172\n",
      "Training step:  5345\n",
      "Loss: 929.6936508121227\n",
      "Training step:  5346\n",
      "Loss: 929.6927623975722\n",
      "Training step:  5347\n",
      "Loss: 929.6918330091634\n",
      "Training step:  5348\n",
      "Loss: 929.6909335846735\n",
      "Training step:  5349\n",
      "Loss: 929.6900166585222\n",
      "Training step:  5350\n",
      "Loss: 929.6891234971733\n",
      "Training step:  5351\n",
      "Loss: 929.6882022735692\n",
      "Training step:  5352\n",
      "Loss: 929.6873162355924\n",
      "Training step:  5353\n",
      "Loss: 929.686392836221\n",
      "Training step:  5354\n",
      "Loss: 929.6855104991529\n",
      "Training step:  5355\n",
      "Loss: 929.6845862949929\n",
      "Training step:  5356\n",
      "Loss: 929.6836895392656\n",
      "Training step:  5357\n",
      "Loss: 929.6827807529859\n",
      "Training step:  5358\n",
      "Loss: 929.6818897505916\n",
      "Training step:  5359\n",
      "Loss: 929.6809756951889\n",
      "Training step:  5360\n",
      "Loss: 929.6800929825641\n",
      "Training step:  5361\n",
      "Loss: 929.6791764238803\n",
      "Training step:  5362\n",
      "Loss: 929.6782987163123\n",
      "Training step:  5363\n",
      "Loss: 929.6773805497139\n",
      "Training step:  5364\n",
      "Loss: 929.676502726242\n",
      "Training step:  5365\n",
      "Loss: 929.6755869982555\n",
      "Training step:  5366\n",
      "Loss: 929.6747117079375\n",
      "Training step:  5367\n",
      "Loss: 929.6737961133603\n",
      "Training step:  5368\n",
      "Loss: 929.6729091304721\n",
      "Training step:  5369\n",
      "Loss: 929.6720071682114\n",
      "Training step:  5370\n",
      "Loss: 929.6711255714149\n",
      "Training step:  5371\n",
      "Loss: 929.6702184156952\n",
      "Training step:  5372\n",
      "Loss: 929.6693449582078\n",
      "Training step:  5373\n",
      "Loss: 929.6684357018306\n",
      "Training step:  5374\n",
      "Loss: 929.6675658670916\n",
      "Training step:  5375\n",
      "Loss: 929.6666558485767\n",
      "Training step:  5376\n",
      "Loss: 929.6657798149057\n",
      "Training step:  5377\n",
      "Loss: 929.6648774547789\n",
      "Training step:  5378\n",
      "Loss: 929.6640071205717\n",
      "Training step:  5379\n",
      "Loss: 929.6631020739593\n",
      "Training step:  5380\n",
      "Loss: 929.6622352716358\n",
      "Training step:  5381\n",
      "Loss: 929.6613297977935\n",
      "Training step:  5382\n",
      "Loss: 929.660449781481\n",
      "Training step:  5383\n",
      "Loss: 929.6595592248664\n",
      "Training step:  5384\n",
      "Loss: 929.6586844060125\n",
      "Training step:  5385\n",
      "Loss: 929.6577888195221\n",
      "Training step:  5386\n",
      "Loss: 929.6569220118835\n",
      "Training step:  5387\n",
      "Loss: 929.656024040045\n",
      "Training step:  5388\n",
      "Loss: 929.6551626156795\n",
      "Training step:  5389\n",
      "Loss: 929.6542626135346\n",
      "Training step:  5390\n",
      "Loss: 929.6534010803654\n",
      "Training step:  5391\n",
      "Loss: 929.652503879743\n",
      "Training step:  5392\n",
      "Loss: 929.6516449963937\n",
      "Training step:  5393\n",
      "Loss: 929.6507478006279\n",
      "Training step:  5394\n",
      "Loss: 929.6498852275992\n",
      "Training step:  5395\n",
      "Loss: 929.6489938930183\n",
      "Training step:  5396\n",
      "Loss: 929.6481362312305\n",
      "Training step:  5397\n",
      "Loss: 929.647242515739\n",
      "Training step:  5398\n",
      "Loss: 929.6463874358304\n",
      "Training step:  5399\n",
      "Loss: 929.6454942944856\n",
      "Training step:  5400\n",
      "Loss: 929.6446287866169\n",
      "Training step:  5401\n",
      "Loss: 929.6437471638479\n",
      "Training step:  5402\n",
      "Loss: 929.6428873727167\n",
      "Training step:  5403\n",
      "Loss: 929.6420028302603\n",
      "Training step:  5404\n",
      "Loss: 929.6411486034259\n",
      "Training step:  5405\n",
      "Loss: 929.6402617104824\n",
      "Training step:  5406\n",
      "Loss: 929.6394122178071\n",
      "Training step:  5407\n",
      "Loss: 929.6385238575631\n",
      "Training step:  5408\n",
      "Loss: 929.6376604602096\n",
      "Training step:  5409\n",
      "Loss: 929.6367853740692\n",
      "Training step:  5410\n",
      "Loss: 929.6359280789062\n",
      "Training step:  5411\n",
      "Loss: 929.6350492146727\n",
      "Training step:  5412\n",
      "Loss: 929.6341995497393\n",
      "Training step:  5413\n",
      "Loss: 929.6333184286112\n",
      "Training step:  5414\n",
      "Loss: 929.6324734498716\n",
      "Training step:  5415\n",
      "Loss: 929.6315908907995\n",
      "Training step:  5416\n",
      "Loss: 929.6307403235838\n",
      "Training step:  5417\n",
      "Loss: 929.6298638015821\n",
      "Training step:  5418\n",
      "Loss: 929.6290197089497\n",
      "Training step:  5419\n",
      "Loss: 929.6281412841984\n",
      "Training step:  5420\n",
      "Loss: 929.6273014011771\n",
      "Training step:  5421\n",
      "Loss: 929.6264215522145\n",
      "Training step:  5422\n",
      "Loss: 929.6255583295582\n",
      "Training step:  5423\n",
      "Loss: 929.6247079665883\n",
      "Training step:  5424\n",
      "Loss: 929.6238351438709\n",
      "Training step:  5425\n",
      "Loss: 929.6229918024331\n",
      "Training step:  5426\n",
      "Loss: 929.6221184801592\n",
      "Training step:  5427\n",
      "Loss: 929.6212789407934\n",
      "Training step:  5428\n",
      "Loss: 929.6204063944199\n",
      "Training step:  5429\n",
      "Loss: 929.6195713962569\n",
      "Training step:  5430\n",
      "Loss: 929.6186981255725\n",
      "Training step:  5431\n",
      "Loss: 929.6178482378758\n",
      "Training step:  5432\n",
      "Loss: 929.6169908293241\n",
      "Training step:  5433\n",
      "Loss: 929.6161457618841\n",
      "Training step:  5434\n",
      "Loss: 929.6152838046322\n",
      "Training step:  5435\n",
      "Loss: 929.614446254073\n",
      "Training step:  5436\n",
      "Loss: 929.6135821837364\n",
      "Training step:  5437\n",
      "Loss: 929.6127496854789\n",
      "Training step:  5438\n",
      "Loss: 929.6118837810236\n",
      "Training step:  5439\n",
      "Loss: 929.6110546360608\n",
      "Training step:  5440\n",
      "Loss: 929.6101880993908\n",
      "Training step:  5441\n",
      "Loss: 929.6093589003323\n",
      "Training step:  5442\n",
      "Loss: 929.6084946152693\n",
      "Training step:  5443\n",
      "Loss: 929.6076677617949\n",
      "Training step:  5444\n",
      "Loss: 929.6068040517688\n",
      "Training step:  5445\n",
      "Loss: 929.6059724541874\n",
      "Training step:  5446\n",
      "Loss: 929.6051148431543\n",
      "Training step:  5447\n",
      "Loss: 929.6042885185184\n",
      "Training step:  5448\n",
      "Loss: 929.603428740286\n",
      "Training step:  5449\n",
      "Loss: 929.6026068936553\n",
      "Training step:  5450\n",
      "Loss: 929.6017457815237\n",
      "Training step:  5451\n",
      "Loss: 929.6009027722807\n",
      "Training step:  5452\n",
      "Loss: 929.6000697102504\n",
      "Training step:  5453\n",
      "Loss: 929.5992252991042\n",
      "Training step:  5454\n",
      "Loss: 929.5983798058822\n",
      "Training step:  5455\n",
      "Loss: 929.5975469419388\n",
      "Training step:  5456\n",
      "Loss: 929.5966975674739\n",
      "Training step:  5457\n",
      "Loss: 929.595871796676\n",
      "Training step:  5458\n",
      "Loss: 929.5950205463562\n",
      "Training step:  5459\n",
      "Loss: 929.5941984302146\n",
      "Training step:  5460\n",
      "Loss: 929.5933465564467\n",
      "Training step:  5461\n",
      "Loss: 929.592526221058\n",
      "Training step:  5462\n",
      "Loss: 929.591675307008\n",
      "Training step:  5463\n",
      "Loss: 929.5908558724799\n",
      "Training step:  5464\n",
      "Loss: 929.5900057208917\n",
      "Training step:  5465\n",
      "Loss: 929.5891888035399\n",
      "Training step:  5466\n",
      "Loss: 929.5883392729257\n",
      "Training step:  5467\n",
      "Loss: 929.5875188802486\n",
      "Training step:  5468\n",
      "Loss: 929.586672973492\n",
      "Training step:  5469\n",
      "Loss: 929.585860820522\n",
      "Training step:  5470\n",
      "Loss: 929.5850137452705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  5471\n",
      "Loss: 929.5841923223571\n",
      "Training step:  5472\n",
      "Loss: 929.5833562995506\n",
      "Training step:  5473\n",
      "Loss: 929.5825404769074\n",
      "Training step:  5474\n",
      "Loss: 929.5817011951266\n",
      "Training step:  5475\n",
      "Loss: 929.5808912121635\n",
      "Training step:  5476\n",
      "Loss: 929.5800502445891\n",
      "Training step:  5477\n",
      "Loss: 929.5792446589572\n",
      "Training step:  5478\n",
      "Loss: 929.5784019925011\n",
      "Training step:  5479\n",
      "Loss: 929.5775841580044\n",
      "Training step:  5480\n",
      "Loss: 929.5767544181128\n",
      "Training step:  5481\n",
      "Loss: 929.5759418891097\n",
      "Training step:  5482\n",
      "Loss: 929.5751078726088\n",
      "Training step:  5483\n",
      "Loss: 929.5743023504454\n",
      "Training step:  5484\n",
      "Loss: 929.5734666786516\n",
      "Training step:  5485\n",
      "Loss: 929.5726655094644\n",
      "Training step:  5486\n",
      "Loss: 929.5718281657552\n",
      "Training step:  5487\n",
      "Loss: 929.5710224501448\n",
      "Training step:  5488\n",
      "Loss: 929.5701910429347\n",
      "Training step:  5489\n",
      "Loss: 929.5693903957568\n",
      "Training step:  5490\n",
      "Loss: 929.5685573198517\n",
      "Training step:  5491\n",
      "Loss: 929.5677586455556\n",
      "Training step:  5492\n",
      "Loss: 929.5669261500065\n",
      "Training step:  5493\n",
      "Loss: 929.5661283354625\n",
      "Training step:  5494\n",
      "Loss: 929.5652970676712\n",
      "Training step:  5495\n",
      "Loss: 929.564500463322\n",
      "Training step:  5496\n",
      "Loss: 929.5636704194815\n",
      "Training step:  5497\n",
      "Loss: 929.5628750234736\n",
      "Training step:  5498\n",
      "Loss: 929.5620462017838\n",
      "Training step:  5499\n",
      "Loss: 929.5612530231474\n",
      "Training step:  5500\n",
      "Loss: 929.5604244252202\n",
      "Training step:  5501\n",
      "Loss: 929.559618810915\n",
      "Training step:  5502\n",
      "Loss: 929.5588037305379\n",
      "Training step:  5503\n",
      "Loss: 929.558002030477\n",
      "Training step:  5504\n",
      "Loss: 929.557183934113\n",
      "Training step:  5505\n",
      "Loss: 929.556388911094\n",
      "Training step:  5506\n",
      "Loss: 929.5555689660066\n",
      "Training step:  5507\n",
      "Loss: 929.5547785560293\n",
      "Training step:  5508\n",
      "Loss: 929.5539570181991\n",
      "Training step:  5509\n",
      "Loss: 929.5531691888682\n",
      "Training step:  5510\n",
      "Loss: 929.5523476188163\n",
      "Training step:  5511\n",
      "Loss: 929.5515467530662\n",
      "Training step:  5512\n",
      "Loss: 929.5507388207437\n",
      "Training step:  5513\n",
      "Loss: 929.5499428133684\n",
      "Training step:  5514\n",
      "Loss: 929.5491309142847\n",
      "Training step:  5515\n",
      "Loss: 929.5483416417443\n",
      "Training step:  5516\n",
      "Loss: 929.5475279551465\n",
      "Training step:  5517\n",
      "Loss: 929.5467432364959\n",
      "Training step:  5518\n",
      "Loss: 929.5459279974868\n",
      "Training step:  5519\n",
      "Loss: 929.5451451936748\n",
      "Training step:  5520\n",
      "Loss: 929.54433053518\n",
      "Training step:  5521\n",
      "Loss: 929.5435489152436\n",
      "Training step:  5522\n",
      "Loss: 929.5427351335971\n",
      "Training step:  5523\n",
      "Loss: 929.541945232688\n",
      "Training step:  5524\n",
      "Loss: 929.5411407371728\n",
      "Training step:  5525\n",
      "Loss: 929.5403562028463\n",
      "Training step:  5526\n",
      "Loss: 929.5395484976196\n",
      "Training step:  5527\n",
      "Loss: 929.5387696376335\n",
      "Training step:  5528\n",
      "Loss: 929.5379604010238\n",
      "Training step:  5529\n",
      "Loss: 929.5371847340175\n",
      "Training step:  5530\n",
      "Loss: 929.5363748409353\n",
      "Training step:  5531\n",
      "Loss: 929.5355865590411\n",
      "Training step:  5532\n",
      "Loss: 929.5347906118675\n",
      "Training step:  5533\n",
      "Loss: 929.5340062816688\n",
      "Training step:  5534\n",
      "Loss: 929.5332064975969\n",
      "Training step:  5535\n",
      "Loss: 929.5324287271452\n",
      "Training step:  5536\n",
      "Loss: 929.531627219451\n",
      "Training step:  5537\n",
      "Loss: 929.5308538868123\n",
      "Training step:  5538\n",
      "Loss: 929.530050887066\n",
      "Training step:  5539\n",
      "Loss: 929.5292816163054\n",
      "Training step:  5540\n",
      "Loss: 929.5284771207324\n",
      "Training step:  5541\n",
      "Loss: 929.527688393358\n",
      "Training step:  5542\n",
      "Loss: 929.5269109656931\n",
      "Training step:  5543\n",
      "Loss: 929.5261213672644\n",
      "Training step:  5544\n",
      "Loss: 929.525333922924\n",
      "Training step:  5545\n",
      "Loss: 929.5245549377247\n",
      "Training step:  5546\n",
      "Loss: 929.5237637213706\n",
      "Training step:  5547\n",
      "Loss: 929.5229912008867\n",
      "Training step:  5548\n",
      "Loss: 929.522197462324\n",
      "Training step:  5549\n",
      "Loss: 929.5214291597765\n",
      "Training step:  5550\n",
      "Loss: 929.5206350262545\n",
      "Training step:  5551\n",
      "Loss: 929.5198700292755\n",
      "Training step:  5552\n",
      "Loss: 929.5190750561742\n",
      "Training step:  5553\n",
      "Loss: 929.5183124759749\n",
      "Training step:  5554\n",
      "Loss: 929.5175175103466\n",
      "Training step:  5555\n",
      "Loss: 929.5167503932154\n",
      "Training step:  5556\n",
      "Loss: 929.5159621877475\n",
      "Training step:  5557\n",
      "Loss: 929.5151987505955\n",
      "Training step:  5558\n",
      "Loss: 929.5144091151556\n",
      "Training step:  5559\n",
      "Loss: 929.5136496399158\n",
      "Training step:  5560\n",
      "Loss: 929.5128585675185\n",
      "Training step:  5561\n",
      "Loss: 929.5120912998309\n",
      "Training step:  5562\n",
      "Loss: 929.5113093921701\n",
      "Training step:  5563\n",
      "Loss: 929.5105461653416\n",
      "Training step:  5564\n",
      "Loss: 929.5097626714793\n",
      "Training step:  5565\n",
      "Loss: 929.5090037271274\n",
      "Training step:  5566\n",
      "Loss: 929.5082188260341\n",
      "Training step:  5567\n",
      "Loss: 929.5074638035162\n",
      "Training step:  5568\n",
      "Loss: 929.5066774892799\n",
      "Training step:  5569\n",
      "Loss: 929.5059194907141\n",
      "Training step:  5570\n",
      "Loss: 929.5051381655571\n",
      "Training step:  5571\n",
      "Loss: 929.5043840491255\n",
      "Training step:  5572\n",
      "Loss: 929.5036013292397\n",
      "Training step:  5573\n",
      "Loss: 929.5028490107445\n",
      "Training step:  5574\n",
      "Loss: 929.5020668714834\n",
      "Training step:  5575\n",
      "Loss: 929.501316287073\n",
      "Training step:  5576\n",
      "Loss: 929.5005347292898\n",
      "Training step:  5577\n",
      "Loss: 929.4997737243257\n",
      "Training step:  5578\n",
      "Loss: 929.4990034199208\n",
      "Training step:  5579\n",
      "Loss: 929.4982469328081\n",
      "Training step:  5580\n",
      "Loss: 929.497473030636\n",
      "Training step:  5581\n",
      "Loss: 929.4967226812245\n",
      "Training step:  5582\n",
      "Loss: 929.4959471320863\n",
      "Training step:  5583\n",
      "Loss: 929.49520096293\n",
      "Training step:  5584\n",
      "Loss: 929.4944240553368\n",
      "Training step:  5585\n",
      "Loss: 929.493676543342\n",
      "Training step:  5586\n",
      "Loss: 929.4929028180547\n",
      "Training step:  5587\n",
      "Loss: 929.4921589918158\n",
      "Training step:  5588\n",
      "Loss: 929.4913843453558\n",
      "Training step:  5589\n",
      "Loss: 929.4906279639166\n",
      "Training step:  5590\n",
      "Loss: 929.4898675891019\n",
      "Training step:  5591\n",
      "Loss: 929.489114119705\n",
      "Training step:  5592\n",
      "Loss: 929.4883503552244\n",
      "Training step:  5593\n",
      "Loss: 929.4876034015925\n",
      "Training step:  5594\n",
      "Loss: 929.4868369835444\n",
      "Training step:  5595\n",
      "Loss: 929.4860950049924\n",
      "Training step:  5596\n",
      "Loss: 929.4853272591504\n",
      "Training step:  5597\n",
      "Loss: 929.4845890554375\n",
      "Training step:  5598\n",
      "Loss: 929.4838199834176\n",
      "Training step:  5599\n",
      "Loss: 929.4830749038055\n",
      "Training step:  5600\n",
      "Loss: 929.4823137339804\n",
      "Training step:  5601\n",
      "Loss: 929.4815731755316\n",
      "Training step:  5602\n",
      "Loss: 929.4808104671741\n",
      "Training step:  5603\n",
      "Loss: 929.4800739846934\n",
      "Training step:  5604\n",
      "Loss: 929.4793099816181\n",
      "Training step:  5605\n",
      "Loss: 929.4785644354844\n",
      "Training step:  5606\n",
      "Loss: 929.4778099596847\n",
      "Training step:  5607\n",
      "Loss: 929.4770693082046\n",
      "Training step:  5608\n",
      "Loss: 929.4763121173487\n",
      "Training step:  5609\n",
      "Loss: 929.4755765577132\n",
      "Training step:  5610\n",
      "Loss: 929.4748177845006\n",
      "Training step:  5611\n",
      "Loss: 929.4740854384469\n",
      "Training step:  5612\n",
      "Loss: 929.4733261457716\n",
      "Training step:  5613\n",
      "Loss: 929.4725949055387\n",
      "Training step:  5614\n",
      "Loss: 929.4718367592492\n",
      "Training step:  5615\n",
      "Loss: 929.471103317518\n",
      "Training step:  5616\n",
      "Loss: 929.4703492643437\n",
      "Training step:  5617\n",
      "Loss: 929.4696195738438\n",
      "Training step:  5618\n",
      "Loss: 929.4688639672661\n",
      "Training step:  5619\n",
      "Loss: 929.468136283651\n",
      "Training step:  5620\n",
      "Loss: 929.4673812548864\n",
      "Training step:  5621\n",
      "Loss: 929.4666461795691\n",
      "Training step:  5622\n",
      "Loss: 929.4658989449174\n",
      "Training step:  5623\n",
      "Loss: 929.4651685627402\n",
      "Training step:  5624\n",
      "Loss: 929.4644197391873\n",
      "Training step:  5625\n",
      "Loss: 929.4636935216021\n",
      "Training step:  5626\n",
      "Loss: 929.4629431661165\n",
      "Training step:  5627\n",
      "Loss: 929.4622204664324\n",
      "Training step:  5628\n",
      "Loss: 929.4614692664821\n",
      "Training step:  5629\n",
      "Loss: 929.4607356754452\n",
      "Training step:  5630\n",
      "Loss: 929.4599959531795\n",
      "Training step:  5631\n",
      "Loss: 929.4592666948349\n",
      "Training step:  5632\n",
      "Loss: 929.4585237427759\n",
      "Training step:  5633\n",
      "Loss: 929.4578002124998\n",
      "Training step:  5634\n",
      "Loss: 929.4570558170149\n",
      "Training step:  5635\n",
      "Loss: 929.4563361992452\n",
      "Training step:  5636\n",
      "Loss: 929.4555905895784\n",
      "Training step:  5637\n",
      "Loss: 929.4548720890464\n",
      "Training step:  5638\n",
      "Loss: 929.4541273114879\n",
      "Training step:  5639\n",
      "Loss: 929.453410192217\n",
      "Training step:  5640\n",
      "Loss: 929.4526662436514\n",
      "Training step:  5641\n",
      "Loss: 929.4519415447082\n",
      "Training step:  5642\n",
      "Loss: 929.4512062120515\n",
      "Training step:  5643\n",
      "Loss: 929.4504860190057\n",
      "Training step:  5644\n",
      "Loss: 929.449748837233\n",
      "Training step:  5645\n",
      "Loss: 929.44903270384\n",
      "Training step:  5646\n",
      "Loss: 929.4482940477836\n",
      "Training step:  5647\n",
      "Loss: 929.4475813509563\n",
      "Training step:  5648\n",
      "Loss: 929.4468418881706\n",
      "Training step:  5649\n",
      "Loss: 929.4461293158\n",
      "Training step:  5650\n",
      "Loss: 929.4453916589874\n",
      "Training step:  5651\n",
      "Loss: 929.4446809605307\n",
      "Training step:  5652\n",
      "Loss: 929.4439438777105\n",
      "Training step:  5653\n",
      "Loss: 929.44323315235\n",
      "Training step:  5654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 929.442497988959\n",
      "Training step:  5655\n",
      "Loss: 929.4417894512911\n",
      "Training step:  5656\n",
      "Loss: 929.4410542468993\n",
      "Training step:  5657\n",
      "Loss: 929.4403383218487\n",
      "Training step:  5658\n",
      "Loss: 929.4396111477446\n",
      "Training step:  5659\n",
      "Loss: 929.4389000902505\n",
      "Training step:  5660\n",
      "Loss: 929.4381711043493\n",
      "Training step:  5661\n",
      "Loss: 929.4374640196827\n",
      "Training step:  5662\n",
      "Loss: 929.436733887786\n",
      "Training step:  5663\n",
      "Loss: 929.4360298720553\n",
      "Training step:  5664\n",
      "Loss: 929.4352989674951\n",
      "Training step:  5665\n",
      "Loss: 929.4345911446611\n",
      "Training step:  5666\n",
      "Loss: 929.4338647383344\n",
      "Training step:  5667\n",
      "Loss: 929.4331615771773\n",
      "Training step:  5668\n",
      "Loss: 929.432433784731\n",
      "Training step:  5669\n",
      "Loss: 929.4317317469399\n",
      "Training step:  5670\n",
      "Loss: 929.4310050265032\n",
      "Training step:  5671\n",
      "Loss: 929.4303040517578\n",
      "Training step:  5672\n",
      "Loss: 929.4295784017617\n",
      "Training step:  5673\n",
      "Loss: 929.4288784884371\n",
      "Training step:  5674\n",
      "Loss: 929.4281539073052\n",
      "Training step:  5675\n",
      "Loss: 929.4274545731237\n",
      "Training step:  5676\n",
      "Loss: 929.4267315417472\n",
      "Training step:  5677\n",
      "Loss: 929.4260343483245\n",
      "Training step:  5678\n",
      "Loss: 929.4253112943333\n",
      "Training step:  5679\n",
      "Loss: 929.4246029676686\n",
      "Training step:  5680\n",
      "Loss: 929.4238932836887\n",
      "Training step:  5681\n",
      "Loss: 929.423186944866\n",
      "Training step:  5682\n",
      "Loss: 929.4224734645237\n",
      "Training step:  5683\n",
      "Loss: 929.4217740227419\n",
      "Training step:  5684\n",
      "Loss: 929.4210583133937\n",
      "Training step:  5685\n",
      "Loss: 929.4203632973135\n",
      "Training step:  5686\n",
      "Loss: 929.4196465103554\n",
      "Training step:  5687\n",
      "Loss: 929.418953473594\n",
      "Training step:  5688\n",
      "Loss: 929.4182369721373\n",
      "Training step:  5689\n",
      "Loss: 929.4175453999774\n",
      "Training step:  5690\n",
      "Loss: 929.416829603755\n",
      "Training step:  5691\n",
      "Loss: 929.4161395793408\n",
      "Training step:  5692\n",
      "Loss: 929.4154243576025\n",
      "Training step:  5693\n",
      "Loss: 929.4147281778215\n",
      "Training step:  5694\n",
      "Loss: 929.4140193616948\n",
      "Training step:  5695\n",
      "Loss: 929.4133277664507\n",
      "Training step:  5696\n",
      "Loss: 929.41261691918\n",
      "Training step:  5697\n",
      "Loss: 929.4119298203116\n",
      "Training step:  5698\n",
      "Loss: 929.4112179050868\n",
      "Training step:  5699\n",
      "Loss: 929.4105309700235\n",
      "Training step:  5700\n",
      "Loss: 929.4098205932635\n",
      "Training step:  5701\n",
      "Loss: 929.409135918262\n",
      "Training step:  5702\n",
      "Loss: 929.4084258010142\n",
      "Training step:  5703\n",
      "Loss: 929.407730229756\n",
      "Training step:  5704\n",
      "Loss: 929.4070325816035\n",
      "Training step:  5705\n",
      "Loss: 929.4063394193803\n",
      "Training step:  5706\n",
      "Loss: 929.4056378512356\n",
      "Training step:  5707\n",
      "Loss: 929.4049505999609\n",
      "Training step:  5708\n",
      "Loss: 929.4042477954124\n",
      "Training step:  5709\n",
      "Loss: 929.4035649340912\n",
      "Training step:  5710\n",
      "Loss: 929.4028610866058\n",
      "Training step:  5711\n",
      "Loss: 929.4021806014607\n",
      "Training step:  5712\n",
      "Loss: 929.4014765602827\n",
      "Training step:  5713\n",
      "Loss: 929.4007962507998\n",
      "Training step:  5714\n",
      "Loss: 929.4000938976052\n",
      "Training step:  5715\n",
      "Loss: 929.3994156510558\n",
      "Training step:  5716\n",
      "Loss: 929.3987135582781\n",
      "Training step:  5717\n",
      "Loss: 929.3980330608049\n",
      "Training step:  5718\n",
      "Loss: 929.3973343783497\n",
      "Training step:  5719\n",
      "Loss: 929.3966577831173\n",
      "Training step:  5720\n",
      "Loss: 929.3959580964467\n",
      "Training step:  5721\n",
      "Loss: 929.3952825613617\n",
      "Training step:  5722\n",
      "Loss: 929.3945836698186\n",
      "Training step:  5723\n",
      "Loss: 929.393903098749\n",
      "Training step:  5724\n",
      "Loss: 929.3932101944367\n",
      "Training step:  5725\n",
      "Loss: 929.3925336398826\n",
      "Training step:  5726\n",
      "Loss: 929.3918388149838\n",
      "Training step:  5727\n",
      "Loss: 929.3911662166809\n",
      "Training step:  5728\n",
      "Loss: 929.3904704820598\n",
      "Training step:  5729\n",
      "Loss: 929.3897934835827\n",
      "Training step:  5730\n",
      "Loss: 929.3891033026297\n",
      "Training step:  5731\n",
      "Loss: 929.3884301794665\n",
      "Training step:  5732\n",
      "Loss: 929.3877386903246\n",
      "Training step:  5733\n",
      "Loss: 929.3870691901204\n",
      "Training step:  5734\n",
      "Loss: 929.3863767182313\n",
      "Training step:  5735\n",
      "Loss: 929.3857046675076\n",
      "Training step:  5736\n",
      "Loss: 929.3850159941599\n",
      "Training step:  5737\n",
      "Loss: 929.3843476426903\n",
      "Training step:  5738\n",
      "Loss: 929.3836580120069\n",
      "Training step:  5739\n",
      "Loss: 929.3829924441288\n",
      "Training step:  5740\n",
      "Loss: 929.3823019828072\n",
      "Training step:  5741\n",
      "Loss: 929.3816227089201\n",
      "Training step:  5742\n",
      "Loss: 929.3809514125803\n",
      "Training step:  5743\n",
      "Loss: 929.380270443496\n",
      "Training step:  5744\n",
      "Loss: 929.3795926952748\n",
      "Training step:  5745\n",
      "Loss: 929.3789195352368\n",
      "Training step:  5746\n",
      "Loss: 929.3782401038666\n",
      "Training step:  5747\n",
      "Loss: 929.377572053621\n",
      "Training step:  5748\n",
      "Loss: 929.3768909306956\n",
      "Training step:  5749\n",
      "Loss: 929.376226944992\n",
      "Training step:  5750\n",
      "Loss: 929.3755448815461\n",
      "Training step:  5751\n",
      "Loss: 929.3748831699447\n",
      "Training step:  5752\n",
      "Loss: 929.3742009519195\n",
      "Training step:  5753\n",
      "Loss: 929.3735396380259\n",
      "Training step:  5754\n",
      "Loss: 929.3728585211605\n",
      "Training step:  5755\n",
      "Loss: 929.3722001651385\n",
      "Training step:  5756\n",
      "Loss: 929.3715187203769\n",
      "Training step:  5757\n",
      "Loss: 929.3708487720506\n",
      "Training step:  5758\n",
      "Loss: 929.3701813642715\n",
      "Training step:  5759\n",
      "Loss: 929.3695123440216\n",
      "Training step:  5760\n",
      "Loss: 929.3688414298798\n",
      "Training step:  5761\n",
      "Loss: 929.3681788963615\n",
      "Training step:  5762\n",
      "Loss: 929.3675053775388\n",
      "Training step:  5763\n",
      "Loss: 929.3668476481727\n",
      "Training step:  5764\n",
      "Loss: 929.3661732533275\n",
      "Training step:  5765\n",
      "Loss: 929.365518237056\n",
      "Training step:  5766\n",
      "Loss: 929.3648432479296\n",
      "Training step:  5767\n",
      "Loss: 929.3641901396201\n",
      "Training step:  5768\n",
      "Loss: 929.3635152989973\n",
      "Training step:  5769\n",
      "Loss: 929.3628616076024\n",
      "Training step:  5770\n",
      "Loss: 929.3621891674603\n",
      "Training step:  5771\n",
      "Loss: 929.3615382764322\n",
      "Training step:  5772\n",
      "Loss: 929.3608652574204\n",
      "Training step:  5773\n",
      "Loss: 929.3602027098091\n",
      "Training step:  5774\n",
      "Loss: 929.359544757118\n",
      "Training step:  5775\n",
      "Loss: 929.3588856022\n",
      "Training step:  5776\n",
      "Loss: 929.3582213302516\n",
      "Training step:  5777\n",
      "Loss: 929.357567848763\n",
      "Training step:  5778\n",
      "Loss: 929.3569014314254\n",
      "Training step:  5779\n",
      "Loss: 929.3562524801123\n",
      "Training step:  5780\n",
      "Loss: 929.3555851658228\n",
      "Training step:  5781\n",
      "Loss: 929.3549376196228\n",
      "Training step:  5782\n",
      "Loss: 929.3542709786849\n",
      "Training step:  5783\n",
      "Loss: 929.3536257340704\n",
      "Training step:  5784\n",
      "Loss: 929.3529588088929\n",
      "Training step:  5785\n",
      "Loss: 929.3523066597221\n",
      "Training step:  5786\n",
      "Loss: 929.3516471880158\n",
      "Training step:  5787\n",
      "Loss: 929.3509987321015\n",
      "Training step:  5788\n",
      "Loss: 929.350337590264\n",
      "Training step:  5789\n",
      "Loss: 929.3496931233075\n",
      "Training step:  5790\n",
      "Loss: 929.3490311217291\n",
      "Training step:  5791\n",
      "Loss: 929.3483892717821\n",
      "Training step:  5792\n",
      "Loss: 929.3477267180004\n",
      "Training step:  5793\n",
      "Loss: 929.3470850734948\n",
      "Training step:  5794\n",
      "Loss: 929.3464240734477\n",
      "Training step:  5795\n",
      "Loss: 929.34578403697\n",
      "Training step:  5796\n",
      "Loss: 929.345123598364\n",
      "Training step:  5797\n",
      "Loss: 929.3444816301964\n",
      "Training step:  5798\n",
      "Loss: 929.3438242767922\n",
      "Training step:  5799\n",
      "Loss: 929.343185821728\n",
      "Training step:  5800\n",
      "Loss: 929.3425276290141\n",
      "Training step:  5801\n",
      "Loss: 929.3418908699064\n",
      "Training step:  5802\n",
      "Loss: 929.3412329675358\n",
      "Training step:  5803\n",
      "Loss: 929.3405875293691\n",
      "Training step:  5804\n",
      "Loss: 929.3399390537908\n",
      "Training step:  5805\n",
      "Loss: 929.3392968996363\n",
      "Training step:  5806\n",
      "Loss: 929.3386460643557\n",
      "Training step:  5807\n",
      "Loss: 929.3380084531835\n",
      "Training step:  5808\n",
      "Loss: 929.3373565207547\n",
      "Training step:  5809\n",
      "Loss: 929.3367221996829\n",
      "Training step:  5810\n",
      "Loss: 929.3360692261516\n",
      "Training step:  5811\n",
      "Loss: 929.3354374067094\n",
      "Training step:  5812\n",
      "Loss: 929.3347841795211\n",
      "Training step:  5813\n",
      "Loss: 929.3341421329874\n",
      "Training step:  5814\n",
      "Loss: 929.3335009266298\n",
      "Training step:  5815\n",
      "Loss: 929.3328605727523\n",
      "Training step:  5816\n",
      "Loss: 929.3322163535777\n",
      "Training step:  5817\n",
      "Loss: 929.3315814272354\n",
      "Training step:  5818\n",
      "Loss: 929.3309350975786\n",
      "Training step:  5819\n",
      "Loss: 929.330304617821\n",
      "Training step:  5820\n",
      "Loss: 929.32965746988\n",
      "Training step:  5821\n",
      "Loss: 929.3290290780847\n",
      "Training step:  5822\n",
      "Loss: 929.3283818390107\n",
      "Training step:  5823\n",
      "Loss: 929.3277545060496\n",
      "Training step:  5824\n",
      "Loss: 929.3271081929458\n",
      "Training step:  5825\n",
      "Loss: 929.3264817994614\n",
      "Training step:  5826\n",
      "Loss: 929.3258364593231\n",
      "Training step:  5827\n",
      "Loss: 929.3252102172991\n",
      "Training step:  5828\n",
      "Loss: 929.3245664095853\n",
      "Training step:  5829\n",
      "Loss: 929.3239428020238\n",
      "Training step:  5830\n",
      "Loss: 929.3232985017709\n",
      "Training step:  5831\n",
      "Loss: 929.3226629440874\n",
      "Training step:  5832\n",
      "Loss: 929.3220336541078\n",
      "Training step:  5833\n",
      "Loss: 929.3213994494013\n",
      "Training step:  5834\n",
      "Loss: 929.3207653199488\n",
      "Training step:  5835\n",
      "Loss: 929.3201374001885\n",
      "Training step:  5836\n",
      "Loss: 929.3195009340983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  5837\n",
      "Loss: 929.3188759466454\n",
      "Training step:  5838\n",
      "Loss: 929.3182399789107\n",
      "Training step:  5839\n",
      "Loss: 929.3176179715473\n",
      "Training step:  5840\n",
      "Loss: 929.3169812367444\n",
      "Training step:  5841\n",
      "Loss: 929.3163616943702\n",
      "Training step:  5842\n",
      "Loss: 929.3157244797881\n",
      "Training step:  5843\n",
      "Loss: 929.3151059815845\n",
      "Training step:  5844\n",
      "Loss: 929.3144689993628\n",
      "Training step:  5845\n",
      "Loss: 929.3138501674514\n",
      "Training step:  5846\n",
      "Loss: 929.313215825025\n",
      "Training step:  5847\n",
      "Loss: 929.3125995805403\n",
      "Training step:  5848\n",
      "Loss: 929.311964772599\n",
      "Training step:  5849\n",
      "Loss: 929.3113433709292\n",
      "Training step:  5850\n",
      "Loss: 929.3107144785351\n",
      "Training step:  5851\n",
      "Loss: 929.3100963671284\n",
      "Training step:  5852\n",
      "Loss: 929.3094665011513\n",
      "Training step:  5853\n",
      "Loss: 929.3088515025865\n",
      "Training step:  5854\n",
      "Loss: 929.3082206899586\n",
      "Training step:  5855\n",
      "Loss: 929.3076083322678\n",
      "Training step:  5856\n",
      "Loss: 929.3069770593571\n",
      "Training step:  5857\n",
      "Loss: 929.3063590368536\n",
      "Training step:  5858\n",
      "Loss: 929.3057338360469\n",
      "Training step:  5859\n",
      "Loss: 929.3051194358845\n",
      "Training step:  5860\n",
      "Loss: 929.3044927696155\n",
      "Training step:  5861\n",
      "Loss: 929.3038817002599\n",
      "Training step:  5862\n",
      "Loss: 929.3032545840257\n",
      "Training step:  5863\n",
      "Loss: 929.3026459055767\n",
      "Training step:  5864\n",
      "Loss: 929.3020183411306\n",
      "Training step:  5865\n",
      "Loss: 929.3014042945401\n",
      "Training step:  5866\n",
      "Loss: 929.3007826971691\n",
      "Training step:  5867\n",
      "Loss: 929.3001720603074\n",
      "Training step:  5868\n",
      "Loss: 929.2995490160636\n",
      "Training step:  5869\n",
      "Loss: 929.2989416757209\n",
      "Training step:  5870\n",
      "Loss: 929.2983181856398\n",
      "Training step:  5871\n",
      "Loss: 929.297713213146\n",
      "Training step:  5872\n",
      "Loss: 929.2970892857747\n",
      "Training step:  5873\n",
      "Loss: 929.2964788216187\n",
      "Training step:  5874\n",
      "Loss: 929.2958608502275\n",
      "Training step:  5875\n",
      "Loss: 929.2952539042655\n",
      "Training step:  5876\n",
      "Loss: 929.2946349944668\n",
      "Training step:  5877\n",
      "Loss: 929.2940310678725\n",
      "Training step:  5878\n",
      "Loss: 929.2934114658912\n",
      "Training step:  5879\n",
      "Loss: 929.2928098874092\n",
      "Training step:  5880\n",
      "Loss: 929.2921898584696\n",
      "Training step:  5881\n",
      "Loss: 929.2915880510277\n",
      "Training step:  5882\n",
      "Loss: 929.2909699114613\n",
      "Training step:  5883\n",
      "Loss: 929.2903705392825\n",
      "Training step:  5884\n",
      "Loss: 929.2897519822371\n",
      "Training step:  5885\n",
      "Loss: 929.2891436696083\n",
      "Training step:  5886\n",
      "Loss: 929.2885357581716\n",
      "Training step:  5887\n",
      "Loss: 929.2879289957876\n",
      "Training step:  5888\n",
      "Loss: 929.2873184367338\n",
      "Training step:  5889\n",
      "Loss: 929.2867165970838\n",
      "Training step:  5890\n",
      "Loss: 929.2861041893794\n",
      "Training step:  5891\n",
      "Loss: 929.2855063915548\n",
      "Training step:  5892\n",
      "Loss: 929.2848933002539\n",
      "Training step:  5893\n",
      "Loss: 929.2842967483855\n",
      "Training step:  5894\n",
      "Loss: 929.2836842984402\n",
      "Training step:  5895\n",
      "Loss: 929.2830896442613\n",
      "Training step:  5896\n",
      "Loss: 929.2824771611946\n",
      "Training step:  5897\n",
      "Loss: 929.2818822039637\n",
      "Training step:  5898\n",
      "Loss: 929.2812716682081\n",
      "Training step:  5899\n",
      "Loss: 929.280679098525\n",
      "Training step:  5900\n",
      "Loss: 929.2800681658899\n",
      "Training step:  5901\n",
      "Loss: 929.2794680435244\n",
      "Training step:  5902\n",
      "Loss: 929.2788657756963\n",
      "Training step:  5903\n",
      "Loss: 929.2782681060916\n",
      "Training step:  5904\n",
      "Loss: 929.2776638983206\n",
      "Training step:  5905\n",
      "Loss: 929.277070220267\n",
      "Training step:  5906\n",
      "Loss: 929.276465128457\n",
      "Training step:  5907\n",
      "Loss: 929.275874357723\n",
      "Training step:  5908\n",
      "Loss: 929.275268613811\n",
      "Training step:  5909\n",
      "Loss: 929.2746801074857\n",
      "Training step:  5910\n",
      "Loss: 929.274073974784\n",
      "Training step:  5911\n",
      "Loss: 929.2734842558134\n",
      "Training step:  5912\n",
      "Loss: 929.2728809284068\n",
      "Training step:  5913\n",
      "Loss: 929.2722935746809\n",
      "Training step:  5914\n",
      "Loss: 929.2716898694482\n",
      "Training step:  5915\n",
      "Loss: 929.2711032339943\n",
      "Training step:  5916\n",
      "Loss: 929.2705004197436\n",
      "Training step:  5917\n",
      "Loss: 929.2699146704983\n",
      "Training step:  5918\n",
      "Loss: 929.2693127448446\n",
      "Training step:  5919\n",
      "Loss: 929.2687281059883\n",
      "Training step:  5920\n",
      "Loss: 929.2681268423739\n",
      "Training step:  5921\n",
      "Loss: 929.2675383288807\n",
      "Training step:  5922\n",
      "Loss: 929.2669416347578\n",
      "Training step:  5923\n",
      "Loss: 929.2663564886059\n",
      "Training step:  5924\n",
      "Loss: 929.2657589209217\n",
      "Training step:  5925\n",
      "Loss: 929.2651763392162\n",
      "Training step:  5926\n",
      "Loss: 929.2645784090805\n",
      "Training step:  5927\n",
      "Loss: 929.2639980414616\n",
      "Training step:  5928\n",
      "Loss: 929.2633997449448\n",
      "Training step:  5929\n",
      "Loss: 929.26281217147\n",
      "Training step:  5930\n",
      "Loss: 929.2622217770817\n",
      "Training step:  5931\n",
      "Loss: 929.2616371109185\n",
      "Training step:  5932\n",
      "Loss: 929.2610448503776\n",
      "Training step:  5933\n",
      "Loss: 929.2604640215218\n",
      "Training step:  5934\n",
      "Loss: 929.2598709186086\n",
      "Training step:  5935\n",
      "Loss: 929.2592926207789\n",
      "Training step:  5936\n",
      "Loss: 929.2586991649246\n",
      "Training step:  5937\n",
      "Loss: 929.2581230549364\n",
      "Training step:  5938\n",
      "Loss: 929.2575292445623\n",
      "Training step:  5939\n",
      "Loss: 929.2569450695321\n",
      "Training step:  5940\n",
      "Loss: 929.2563593143935\n",
      "Training step:  5941\n",
      "Loss: 929.2557782392404\n",
      "Training step:  5942\n",
      "Loss: 929.2551907757831\n",
      "Training step:  5943\n",
      "Loss: 929.2546137668659\n",
      "Training step:  5944\n",
      "Loss: 929.2540256098947\n",
      "Training step:  5945\n",
      "Loss: 929.2534512484219\n",
      "Training step:  5946\n",
      "Loss: 929.2528625009672\n",
      "Training step:  5947\n",
      "Loss: 929.2522887725122\n",
      "Training step:  5948\n",
      "Loss: 929.2517012422799\n",
      "Training step:  5949\n",
      "Loss: 929.2511295962296\n",
      "Training step:  5950\n",
      "Loss: 929.2505417245195\n",
      "Training step:  5951\n",
      "Loss: 929.2499659056564\n",
      "Training step:  5952\n",
      "Loss: 929.2493829462454\n",
      "Training step:  5953\n",
      "Loss: 929.2488101117472\n",
      "Training step:  5954\n",
      "Loss: 929.2482263600385\n",
      "Training step:  5955\n",
      "Loss: 929.2476559975368\n",
      "Training step:  5956\n",
      "Loss: 929.2470719166988\n",
      "Training step:  5957\n",
      "Loss: 929.246503691357\n",
      "Training step:  5958\n",
      "Loss: 929.24591927827\n",
      "Training step:  5959\n",
      "Loss: 929.2453488047344\n",
      "Training step:  5960\n",
      "Loss: 929.2447678450992\n",
      "Training step:  5961\n",
      "Loss: 929.2441998115363\n",
      "Training step:  5962\n",
      "Loss: 929.2436183677073\n",
      "Training step:  5963\n",
      "Loss: 929.2430526450205\n",
      "Training step:  5964\n",
      "Loss: 929.2424708793627\n",
      "Training step:  5965\n",
      "Loss: 929.241901325578\n",
      "Training step:  5966\n",
      "Loss: 929.2413236879312\n",
      "Training step:  5967\n",
      "Loss: 929.2407576115656\n",
      "Training step:  5968\n",
      "Loss: 929.2401792686995\n",
      "Training step:  5969\n",
      "Loss: 929.2396154962404\n",
      "Training step:  5970\n",
      "Loss: 929.2390368395907\n",
      "Training step:  5971\n",
      "Loss: 929.238474823575\n",
      "Training step:  5972\n",
      "Loss: 929.2378961842747\n",
      "Training step:  5973\n",
      "Loss: 929.2373268722864\n",
      "Training step:  5974\n",
      "Loss: 929.2367564561117\n",
      "Training step:  5975\n",
      "Loss: 929.2361894704611\n",
      "Training step:  5976\n",
      "Loss: 929.2356171509558\n",
      "Training step:  5977\n",
      "Loss: 929.2350540764822\n",
      "Training step:  5978\n",
      "Loss: 929.2344810283877\n",
      "Training step:  5979\n",
      "Loss: 929.2339203577493\n",
      "Training step:  5980\n",
      "Loss: 929.2333468314229\n",
      "Training step:  5981\n",
      "Loss: 929.2327884220133\n",
      "Training step:  5982\n",
      "Loss: 929.2322145891555\n",
      "Training step:  5983\n",
      "Loss: 929.2316564635503\n",
      "Training step:  5984\n",
      "Loss: 929.2310840845745\n",
      "Training step:  5985\n",
      "Loss: 929.2305273091913\n",
      "Training step:  5986\n",
      "Loss: 929.2299552573497\n",
      "Training step:  5987\n",
      "Loss: 929.2293943557528\n",
      "Training step:  5988\n",
      "Loss: 929.2288268515831\n",
      "Training step:  5989\n",
      "Loss: 929.2282691089043\n",
      "Training step:  5990\n",
      "Loss: 929.2277008807151\n",
      "Training step:  5991\n",
      "Loss: 929.2271455030107\n",
      "Training step:  5992\n",
      "Loss: 929.2265768128605\n",
      "Training step:  5993\n",
      "Loss: 929.2260236632828\n",
      "Training step:  5994\n",
      "Loss: 929.2254546798149\n",
      "Training step:  5995\n",
      "Loss: 929.2248966132483\n",
      "Training step:  5996\n",
      "Loss: 929.2243331685476\n",
      "Training step:  5997\n",
      "Loss: 929.2237779202281\n",
      "Training step:  5998\n",
      "Loss: 929.2232129801403\n",
      "Training step:  5999\n",
      "Loss: 929.2226609881712\n",
      "Training step:  6000\n",
      "Loss: 929.2220957595608\n",
      "Training step:  6001\n",
      "Loss: 929.2215454687009\n",
      "Training step:  6002\n",
      "Loss: 929.2209802742034\n",
      "Training step:  6003\n",
      "Loss: 929.2204308266345\n",
      "Training step:  6004\n",
      "Loss: 929.2198663115815\n",
      "Training step:  6005\n",
      "Loss: 929.2193157431717\n",
      "Training step:  6006\n",
      "Loss: 929.2187540225804\n",
      "Training step:  6007\n",
      "Loss: 929.2182054600809\n",
      "Training step:  6008\n",
      "Loss: 929.2176433018834\n",
      "Training step:  6009\n",
      "Loss: 929.2170969244287\n",
      "Training step:  6010\n",
      "Loss: 929.2165344920094\n",
      "Training step:  6011\n",
      "Loss: 929.2159792234249\n",
      "Training step:  6012\n",
      "Loss: 929.2154278777238\n",
      "Training step:  6013\n",
      "Loss: 929.2148732633713\n",
      "Training step:  6014\n",
      "Loss: 929.2143184420607\n",
      "Training step:  6015\n",
      "Loss: 929.2137695472784\n",
      "Training step:  6016\n",
      "Loss: 929.2132130209455\n",
      "Training step:  6017\n",
      "Loss: 929.2126664459628\n",
      "Training step:  6018\n",
      "Loss: 929.2121103906652\n",
      "Training step:  6019\n",
      "Loss: 929.2115659713695\n",
      "Training step:  6020\n",
      "Loss: 929.2110096492131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  6021\n",
      "Loss: 929.2104672115579\n",
      "Training step:  6022\n",
      "Loss: 929.2099106247882\n",
      "Training step:  6023\n",
      "Loss: 929.209367932852\n",
      "Training step:  6024\n",
      "Loss: 929.2088131347019\n",
      "Training step:  6025\n",
      "Loss: 929.208272497355\n",
      "Training step:  6026\n",
      "Loss: 929.2077174374622\n",
      "Training step:  6027\n",
      "Loss: 929.2071727287215\n",
      "Training step:  6028\n",
      "Loss: 929.2066222074769\n",
      "Training step:  6029\n",
      "Loss: 929.2060804758218\n",
      "Training step:  6030\n",
      "Loss: 929.2055294043345\n",
      "Training step:  6031\n",
      "Loss: 929.2049898147801\n",
      "Training step:  6032\n",
      "Loss: 929.2044384932807\n",
      "Training step:  6033\n",
      "Loss: 929.2039008574724\n",
      "Training step:  6034\n",
      "Loss: 929.2033492832214\n",
      "Training step:  6035\n",
      "Loss: 929.2028119319722\n",
      "Training step:  6036\n",
      "Loss: 929.2022615725981\n",
      "Training step:  6037\n",
      "Loss: 929.2017256624401\n",
      "Training step:  6038\n",
      "Loss: 929.2011756367625\n",
      "Training step:  6039\n",
      "Loss: 929.200635229582\n",
      "Training step:  6040\n",
      "Loss: 929.2000903876592\n",
      "Training step:  6041\n",
      "Loss: 929.1995525341471\n",
      "Training step:  6042\n",
      "Loss: 929.1990063291289\n",
      "Training step:  6043\n",
      "Loss: 929.1984715545801\n",
      "Training step:  6044\n",
      "Loss: 929.1979249597947\n",
      "Training step:  6045\n",
      "Loss: 929.1973922784471\n",
      "Training step:  6046\n",
      "Loss: 929.1968454419895\n",
      "Training step:  6047\n",
      "Loss: 929.1963103262576\n",
      "Training step:  6048\n",
      "Loss: 929.1957659160363\n",
      "Training step:  6049\n",
      "Loss: 929.1952343128829\n",
      "Training step:  6050\n",
      "Loss: 929.1946894072805\n",
      "Training step:  6051\n",
      "Loss: 929.1941588703098\n",
      "Training step:  6052\n",
      "Loss: 929.1936146149444\n",
      "Training step:  6053\n",
      "Loss: 929.1930829033682\n",
      "Training step:  6054\n",
      "Loss: 929.192540996815\n",
      "Training step:  6055\n",
      "Loss: 929.1920116032243\n",
      "Training step:  6056\n",
      "Loss: 929.1914693179319\n",
      "Training step:  6057\n",
      "Loss: 929.1909413886596\n",
      "Training step:  6058\n",
      "Loss: 929.1903994377219\n",
      "Training step:  6059\n",
      "Loss: 929.1898677151489\n",
      "Training step:  6060\n",
      "Loss: 929.189329959227\n",
      "Training step:  6061\n",
      "Loss: 929.1888011557643\n",
      "Training step:  6062\n",
      "Loss: 929.1882624459365\n",
      "Training step:  6063\n",
      "Loss: 929.1877362109022\n",
      "Training step:  6064\n",
      "Loss: 929.1871972740819\n",
      "Training step:  6065\n",
      "Loss: 929.1866729194668\n",
      "Training step:  6066\n",
      "Loss: 929.1861337612785\n",
      "Training step:  6067\n",
      "Loss: 929.1856012847867\n",
      "Training step:  6068\n",
      "Loss: 929.1850728036798\n",
      "Training step:  6069\n",
      "Loss: 929.1845409513044\n",
      "Training step:  6070\n",
      "Loss: 929.1840093661067\n",
      "Training step:  6071\n",
      "Loss: 929.1834821661039\n",
      "Training step:  6072\n",
      "Loss: 929.1829489328182\n",
      "Training step:  6073\n",
      "Loss: 929.1824251638701\n",
      "Training step:  6074\n",
      "Loss: 929.181891543522\n",
      "Training step:  6075\n",
      "Loss: 929.1813693452804\n",
      "Training step:  6076\n",
      "Loss: 929.1808357959625\n",
      "Training step:  6077\n",
      "Loss: 929.1803146453325\n",
      "Training step:  6078\n",
      "Loss: 929.1797816834544\n",
      "Training step:  6079\n",
      "Loss: 929.1792623603953\n",
      "Training step:  6080\n",
      "Loss: 929.1787291893183\n",
      "Training step:  6081\n",
      "Loss: 929.1782039996805\n",
      "Training step:  6082\n",
      "Loss: 929.1776776588131\n",
      "Training step:  6083\n",
      "Loss: 929.1771545224307\n",
      "Training step:  6084\n",
      "Loss: 929.1766266055972\n",
      "Training step:  6085\n",
      "Loss: 929.1761068510677\n",
      "Training step:  6086\n",
      "Loss: 929.1755785915893\n",
      "Training step:  6087\n",
      "Loss: 929.175060679262\n",
      "Training step:  6088\n",
      "Loss: 929.1745322154306\n",
      "Training step:  6089\n",
      "Loss: 929.1740161326768\n",
      "Training step:  6090\n",
      "Loss: 929.1734874677333\n",
      "Training step:  6091\n",
      "Loss: 929.1729717332644\n",
      "Training step:  6092\n",
      "Loss: 929.1724443360325\n",
      "Training step:  6093\n",
      "Loss: 929.1719298102905\n",
      "Training step:  6094\n",
      "Loss: 929.1714026362017\n",
      "Training step:  6095\n",
      "Loss: 929.1708873907785\n",
      "Training step:  6096\n",
      "Loss: 929.1703624339162\n",
      "Training step:  6097\n",
      "Loss: 929.1698490524839\n",
      "Training step:  6098\n",
      "Loss: 929.1693237631644\n",
      "Training step:  6099\n",
      "Loss: 929.1688117811464\n",
      "Training step:  6100\n",
      "Loss: 929.1682868293911\n",
      "Training step:  6101\n",
      "Loss: 929.1677721332101\n",
      "Training step:  6102\n",
      "Loss: 929.1672506345342\n",
      "Training step:  6103\n",
      "Loss: 929.1667384955028\n",
      "Training step:  6104\n",
      "Loss: 929.1662164247133\n",
      "Training step:  6105\n",
      "Loss: 929.1657063313281\n",
      "Training step:  6106\n",
      "Loss: 929.1651840750212\n",
      "Training step:  6107\n",
      "Loss: 929.1646752174053\n",
      "Training step:  6108\n",
      "Loss: 929.1641533004456\n",
      "Training step:  6109\n",
      "Loss: 929.163639348626\n",
      "Training step:  6110\n",
      "Loss: 929.1631222666563\n",
      "Training step:  6111\n",
      "Loss: 929.1626112566325\n",
      "Training step:  6112\n",
      "Loss: 929.1620932849247\n",
      "Training step:  6113\n",
      "Loss: 929.1615852755624\n",
      "Training step:  6114\n",
      "Loss: 929.1610668344965\n",
      "Training step:  6115\n",
      "Loss: 929.160559818676\n",
      "Training step:  6116\n",
      "Loss: 929.1600420029134\n",
      "Training step:  6117\n",
      "Loss: 929.1595368702974\n",
      "Training step:  6118\n",
      "Loss: 929.1590188789526\n",
      "Training step:  6119\n",
      "Loss: 929.1585089771485\n",
      "Training step:  6120\n",
      "Loss: 929.1579963919276\n",
      "Training step:  6121\n",
      "Loss: 929.1574887364138\n",
      "Training step:  6122\n",
      "Loss: 929.1569748262176\n",
      "Training step:  6123\n",
      "Loss: 929.1564701757807\n",
      "Training step:  6124\n",
      "Loss: 929.1559559775868\n",
      "Training step:  6125\n",
      "Loss: 929.1554532300479\n",
      "Training step:  6126\n",
      "Loss: 929.1549388595216\n",
      "Training step:  6127\n",
      "Loss: 929.1544370958432\n",
      "Training step:  6128\n",
      "Loss: 929.1539233015993\n",
      "Training step:  6129\n",
      "Loss: 929.1534227309803\n",
      "Training step:  6130\n",
      "Loss: 929.1529092775402\n",
      "Training step:  6131\n",
      "Loss: 929.1524044663923\n",
      "Training step:  6132\n",
      "Loss: 929.151895848445\n",
      "Training step:  6133\n",
      "Loss: 929.151393412447\n",
      "Training step:  6134\n",
      "Loss: 929.1508836678117\n",
      "Training step:  6135\n",
      "Loss: 929.1503839616649\n",
      "Training step:  6136\n",
      "Loss: 929.1498739325965\n",
      "Training step:  6137\n",
      "Loss: 929.1493761016225\n",
      "Training step:  6138\n",
      "Loss: 929.1488659121324\n",
      "Training step:  6139\n",
      "Loss: 929.1483675595863\n",
      "Training step:  6140\n",
      "Loss: 929.1478592304159\n",
      "Training step:  6141\n",
      "Loss: 929.1473627159013\n",
      "Training step:  6142\n",
      "Loss: 929.146854233047\n",
      "Training step:  6143\n",
      "Loss: 929.1463542462291\n",
      "Training step:  6144\n",
      "Loss: 929.1458497734668\n",
      "Training step:  6145\n",
      "Loss: 929.1453522651337\n",
      "Training step:  6146\n",
      "Loss: 929.1448470114607\n",
      "Training step:  6147\n",
      "Loss: 929.1443518147712\n",
      "Training step:  6148\n",
      "Loss: 929.1438464113149\n",
      "Training step:  6149\n",
      "Loss: 929.1433529200431\n",
      "Training step:  6150\n",
      "Loss: 929.1428473653574\n",
      "Training step:  6151\n",
      "Loss: 929.1423535625026\n",
      "Training step:  6152\n",
      "Loss: 929.1418496214625\n",
      "Training step:  6153\n",
      "Loss: 929.1413576521429\n",
      "Training step:  6154\n",
      "Loss: 929.1408535648385\n",
      "Training step:  6155\n",
      "Loss: 929.1403582998277\n",
      "Training step:  6156\n",
      "Loss: 929.1398580046396\n",
      "Training step:  6157\n",
      "Loss: 929.1393652674174\n",
      "Training step:  6158\n",
      "Loss: 929.1388645219396\n",
      "Training step:  6159\n",
      "Loss: 929.1383737089378\n",
      "Training step:  6160\n",
      "Loss: 929.1378726913363\n",
      "Training step:  6161\n",
      "Loss: 929.1373837006091\n",
      "Training step:  6162\n",
      "Loss: 929.1368825400501\n",
      "Training step:  6163\n",
      "Loss: 929.1363891697385\n",
      "Training step:  6164\n",
      "Loss: 929.1358925186078\n",
      "Training step:  6165\n",
      "Loss: 929.1354019141862\n",
      "Training step:  6166\n",
      "Loss: 929.1349041604359\n",
      "Training step:  6167\n",
      "Loss: 929.1344153275326\n",
      "Training step:  6168\n",
      "Loss: 929.1339182027517\n",
      "Training step:  6169\n",
      "Loss: 929.133431132409\n",
      "Training step:  6170\n",
      "Loss: 929.1329338763863\n",
      "Training step:  6171\n",
      "Loss: 929.1324484682119\n",
      "Training step:  6172\n",
      "Loss: 929.1319510778791\n",
      "Training step:  6173\n",
      "Loss: 929.1314617991073\n",
      "Training step:  6174\n",
      "Loss: 929.1309689628422\n",
      "Training step:  6175\n",
      "Loss: 929.1304818313861\n",
      "Training step:  6176\n",
      "Loss: 929.1299879715532\n",
      "Training step:  6177\n",
      "Loss: 929.1295034294093\n",
      "Training step:  6178\n",
      "Loss: 929.1290094511885\n",
      "Training step:  6179\n",
      "Loss: 929.12852655636\n",
      "Training step:  6180\n",
      "Loss: 929.12803244928\n",
      "Training step:  6181\n",
      "Loss: 929.1275500119125\n",
      "Training step:  6182\n",
      "Loss: 929.1270568041941\n",
      "Training step:  6183\n",
      "Loss: 929.1265756167293\n",
      "Training step:  6184\n",
      "Loss: 929.1260827503183\n",
      "Training step:  6185\n",
      "Loss: 929.1256002007354\n",
      "Training step:  6186\n",
      "Loss: 929.1251097600434\n",
      "Training step:  6187\n",
      "Loss: 929.124629087457\n",
      "Training step:  6188\n",
      "Loss: 929.1241384135559\n",
      "Training step:  6189\n",
      "Loss: 929.1236595036361\n",
      "Training step:  6190\n",
      "Loss: 929.1231687099357\n",
      "Training step:  6191\n",
      "Loss: 929.1226851075552\n",
      "Training step:  6192\n",
      "Loss: 929.1221997056772\n",
      "Training step:  6193\n",
      "Loss: 929.1217181596992\n",
      "Training step:  6194\n",
      "Loss: 929.1212314939688\n",
      "Training step:  6195\n",
      "Loss: 929.1207528716147\n",
      "Training step:  6196\n",
      "Loss: 929.1202658449694\n",
      "Training step:  6197\n",
      "Loss: 929.1197889701696\n",
      "Training step:  6198\n",
      "Loss: 929.1193018274467\n",
      "Training step:  6199\n",
      "Loss: 929.1188261332586\n",
      "Training step:  6200\n",
      "Loss: 929.1183393057916\n",
      "Training step:  6201\n",
      "Loss: 929.1178636995385\n",
      "Training step:  6202\n",
      "Loss: 929.117378108782\n",
      "Training step:  6203\n",
      "Loss: 929.1169041803562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  6204\n",
      "Loss: 929.1164184772354\n",
      "Training step:  6205\n",
      "Loss: 929.1159378112208\n",
      "Training step:  6206\n",
      "Loss: 929.1154613856652\n",
      "Training step:  6207\n",
      "Loss: 929.1149800955637\n",
      "Training step:  6208\n",
      "Loss: 929.1145004713958\n",
      "Training step:  6209\n",
      "Loss: 929.1140229988858\n",
      "Training step:  6210\n",
      "Loss: 929.1135420906456\n",
      "Training step:  6211\n",
      "Loss: 929.1130674023027\n",
      "Training step:  6212\n",
      "Loss: 929.1125856695434\n",
      "Training step:  6213\n",
      "Loss: 929.1121130731748\n",
      "Training step:  6214\n",
      "Loss: 929.1116318215481\n",
      "Training step:  6215\n",
      "Loss: 929.1111601303438\n",
      "Training step:  6216\n",
      "Loss: 929.1106793265776\n",
      "Training step:  6217\n",
      "Loss: 929.1102080873552\n",
      "Training step:  6218\n",
      "Loss: 929.1097278892732\n",
      "Training step:  6219\n",
      "Loss: 929.109257810726\n",
      "Training step:  6220\n",
      "Loss: 929.1087781386635\n",
      "Training step:  6221\n",
      "Loss: 929.1083092700275\n",
      "Training step:  6222\n",
      "Loss: 929.1078299185373\n",
      "Training step:  6223\n",
      "Loss: 929.1073592487915\n",
      "Training step:  6224\n",
      "Loss: 929.1068822796472\n",
      "Training step:  6225\n",
      "Loss: 929.1064139456954\n",
      "Training step:  6226\n",
      "Loss: 929.1059365820403\n",
      "Training step:  6227\n",
      "Loss: 929.1054698590307\n",
      "Training step:  6228\n",
      "Loss: 929.104992549604\n",
      "Training step:  6229\n",
      "Loss: 929.1045208907885\n",
      "Training step:  6230\n",
      "Loss: 929.1040503956057\n",
      "Training step:  6231\n",
      "Loss: 929.1035797162956\n",
      "Training step:  6232\n",
      "Loss: 929.103107294518\n",
      "Training step:  6233\n",
      "Loss: 929.102640081209\n",
      "Training step:  6234\n",
      "Loss: 929.1021668023719\n",
      "Training step:  6235\n",
      "Loss: 929.1017019346609\n",
      "Training step:  6236\n",
      "Loss: 929.1012289681975\n",
      "Training step:  6237\n",
      "Loss: 929.1007656721\n",
      "Training step:  6238\n",
      "Loss: 929.1002935562518\n",
      "Training step:  6239\n",
      "Loss: 929.0998313487853\n",
      "Training step:  6240\n",
      "Loss: 929.0993592870033\n",
      "Training step:  6241\n",
      "Loss: 929.0988926045105\n",
      "Training step:  6242\n",
      "Loss: 929.0984254953144\n",
      "Training step:  6243\n",
      "Loss: 929.0979609651961\n",
      "Training step:  6244\n",
      "Loss: 929.097492500749\n",
      "Training step:  6245\n",
      "Loss: 929.0970307520298\n",
      "Training step:  6246\n",
      "Loss: 929.0965622404276\n",
      "Training step:  6247\n",
      "Loss: 929.0961020160407\n",
      "Training step:  6248\n",
      "Loss: 929.0956334206909\n",
      "Training step:  6249\n",
      "Loss: 929.0951744881348\n",
      "Training step:  6250\n",
      "Loss: 929.0947060316495\n",
      "Training step:  6251\n",
      "Loss: 929.0942482382893\n",
      "Training step:  6252\n",
      "Loss: 929.093780061398\n",
      "Training step:  6253\n",
      "Loss: 929.0933209441192\n",
      "Training step:  6254\n",
      "Loss: 929.0928552003173\n",
      "Training step:  6255\n",
      "Loss: 929.0923977441793\n",
      "Training step:  6256\n",
      "Loss: 929.0919319271275\n",
      "Training step:  6257\n",
      "Loss: 929.0914759765798\n",
      "Training step:  6258\n",
      "Loss: 929.0910100832828\n",
      "Training step:  6259\n",
      "Loss: 929.0905534025521\n",
      "Training step:  6260\n",
      "Loss: 929.0900895801923\n",
      "Training step:  6261\n",
      "Loss: 929.0896343347747\n",
      "Training step:  6262\n",
      "Loss: 929.08917032727\n",
      "Training step:  6263\n",
      "Loss: 929.0887166975508\n",
      "Training step:  6264\n",
      "Loss: 929.0882526183644\n",
      "Training step:  6265\n",
      "Loss: 929.0877947351474\n",
      "Training step:  6266\n",
      "Loss: 929.0873356911259\n",
      "Training step:  6267\n",
      "Loss: 929.0868795696215\n",
      "Training step:  6268\n",
      "Loss: 929.086419180714\n",
      "Training step:  6269\n",
      "Loss: 929.0859658346645\n",
      "Training step:  6270\n",
      "Loss: 929.0855053031516\n",
      "Training step:  6271\n",
      "Loss: 929.0850535588798\n",
      "Training step:  6272\n",
      "Loss: 929.0845929587624\n",
      "Training step:  6273\n",
      "Loss: 929.084142692191\n",
      "Training step:  6274\n",
      "Loss: 929.0836820261354\n",
      "Training step:  6275\n",
      "Loss: 929.083231260418\n",
      "Training step:  6276\n",
      "Loss: 929.0827723942862\n",
      "Training step:  6277\n",
      "Loss: 929.0823231000522\n",
      "Training step:  6278\n",
      "Loss: 929.0818641721985\n",
      "Training step:  6279\n",
      "Loss: 929.0814155913818\n",
      "Training step:  6280\n",
      "Loss: 929.0809573216729\n",
      "Training step:  6281\n",
      "Loss: 929.0805094362403\n",
      "Training step:  6282\n",
      "Loss: 929.0800517113582\n",
      "Training step:  6283\n",
      "Loss: 929.0796033211244\n",
      "Training step:  6284\n",
      "Loss: 929.0791474384586\n",
      "Training step:  6285\n",
      "Loss: 929.0787005320842\n",
      "Training step:  6286\n",
      "Loss: 929.0782444850078\n",
      "Training step:  6287\n",
      "Loss: 929.0777987271346\n",
      "Training step:  6288\n",
      "Loss: 929.0773430227748\n",
      "Training step:  6289\n",
      "Loss: 929.076896337445\n",
      "Training step:  6290\n",
      "Loss: 929.0764422823117\n",
      "Training step:  6291\n",
      "Loss: 929.0759975916313\n",
      "Training step:  6292\n",
      "Loss: 929.0755434749692\n",
      "Training step:  6293\n",
      "Loss: 929.0750998078846\n",
      "Training step:  6294\n",
      "Loss: 929.074646034699\n",
      "Training step:  6295\n",
      "Loss: 929.07419981713\n",
      "Training step:  6296\n",
      "Loss: 929.073749003427\n",
      "Training step:  6297\n",
      "Loss: 929.0733050557368\n",
      "Training step:  6298\n",
      "Loss: 929.0728539375167\n",
      "Training step:  6299\n",
      "Loss: 929.0724116113759\n",
      "Training step:  6300\n",
      "Loss: 929.0719604458467\n",
      "Training step:  6301\n",
      "Loss: 929.0715195505458\n",
      "Training step:  6302\n",
      "Loss: 929.0710683356511\n",
      "Training step:  6303\n",
      "Loss: 929.0706239851082\n",
      "Training step:  6304\n",
      "Loss: 929.0701768575531\n",
      "Training step:  6305\n",
      "Loss: 929.0697343414352\n",
      "Training step:  6306\n",
      "Loss: 929.0692862950349\n",
      "Training step:  6307\n",
      "Loss: 929.0688461408002\n",
      "Training step:  6308\n",
      "Loss: 929.0683980741483\n",
      "Training step:  6309\n",
      "Loss: 929.0679589414772\n",
      "Training step:  6310\n",
      "Loss: 929.0675112497952\n",
      "Training step:  6311\n",
      "Loss: 929.0670735059566\n",
      "Training step:  6312\n",
      "Loss: 929.0666257703673\n",
      "Training step:  6313\n",
      "Loss: 929.0661826152738\n",
      "Training step:  6314\n",
      "Loss: 929.0657421026212\n",
      "Training step:  6315\n",
      "Loss: 929.0652989209907\n",
      "Training step:  6316\n",
      "Loss: 929.0648567703012\n",
      "Training step:  6317\n",
      "Loss: 929.0644171501508\n",
      "Training step:  6318\n",
      "Loss: 929.0639739998843\n",
      "Training step:  6319\n",
      "Loss: 929.0635364612963\n",
      "Training step:  6320\n",
      "Loss: 929.0630932279033\n",
      "Training step:  6321\n",
      "Loss: 929.0626574771559\n",
      "Training step:  6322\n",
      "Loss: 929.0622142067908\n",
      "Training step:  6323\n",
      "Loss: 929.0617796466474\n",
      "Training step:  6324\n",
      "Loss: 929.0613365355662\n",
      "Training step:  6325\n",
      "Loss: 929.0609030311367\n",
      "Training step:  6326\n",
      "Loss: 929.0604602053413\n",
      "Training step:  6327\n",
      "Loss: 929.0600273540343\n",
      "Training step:  6328\n",
      "Loss: 929.0595851916867\n",
      "Training step:  6329\n",
      "Loss: 929.0591516803742\n",
      "Training step:  6330\n",
      "Loss: 929.0587113879973\n",
      "Training step:  6331\n",
      "Loss: 929.0582792625745\n",
      "Training step:  6332\n",
      "Loss: 929.0578389403967\n",
      "Training step:  6333\n",
      "Loss: 929.0574081947336\n",
      "Training step:  6334\n",
      "Loss: 929.0569677619884\n",
      "Training step:  6335\n",
      "Loss: 929.0565336761808\n",
      "Training step:  6336\n",
      "Loss: 929.0560970982672\n",
      "Training step:  6337\n",
      "Loss: 929.0556650013572\n",
      "Training step:  6338\n",
      "Loss: 929.0552275551008\n",
      "Training step:  6339\n",
      "Loss: 929.0547977210322\n",
      "Training step:  6340\n",
      "Loss: 929.0543602568994\n",
      "Training step:  6341\n",
      "Loss: 929.0539317904725\n",
      "Training step:  6342\n",
      "Loss: 929.053494298163\n",
      "Training step:  6343\n",
      "Loss: 929.0530664870674\n",
      "Training step:  6344\n",
      "Loss: 929.0526296501438\n",
      "Training step:  6345\n",
      "Loss: 929.0522026706063\n",
      "Training step:  6346\n",
      "Loss: 929.0517662972068\n",
      "Training step:  6347\n",
      "Loss: 929.0513359695309\n",
      "Training step:  6348\n",
      "Loss: 929.050903412259\n",
      "Training step:  6349\n",
      "Loss: 929.0504749851029\n",
      "Training step:  6350\n",
      "Loss: 929.0500415881393\n",
      "Training step:  6351\n",
      "Loss: 929.049615392077\n",
      "Training step:  6352\n",
      "Loss: 929.0491819007558\n",
      "Training step:  6353\n",
      "Loss: 929.0487571596428\n",
      "Training step:  6354\n",
      "Loss: 929.0483236494938\n",
      "Training step:  6355\n",
      "Loss: 929.0478996783529\n",
      "Training step:  6356\n",
      "Loss: 929.0474666982578\n",
      "Training step:  6357\n",
      "Loss: 929.0470421095943\n",
      "Training step:  6358\n",
      "Loss: 929.046610927988\n",
      "Training step:  6359\n",
      "Loss: 929.0461876753387\n",
      "Training step:  6360\n",
      "Loss: 929.0457563202917\n",
      "Training step:  6361\n",
      "Loss: 929.0453345743304\n",
      "Training step:  6362\n",
      "Loss: 929.0449032029303\n",
      "Training step:  6363\n",
      "Loss: 929.0444762663989\n",
      "Training step:  6364\n",
      "Loss: 929.0440515164925\n",
      "Training step:  6365\n",
      "Loss: 929.0436249366167\n",
      "Training step:  6366\n",
      "Loss: 929.0431986650825\n",
      "Training step:  6367\n",
      "Loss: 929.0427748829939\n",
      "Training step:  6368\n",
      "Loss: 929.0423480948766\n",
      "Training step:  6369\n",
      "Loss: 929.0419266076638\n",
      "Training step:  6370\n",
      "Loss: 929.0414993788573\n",
      "Training step:  6371\n",
      "Loss: 929.0410790882606\n",
      "Training step:  6372\n",
      "Loss: 929.0406525379677\n",
      "Training step:  6373\n",
      "Loss: 929.0402335091117\n",
      "Training step:  6374\n",
      "Loss: 929.0398069459338\n",
      "Training step:  6375\n",
      "Loss: 929.0393889197737\n",
      "Training step:  6376\n",
      "Loss: 929.0389626440067\n",
      "Training step:  6377\n",
      "Loss: 929.038544660347\n",
      "Training step:  6378\n",
      "Loss: 929.0381196258757\n",
      "Training step:  6379\n",
      "Loss: 929.0377028998403\n",
      "Training step:  6380\n",
      "Loss: 929.037277855973\n",
      "Training step:  6381\n",
      "Loss: 929.0368587498652\n",
      "Training step:  6382\n",
      "Loss: 929.0364366782259\n",
      "Training step:  6383\n",
      "Loss: 929.0360192563084\n",
      "Training step:  6384\n",
      "Loss: 929.0355965079432\n",
      "Training step:  6385\n",
      "Loss: 929.0351812135308\n",
      "Training step:  6386\n",
      "Loss: 929.0347584434481\n",
      "Training step:  6387\n",
      "Loss: 929.0343442622714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  6388\n",
      "Loss: 929.0339216663199\n",
      "Training step:  6389\n",
      "Loss: 929.0335042439879\n",
      "Training step:  6390\n",
      "Loss: 929.0330854089921\n",
      "Training step:  6391\n",
      "Loss: 929.0326697219313\n",
      "Training step:  6392\n",
      "Loss: 929.0322501384353\n",
      "Training step:  6393\n",
      "Loss: 929.0318365650495\n",
      "Training step:  6394\n",
      "Loss: 929.0314169137264\n",
      "Training step:  6395\n",
      "Loss: 929.0310047268144\n",
      "Training step:  6396\n",
      "Loss: 929.0305850735937\n",
      "Training step:  6397\n",
      "Loss: 929.030174052649\n",
      "Training step:  6398\n",
      "Loss: 929.0297545110474\n",
      "Training step:  6399\n",
      "Loss: 929.0293398112175\n",
      "Training step:  6400\n",
      "Loss: 929.0289247821239\n",
      "Training step:  6401\n",
      "Loss: 929.0285114478042\n",
      "Training step:  6402\n",
      "Loss: 929.0280953117808\n",
      "Training step:  6403\n",
      "Loss: 929.0276844006027\n",
      "Training step:  6404\n",
      "Loss: 929.0272682209463\n",
      "Training step:  6405\n",
      "Loss: 929.0268586808967\n",
      "Training step:  6406\n",
      "Loss: 929.0264425022799\n",
      "Training step:  6407\n",
      "Loss: 929.026034231618\n",
      "Training step:  6408\n",
      "Loss: 929.0256180565799\n",
      "Training step:  6409\n",
      "Loss: 929.0252101715404\n",
      "Training step:  6410\n",
      "Loss: 929.0247948968308\n",
      "Training step:  6411\n",
      "Loss: 929.0243877664462\n",
      "Training step:  6412\n",
      "Loss: 929.02397294053\n",
      "Training step:  6413\n",
      "Loss: 929.0235651119937\n",
      "Training step:  6414\n",
      "Loss: 929.0231519171314\n",
      "Training step:  6415\n",
      "Loss: 929.0227455593619\n",
      "Training step:  6416\n",
      "Loss: 929.0223323741124\n",
      "Training step:  6417\n",
      "Loss: 929.0219272712557\n",
      "Training step:  6418\n",
      "Loss: 929.0215140942059\n",
      "Training step:  6419\n",
      "Loss: 929.0211051247747\n",
      "Training step:  6420\n",
      "Loss: 929.0206958131314\n",
      "Training step:  6421\n",
      "Loss: 929.020288665748\n",
      "Training step:  6422\n",
      "Loss: 929.0198788024387\n",
      "Training step:  6423\n",
      "Loss: 929.0194737930982\n",
      "Training step:  6424\n",
      "Loss: 929.019063506515\n",
      "Training step:  6425\n",
      "Loss: 929.0186597046029\n",
      "Training step:  6426\n",
      "Loss: 929.0182499342357\n",
      "Training step:  6427\n",
      "Loss: 929.0178474370078\n",
      "Training step:  6428\n",
      "Loss: 929.0174376782907\n",
      "Training step:  6429\n",
      "Loss: 929.0170364187259\n",
      "Training step:  6430\n",
      "Loss: 929.0166266738327\n",
      "Training step:  6431\n",
      "Loss: 929.0162209286833\n",
      "Training step:  6432\n",
      "Loss: 929.0158170415239\n",
      "Training step:  6433\n",
      "Loss: 929.015411689419\n",
      "Training step:  6434\n",
      "Loss: 929.0150065414329\n",
      "Training step:  6435\n",
      "Loss: 929.0146031690372\n",
      "Training step:  6436\n",
      "Loss: 929.0141979021006\n",
      "Training step:  6437\n",
      "Loss: 929.0137967477316\n",
      "Training step:  6438\n",
      "Loss: 929.013391119528\n",
      "Training step:  6439\n",
      "Loss: 929.012991663078\n",
      "Training step:  6440\n",
      "Loss: 929.0125860426381\n",
      "Training step:  6441\n",
      "Loss: 929.0121875266295\n",
      "Training step:  6442\n",
      "Loss: 929.0117821948381\n",
      "Training step:  6443\n",
      "Loss: 929.0113845343973\n",
      "Training step:  6444\n",
      "Loss: 929.010979570027\n",
      "Training step:  6445\n",
      "Loss: 929.0105825114321\n",
      "Training step:  6446\n",
      "Loss: 929.0101781533024\n",
      "Training step:  6447\n",
      "Loss: 929.0097816048865\n",
      "Training step:  6448\n",
      "Loss: 929.0093779330133\n",
      "Training step:  6449\n",
      "Loss: 929.0089821390784\n",
      "Training step:  6450\n",
      "Loss: 929.0085789079867\n",
      "Training step:  6451\n",
      "Loss: 929.0081823591569\n",
      "Training step:  6452\n",
      "Loss: 929.0077806792546\n",
      "Training step:  6453\n",
      "Loss: 929.0073856533749\n",
      "Training step:  6454\n",
      "Loss: 929.0069839125917\n",
      "Training step:  6455\n",
      "Loss: 929.0065898523012\n",
      "Training step:  6456\n",
      "Loss: 929.0061884482196\n",
      "Training step:  6457\n",
      "Loss: 929.0057945155245\n",
      "Training step:  6458\n",
      "Loss: 929.0053940373792\n",
      "Training step:  6459\n",
      "Loss: 929.0050014054158\n",
      "Training step:  6460\n",
      "Loss: 929.004600954979\n",
      "Training step:  6461\n",
      "Loss: 929.0042041112714\n",
      "Training step:  6462\n",
      "Loss: 929.0038092490884\n",
      "Training step:  6463\n",
      "Loss: 929.0034127067178\n",
      "Training step:  6464\n",
      "Loss: 929.0030166625502\n",
      "Training step:  6465\n",
      "Loss: 929.002622208188\n",
      "Training step:  6466\n",
      "Loss: 929.0022258311714\n",
      "Training step:  6467\n",
      "Loss: 929.0018335813428\n",
      "Training step:  6468\n",
      "Loss: 929.0014368671444\n",
      "Training step:  6469\n",
      "Loss: 929.0010459671239\n",
      "Training step:  6470\n",
      "Loss: 929.0006495703893\n",
      "Training step:  6471\n",
      "Loss: 929.0002596809185\n",
      "Training step:  6472\n",
      "Loss: 928.9998634724163\n",
      "Training step:  6473\n",
      "Loss: 928.9994745957554\n",
      "Training step:  6474\n",
      "Loss: 928.9990785763964\n",
      "Training step:  6475\n",
      "Loss: 928.9986900053394\n",
      "Training step:  6476\n",
      "Loss: 928.9982948648558\n",
      "Training step:  6477\n",
      "Loss: 928.9979074432019\n",
      "Training step:  6478\n",
      "Loss: 928.9975123358024\n",
      "Training step:  6479\n",
      "Loss: 928.9971206635518\n",
      "Training step:  6480\n",
      "Loss: 928.9967309149324\n",
      "Training step:  6481\n",
      "Loss: 928.9963393727631\n",
      "Training step:  6482\n",
      "Loss: 928.9959487787046\n",
      "Training step:  6483\n",
      "Loss: 928.9955599937065\n",
      "Training step:  6484\n",
      "Loss: 928.9951687090662\n",
      "Training step:  6485\n",
      "Loss: 928.9947818934845\n",
      "Training step:  6486\n",
      "Loss: 928.9943905641944\n",
      "Training step:  6487\n",
      "Loss: 928.9940045060872\n",
      "Training step:  6488\n",
      "Loss: 928.9936137578602\n",
      "Training step:  6489\n",
      "Loss: 928.9932288350096\n",
      "Training step:  6490\n",
      "Loss: 928.9928381231355\n",
      "Training step:  6491\n",
      "Loss: 928.9924540951566\n",
      "Training step:  6492\n",
      "Loss: 928.9920636722644\n",
      "Training step:  6493\n",
      "Loss: 928.9916802288453\n",
      "Training step:  6494\n",
      "Loss: 928.9912903280889\n",
      "Training step:  6495\n",
      "Loss: 928.9909076837673\n",
      "Training step:  6496\n",
      "Loss: 928.9905182019603\n",
      "Training step:  6497\n",
      "Loss: 928.9901354532666\n",
      "Training step:  6498\n",
      "Loss: 928.9897471113593\n",
      "Training step:  6499\n",
      "Loss: 928.9893655761686\n",
      "Training step:  6500\n",
      "Loss: 928.9889772795817\n",
      "Training step:  6501\n",
      "Loss: 928.9885955688522\n",
      "Training step:  6502\n",
      "Loss: 928.9882084910678\n",
      "Training step:  6503\n",
      "Loss: 928.9878279713319\n",
      "Training step:  6504\n",
      "Loss: 928.9874408603894\n",
      "Training step:  6505\n",
      "Loss: 928.987060716719\n",
      "Training step:  6506\n",
      "Loss: 928.9866743887276\n",
      "Training step:  6507\n",
      "Loss: 928.986295128642\n",
      "Training step:  6508\n",
      "Loss: 928.9859090549348\n",
      "Training step:  6509\n",
      "Loss: 928.9855281508961\n",
      "Training step:  6510\n",
      "Loss: 928.9851442543466\n",
      "Training step:  6511\n",
      "Loss: 928.9847649796984\n",
      "Training step:  6512\n",
      "Loss: 928.9843807514553\n",
      "Training step:  6513\n",
      "Loss: 928.9840030715907\n",
      "Training step:  6514\n",
      "Loss: 928.9836188843262\n",
      "Training step:  6515\n",
      "Loss: 928.9832417850153\n",
      "Training step:  6516\n",
      "Loss: 928.9828581726381\n",
      "Training step:  6517\n",
      "Loss: 928.9824818786399\n",
      "Training step:  6518\n",
      "Loss: 928.9820985987413\n",
      "Training step:  6519\n",
      "Loss: 928.9817204198188\n",
      "Training step:  6520\n",
      "Loss: 928.9813394626366\n",
      "Training step:  6521\n",
      "Loss: 928.9809628818241\n",
      "Training step:  6522\n",
      "Loss: 928.9805817952313\n",
      "Training step:  6523\n",
      "Loss: 928.9802065865481\n",
      "Training step:  6524\n",
      "Loss: 928.9798255571252\n",
      "Training step:  6525\n",
      "Loss: 928.9794514605261\n",
      "Training step:  6526\n",
      "Loss: 928.9790704813787\n",
      "Training step:  6527\n",
      "Loss: 928.978696434294\n",
      "Training step:  6528\n",
      "Loss: 928.9783164229244\n",
      "Training step:  6529\n",
      "Loss: 928.9779432840473\n",
      "Training step:  6530\n",
      "Loss: 928.9775636057403\n",
      "Training step:  6531\n",
      "Loss: 928.9771898301403\n",
      "Training step:  6532\n",
      "Loss: 928.976811549928\n",
      "Training step:  6533\n",
      "Loss: 928.9764391570033\n",
      "Training step:  6534\n",
      "Loss: 928.9760608653914\n",
      "Training step:  6535\n",
      "Loss: 928.975689362259\n",
      "Training step:  6536\n",
      "Loss: 928.9753114023971\n",
      "Training step:  6537\n",
      "Loss: 928.9749395805994\n",
      "Training step:  6538\n",
      "Loss: 928.9745628642776\n",
      "Training step:  6539\n",
      "Loss: 928.9741922673066\n",
      "Training step:  6540\n",
      "Loss: 928.9738155355196\n",
      "Training step:  6541\n",
      "Loss: 928.9734458187662\n",
      "Training step:  6542\n",
      "Loss: 928.9730694170659\n",
      "Training step:  6543\n",
      "Loss: 928.9726970303019\n",
      "Training step:  6544\n",
      "Loss: 928.9723233720105\n",
      "Training step:  6545\n",
      "Loss: 928.9719526362034\n",
      "Training step:  6546\n",
      "Loss: 928.9715785994014\n",
      "Training step:  6547\n",
      "Loss: 928.9712096669026\n",
      "Training step:  6548\n",
      "Loss: 928.9708355449701\n",
      "Training step:  6549\n",
      "Loss: 928.9704674130618\n",
      "Training step:  6550\n",
      "Loss: 928.9700937703528\n",
      "Training step:  6551\n",
      "Loss: 928.9697267694658\n",
      "Training step:  6552\n",
      "Loss: 928.9693531848229\n",
      "Training step:  6553\n",
      "Loss: 928.9689838067212\n",
      "Training step:  6554\n",
      "Loss: 928.968612854863\n",
      "Training step:  6555\n",
      "Loss: 928.9682451117523\n",
      "Training step:  6556\n",
      "Loss: 928.9678736394703\n",
      "Training step:  6557\n",
      "Loss: 928.9675076857336\n",
      "Training step:  6558\n",
      "Loss: 928.9671362889975\n",
      "Training step:  6559\n",
      "Loss: 928.9667709319971\n",
      "Training step:  6560\n",
      "Loss: 928.966400085686\n",
      "Training step:  6561\n",
      "Loss: 928.9660357712204\n",
      "Training step:  6562\n",
      "Loss: 928.9656649869438\n",
      "Training step:  6563\n",
      "Loss: 928.9652982356396\n",
      "Training step:  6564\n",
      "Loss: 928.9649300966411\n",
      "Training step:  6565\n",
      "Loss: 928.9645650081077\n",
      "Training step:  6566\n",
      "Loss: 928.9641963691334\n",
      "Training step:  6567\n",
      "Loss: 928.9638330476859\n",
      "Training step:  6568\n",
      "Loss: 928.9634644924876\n",
      "Training step:  6569\n",
      "Loss: 928.9631022303606\n",
      "Training step:  6570\n",
      "Loss: 928.9627337395723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  6571\n",
      "Loss: 928.9623715752272\n",
      "Training step:  6572\n",
      "Loss: 928.9620040426724\n",
      "Training step:  6573\n",
      "Loss: 928.9616429626656\n",
      "Training step:  6574\n",
      "Loss: 928.9612754954566\n",
      "Training step:  6575\n",
      "Loss: 928.9609111718173\n",
      "Training step:  6576\n",
      "Loss: 928.9605476552556\n",
      "Training step:  6577\n",
      "Loss: 928.9601843256287\n",
      "Training step:  6578\n",
      "Loss: 928.9598199177651\n",
      "Training step:  6579\n",
      "Loss: 928.9594581991167\n",
      "Training step:  6580\n",
      "Loss: 928.9590937918151\n",
      "Training step:  6581\n",
      "Loss: 928.9587337849364\n",
      "Training step:  6582\n",
      "Loss: 928.9583693626173\n",
      "Training step:  6583\n",
      "Loss: 928.9580103732599\n",
      "Training step:  6584\n",
      "Loss: 928.9576461537048\n",
      "Training step:  6585\n",
      "Loss: 928.9572879774009\n",
      "Training step:  6586\n",
      "Loss: 928.9569240454722\n",
      "Training step:  6587\n",
      "Loss: 928.9565666136191\n",
      "Training step:  6588\n",
      "Loss: 928.9562030328213\n",
      "Training step:  6589\n",
      "Loss: 928.9558455948861\n",
      "Training step:  6590\n",
      "Loss: 928.9554830440148\n",
      "Training step:  6591\n",
      "Loss: 928.9551266604668\n",
      "Training step:  6592\n",
      "Loss: 928.9547641803188\n",
      "Training step:  6593\n",
      "Loss: 928.9544074473023\n",
      "Training step:  6594\n",
      "Loss: 928.9540460475116\n",
      "Training step:  6595\n",
      "Loss: 928.9536906401659\n",
      "Training step:  6596\n",
      "Loss: 928.9533293131253\n",
      "Training step:  6597\n",
      "Loss: 928.952974577337\n",
      "Training step:  6598\n",
      "Loss: 928.9526136595224\n",
      "Training step:  6599\n",
      "Loss: 928.9522567772042\n",
      "Training step:  6600\n",
      "Loss: 928.9518983759721\n",
      "Training step:  6601\n",
      "Loss: 928.9515429291815\n",
      "Training step:  6602\n",
      "Loss: 928.9511840665419\n",
      "Training step:  6603\n",
      "Loss: 928.9508303086808\n",
      "Training step:  6604\n",
      "Loss: 928.9504714807204\n",
      "Training step:  6605\n",
      "Loss: 928.9501183688502\n",
      "Training step:  6606\n",
      "Loss: 928.9497600731523\n",
      "Training step:  6607\n",
      "Loss: 928.9494079543499\n",
      "Training step:  6608\n",
      "Loss: 928.9490497343672\n",
      "Training step:  6609\n",
      "Loss: 928.9486949961456\n",
      "Training step:  6610\n",
      "Loss: 928.9483398236603\n",
      "Training step:  6611\n",
      "Loss: 928.9479864096206\n",
      "Training step:  6612\n",
      "Loss: 928.9476306715695\n",
      "Training step:  6613\n",
      "Loss: 928.9472790070009\n",
      "Training step:  6614\n",
      "Loss: 928.9469232212\n",
      "Training step:  6615\n",
      "Loss: 928.9465722779961\n",
      "Training step:  6616\n",
      "Loss: 928.9462169706776\n",
      "Training step:  6617\n",
      "Loss: 928.945867098924\n",
      "Training step:  6618\n",
      "Loss: 928.9455118689309\n",
      "Training step:  6619\n",
      "Loss: 928.9451622433247\n",
      "Training step:  6620\n",
      "Loss: 928.944807835774\n",
      "Training step:  6621\n",
      "Loss: 928.9444591837636\n",
      "Training step:  6622\n",
      "Loss: 928.9441046426888\n",
      "Training step:  6623\n",
      "Loss: 928.9437538952915\n",
      "Training step:  6624\n",
      "Loss: 928.9434019614488\n",
      "Training step:  6625\n",
      "Loss: 928.9430526609875\n",
      "Training step:  6626\n",
      "Loss: 928.9427002914069\n",
      "Training step:  6627\n",
      "Loss: 928.9423521871093\n",
      "Training step:  6628\n",
      "Loss: 928.9420000402034\n",
      "Training step:  6629\n",
      "Loss: 928.9416532811374\n",
      "Training step:  6630\n",
      "Loss: 928.9413012125252\n",
      "Training step:  6631\n",
      "Loss: 928.9409549805719\n",
      "Training step:  6632\n",
      "Loss: 928.9406034384373\n",
      "Training step:  6633\n",
      "Loss: 928.9402578496303\n",
      "Training step:  6634\n",
      "Loss: 928.9399067088277\n",
      "Training step:  6635\n",
      "Loss: 928.9395606903502\n",
      "Training step:  6636\n",
      "Loss: 928.9392106354426\n",
      "Training step:  6637\n",
      "Loss: 928.9388659316603\n",
      "Training step:  6638\n",
      "Loss: 928.9385159649872\n",
      "Training step:  6639\n",
      "Loss: 928.9381719092514\n",
      "Training step:  6640\n",
      "Loss: 928.9378223426415\n",
      "Training step:  6641\n",
      "Loss: 928.9374779747542\n",
      "Training step:  6642\n",
      "Loss: 928.9371295235144\n",
      "Training step:  6643\n",
      "Loss: 928.9367863068018\n",
      "Training step:  6644\n",
      "Loss: 928.9364378829317\n",
      "Training step:  6645\n",
      "Loss: 928.9360953788482\n",
      "Training step:  6646\n",
      "Loss: 928.9357473531701\n",
      "Training step:  6647\n",
      "Loss: 928.9354031187008\n",
      "Training step:  6648\n",
      "Loss: 928.9350571148293\n",
      "Training step:  6649\n",
      "Loss: 928.9347143542383\n",
      "Training step:  6650\n",
      "Loss: 928.9343679399246\n",
      "Training step:  6651\n",
      "Loss: 928.9340267694503\n",
      "Training step:  6652\n",
      "Loss: 928.933680450274\n",
      "Training step:  6653\n",
      "Loss: 928.9333398328667\n",
      "Training step:  6654\n",
      "Loss: 928.9329940270079\n",
      "Training step:  6655\n",
      "Loss: 928.9326536933698\n",
      "Training step:  6656\n",
      "Loss: 928.9323085170132\n",
      "Training step:  6657\n",
      "Loss: 928.93196898507\n",
      "Training step:  6658\n",
      "Loss: 928.9316241287532\n",
      "Training step:  6659\n",
      "Loss: 928.931283436417\n",
      "Training step:  6660\n",
      "Loss: 928.9309400876652\n",
      "Training step:  6661\n",
      "Loss: 928.9306008868679\n",
      "Training step:  6662\n",
      "Loss: 928.9302574794104\n",
      "Training step:  6663\n",
      "Loss: 928.9299194425272\n",
      "Training step:  6664\n",
      "Loss: 928.9295761261402\n",
      "Training step:  6665\n",
      "Loss: 928.9292383900475\n",
      "Training step:  6666\n",
      "Loss: 928.9288958026443\n",
      "Training step:  6667\n",
      "Loss: 928.928558996936\n",
      "Training step:  6668\n",
      "Loss: 928.9282165008805\n",
      "Training step:  6669\n",
      "Loss: 928.9278764787641\n",
      "Training step:  6670\n",
      "Loss: 928.9275387594495\n",
      "Training step:  6671\n",
      "Loss: 928.9271977764379\n",
      "Training step:  6672\n",
      "Loss: 928.9268591100529\n",
      "Training step:  6673\n",
      "Loss: 928.9265203631311\n",
      "Training step:  6674\n",
      "Loss: 928.9261814847525\n",
      "Training step:  6675\n",
      "Loss: 928.9258447409882\n",
      "Training step:  6676\n",
      "Loss: 928.9255054834799\n",
      "Training step:  6677\n",
      "Loss: 928.9251701598026\n",
      "Training step:  6678\n",
      "Loss: 928.9248310314225\n",
      "Training step:  6679\n",
      "Loss: 928.9244966211754\n",
      "Training step:  6680\n",
      "Loss: 928.9241577056874\n",
      "Training step:  6681\n",
      "Loss: 928.9238237702011\n",
      "Training step:  6682\n",
      "Loss: 928.9234854028215\n",
      "Training step:  6683\n",
      "Loss: 928.9231522608894\n",
      "Training step:  6684\n",
      "Loss: 928.922814116417\n",
      "Training step:  6685\n",
      "Loss: 928.922481220166\n",
      "Training step:  6686\n",
      "Loss: 928.9221437448035\n",
      "Training step:  6687\n",
      "Loss: 928.9218115536088\n",
      "Training step:  6688\n",
      "Loss: 928.9214744666133\n",
      "Training step:  6689\n",
      "Loss: 928.9211425555245\n",
      "Training step:  6690\n",
      "Loss: 928.9208060892316\n",
      "Training step:  6691\n",
      "Loss: 928.9204749541711\n",
      "Training step:  6692\n",
      "Loss: 928.9201388046323\n",
      "Training step:  6693\n",
      "Loss: 928.9198072274497\n",
      "Training step:  6694\n",
      "Loss: 928.9194720263527\n",
      "Training step:  6695\n",
      "Loss: 928.919141814676\n",
      "Training step:  6696\n",
      "Loss: 928.9188067148001\n",
      "Training step:  6697\n",
      "Loss: 928.9184770047656\n",
      "Training step:  6698\n",
      "Loss: 928.9181424058238\n",
      "Training step:  6699\n",
      "Loss: 928.9178129743335\n",
      "Training step:  6700\n",
      "Loss: 928.9174789016915\n",
      "Training step:  6701\n",
      "Loss: 928.9171502562057\n",
      "Training step:  6702\n",
      "Loss: 928.9168165706302\n",
      "Training step:  6703\n",
      "Loss: 928.9164865406905\n",
      "Training step:  6704\n",
      "Loss: 928.9161544880274\n",
      "Training step:  6705\n",
      "Loss: 928.9158259351585\n",
      "Training step:  6706\n",
      "Loss: 928.915493649402\n",
      "Training step:  6707\n",
      "Loss: 928.9151660360682\n",
      "Training step:  6708\n",
      "Loss: 928.9148341601556\n",
      "Training step:  6709\n",
      "Loss: 928.9145074148321\n",
      "Training step:  6710\n",
      "Loss: 928.9141757521961\n",
      "Training step:  6711\n",
      "Loss: 928.9138488893989\n",
      "Training step:  6712\n",
      "Loss: 928.9135179721869\n",
      "Training step:  6713\n",
      "Loss: 928.9131923502246\n",
      "Training step:  6714\n",
      "Loss: 928.9128615361603\n",
      "Training step:  6715\n",
      "Loss: 928.9125330585233\n",
      "Training step:  6716\n",
      "Loss: 928.9122060029065\n",
      "Training step:  6717\n",
      "Loss: 928.9118776188424\n",
      "Training step:  6718\n",
      "Loss: 928.9115500237198\n",
      "Training step:  6719\n",
      "Loss: 928.9112237428668\n",
      "Training step:  6720\n",
      "Loss: 928.910895705858\n",
      "Training step:  6721\n",
      "Loss: 928.9105707336877\n",
      "Training step:  6722\n",
      "Loss: 928.9102427806944\n",
      "Training step:  6723\n",
      "Loss: 928.9099190002585\n",
      "Training step:  6724\n",
      "Loss: 928.909591069888\n",
      "Training step:  6725\n",
      "Loss: 928.9092680322324\n",
      "Training step:  6726\n",
      "Loss: 928.9089404343414\n",
      "Training step:  6727\n",
      "Loss: 928.9086180494556\n",
      "Training step:  6728\n",
      "Loss: 928.9082907843174\n",
      "Training step:  6729\n",
      "Loss: 928.9079681654703\n",
      "Training step:  6730\n",
      "Loss: 928.9076415258528\n",
      "Training step:  6731\n",
      "Loss: 928.9073197091357\n",
      "Training step:  6732\n",
      "Loss: 928.9069935058552\n",
      "Training step:  6733\n",
      "Loss: 928.9066726143429\n",
      "Training step:  6734\n",
      "Loss: 928.9063467600956\n",
      "Training step:  6735\n",
      "Loss: 928.9060261299124\n",
      "Training step:  6736\n",
      "Loss: 928.9057008416726\n",
      "Training step:  6737\n",
      "Loss: 928.9053810002988\n",
      "Training step:  6738\n",
      "Loss: 928.9050560233903\n",
      "Training step:  6739\n",
      "Loss: 928.9047344241151\n",
      "Training step:  6740\n",
      "Loss: 928.9044114345826\n",
      "Training step:  6741\n",
      "Loss: 928.9040912083053\n",
      "Training step:  6742\n",
      "Loss: 928.9037678395091\n",
      "Training step:  6743\n",
      "Loss: 928.9034485466419\n",
      "Training step:  6744\n",
      "Loss: 928.9031257206784\n",
      "Training step:  6745\n",
      "Loss: 928.9028074321725\n",
      "Training step:  6746\n",
      "Loss: 928.902484717452\n",
      "Training step:  6747\n",
      "Loss: 928.9021669670607\n",
      "Training step:  6748\n",
      "Loss: 928.9018446794794\n",
      "Training step:  6749\n",
      "Loss: 928.9015266069632\n",
      "Training step:  6750\n",
      "Loss: 928.9012049555454\n",
      "Training step:  6751\n",
      "Loss: 928.9008883738143\n",
      "Training step:  6752\n",
      "Loss: 928.9005668166242\n",
      "Training step:  6753\n",
      "Loss: 928.9002495596155\n",
      "Training step:  6754\n",
      "Loss: 928.899929155472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  6755\n",
      "Loss: 928.89961316607\n",
      "Training step:  6756\n",
      "Loss: 928.8992928114124\n",
      "Training step:  6757\n",
      "Loss: 928.8989777709493\n",
      "Training step:  6758\n",
      "Loss: 928.8986575274815\n",
      "Training step:  6759\n",
      "Loss: 928.8983396801096\n",
      "Training step:  6760\n",
      "Loss: 928.8980237526085\n",
      "Training step:  6761\n",
      "Loss: 928.897705352346\n",
      "Training step:  6762\n",
      "Loss: 928.8973887566328\n",
      "Training step:  6763\n",
      "Loss: 928.897072206026\n",
      "Training step:  6764\n",
      "Loss: 928.896755208412\n",
      "Training step:  6765\n",
      "Loss: 928.8964403534777\n",
      "Training step:  6766\n",
      "Loss: 928.8961230872713\n",
      "Training step:  6767\n",
      "Loss: 928.895809051258\n",
      "Training step:  6768\n",
      "Loss: 928.8954922628989\n",
      "Training step:  6769\n",
      "Loss: 928.8951791475513\n",
      "Training step:  6770\n",
      "Loss: 928.8948623246592\n",
      "Training step:  6771\n",
      "Loss: 928.8945501004383\n",
      "Training step:  6772\n",
      "Loss: 928.8942335904865\n",
      "Training step:  6773\n",
      "Loss: 928.8939218094025\n",
      "Training step:  6774\n",
      "Loss: 928.8936058095801\n",
      "Training step:  6775\n",
      "Loss: 928.8932945488003\n",
      "Training step:  6776\n",
      "Loss: 928.892978968271\n",
      "Training step:  6777\n",
      "Loss: 928.8926682741069\n",
      "Training step:  6778\n",
      "Loss: 928.8923530647727\n",
      "Training step:  6779\n",
      "Loss: 928.8920413761833\n",
      "Training step:  6780\n",
      "Loss: 928.8917275435042\n",
      "Training step:  6781\n",
      "Loss: 928.8914171171525\n",
      "Training step:  6782\n",
      "Loss: 928.8911032283291\n",
      "Training step:  6783\n",
      "Loss: 928.8907938694863\n",
      "Training step:  6784\n",
      "Loss: 928.8904800994877\n",
      "Training step:  6785\n",
      "Loss: 928.8901711635501\n",
      "Training step:  6786\n",
      "Loss: 928.8898579094584\n",
      "Training step:  6787\n",
      "Loss: 928.8895495334884\n",
      "Training step:  6788\n",
      "Loss: 928.8892366485751\n",
      "Training step:  6789\n",
      "Loss: 928.8889279212793\n",
      "Training step:  6790\n",
      "Loss: 928.8886159610795\n",
      "Training step:  6791\n",
      "Loss: 928.8883083655976\n",
      "Training step:  6792\n",
      "Loss: 928.887996455584\n",
      "Training step:  6793\n",
      "Loss: 928.8876892341107\n",
      "Training step:  6794\n",
      "Loss: 928.8873778043823\n",
      "Training step:  6795\n",
      "Loss: 928.8870710147498\n",
      "Training step:  6796\n",
      "Loss: 928.8867600734418\n",
      "Training step:  6797\n",
      "Loss: 928.8864539960663\n",
      "Training step:  6798\n",
      "Loss: 928.8861434211765\n",
      "Training step:  6799\n",
      "Loss: 928.8858358565462\n",
      "Training step:  6800\n",
      "Loss: 928.8855270144516\n",
      "Training step:  6801\n",
      "Loss: 928.885220731503\n",
      "Training step:  6802\n",
      "Loss: 928.8849115651363\n",
      "Training step:  6803\n",
      "Loss: 928.884606036747\n",
      "Training step:  6804\n",
      "Loss: 928.8842969157577\n",
      "Training step:  6805\n",
      "Loss: 928.8839919963614\n",
      "Training step:  6806\n",
      "Loss: 928.8836835712542\n",
      "Training step:  6807\n",
      "Loss: 928.8833796906122\n",
      "Training step:  6808\n",
      "Loss: 928.883071484282\n",
      "Training step:  6809\n",
      "Loss: 928.8827668513422\n",
      "Training step:  6810\n",
      "Loss: 928.8824596157293\n",
      "Training step:  6811\n",
      "Loss: 928.8821564284765\n",
      "Training step:  6812\n",
      "Loss: 928.8818492530241\n",
      "Training step:  6813\n",
      "Loss: 928.881546893861\n",
      "Training step:  6814\n",
      "Loss: 928.8812399008365\n",
      "Training step:  6815\n",
      "Loss: 928.8809358601907\n",
      "Training step:  6816\n",
      "Loss: 928.8806308466103\n",
      "Training step:  6817\n",
      "Loss: 928.8803279767191\n",
      "Training step:  6818\n",
      "Loss: 928.8800226663724\n",
      "Training step:  6819\n",
      "Loss: 928.879721144553\n",
      "Training step:  6820\n",
      "Loss: 928.8794159051381\n",
      "Training step:  6821\n",
      "Loss: 928.8791149424876\n",
      "Training step:  6822\n",
      "Loss: 928.8788100846238\n",
      "Training step:  6823\n",
      "Loss: 928.8785098809277\n",
      "Training step:  6824\n",
      "Loss: 928.8782052502223\n",
      "Training step:  6825\n",
      "Loss: 928.8779035442552\n",
      "Training step:  6826\n",
      "Loss: 928.8776004998581\n",
      "Training step:  6827\n",
      "Loss: 928.8772999195115\n",
      "Training step:  6828\n",
      "Loss: 928.8769968780431\n",
      "Training step:  6829\n",
      "Loss: 928.8766976064215\n",
      "Training step:  6830\n",
      "Loss: 928.8763946342591\n",
      "Training step:  6831\n",
      "Loss: 928.8760961750424\n",
      "Training step:  6832\n",
      "Loss: 928.8757933871676\n",
      "Training step:  6833\n",
      "Loss: 928.8754944766964\n",
      "Training step:  6834\n",
      "Loss: 928.8751926048091\n",
      "Training step:  6835\n",
      "Loss: 928.8748948740754\n",
      "Training step:  6836\n",
      "Loss: 928.8745930599475\n",
      "Training step:  6837\n",
      "Loss: 928.8742958134046\n",
      "Training step:  6838\n",
      "Loss: 928.8739944214465\n",
      "Training step:  6839\n",
      "Loss: 928.8736973258724\n",
      "Training step:  6840\n",
      "Loss: 928.8733965578792\n",
      "Training step:  6841\n",
      "Loss: 928.8731003586313\n",
      "Training step:  6842\n",
      "Loss: 928.8727997773659\n",
      "Training step:  6843\n",
      "Loss: 928.8725017825568\n",
      "Training step:  6844\n",
      "Loss: 928.8722034259733\n",
      "Training step:  6845\n",
      "Loss: 928.8719063480083\n",
      "Training step:  6846\n",
      "Loss: 928.8716075369504\n",
      "Training step:  6847\n",
      "Loss: 928.8713115113105\n",
      "Training step:  6848\n",
      "Loss: 928.8710127802027\n",
      "Training step:  6849\n",
      "Loss: 928.8707179978978\n",
      "Training step:  6850\n",
      "Loss: 928.8704194428929\n",
      "Training step:  6851\n",
      "Loss: 928.8701251512858\n",
      "Training step:  6852\n",
      "Loss: 928.8698270049937\n",
      "Training step:  6853\n",
      "Loss: 928.8695332735589\n",
      "Training step:  6854\n",
      "Loss: 928.8692355260397\n",
      "Training step:  6855\n",
      "Loss: 928.8689416384216\n",
      "Training step:  6856\n",
      "Loss: 928.8686447608785\n",
      "Training step:  6857\n",
      "Loss: 928.8683517685232\n",
      "Training step:  6858\n",
      "Loss: 928.8680549575723\n",
      "Training step:  6859\n",
      "Loss: 928.867762572356\n",
      "Training step:  6860\n",
      "Loss: 928.8674661168992\n",
      "Training step:  6861\n",
      "Loss: 928.8671724169636\n",
      "Training step:  6862\n",
      "Loss: 928.8668773505035\n",
      "Training step:  6863\n",
      "Loss: 928.8665846318952\n",
      "Training step:  6864\n",
      "Loss: 928.8662896256182\n",
      "Training step:  6865\n",
      "Loss: 928.8659982464623\n",
      "Training step:  6866\n",
      "Loss: 928.8657033149424\n",
      "Training step:  6867\n",
      "Loss: 928.8654126739126\n",
      "Training step:  6868\n",
      "Loss: 928.8651179698104\n",
      "Training step:  6869\n",
      "Loss: 928.864825932239\n",
      "Training step:  6870\n",
      "Loss: 928.8645329313218\n",
      "Training step:  6871\n",
      "Loss: 928.8642420106867\n",
      "Training step:  6872\n",
      "Loss: 928.8639487451173\n",
      "Training step:  6873\n",
      "Loss: 928.8636586696579\n",
      "Training step:  6874\n",
      "Loss: 928.8633658207461\n",
      "Training step:  6875\n",
      "Loss: 928.8630766419083\n",
      "Training step:  6876\n",
      "Loss: 928.8627838593803\n",
      "Training step:  6877\n",
      "Loss: 928.862495158048\n",
      "Training step:  6878\n",
      "Loss: 928.8622027769753\n",
      "Training step:  6879\n",
      "Loss: 928.8619145395072\n",
      "Training step:  6880\n",
      "Loss: 928.8616225681751\n",
      "Training step:  6881\n",
      "Loss: 928.8613342152504\n",
      "Training step:  6882\n",
      "Loss: 928.8610430806739\n",
      "Training step:  6883\n",
      "Loss: 928.860755649314\n",
      "Training step:  6884\n",
      "Loss: 928.8604645879154\n",
      "Training step:  6885\n",
      "Loss: 928.8601777065438\n",
      "Training step:  6886\n",
      "Loss: 928.8598869685774\n",
      "Training step:  6887\n",
      "Loss: 928.8595981628386\n",
      "Training step:  6888\n",
      "Loss: 928.8593098273028\n",
      "Training step:  6889\n",
      "Loss: 928.8590215869656\n",
      "Training step:  6890\n",
      "Loss: 928.8587330844099\n",
      "Training step:  6891\n",
      "Loss: 928.85844627017\n",
      "Training step:  6892\n",
      "Loss: 928.8581575248231\n",
      "Training step:  6893\n",
      "Loss: 928.8578719412209\n",
      "Training step:  6894\n",
      "Loss: 928.8575832390699\n",
      "Training step:  6895\n",
      "Loss: 928.857298064326\n",
      "Training step:  6896\n",
      "Loss: 928.8570098406834\n",
      "Training step:  6897\n",
      "Loss: 928.8567254069485\n",
      "Training step:  6898\n",
      "Loss: 928.8564373452297\n",
      "Training step:  6899\n",
      "Loss: 928.8561531061199\n",
      "Training step:  6900\n",
      "Loss: 928.855865599743\n",
      "Training step:  6901\n",
      "Loss: 928.8555820005611\n",
      "Training step:  6902\n",
      "Loss: 928.8552948150905\n",
      "Training step:  6903\n",
      "Loss: 928.8550108599156\n",
      "Training step:  6904\n",
      "Loss: 928.854724460837\n",
      "Training step:  6905\n",
      "Loss: 928.8544416823893\n",
      "Training step:  6906\n",
      "Loss: 928.8541553607604\n",
      "Training step:  6907\n",
      "Loss: 928.8538730410918\n",
      "Training step:  6908\n",
      "Loss: 928.8535871212017\n",
      "Training step:  6909\n",
      "Loss: 928.8533051311301\n",
      "Training step:  6910\n",
      "Loss: 928.8530196152024\n",
      "Training step:  6911\n",
      "Loss: 928.8527376126426\n",
      "Training step:  6912\n",
      "Loss: 928.8524528319739\n",
      "Training step:  6913\n",
      "Loss: 928.8521718235039\n",
      "Training step:  6914\n",
      "Loss: 928.8518871179679\n",
      "Training step:  6915\n",
      "Loss: 928.8516052866698\n",
      "Training step:  6916\n",
      "Loss: 928.8513215705606\n",
      "Training step:  6917\n",
      "Loss: 928.8510406161986\n",
      "Training step:  6918\n",
      "Loss: 928.8507567975795\n",
      "Training step:  6919\n",
      "Loss: 928.8504766318413\n",
      "Training step:  6920\n",
      "Loss: 928.8501930807573\n",
      "Training step:  6921\n",
      "Loss: 928.8499132366863\n",
      "Training step:  6922\n",
      "Loss: 928.8496300859617\n",
      "Training step:  6923\n",
      "Loss: 928.8493505277344\n",
      "Training step:  6924\n",
      "Loss: 928.8490680012346\n",
      "Training step:  6925\n",
      "Loss: 928.8487897221944\n",
      "Training step:  6926\n",
      "Loss: 928.8485073852614\n",
      "Training step:  6927\n",
      "Loss: 928.8482280163256\n",
      "Training step:  6928\n",
      "Loss: 928.8479472188619\n",
      "Training step:  6929\n",
      "Loss: 928.8476687823421\n",
      "Training step:  6930\n",
      "Loss: 928.8473877656653\n",
      "Training step:  6931\n",
      "Loss: 928.8471103052791\n",
      "Training step:  6932\n",
      "Loss: 928.8468295673375\n",
      "Training step:  6933\n",
      "Loss: 928.8465527852723\n",
      "Training step:  6934\n",
      "Loss: 928.8462722117002\n",
      "Training step:  6935\n",
      "Loss: 928.8459951456013\n",
      "Training step:  6936\n",
      "Loss: 928.8457153844164\n",
      "Training step:  6937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 928.8454393649513\n",
      "Training step:  6938\n",
      "Loss: 928.8451596812201\n",
      "Training step:  6939\n",
      "Loss: 928.8448841836713\n",
      "Training step:  6940\n",
      "Loss: 928.8446048148736\n",
      "Training step:  6941\n",
      "Loss: 928.8443277710093\n",
      "Training step:  6942\n",
      "Loss: 928.8440504434335\n",
      "Training step:  6943\n",
      "Loss: 928.8437742033387\n",
      "Training step:  6944\n",
      "Loss: 928.8434965204048\n",
      "Training step:  6945\n",
      "Loss: 928.8432213753639\n",
      "Training step:  6946\n",
      "Loss: 928.8429438660403\n",
      "Training step:  6947\n",
      "Loss: 928.8426696174905\n",
      "Training step:  6948\n",
      "Loss: 928.8423922723001\n",
      "Training step:  6949\n",
      "Loss: 928.8421186984073\n",
      "Training step:  6950\n",
      "Loss: 928.8418415184885\n",
      "Training step:  6951\n",
      "Loss: 928.8415667811179\n",
      "Training step:  6952\n",
      "Loss: 928.8412911312136\n",
      "Training step:  6953\n",
      "Loss: 928.8410174297184\n",
      "Training step:  6954\n",
      "Loss: 928.8407415741756\n",
      "Training step:  6955\n",
      "Loss: 928.8404690129828\n",
      "Training step:  6956\n",
      "Loss: 928.8401932038925\n",
      "Training step:  6957\n",
      "Loss: 928.8399209056422\n",
      "Training step:  6958\n",
      "Loss: 928.8396456817854\n",
      "Training step:  6959\n",
      "Loss: 928.8393740685324\n",
      "Training step:  6960\n",
      "Loss: 928.8390990107954\n",
      "Training step:  6961\n",
      "Loss: 928.8388266192478\n",
      "Training step:  6962\n",
      "Loss: 928.8385526451618\n",
      "Training step:  6963\n",
      "Loss: 928.8382814185999\n",
      "Training step:  6964\n",
      "Loss: 928.8380075174853\n",
      "Training step:  6965\n",
      "Loss: 928.8377370365698\n",
      "Training step:  6966\n",
      "Loss: 928.8374632679058\n",
      "Training step:  6967\n",
      "Loss: 928.8371933722403\n",
      "Training step:  6968\n",
      "Loss: 928.836919844905\n",
      "Training step:  6969\n",
      "Loss: 928.8366486245211\n",
      "Training step:  6970\n",
      "Loss: 928.8363766968195\n",
      "Training step:  6971\n",
      "Loss: 928.8361064260853\n",
      "Training step:  6972\n",
      "Loss: 928.8358343108578\n",
      "Training step:  6973\n",
      "Loss: 928.8355650578429\n",
      "Training step:  6974\n",
      "Loss: 928.8352932395939\n",
      "Training step:  6975\n",
      "Loss: 928.8350247122338\n",
      "Training step:  6976\n",
      "Loss: 928.8347530275064\n",
      "Training step:  6977\n",
      "Loss: 928.8344851552688\n",
      "Training step:  6978\n",
      "Loss: 928.8342136956552\n",
      "Training step:  6979\n",
      "Loss: 928.8339446517684\n",
      "Training step:  6980\n",
      "Loss: 928.8336746532922\n",
      "Training step:  6981\n",
      "Loss: 928.8334066371923\n",
      "Training step:  6982\n",
      "Loss: 928.8331364482087\n",
      "Training step:  6983\n",
      "Loss: 928.8328695340429\n",
      "Training step:  6984\n",
      "Loss: 928.8325993957365\n",
      "Training step:  6985\n",
      "Loss: 928.8323327415997\n",
      "Training step:  6986\n",
      "Loss: 928.832063172944\n",
      "Training step:  6987\n",
      "Loss: 928.8317971833145\n",
      "Training step:  6988\n",
      "Loss: 928.831527782403\n",
      "Training step:  6989\n",
      "Loss: 928.83126012357\n",
      "Training step:  6990\n",
      "Loss: 928.8309929513674\n",
      "Training step:  6991\n",
      "Loss: 928.8307255226488\n",
      "Training step:  6992\n",
      "Loss: 928.830457964106\n",
      "Training step:  6993\n",
      "Loss: 928.8301917524542\n",
      "Training step:  6994\n",
      "Loss: 928.8299240392457\n",
      "Training step:  6995\n",
      "Loss: 928.8296588478318\n",
      "Training step:  6996\n",
      "Loss: 928.8293911949871\n",
      "Training step:  6997\n",
      "Loss: 928.8291265673029\n",
      "Training step:  6998\n",
      "Loss: 928.8288592187835\n",
      "Training step:  6999\n",
      "Loss: 928.8285949518395\n",
      "Training step:  7000\n",
      "Loss: 928.8283280538932\n",
      "Training step:  7001\n",
      "Loss: 928.828064350001\n",
      "Training step:  7002\n",
      "Loss: 928.8277976736591\n",
      "Training step:  7003\n",
      "Loss: 928.8275343565637\n",
      "Training step:  7004\n",
      "Loss: 928.8272682084814\n",
      "Training step:  7005\n",
      "Loss: 928.8270054856065\n",
      "Training step:  7006\n",
      "Loss: 928.8267395362716\n",
      "Training step:  7007\n",
      "Loss: 928.8264757348572\n",
      "Training step:  7008\n",
      "Loss: 928.8262115670226\n",
      "Training step:  7009\n",
      "Loss: 928.8259484137952\n",
      "Training step:  7010\n",
      "Loss: 928.8256839653578\n",
      "Training step:  7011\n",
      "Loss: 928.825421927556\n",
      "Training step:  7012\n",
      "Loss: 928.8251574993012\n",
      "Training step:  7013\n",
      "Loss: 928.8248961917542\n",
      "Training step:  7014\n",
      "Loss: 928.8246320555559\n",
      "Training step:  7015\n",
      "Loss: 928.8243712607808\n",
      "Training step:  7016\n",
      "Loss: 928.8241073637499\n",
      "Training step:  7017\n",
      "Loss: 928.8238457659196\n",
      "Training step:  7018\n",
      "Loss: 928.8235832106812\n",
      "Training step:  7019\n",
      "Loss: 928.823322440436\n",
      "Training step:  7020\n",
      "Loss: 928.8230596962144\n",
      "Training step:  7021\n",
      "Loss: 928.8227999319644\n",
      "Training step:  7022\n",
      "Loss: 928.8225373333332\n",
      "Training step:  7023\n",
      "Loss: 928.822278014439\n",
      "Training step:  7024\n",
      "Loss: 928.8220157820862\n",
      "Training step:  7025\n",
      "Loss: 928.8217567145457\n",
      "Training step:  7026\n",
      "Loss: 928.8214948497692\n",
      "Training step:  7027\n",
      "Loss: 928.821235671403\n",
      "Training step:  7028\n",
      "Loss: 928.8209745415824\n",
      "Training step:  7029\n",
      "Loss: 928.8207163154771\n",
      "Training step:  7030\n",
      "Loss: 928.8204552822144\n",
      "Training step:  7031\n",
      "Loss: 928.8201975517271\n",
      "Training step:  7032\n",
      "Loss: 928.8199368058253\n",
      "Training step:  7033\n",
      "Loss: 928.8196784938534\n",
      "Training step:  7034\n",
      "Loss: 928.8194188456455\n",
      "Training step:  7035\n",
      "Loss: 928.8191614754913\n",
      "Training step:  7036\n",
      "Loss: 928.8189017502502\n",
      "Training step:  7037\n",
      "Loss: 928.8186451959543\n",
      "Training step:  7038\n",
      "Loss: 928.8183856931525\n",
      "Training step:  7039\n",
      "Loss: 928.8181293237434\n",
      "Training step:  7040\n",
      "Loss: 928.8178705780214\n",
      "Training step:  7041\n",
      "Loss: 928.8176148451796\n",
      "Training step:  7042\n",
      "Loss: 928.8173562730071\n",
      "Training step:  7043\n",
      "Loss: 928.8171002795614\n",
      "Training step:  7044\n",
      "Loss: 928.8168424353989\n",
      "Training step:  7045\n",
      "Loss: 928.8165873113735\n",
      "Training step:  7046\n",
      "Loss: 928.8163296127171\n",
      "Training step:  7047\n",
      "Loss: 928.8160751342378\n",
      "Training step:  7048\n",
      "Loss: 928.8158176057863\n",
      "Training step:  7049\n",
      "Loss: 928.8155618162186\n",
      "Training step:  7050\n",
      "Loss: 928.8153062084172\n",
      "Training step:  7051\n",
      "Loss: 928.815050970366\n",
      "Training step:  7052\n",
      "Loss: 928.8147951190799\n",
      "Training step:  7053\n",
      "Loss: 928.8145408880464\n",
      "Training step:  7054\n",
      "Loss: 928.8142850000607\n",
      "Training step:  7055\n",
      "Loss: 928.8140317042652\n",
      "Training step:  7056\n",
      "Loss: 928.8137759608906\n",
      "Training step:  7057\n",
      "Loss: 928.8135233039949\n",
      "Training step:  7058\n",
      "Loss: 928.8132677310034\n",
      "Training step:  7059\n",
      "Loss: 928.8130154890624\n",
      "Training step:  7060\n",
      "Loss: 928.8127602701873\n",
      "Training step:  7061\n",
      "Loss: 928.812508303166\n",
      "Training step:  7062\n",
      "Loss: 928.8122535336895\n",
      "Training step:  7063\n",
      "Loss: 928.8120021889084\n",
      "Training step:  7064\n",
      "Loss: 928.811747590494\n",
      "Training step:  7065\n",
      "Loss: 928.8114946005041\n",
      "Training step:  7066\n",
      "Loss: 928.8112428524421\n",
      "Training step:  7067\n",
      "Loss: 928.8109896844242\n",
      "Training step:  7068\n",
      "Loss: 928.8107375036835\n",
      "Training step:  7069\n",
      "Loss: 928.8104854962438\n",
      "Training step:  7070\n",
      "Loss: 928.810233208406\n",
      "Training step:  7071\n",
      "Loss: 928.8099823114716\n",
      "Training step:  7072\n",
      "Loss: 928.8097298675235\n",
      "Training step:  7073\n",
      "Loss: 928.8094797612073\n",
      "Training step:  7074\n",
      "Loss: 928.8092275952957\n",
      "Training step:  7075\n",
      "Loss: 928.8089781134645\n",
      "Training step:  7076\n",
      "Loss: 928.8087260861184\n",
      "Training step:  7077\n",
      "Loss: 928.8084771643405\n",
      "Training step:  7078\n",
      "Loss: 928.8082253708916\n",
      "Training step:  7079\n",
      "Loss: 928.8079767341749\n",
      "Training step:  7080\n",
      "Loss: 928.8077253787171\n",
      "Training step:  7081\n",
      "Loss: 928.8074772263637\n",
      "Training step:  7082\n",
      "Loss: 928.8072261630739\n",
      "Training step:  7083\n",
      "Loss: 928.8069775094187\n",
      "Training step:  7084\n",
      "Loss: 928.8067273952221\n",
      "Training step:  7085\n",
      "Loss: 928.8064796260303\n",
      "Training step:  7086\n",
      "Loss: 928.8062296002206\n",
      "Training step:  7087\n",
      "Loss: 928.8059824510976\n",
      "Training step:  7088\n",
      "Loss: 928.8057325648497\n",
      "Training step:  7089\n",
      "Loss: 928.8054860332982\n",
      "Training step:  7090\n",
      "Loss: 928.8052363185462\n",
      "Training step:  7091\n",
      "Loss: 928.8049882007898\n",
      "Training step:  7092\n",
      "Loss: 928.8047412512963\n",
      "Training step:  7093\n",
      "Loss: 928.804492936342\n",
      "Training step:  7094\n",
      "Loss: 928.8042456095571\n",
      "Training step:  7095\n",
      "Loss: 928.8039984167443\n",
      "Training step:  7096\n",
      "Loss: 928.8037509910378\n",
      "Training step:  7097\n",
      "Loss: 928.8035048736198\n",
      "Training step:  7098\n",
      "Loss: 928.8032573768129\n",
      "Training step:  7099\n",
      "Loss: 928.8030119495551\n",
      "Training step:  7100\n",
      "Loss: 928.8027646636133\n",
      "Training step:  7101\n",
      "Loss: 928.8025199113358\n",
      "Training step:  7102\n",
      "Loss: 928.8022727656412\n",
      "Training step:  7103\n",
      "Loss: 928.8020285584746\n",
      "Training step:  7104\n",
      "Loss: 928.8017816448258\n",
      "Training step:  7105\n",
      "Loss: 928.801537837805\n",
      "Training step:  7106\n",
      "Loss: 928.8012912670945\n",
      "Training step:  7107\n",
      "Loss: 928.8010475388573\n",
      "Training step:  7108\n",
      "Loss: 928.8008015626425\n",
      "Training step:  7109\n",
      "Loss: 928.800558442404\n",
      "Training step:  7110\n",
      "Loss: 928.8003126072223\n",
      "Training step:  7111\n",
      "Loss: 928.8000694985017\n",
      "Training step:  7112\n",
      "Loss: 928.7998243161683\n",
      "Training step:  7113\n",
      "Loss: 928.7995818495374\n",
      "Training step:  7114\n",
      "Loss: 928.799336809566\n",
      "Training step:  7115\n",
      "Loss: 928.7990948230739\n",
      "Training step:  7116\n",
      "Loss: 928.7988500391722\n",
      "Training step:  7117\n",
      "Loss: 928.7986074502321\n",
      "Training step:  7118\n",
      "Loss: 928.798363786618\n",
      "Training step:  7119\n",
      "Loss: 928.7981219724475\n",
      "Training step:  7120\n",
      "Loss: 928.797878317957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  7121\n",
      "Loss: 928.7976372073549\n",
      "Training step:  7122\n",
      "Loss: 928.7973936966719\n",
      "Training step:  7123\n",
      "Loss: 928.7971531823353\n",
      "Training step:  7124\n",
      "Loss: 928.7969098136266\n",
      "Training step:  7125\n",
      "Loss: 928.7966684131295\n",
      "Training step:  7126\n",
      "Loss: 928.7964265170143\n",
      "Training step:  7127\n",
      "Loss: 928.7961857574214\n",
      "Training step:  7128\n",
      "Loss: 928.7959436496607\n",
      "Training step:  7129\n",
      "Loss: 928.7957038577973\n",
      "Training step:  7130\n",
      "Loss: 928.7954618666772\n",
      "Training step:  7131\n",
      "Loss: 928.7952226984909\n",
      "Training step:  7132\n",
      "Loss: 928.7949808493714\n",
      "Training step:  7133\n",
      "Loss: 928.7947419233088\n",
      "Training step:  7134\n",
      "Loss: 928.794500555805\n",
      "Training step:  7135\n",
      "Loss: 928.7942622076938\n",
      "Training step:  7136\n",
      "Loss: 928.7940209582101\n",
      "Training step:  7137\n",
      "Loss: 928.7937811957636\n",
      "Training step:  7138\n",
      "Loss: 928.7935426045033\n",
      "Training step:  7139\n",
      "Loss: 928.7933025900379\n",
      "Training step:  7140\n",
      "Loss: 928.7930636614428\n",
      "Training step:  7141\n",
      "Loss: 928.7928248244068\n",
      "Training step:  7142\n",
      "Loss: 928.792585703143\n",
      "Training step:  7143\n",
      "Loss: 928.7923477633597\n",
      "Training step:  7144\n",
      "Loss: 928.7921087026937\n",
      "Training step:  7145\n",
      "Loss: 928.7918715353985\n",
      "Training step:  7146\n",
      "Loss: 928.7916325657845\n",
      "Training step:  7147\n",
      "Loss: 928.7913960468102\n",
      "Training step:  7148\n",
      "Loss: 928.7911572211979\n",
      "Training step:  7149\n",
      "Loss: 928.7909210409309\n",
      "Training step:  7150\n",
      "Loss: 928.7906825988226\n",
      "Training step:  7151\n",
      "Loss: 928.7904469329187\n",
      "Training step:  7152\n",
      "Loss: 928.7902087194487\n",
      "Training step:  7153\n",
      "Loss: 928.7899732490932\n",
      "Training step:  7154\n",
      "Loss: 928.7897355258461\n",
      "Training step:  7155\n",
      "Loss: 928.7895006158001\n",
      "Training step:  7156\n",
      "Loss: 928.7892630651279\n",
      "Training step:  7157\n",
      "Loss: 928.7890272835609\n",
      "Training step:  7158\n",
      "Loss: 928.7887911385826\n",
      "Training step:  7159\n",
      "Loss: 928.7885559763887\n",
      "Training step:  7160\n",
      "Loss: 928.788319636737\n",
      "Training step:  7161\n",
      "Loss: 928.7880854058036\n",
      "Training step:  7162\n",
      "Loss: 928.7878491555582\n",
      "Training step:  7163\n",
      "Loss: 928.7876155616295\n",
      "Training step:  7164\n",
      "Loss: 928.7873794550975\n",
      "Training step:  7165\n",
      "Loss: 928.7871461858151\n",
      "Training step:  7166\n",
      "Loss: 928.7869104630649\n",
      "Training step:  7167\n",
      "Loss: 928.7866776465859\n",
      "Training step:  7168\n",
      "Loss: 928.7864421740978\n",
      "Training step:  7169\n",
      "Loss: 928.786208247333\n",
      "Training step:  7170\n",
      "Loss: 928.785974451943\n",
      "Training step:  7171\n",
      "Loss: 928.7857410748039\n",
      "Training step:  7172\n",
      "Loss: 928.7855070967084\n",
      "Training step:  7173\n",
      "Loss: 928.7852747026019\n",
      "Training step:  7174\n",
      "Loss: 928.7850407302701\n",
      "Training step:  7175\n",
      "Loss: 928.7848090177902\n",
      "Training step:  7176\n",
      "Loss: 928.7845751932226\n",
      "Training step:  7177\n",
      "Loss: 928.7843438701708\n",
      "Training step:  7178\n",
      "Loss: 928.7841103661323\n",
      "Training step:  7179\n",
      "Loss: 928.7838795995855\n",
      "Training step:  7180\n",
      "Loss: 928.7836462680624\n",
      "Training step:  7181\n",
      "Loss: 928.7834149649666\n",
      "Training step:  7182\n",
      "Loss: 928.783182632134\n",
      "Training step:  7183\n",
      "Loss: 928.7829520733458\n",
      "Training step:  7184\n",
      "Loss: 928.782719760769\n",
      "Training step:  7185\n",
      "Loss: 928.7824898548074\n",
      "Training step:  7186\n",
      "Loss: 928.7822576883101\n",
      "Training step:  7187\n",
      "Loss: 928.782028340365\n",
      "Training step:  7188\n",
      "Loss: 928.7817963463021\n",
      "Training step:  7189\n",
      "Loss: 928.7815658517854\n",
      "Training step:  7190\n",
      "Loss: 928.7813355899239\n",
      "Training step:  7191\n",
      "Loss: 928.7811055653908\n",
      "Training step:  7192\n",
      "Loss: 928.780875133107\n",
      "Training step:  7193\n",
      "Loss: 928.7806460679767\n",
      "Training step:  7194\n",
      "Loss: 928.780415579353\n",
      "Training step:  7195\n",
      "Loss: 928.78018707573\n",
      "Training step:  7196\n",
      "Loss: 928.7799568978313\n",
      "Training step:  7197\n",
      "Loss: 928.7797289647631\n",
      "Training step:  7198\n",
      "Loss: 928.7794989327938\n",
      "Training step:  7199\n",
      "Loss: 928.7792715509893\n",
      "Training step:  7200\n",
      "Loss: 928.7790416911337\n",
      "Training step:  7201\n",
      "Loss: 928.7788136734201\n",
      "Training step:  7202\n",
      "Loss: 928.7785849315021\n",
      "Training step:  7203\n",
      "Loss: 928.7783576010314\n",
      "Training step:  7204\n",
      "Loss: 928.7781288741908\n",
      "Training step:  7205\n",
      "Loss: 928.7779022015108\n",
      "Training step:  7206\n",
      "Loss: 928.7776736233129\n",
      "Training step:  7207\n",
      "Loss: 928.7774474975117\n",
      "Training step:  7208\n",
      "Loss: 928.7772190649235\n",
      "Training step:  7209\n",
      "Loss: 928.7769929241313\n",
      "Training step:  7210\n",
      "Loss: 928.7767651031785\n",
      "Training step:  7211\n",
      "Loss: 928.776539565328\n",
      "Training step:  7212\n",
      "Loss: 928.7763118911635\n",
      "Training step:  7213\n",
      "Loss: 928.7760867921315\n",
      "Training step:  7214\n",
      "Loss: 928.7758593628847\n",
      "Training step:  7215\n",
      "Loss: 928.7756338313686\n",
      "Training step:  7216\n",
      "Loss: 928.7754073115119\n",
      "Training step:  7217\n",
      "Loss: 928.7751824736313\n",
      "Training step:  7218\n",
      "Loss: 928.7749560104164\n",
      "Training step:  7219\n",
      "Loss: 928.7747318009801\n",
      "Training step:  7220\n",
      "Loss: 928.7745054851338\n",
      "Training step:  7221\n",
      "Loss: 928.7742818145844\n",
      "Training step:  7222\n",
      "Loss: 928.7740556709131\n",
      "Training step:  7223\n",
      "Loss: 928.7738308550404\n",
      "Training step:  7224\n",
      "Loss: 928.7736065121804\n",
      "Training step:  7225\n",
      "Loss: 928.7733820270785\n",
      "Training step:  7226\n",
      "Loss: 928.7731575163775\n",
      "Training step:  7227\n",
      "Loss: 928.7729339836707\n",
      "Training step:  7228\n",
      "Loss: 928.7727094329936\n",
      "Training step:  7229\n",
      "Loss: 928.7724866177073\n",
      "Training step:  7230\n",
      "Loss: 928.7722621665397\n",
      "Training step:  7231\n",
      "Loss: 928.7720398648482\n",
      "Training step:  7232\n",
      "Loss: 928.7718156099388\n",
      "Training step:  7233\n",
      "Loss: 928.7715937404089\n",
      "Training step:  7234\n",
      "Loss: 928.7713697576786\n",
      "Training step:  7235\n",
      "Loss: 928.771148291249\n",
      "Training step:  7236\n",
      "Loss: 928.7709245803928\n",
      "Training step:  7237\n",
      "Loss: 928.7707027132718\n",
      "Training step:  7238\n",
      "Loss: 928.770479870019\n",
      "Training step:  7239\n",
      "Loss: 928.7702586624636\n",
      "Training step:  7240\n",
      "Loss: 928.7700359001625\n",
      "Training step:  7241\n",
      "Loss: 928.7698153059526\n",
      "Training step:  7242\n",
      "Loss: 928.7695926920385\n",
      "Training step:  7243\n",
      "Loss: 928.7693726247263\n",
      "Training step:  7244\n",
      "Loss: 928.7691501828389\n",
      "Training step:  7245\n",
      "Loss: 928.768929074402\n",
      "Training step:  7246\n",
      "Loss: 928.7687082332908\n",
      "Training step:  7247\n",
      "Loss: 928.7684875718791\n",
      "Training step:  7248\n",
      "Loss: 928.7682665927559\n",
      "Training step:  7249\n",
      "Loss: 928.768046827487\n",
      "Training step:  7250\n",
      "Loss: 928.7678258111752\n",
      "Training step:  7251\n",
      "Loss: 928.7676066677544\n",
      "Training step:  7252\n",
      "Loss: 928.7673858467587\n",
      "Training step:  7253\n",
      "Loss: 928.7671672516697\n",
      "Training step:  7254\n",
      "Loss: 928.7669465788846\n",
      "Training step:  7255\n",
      "Loss: 928.7667283779989\n",
      "Training step:  7256\n",
      "Loss: 928.7665079988626\n",
      "Training step:  7257\n",
      "Loss: 928.7662898557041\n",
      "Training step:  7258\n",
      "Loss: 928.7660700047268\n",
      "Training step:  7259\n",
      "Loss: 928.7658524084977\n",
      "Training step:  7260\n",
      "Loss: 928.7656326852918\n",
      "Training step:  7261\n",
      "Loss: 928.7654150684724\n",
      "Training step:  7262\n",
      "Loss: 928.7651959652238\n",
      "Training step:  7263\n",
      "Loss: 928.7649789076976\n",
      "Training step:  7264\n",
      "Loss: 928.7647599304541\n",
      "Training step:  7265\n",
      "Loss: 928.7645434156404\n",
      "Training step:  7266\n",
      "Loss: 928.7643245859067\n",
      "Training step:  7267\n",
      "Loss: 928.7641068920126\n",
      "Training step:  7268\n",
      "Loss: 928.7638902265792\n",
      "Training step:  7269\n",
      "Loss: 928.763672098416\n",
      "Training step:  7270\n",
      "Loss: 928.7634559796596\n",
      "Training step:  7271\n",
      "Loss: 928.7632380290169\n",
      "Training step:  7272\n",
      "Loss: 928.7630223399806\n",
      "Training step:  7273\n",
      "Loss: 928.762804624543\n",
      "Training step:  7274\n",
      "Loss: 928.7625887046152\n",
      "Training step:  7275\n",
      "Loss: 928.7623717929872\n",
      "Training step:  7276\n",
      "Loss: 928.762156465949\n",
      "Training step:  7277\n",
      "Loss: 928.7619396143924\n",
      "Training step:  7278\n",
      "Loss: 928.7617249239618\n",
      "Training step:  7279\n",
      "Loss: 928.7615081867183\n",
      "Training step:  7280\n",
      "Loss: 928.7612930222944\n",
      "Training step:  7281\n",
      "Loss: 928.7610773819906\n",
      "Training step:  7282\n",
      "Loss: 928.760862825254\n",
      "Training step:  7283\n",
      "Loss: 928.7606470245137\n",
      "Training step:  7284\n",
      "Loss: 928.7604331728792\n",
      "Training step:  7285\n",
      "Loss: 928.7602175813939\n",
      "Training step:  7286\n",
      "Loss: 928.760004095147\n",
      "Training step:  7287\n",
      "Loss: 928.7597887116631\n",
      "Training step:  7288\n",
      "Loss: 928.7595756094867\n",
      "Training step:  7289\n",
      "Loss: 928.7593605668778\n",
      "Training step:  7290\n",
      "Loss: 928.7591476881081\n",
      "Training step:  7291\n",
      "Loss: 928.7589330263199\n",
      "Training step:  7292\n",
      "Loss: 928.7587206689901\n",
      "Training step:  7293\n",
      "Loss: 928.7585061656977\n",
      "Training step:  7294\n",
      "Loss: 928.7582927538672\n",
      "Training step:  7295\n",
      "Loss: 928.7580801328287\n",
      "Training step:  7296\n",
      "Loss: 928.7578669055226\n",
      "Training step:  7297\n",
      "Loss: 928.7576540853681\n",
      "Training step:  7298\n",
      "Loss: 928.7574418021237\n",
      "Training step:  7299\n",
      "Loss: 928.7572288732902\n",
      "Training step:  7300\n",
      "Loss: 928.7570173111468\n",
      "Training step:  7301\n",
      "Loss: 928.756804480125\n",
      "Training step:  7302\n",
      "Loss: 928.7565934224085\n",
      "Training step:  7303\n",
      "Loss: 928.7563807694493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  7304\n",
      "Loss: 928.7561700997354\n",
      "Training step:  7305\n",
      "Loss: 928.7559576913127\n",
      "Training step:  7306\n",
      "Loss: 928.7557475157378\n",
      "Training step:  7307\n",
      "Loss: 928.7555352933616\n",
      "Training step:  7308\n",
      "Loss: 928.7553249635367\n",
      "Training step:  7309\n",
      "Loss: 928.7551133427479\n",
      "Training step:  7310\n",
      "Loss: 928.7549035874664\n",
      "Training step:  7311\n",
      "Loss: 928.7546921209583\n",
      "Training step:  7312\n",
      "Loss: 928.7544828632173\n",
      "Training step:  7313\n",
      "Loss: 928.7542715762186\n",
      "Training step:  7314\n",
      "Loss: 928.7540616606562\n",
      "Training step:  7315\n",
      "Loss: 928.7538516162426\n",
      "Training step:  7316\n",
      "Loss: 928.7536421973626\n",
      "Training step:  7317\n",
      "Loss: 928.7534320259801\n",
      "Training step:  7318\n",
      "Loss: 928.7532233431463\n",
      "Training step:  7319\n",
      "Loss: 928.7530132407181\n",
      "Training step:  7320\n",
      "Loss: 928.7528051143173\n",
      "Training step:  7321\n",
      "Loss: 928.7525951896503\n",
      "Training step:  7322\n",
      "Loss: 928.7523873924305\n",
      "Training step:  7323\n",
      "Loss: 928.7521777701544\n",
      "Training step:  7324\n",
      "Loss: 928.7519702593244\n",
      "Training step:  7325\n",
      "Loss: 928.7517609441201\n",
      "Training step:  7326\n",
      "Loss: 928.7515538222522\n",
      "Training step:  7327\n",
      "Loss: 928.7513447709695\n",
      "Training step:  7328\n",
      "Loss: 928.7511373424213\n",
      "Training step:  7329\n",
      "Loss: 928.750929081291\n",
      "Training step:  7330\n",
      "Loss: 928.7507222666812\n",
      "Training step:  7331\n",
      "Loss: 928.750514020329\n",
      "Training step:  7332\n",
      "Loss: 928.7503077967034\n",
      "Training step:  7333\n",
      "Loss: 928.7500997077908\n",
      "Training step:  7334\n",
      "Loss: 928.7498937739551\n",
      "Training step:  7335\n",
      "Loss: 928.7496860226155\n",
      "Training step:  7336\n",
      "Loss: 928.7494804150887\n",
      "Training step:  7337\n",
      "Loss: 928.7492729449237\n",
      "Training step:  7338\n",
      "Loss: 928.7490673749975\n",
      "Training step:  7339\n",
      "Loss: 928.7488604648576\n",
      "Training step:  7340\n",
      "Loss: 928.7486555399324\n",
      "Training step:  7341\n",
      "Loss: 928.7484487204706\n",
      "Training step:  7342\n",
      "Loss: 928.7482438018428\n",
      "Training step:  7343\n",
      "Loss: 928.7480375122029\n",
      "Training step:  7344\n",
      "Loss: 928.7478331473177\n",
      "Training step:  7345\n",
      "Loss: 928.7476269867371\n",
      "Training step:  7346\n",
      "Loss: 928.7474231207261\n",
      "Training step:  7347\n",
      "Loss: 928.7472171101117\n",
      "Training step:  7348\n",
      "Loss: 928.7470123268672\n",
      "Training step:  7349\n",
      "Loss: 928.7468081486014\n",
      "Training step:  7350\n",
      "Loss: 928.7466032533088\n",
      "Training step:  7351\n",
      "Loss: 928.7463989513479\n",
      "Training step:  7352\n",
      "Loss: 928.7461949499298\n",
      "Training step:  7353\n",
      "Loss: 928.7459905484053\n",
      "Training step:  7354\n",
      "Loss: 928.745787284621\n",
      "Training step:  7355\n",
      "Loss: 928.7455829448043\n",
      "Training step:  7356\n",
      "Loss: 928.7453802601934\n",
      "Training step:  7357\n",
      "Loss: 928.7451760499412\n",
      "Training step:  7358\n",
      "Loss: 928.7449738582574\n",
      "Training step:  7359\n",
      "Loss: 928.7447697967398\n",
      "Training step:  7360\n",
      "Loss: 928.7445679530089\n",
      "Training step:  7361\n",
      "Loss: 928.7443641562865\n",
      "Training step:  7362\n",
      "Loss: 928.7441625202082\n",
      "Training step:  7363\n",
      "Loss: 928.743959105708\n",
      "Training step:  7364\n",
      "Loss: 928.7437579471765\n",
      "Training step:  7365\n",
      "Loss: 928.7435546826669\n",
      "Training step:  7366\n",
      "Loss: 928.7433525647357\n",
      "Training step:  7367\n",
      "Loss: 928.74315123291\n",
      "Training step:  7368\n",
      "Loss: 928.7429489607683\n",
      "Training step:  7369\n",
      "Loss: 928.7427474592876\n",
      "Training step:  7370\n",
      "Loss: 928.7425460698202\n",
      "Training step:  7371\n",
      "Loss: 928.7423444757227\n",
      "Training step:  7372\n",
      "Loss: 928.7421438112087\n",
      "Training step:  7373\n",
      "Loss: 928.7419422641343\n",
      "Training step:  7374\n",
      "Loss: 928.7417421900324\n",
      "Training step:  7375\n",
      "Loss: 928.7415407530029\n",
      "Training step:  7376\n",
      "Loss: 928.741341186723\n",
      "Training step:  7377\n",
      "Loss: 928.7411398785503\n",
      "Training step:  7378\n",
      "Loss: 928.7409406724479\n",
      "Training step:  7379\n",
      "Loss: 928.7407396174556\n",
      "Training step:  7380\n",
      "Loss: 928.7405407637859\n",
      "Training step:  7381\n",
      "Loss: 928.7403399742205\n",
      "Training step:  7382\n",
      "Loss: 928.7401411431979\n",
      "Training step:  7383\n",
      "Loss: 928.7399408950365\n",
      "Training step:  7384\n",
      "Loss: 928.7397425317495\n",
      "Training step:  7385\n",
      "Loss: 928.7395424129564\n",
      "Training step:  7386\n",
      "Loss: 928.7393444475094\n",
      "Training step:  7387\n",
      "Loss: 928.7391445331409\n",
      "Training step:  7388\n",
      "Loss: 928.7389460378661\n",
      "Training step:  7389\n",
      "Loss: 928.7387472216335\n",
      "Training step:  7390\n",
      "Loss: 928.7385491619447\n",
      "Training step:  7391\n",
      "Loss: 928.73835030035\n",
      "Training step:  7392\n",
      "Loss: 928.7381528883257\n",
      "Training step:  7393\n",
      "Loss: 928.7379541378691\n",
      "Training step:  7394\n",
      "Loss: 928.7377572241567\n",
      "Training step:  7395\n",
      "Loss: 928.7375586036671\n",
      "Training step:  7396\n",
      "Loss: 928.7373621232505\n",
      "Training step:  7397\n",
      "Loss: 928.7371636706223\n",
      "Training step:  7398\n",
      "Loss: 928.7369668669603\n",
      "Training step:  7399\n",
      "Loss: 928.736769199991\n",
      "Training step:  7400\n",
      "Loss: 928.7365729466343\n",
      "Training step:  7401\n",
      "Loss: 928.7363753753372\n",
      "Training step:  7402\n",
      "Loss: 928.7361796376533\n",
      "Training step:  7403\n",
      "Loss: 928.7359821969308\n",
      "Training step:  7404\n",
      "Loss: 928.7357868504314\n",
      "Training step:  7405\n",
      "Loss: 928.735589612608\n",
      "Training step:  7406\n",
      "Loss: 928.7353937573869\n",
      "Training step:  7407\n",
      "Loss: 928.735197585181\n",
      "Training step:  7408\n",
      "Loss: 928.7350021604143\n",
      "Training step:  7409\n",
      "Loss: 928.7348059475376\n",
      "Training step:  7410\n",
      "Loss: 928.7346111596003\n",
      "Training step:  7411\n",
      "Loss: 928.7344150584707\n",
      "Training step:  7412\n",
      "Loss: 928.734220759532\n",
      "Training step:  7413\n",
      "Loss: 928.7340247677337\n",
      "Training step:  7414\n",
      "Loss: 928.7338308588227\n",
      "Training step:  7415\n",
      "Loss: 928.7336350914687\n",
      "Training step:  7416\n",
      "Loss: 928.7334411058412\n",
      "Training step:  7417\n",
      "Loss: 928.7332459703172\n",
      "Training step:  7418\n",
      "Loss: 928.7330524409203\n",
      "Training step:  7419\n",
      "Loss: 928.7328574161271\n",
      "Training step:  7420\n",
      "Loss: 928.7326643715029\n",
      "Training step:  7421\n",
      "Loss: 928.7324694766123\n",
      "Training step:  7422\n",
      "Loss: 928.732276136765\n",
      "Training step:  7423\n",
      "Loss: 928.7320820098563\n",
      "Training step:  7424\n",
      "Loss: 928.7318891792154\n",
      "Training step:  7425\n",
      "Loss: 928.7316951505701\n",
      "Training step:  7426\n",
      "Loss: 928.7315028226612\n",
      "Training step:  7427\n",
      "Loss: 928.731308904359\n",
      "Training step:  7428\n",
      "Loss: 928.7311170571012\n",
      "Training step:  7429\n",
      "Loss: 928.7309232686712\n",
      "Training step:  7430\n",
      "Loss: 928.7307307336499\n",
      "Training step:  7431\n",
      "Loss: 928.7305382078672\n",
      "Training step:  7432\n",
      "Loss: 928.7303460334191\n",
      "Training step:  7433\n",
      "Loss: 928.730153433776\n",
      "Training step:  7434\n",
      "Loss: 928.7299619311009\n",
      "Training step:  7435\n",
      "Loss: 928.729769385617\n",
      "Training step:  7436\n",
      "Loss: 928.7295784340027\n",
      "Training step:  7437\n",
      "Loss: 928.729385998703\n",
      "Training step:  7438\n",
      "Loss: 928.7291954663199\n",
      "Training step:  7439\n",
      "Loss: 928.7290032162025\n",
      "Training step:  7440\n",
      "Loss: 928.7288129173357\n",
      "Training step:  7441\n",
      "Loss: 928.728621010056\n",
      "Training step:  7442\n",
      "Loss: 928.7284310802\n",
      "Training step:  7443\n",
      "Loss: 928.7282393725694\n",
      "Training step:  7444\n",
      "Loss: 928.7280491149907\n",
      "Training step:  7445\n",
      "Loss: 928.727858213914\n",
      "Training step:  7446\n",
      "Loss: 928.7276684312286\n",
      "Training step:  7447\n",
      "Loss: 928.7274776215023\n",
      "Training step:  7448\n",
      "Loss: 928.7272883427542\n",
      "Training step:  7449\n",
      "Loss: 928.7270976447383\n",
      "Training step:  7450\n",
      "Loss: 928.726908835842\n",
      "Training step:  7451\n",
      "Loss: 928.7267182683164\n",
      "Training step:  7452\n",
      "Loss: 928.7265293933965\n",
      "Training step:  7453\n",
      "Loss: 928.7263394329475\n",
      "Training step:  7454\n",
      "Loss: 928.7261510028618\n",
      "Training step:  7455\n",
      "Loss: 928.725961155284\n",
      "Training step:  7456\n",
      "Loss: 928.725773192116\n",
      "Training step:  7457\n",
      "Loss: 928.7255834749435\n",
      "Training step:  7458\n",
      "Loss: 928.7253948414233\n",
      "Training step:  7459\n",
      "Loss: 928.7252064480174\n",
      "Training step:  7460\n",
      "Loss: 928.7250180370692\n",
      "Training step:  7461\n",
      "Loss: 928.724829566398\n",
      "Training step:  7462\n",
      "Loss: 928.7246418474689\n",
      "Training step:  7463\n",
      "Loss: 928.7244534123995\n",
      "Training step:  7464\n",
      "Loss: 928.7242662409178\n",
      "Training step:  7465\n",
      "Loss: 928.7240779208323\n",
      "Training step:  7466\n",
      "Loss: 928.7238912116381\n",
      "Training step:  7467\n",
      "Loss: 928.7237030226333\n",
      "Training step:  7468\n",
      "Loss: 928.7235166633648\n",
      "Training step:  7469\n",
      "Loss: 928.7233286925047\n",
      "Training step:  7470\n",
      "Loss: 928.7231426007522\n",
      "Training step:  7471\n",
      "Loss: 928.7229549255246\n",
      "Training step:  7472\n",
      "Loss: 928.7227691431822\n",
      "Training step:  7473\n",
      "Loss: 928.722581713974\n",
      "Training step:  7474\n",
      "Loss: 928.7223959572301\n",
      "Training step:  7475\n",
      "Loss: 928.7222090221507\n",
      "Training step:  7476\n",
      "Loss: 928.7220237141993\n",
      "Training step:  7477\n",
      "Loss: 928.7218368924123\n",
      "Training step:  7478\n",
      "Loss: 928.7216519703212\n",
      "Training step:  7479\n",
      "Loss: 928.7214653450098\n",
      "Training step:  7480\n",
      "Loss: 928.7212800723231\n",
      "Training step:  7481\n",
      "Loss: 928.7210942492874\n",
      "Training step:  7482\n",
      "Loss: 928.7209094470329\n",
      "Training step:  7483\n",
      "Loss: 928.7207237200486\n",
      "Training step:  7484\n",
      "Loss: 928.7205394027638\n",
      "Training step:  7485\n",
      "Loss: 928.7203537898548\n",
      "Training step:  7486\n",
      "Loss: 928.7201699252215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  7487\n",
      "Loss: 928.719984443435\n",
      "Training step:  7488\n",
      "Loss: 928.7198007500451\n",
      "Training step:  7489\n",
      "Loss: 928.7196156332069\n",
      "Training step:  7490\n",
      "Loss: 928.7194323766691\n",
      "Training step:  7491\n",
      "Loss: 928.7192473907722\n",
      "Training step:  7492\n",
      "Loss: 928.7190633499484\n",
      "Training step:  7493\n",
      "Loss: 928.7188800684545\n",
      "Training step:  7494\n",
      "Loss: 928.7186958627735\n",
      "Training step:  7495\n",
      "Loss: 928.7185124548438\n",
      "Training step:  7496\n",
      "Loss: 928.7183290189863\n",
      "Training step:  7497\n",
      "Loss: 928.7181455609057\n",
      "Training step:  7498\n",
      "Loss: 928.7179627668969\n",
      "Training step:  7499\n",
      "Loss: 928.7177793503646\n",
      "Training step:  7500\n",
      "Loss: 928.7175970824244\n",
      "Training step:  7501\n",
      "Loss: 928.7174137830352\n",
      "Training step:  7502\n",
      "Loss: 928.7172319604981\n",
      "Training step:  7503\n",
      "Loss: 928.71704879265\n",
      "Training step:  7504\n",
      "Loss: 928.7168673077078\n",
      "Training step:  7505\n",
      "Loss: 928.7166843537506\n",
      "Training step:  7506\n",
      "Loss: 928.7165032061843\n",
      "Training step:  7507\n",
      "Loss: 928.7163204659704\n",
      "Training step:  7508\n",
      "Loss: 928.7161390486091\n",
      "Training step:  7509\n",
      "Loss: 928.7159570230866\n",
      "Training step:  7510\n",
      "Loss: 928.7157760740513\n",
      "Training step:  7511\n",
      "Loss: 928.7155941435846\n",
      "Training step:  7512\n",
      "Loss: 928.7154136652158\n",
      "Training step:  7513\n",
      "Loss: 928.7152318662464\n",
      "Training step:  7514\n",
      "Loss: 928.7150518081178\n",
      "Training step:  7515\n",
      "Loss: 928.7148701260327\n",
      "Training step:  7516\n",
      "Loss: 928.7146895750975\n",
      "Training step:  7517\n",
      "Loss: 928.7145089241753\n",
      "Training step:  7518\n",
      "Loss: 928.7143287419451\n",
      "Training step:  7519\n",
      "Loss: 928.71414804088\n",
      "Training step:  7520\n",
      "Loss: 928.7139684629124\n",
      "Training step:  7521\n",
      "Loss: 928.7137878662485\n",
      "Training step:  7522\n",
      "Loss: 928.7136087425678\n",
      "Training step:  7523\n",
      "Loss: 928.7134282772336\n",
      "Training step:  7524\n",
      "Loss: 928.7132495695358\n",
      "Training step:  7525\n",
      "Loss: 928.7130692349277\n",
      "Training step:  7526\n",
      "Loss: 928.7128898689284\n",
      "Training step:  7527\n",
      "Loss: 928.7127109573045\n",
      "Training step:  7528\n",
      "Loss: 928.7125316161396\n",
      "Training step:  7529\n",
      "Loss: 928.7123526356269\n",
      "Training step:  7530\n",
      "Loss: 928.7121739766606\n",
      "Training step:  7531\n",
      "Loss: 928.7119949479206\n",
      "Training step:  7532\n",
      "Loss: 928.7118168852902\n",
      "Training step:  7533\n",
      "Loss: 928.7116379766528\n",
      "Training step:  7534\n",
      "Loss: 928.7114602814709\n",
      "Training step:  7535\n",
      "Loss: 928.711281553809\n",
      "Training step:  7536\n",
      "Loss: 928.7111042843188\n",
      "Training step:  7537\n",
      "Loss: 928.7109256874513\n",
      "Training step:  7538\n",
      "Loss: 928.7107487939996\n",
      "Training step:  7539\n",
      "Loss: 928.7105703755714\n",
      "Training step:  7540\n",
      "Loss: 928.7103934679388\n",
      "Training step:  7541\n",
      "Loss: 928.7102155769051\n",
      "Training step:  7542\n",
      "Loss: 928.7100390621995\n",
      "Training step:  7543\n",
      "Loss: 928.709861302413\n",
      "Training step:  7544\n",
      "Loss: 928.7096851317373\n",
      "Training step:  7545\n",
      "Loss: 928.7095075626167\n",
      "Training step:  7546\n",
      "Loss: 928.7093312105725\n",
      "Training step:  7547\n",
      "Loss: 928.7091542423714\n",
      "Training step:  7548\n",
      "Loss: 928.7089783620496\n",
      "Training step:  7549\n",
      "Loss: 928.7088014983611\n",
      "Training step:  7550\n",
      "Loss: 928.7086260591855\n",
      "Training step:  7551\n",
      "Loss: 928.708449326802\n",
      "Training step:  7552\n",
      "Loss: 928.7082742920248\n",
      "Training step:  7553\n",
      "Loss: 928.7080976904274\n",
      "Training step:  7554\n",
      "Loss: 928.7079219491542\n",
      "Training step:  7555\n",
      "Loss: 928.7077469639107\n",
      "Training step:  7556\n",
      "Loss: 928.7075709298745\n",
      "Training step:  7557\n",
      "Loss: 928.7073962513804\n",
      "Training step:  7558\n",
      "Loss: 928.7072204561533\n",
      "Training step:  7559\n",
      "Loss: 928.7070460073355\n",
      "Training step:  7560\n",
      "Loss: 928.7068704710099\n",
      "Training step:  7561\n",
      "Loss: 928.7066964160136\n",
      "Training step:  7562\n",
      "Loss: 928.706521074855\n",
      "Training step:  7563\n",
      "Loss: 928.7063472549552\n",
      "Training step:  7564\n",
      "Loss: 928.7061721411233\n",
      "Training step:  7565\n",
      "Loss: 928.7059979325612\n",
      "Training step:  7566\n",
      "Loss: 928.7058238178411\n",
      "Training step:  7567\n",
      "Loss: 928.7056499441445\n",
      "Training step:  7568\n",
      "Loss: 928.705475761381\n",
      "Training step:  7569\n",
      "Loss: 928.7053024907649\n",
      "Training step:  7570\n",
      "Loss: 928.7051283543358\n",
      "Training step:  7571\n",
      "Loss: 928.704955524048\n",
      "Training step:  7572\n",
      "Loss: 928.7047815631925\n",
      "Training step:  7573\n",
      "Loss: 928.7046090746283\n",
      "Training step:  7574\n",
      "Loss: 928.7044352859118\n",
      "Training step:  7575\n",
      "Loss: 928.7042627944909\n",
      "Training step:  7576\n",
      "Loss: 928.7040894849374\n",
      "Training step:  7577\n",
      "Loss: 928.7039173905393\n",
      "Training step:  7578\n",
      "Loss: 928.7037441649538\n",
      "Training step:  7579\n",
      "Loss: 928.7035723898393\n",
      "Training step:  7580\n",
      "Loss: 928.7033994302479\n",
      "Training step:  7581\n",
      "Loss: 928.7032279801704\n",
      "Training step:  7582\n",
      "Loss: 928.7030552288425\n",
      "Training step:  7583\n",
      "Loss: 928.7028835870439\n",
      "Training step:  7584\n",
      "Loss: 928.7027114400904\n",
      "Training step:  7585\n",
      "Loss: 928.7025402666455\n",
      "Training step:  7586\n",
      "Loss: 928.70236821147\n",
      "Training step:  7587\n",
      "Loss: 928.7021974986703\n",
      "Training step:  7588\n",
      "Loss: 928.7020255302216\n",
      "Training step:  7589\n",
      "Loss: 928.7018551182748\n",
      "Training step:  7590\n",
      "Loss: 928.7016834213899\n",
      "Training step:  7591\n",
      "Loss: 928.7015128738341\n",
      "Training step:  7592\n",
      "Loss: 928.7013417393301\n",
      "Training step:  7593\n",
      "Loss: 928.7011716385562\n",
      "Training step:  7594\n",
      "Loss: 928.7010006276677\n",
      "Training step:  7595\n",
      "Loss: 928.7008309316777\n",
      "Training step:  7596\n",
      "Loss: 928.7006600522324\n",
      "Training step:  7597\n",
      "Loss: 928.7004907428088\n",
      "Training step:  7598\n",
      "Loss: 928.7003199939915\n",
      "Training step:  7599\n",
      "Loss: 928.7001500776325\n",
      "Training step:  7600\n",
      "Loss: 928.6999807081235\n",
      "Training step:  7601\n",
      "Loss: 928.6998107223861\n",
      "Training step:  7602\n",
      "Loss: 928.6996412883123\n",
      "Training step:  7603\n",
      "Loss: 928.6994719752846\n",
      "Training step:  7604\n",
      "Loss: 928.6993025145774\n",
      "Training step:  7605\n",
      "Loss: 928.699133749547\n",
      "Training step:  7606\n",
      "Loss: 928.6989643426283\n",
      "Training step:  7607\n",
      "Loss: 928.6987960574031\n",
      "Training step:  7608\n",
      "Loss: 928.6986267663304\n",
      "Training step:  7609\n",
      "Loss: 928.6984588800618\n",
      "Training step:  7610\n",
      "Loss: 928.6982897195143\n",
      "Training step:  7611\n",
      "Loss: 928.6981221842418\n",
      "Training step:  7612\n",
      "Loss: 928.6979531967718\n",
      "Training step:  7613\n",
      "Loss: 928.6977853927353\n",
      "Training step:  7614\n",
      "Loss: 928.6976170941757\n",
      "Training step:  7615\n",
      "Loss: 928.6974496891327\n",
      "Training step:  7616\n",
      "Loss: 928.6972815143677\n",
      "Training step:  7617\n",
      "Loss: 928.6971145052127\n",
      "Training step:  7618\n",
      "Loss: 928.6969464461383\n",
      "Training step:  7619\n",
      "Loss: 928.6967798318441\n",
      "Training step:  7620\n",
      "Loss: 928.6966119033799\n",
      "Training step:  7621\n",
      "Loss: 928.6964456086422\n",
      "Training step:  7622\n",
      "Loss: 928.6962778785708\n",
      "Training step:  7623\n",
      "Loss: 928.6961110691296\n",
      "Training step:  7624\n",
      "Loss: 928.6959443710779\n",
      "Training step:  7625\n",
      "Loss: 928.6957778226931\n",
      "Training step:  7626\n",
      "Loss: 928.6956111031886\n",
      "Training step:  7627\n",
      "Loss: 928.6954450896594\n",
      "Training step:  7628\n",
      "Loss: 928.6952784469037\n",
      "Training step:  7629\n",
      "Loss: 928.6951128800782\n",
      "Training step:  7630\n",
      "Loss: 928.6949463542002\n",
      "Training step:  7631\n",
      "Loss: 928.6947811774996\n",
      "Training step:  7632\n",
      "Loss: 928.6946147823423\n",
      "Training step:  7633\n",
      "Loss: 928.6944499784931\n",
      "Training step:  7634\n",
      "Loss: 928.6942837277064\n",
      "Training step:  7635\n",
      "Loss: 928.6941183835966\n",
      "Training step:  7636\n",
      "Loss: 928.6939532384664\n",
      "Training step:  7637\n",
      "Loss: 928.6937880839669\n",
      "Training step:  7638\n",
      "Loss: 928.6936229219949\n",
      "Training step:  7639\n",
      "Loss: 928.693458296249\n",
      "Training step:  7640\n",
      "Loss: 928.6932931716542\n",
      "Training step:  7641\n",
      "Loss: 928.6931290328674\n",
      "Training step:  7642\n",
      "Loss: 928.6929640253283\n",
      "Training step:  7643\n",
      "Loss: 928.6928002719935\n",
      "Training step:  7644\n",
      "Loss: 928.6926353952683\n",
      "Training step:  7645\n",
      "Loss: 928.692471939003\n",
      "Training step:  7646\n",
      "Loss: 928.6923072617869\n",
      "Training step:  7647\n",
      "Loss: 928.6921441008603\n",
      "Training step:  7648\n",
      "Loss: 928.6919796229884\n",
      "Training step:  7649\n",
      "Loss: 928.6918163329033\n",
      "Training step:  7650\n",
      "Loss: 928.691652379228\n",
      "Training step:  7651\n",
      "Loss: 928.6914895202997\n",
      "Training step:  7652\n",
      "Loss: 928.6913256822459\n",
      "Training step:  7653\n",
      "Loss: 928.6911632047785\n",
      "Training step:  7654\n",
      "Loss: 928.690999497202\n",
      "Training step:  7655\n",
      "Loss: 928.6908372877475\n",
      "Training step:  7656\n",
      "Loss: 928.6906738029049\n",
      "Training step:  7657\n",
      "Loss: 928.6905116908216\n",
      "Training step:  7658\n",
      "Loss: 928.690348583972\n",
      "Training step:  7659\n",
      "Loss: 928.6901868307982\n",
      "Training step:  7660\n",
      "Loss: 928.690023854574\n",
      "Training step:  7661\n",
      "Loss: 928.6898623709396\n",
      "Training step:  7662\n",
      "Loss: 928.6896996120872\n",
      "Training step:  7663\n",
      "Loss: 928.6895379915836\n",
      "Training step:  7664\n",
      "Loss: 928.6893757649923\n",
      "Training step:  7665\n",
      "Loss: 928.6892145595481\n",
      "Training step:  7666\n",
      "Loss: 928.6890524303046\n",
      "Training step:  7667\n",
      "Loss: 928.6888916246552\n",
      "Training step:  7668\n",
      "Loss: 928.6887296262297\n",
      "Training step:  7669\n",
      "Loss: 928.6885690858375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  7670\n",
      "Loss: 928.6884073080256\n",
      "Training step:  7671\n",
      "Loss: 928.6882468675717\n",
      "Training step:  7672\n",
      "Loss: 928.6880854395864\n",
      "Training step:  7673\n",
      "Loss: 928.6879253742246\n",
      "Training step:  7674\n",
      "Loss: 928.6877640769238\n",
      "Training step:  7675\n",
      "Loss: 928.6876040015509\n",
      "Training step:  7676\n",
      "Loss: 928.6874431793082\n",
      "Training step:  7677\n",
      "Loss: 928.6872834557033\n",
      "Training step:  7678\n",
      "Loss: 928.687122729781\n",
      "Training step:  7679\n",
      "Loss: 928.6869633488362\n",
      "Training step:  7680\n",
      "Loss: 928.68680280227\n",
      "Training step:  7681\n",
      "Loss: 928.6866432600419\n",
      "Training step:  7682\n",
      "Loss: 928.6864832724731\n",
      "Training step:  7683\n",
      "Loss: 928.6863241196274\n",
      "Training step:  7684\n",
      "Loss: 928.6861642356686\n",
      "Training step:  7685\n",
      "Loss: 928.6860054753424\n",
      "Training step:  7686\n",
      "Loss: 928.6858457087199\n",
      "Training step:  7687\n",
      "Loss: 928.6856873168923\n",
      "Training step:  7688\n",
      "Loss: 928.6855276802637\n",
      "Training step:  7689\n",
      "Loss: 928.6853689263517\n",
      "Training step:  7690\n",
      "Loss: 928.6852101371508\n",
      "Training step:  7691\n",
      "Loss: 928.6850516480088\n",
      "Training step:  7692\n",
      "Loss: 928.6848928635742\n",
      "Training step:  7693\n",
      "Loss: 928.6847348698994\n",
      "Training step:  7694\n",
      "Loss: 928.6845761972185\n",
      "Training step:  7695\n",
      "Loss: 928.6844185832451\n",
      "Training step:  7696\n",
      "Loss: 928.6842600272655\n",
      "Training step:  7697\n",
      "Loss: 928.684102778131\n",
      "Training step:  7698\n",
      "Loss: 928.6839443520827\n",
      "Training step:  7699\n",
      "Loss: 928.6837872571815\n",
      "Training step:  7700\n",
      "Loss: 928.6836291380005\n",
      "Training step:  7701\n",
      "Loss: 928.6834723970791\n",
      "Training step:  7702\n",
      "Loss: 928.6833144075208\n",
      "Training step:  7703\n",
      "Loss: 928.6831571220024\n",
      "Training step:  7704\n",
      "Loss: 928.6830003004819\n",
      "Training step:  7705\n",
      "Loss: 928.6828429187103\n",
      "Training step:  7706\n",
      "Loss: 928.6826865005015\n",
      "Training step:  7707\n",
      "Loss: 928.6825292130814\n",
      "Training step:  7708\n",
      "Loss: 928.6823731648091\n",
      "Training step:  7709\n",
      "Loss: 928.6822160121363\n",
      "Training step:  7710\n",
      "Loss: 928.6820596883178\n",
      "Training step:  7711\n",
      "Loss: 928.6819032999736\n",
      "Training step:  7712\n",
      "Loss: 928.6817472847051\n",
      "Training step:  7713\n",
      "Loss: 928.6815909167369\n",
      "Training step:  7714\n",
      "Loss: 928.6814354010573\n",
      "Training step:  7715\n",
      "Loss: 928.6812791012155\n",
      "Training step:  7716\n",
      "Loss: 928.6811239327883\n",
      "Training step:  7717\n",
      "Loss: 928.6809677961235\n",
      "Training step:  7718\n",
      "Loss: 928.6808129255414\n",
      "Training step:  7719\n",
      "Loss: 928.6806569365028\n",
      "Training step:  7720\n",
      "Loss: 928.6805016084943\n",
      "Training step:  7721\n",
      "Loss: 928.680346779951\n",
      "Training step:  7722\n",
      "Loss: 928.6801914830684\n",
      "Training step:  7723\n",
      "Loss: 928.6800366051025\n",
      "Training step:  7724\n",
      "Loss: 928.6798819218149\n",
      "Training step:  7725\n",
      "Loss: 928.6797270273779\n",
      "Training step:  7726\n",
      "Loss: 928.6795728209715\n",
      "Training step:  7727\n",
      "Loss: 928.6794180186865\n",
      "Training step:  7728\n",
      "Loss: 928.6792642008203\n",
      "Training step:  7729\n",
      "Loss: 928.679109514674\n",
      "Training step:  7730\n",
      "Loss: 928.6789560250803\n",
      "Training step:  7731\n",
      "Loss: 928.6788014916224\n",
      "Training step:  7732\n",
      "Loss: 928.6786482763779\n",
      "Training step:  7733\n",
      "Loss: 928.6784939325782\n",
      "Training step:  7734\n",
      "Loss: 928.6783407224183\n",
      "Training step:  7735\n",
      "Loss: 928.6781868234726\n",
      "Training step:  7736\n",
      "Loss: 928.6780339398504\n",
      "Training step:  7737\n",
      "Loss: 928.6778801573305\n",
      "Training step:  7738\n",
      "Loss: 928.6777276237954\n",
      "Training step:  7739\n",
      "Loss: 928.6775739699689\n",
      "Training step:  7740\n",
      "Loss: 928.6774212989615\n",
      "Training step:  7741\n",
      "Loss: 928.677268171882\n",
      "Training step:  7742\n",
      "Loss: 928.6771158675238\n",
      "Training step:  7743\n",
      "Loss: 928.6769628617441\n",
      "Training step:  7744\n",
      "Loss: 928.6768109055198\n",
      "Training step:  7745\n",
      "Loss: 928.6766580159974\n",
      "Training step:  7746\n",
      "Loss: 928.6765064070286\n",
      "Training step:  7747\n",
      "Loss: 928.6763536460792\n",
      "Training step:  7748\n",
      "Loss: 928.6762018283741\n",
      "Training step:  7749\n",
      "Loss: 928.6760496840083\n",
      "Training step:  7750\n",
      "Loss: 928.6758981973746\n",
      "Training step:  7751\n",
      "Loss: 928.6757461673607\n",
      "Training step:  7752\n",
      "Loss: 928.6755950389826\n",
      "Training step:  7753\n",
      "Loss: 928.6754431256657\n",
      "Training step:  7754\n",
      "Loss: 928.6752923418748\n",
      "Training step:  7755\n",
      "Loss: 928.6751405574419\n",
      "Training step:  7756\n",
      "Loss: 928.6749901038233\n",
      "Training step:  7757\n",
      "Loss: 928.6748384476118\n",
      "Training step:  7758\n",
      "Loss: 928.6746875009271\n",
      "Training step:  7759\n",
      "Loss: 928.6745370047296\n",
      "Training step:  7760\n",
      "Loss: 928.6743859435222\n",
      "Training step:  7761\n",
      "Loss: 928.6742357995084\n",
      "Training step:  7762\n",
      "Loss: 928.6740848551034\n",
      "Training step:  7763\n",
      "Loss: 928.6739350275475\n",
      "Training step:  7764\n",
      "Loss: 928.6737842560519\n",
      "Training step:  7765\n",
      "Loss: 928.6736346202518\n",
      "Training step:  7766\n",
      "Loss: 928.6734840799124\n",
      "Training step:  7767\n",
      "Loss: 928.6733345677791\n",
      "Training step:  7768\n",
      "Loss: 928.6731843156681\n",
      "Training step:  7769\n",
      "Loss: 928.6730351588369\n",
      "Training step:  7770\n",
      "Loss: 928.6728850633936\n",
      "Training step:  7771\n",
      "Loss: 928.6727359526217\n",
      "Training step:  7772\n",
      "Loss: 928.672586206004\n",
      "Training step:  7773\n",
      "Loss: 928.6724375386083\n",
      "Training step:  7774\n",
      "Loss: 928.6722878887638\n",
      "Training step:  7775\n",
      "Loss: 928.6721394660455\n",
      "Training step:  7776\n",
      "Loss: 928.6719900176383\n",
      "Training step:  7777\n",
      "Loss: 928.6718416956533\n",
      "Training step:  7778\n",
      "Loss: 928.6716925540014\n",
      "Training step:  7779\n",
      "Loss: 928.6715445804005\n",
      "Training step:  7780\n",
      "Loss: 928.6713955670178\n",
      "Training step:  7781\n",
      "Loss: 928.6712476568529\n",
      "Training step:  7782\n",
      "Loss: 928.6710989740066\n",
      "Training step:  7783\n",
      "Loss: 928.6709514218828\n",
      "Training step:  7784\n",
      "Loss: 928.6708028550983\n",
      "Training step:  7785\n",
      "Loss: 928.6706555913959\n",
      "Training step:  7786\n",
      "Loss: 928.6705071941371\n",
      "Training step:  7787\n",
      "Loss: 928.6703595601766\n",
      "Training step:  7788\n",
      "Loss: 928.6702120757604\n",
      "Training step:  7789\n",
      "Loss: 928.6700645118067\n",
      "Training step:  7790\n",
      "Loss: 928.6699171075836\n",
      "Training step:  7791\n",
      "Loss: 928.6697699798433\n",
      "Training step:  7792\n",
      "Loss: 928.6696226033865\n",
      "Training step:  7793\n",
      "Loss: 928.669475917873\n",
      "Training step:  7794\n",
      "Loss: 928.6693286354488\n",
      "Training step:  7795\n",
      "Loss: 928.6691823097173\n",
      "Training step:  7796\n",
      "Loss: 928.6690351339107\n",
      "Training step:  7797\n",
      "Loss: 928.6688891262789\n",
      "Training step:  7798\n",
      "Loss: 928.6687420974056\n",
      "Training step:  7799\n",
      "Loss: 928.6685960695667\n",
      "Training step:  7800\n",
      "Loss: 928.6684494617316\n",
      "Training step:  7801\n",
      "Loss: 928.6683037703032\n",
      "Training step:  7802\n",
      "Loss: 928.6681572792331\n",
      "Training step:  7803\n",
      "Loss: 928.6680119158838\n",
      "Training step:  7804\n",
      "Loss: 928.6678655519297\n",
      "Training step:  7805\n",
      "Loss: 928.6677198756369\n",
      "Training step:  7806\n",
      "Loss: 928.6675742775499\n",
      "Training step:  7807\n",
      "Loss: 928.6674288148204\n",
      "Training step:  7808\n",
      "Loss: 928.6672832471485\n",
      "Training step:  7809\n",
      "Loss: 928.6671382189135\n",
      "Training step:  7810\n",
      "Loss: 928.6669927115353\n",
      "Training step:  7811\n",
      "Loss: 928.6668480796138\n",
      "Training step:  7812\n",
      "Loss: 928.6667026877361\n",
      "Training step:  7813\n",
      "Loss: 928.6665583467171\n",
      "Training step:  7814\n",
      "Loss: 928.6664131149429\n",
      "Training step:  7815\n",
      "Loss: 928.666269029549\n",
      "Training step:  7816\n",
      "Loss: 928.6661239782612\n",
      "Training step:  7817\n",
      "Loss: 928.6659800065631\n",
      "Training step:  7818\n",
      "Loss: 928.6658352651242\n",
      "Training step:  7819\n",
      "Loss: 928.665691603824\n",
      "Training step:  7820\n",
      "Loss: 928.6655469892721\n",
      "Training step:  7821\n",
      "Loss: 928.6654032468975\n",
      "Training step:  7822\n",
      "Loss: 928.6652590712682\n",
      "Training step:  7823\n",
      "Loss: 928.6651156827031\n",
      "Training step:  7824\n",
      "Loss: 928.6649716265043\n",
      "Training step:  7825\n",
      "Loss: 928.6648285590029\n",
      "Training step:  7826\n",
      "Loss: 928.6646846183734\n",
      "Training step:  7827\n",
      "Loss: 928.6645418290973\n",
      "Training step:  7828\n",
      "Loss: 928.6643980541877\n",
      "Training step:  7829\n",
      "Loss: 928.664255017025\n",
      "Training step:  7830\n",
      "Loss: 928.6641118942978\n",
      "Training step:  7831\n",
      "Loss: 928.6639691271724\n",
      "Training step:  7832\n",
      "Loss: 928.663826036932\n",
      "Training step:  7833\n",
      "Loss: 928.6636836926406\n",
      "Training step:  7834\n",
      "Loss: 928.6635407116567\n",
      "Training step:  7835\n",
      "Loss: 928.6633986965791\n",
      "Training step:  7836\n",
      "Loss: 928.6632558312093\n",
      "Training step:  7837\n",
      "Loss: 928.6631140919078\n",
      "Training step:  7838\n",
      "Loss: 928.6629713914065\n",
      "Training step:  7839\n",
      "Loss: 928.662829508029\n",
      "Training step:  7840\n",
      "Loss: 928.6626873205256\n",
      "Training step:  7841\n",
      "Loss: 928.6625457585596\n",
      "Training step:  7842\n",
      "Loss: 928.6624036522658\n",
      "Training step:  7843\n",
      "Loss: 928.6622624509146\n",
      "Training step:  7844\n",
      "Loss: 928.6621204599888\n",
      "Training step:  7845\n",
      "Loss: 928.6619795732838\n",
      "Training step:  7846\n",
      "Loss: 928.6618377083912\n",
      "Training step:  7847\n",
      "Loss: 928.6616964823032\n",
      "Training step:  7848\n",
      "Loss: 928.6615554200739\n",
      "Training step:  7849\n",
      "Loss: 928.6614143747231\n",
      "Training step:  7850\n",
      "Loss: 928.6612733313899\n",
      "Training step:  7851\n",
      "Loss: 928.6611327134963\n",
      "Training step:  7852\n",
      "Loss: 928.6609917281489\n",
      "Training step:  7853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 928.6608514960151\n",
      "Training step:  7854\n",
      "Loss: 928.6607106273755\n",
      "Training step:  7855\n",
      "Loss: 928.6605706749775\n",
      "Training step:  7856\n",
      "Loss: 928.6604299522897\n",
      "Training step:  7857\n",
      "Loss: 928.6602902780334\n",
      "Training step:  7858\n",
      "Loss: 928.6601497118168\n",
      "Training step:  7859\n",
      "Loss: 928.6600101463655\n",
      "Training step:  7860\n",
      "Loss: 928.6598698814635\n",
      "Training step:  7861\n",
      "Loss: 928.6597306144671\n",
      "Training step:  7862\n",
      "Loss: 928.6595904752749\n",
      "Training step:  7863\n",
      "Loss: 928.6594511485772\n",
      "Training step:  7864\n",
      "Loss: 928.659311416774\n",
      "Training step:  7865\n",
      "Loss: 928.6591724318034\n",
      "Training step:  7866\n",
      "Loss: 928.6590328081519\n",
      "Training step:  7867\n",
      "Loss: 928.6588941419308\n",
      "Training step:  7868\n",
      "Loss: 928.6587546439602\n",
      "Training step:  7869\n",
      "Loss: 928.6586162028532\n",
      "Training step:  7870\n",
      "Loss: 928.658476897245\n",
      "Training step:  7871\n",
      "Loss: 928.6583384272668\n",
      "Training step:  7872\n",
      "Loss: 928.6581994894523\n",
      "Training step:  7873\n",
      "Loss: 928.6580613701426\n",
      "Training step:  7874\n",
      "Loss: 928.657922548017\n",
      "Training step:  7875\n",
      "Loss: 928.6577847342063\n",
      "Training step:  7876\n",
      "Loss: 928.6576460373986\n",
      "Training step:  7877\n",
      "Loss: 928.657508258972\n",
      "Training step:  7878\n",
      "Loss: 928.6573698984542\n",
      "Training step:  7879\n",
      "Loss: 928.6572324409929\n",
      "Training step:  7880\n",
      "Loss: 928.6570941957401\n",
      "Training step:  7881\n",
      "Loss: 928.6569569729164\n",
      "Training step:  7882\n",
      "Loss: 928.656818908104\n",
      "Training step:  7883\n",
      "Loss: 928.6566816068257\n",
      "Training step:  7884\n",
      "Loss: 928.6565439852508\n",
      "Training step:  7885\n",
      "Loss: 928.6564069987858\n",
      "Training step:  7886\n",
      "Loss: 928.656269481897\n",
      "Training step:  7887\n",
      "Loss: 928.6561328145309\n",
      "Training step:  7888\n",
      "Loss: 928.6559954125979\n",
      "Training step:  7889\n",
      "Loss: 928.6558590465048\n",
      "Training step:  7890\n",
      "Loss: 928.6557217692058\n",
      "Training step:  7891\n",
      "Loss: 928.6555850869693\n",
      "Training step:  7892\n",
      "Loss: 928.6554485673665\n",
      "Training step:  7893\n",
      "Loss: 928.6553120658665\n",
      "Training step:  7894\n",
      "Loss: 928.6551755706668\n",
      "Training step:  7895\n",
      "Loss: 928.655039475975\n",
      "Training step:  7896\n",
      "Loss: 928.6549030416019\n",
      "Training step:  7897\n",
      "Loss: 928.6547673147534\n",
      "Training step:  7898\n",
      "Loss: 928.6546309966519\n",
      "Training step:  7899\n",
      "Loss: 928.6544955682291\n",
      "Training step:  7900\n",
      "Loss: 928.6543593644681\n",
      "Training step:  7901\n",
      "Loss: 928.6542241832519\n",
      "Training step:  7902\n",
      "Loss: 928.6540881508287\n",
      "Training step:  7903\n",
      "Loss: 928.6539530490451\n",
      "Training step:  7904\n",
      "Loss: 928.6538173211364\n",
      "Training step:  7905\n",
      "Loss: 928.6536825181117\n",
      "Training step:  7906\n",
      "Loss: 928.6535469143191\n",
      "Training step:  7907\n",
      "Loss: 928.6534123024663\n",
      "Training step:  7908\n",
      "Loss: 928.6532769036507\n",
      "Training step:  7909\n",
      "Loss: 928.6531425187211\n",
      "Training step:  7910\n",
      "Loss: 928.6530073028525\n",
      "Training step:  7911\n",
      "Loss: 928.6528727917093\n",
      "Training step:  7912\n",
      "Loss: 928.6527380620445\n",
      "Training step:  7913\n",
      "Loss: 928.652603836517\n",
      "Training step:  7914\n",
      "Loss: 928.6524691913206\n",
      "Training step:  7915\n",
      "Loss: 928.6523353002486\n",
      "Training step:  7916\n",
      "Loss: 928.652200770903\n",
      "Training step:  7917\n",
      "Loss: 928.6520671729735\n",
      "Training step:  7918\n",
      "Loss: 928.6519327576452\n",
      "Training step:  7919\n",
      "Loss: 928.6517991057436\n",
      "Training step:  7920\n",
      "Loss: 928.6516650891065\n",
      "Training step:  7921\n",
      "Loss: 928.6515317621266\n",
      "Training step:  7922\n",
      "Loss: 928.6513978488576\n",
      "Training step:  7923\n",
      "Loss: 928.6512648295189\n",
      "Training step:  7924\n",
      "Loss: 928.6511310402819\n",
      "Training step:  7925\n",
      "Loss: 928.6509980690421\n",
      "Training step:  7926\n",
      "Loss: 928.6508645935437\n",
      "Training step:  7927\n",
      "Loss: 928.6507319241928\n",
      "Training step:  7928\n",
      "Loss: 928.6505985635235\n",
      "Training step:  7929\n",
      "Loss: 928.6504661838411\n",
      "Training step:  7930\n",
      "Loss: 928.650332946436\n",
      "Training step:  7931\n",
      "Loss: 928.6502002136953\n",
      "Training step:  7932\n",
      "Loss: 928.650067834193\n",
      "Training step:  7933\n",
      "Loss: 928.64993506723\n",
      "Training step:  7934\n",
      "Loss: 928.6498030040188\n",
      "Training step:  7935\n",
      "Loss: 928.6496703347656\n",
      "Training step:  7936\n",
      "Loss: 928.6495385655701\n",
      "Training step:  7937\n",
      "Loss: 928.6494060231356\n",
      "Training step:  7938\n",
      "Loss: 928.6492740815717\n",
      "Training step:  7939\n",
      "Loss: 928.6491421274419\n",
      "Training step:  7940\n",
      "Loss: 928.6490104279393\n",
      "Training step:  7941\n",
      "Loss: 928.6488785247992\n",
      "Training step:  7942\n",
      "Loss: 928.6487471640443\n",
      "Training step:  7943\n",
      "Loss: 928.6486153606216\n",
      "Training step:  7944\n",
      "Loss: 928.6484842920721\n",
      "Training step:  7945\n",
      "Loss: 928.6483526155494\n",
      "Training step:  7946\n",
      "Loss: 928.6482218085201\n",
      "Training step:  7947\n",
      "Loss: 928.6480902920313\n",
      "Training step:  7948\n",
      "Loss: 928.6479596678071\n",
      "Training step:  7949\n",
      "Loss: 928.6478283525299\n",
      "Training step:  7950\n",
      "Loss: 928.6476979479767\n",
      "Training step:  7951\n",
      "Loss: 928.647566809386\n",
      "Training step:  7952\n",
      "Loss: 928.6474363433291\n",
      "Training step:  7953\n",
      "Loss: 928.6473056643248\n",
      "Training step:  7954\n",
      "Loss: 928.6471754736245\n",
      "Training step:  7955\n",
      "Loss: 928.6470448832227\n",
      "Training step:  7956\n",
      "Loss: 928.64691500704\n",
      "Training step:  7957\n",
      "Loss: 928.6467845102878\n",
      "Training step:  7958\n",
      "Loss: 928.6466549037046\n",
      "Training step:  7959\n",
      "Loss: 928.6465245615004\n",
      "Training step:  7960\n",
      "Loss: 928.6463947818863\n",
      "Training step:  7961\n",
      "Loss: 928.6462649982167\n",
      "Training step:  7962\n",
      "Loss: 928.6461354363172\n",
      "Training step:  7963\n",
      "Loss: 928.6460056970462\n",
      "Training step:  7964\n",
      "Loss: 928.6458765010643\n",
      "Training step:  7965\n",
      "Loss: 928.6457468580288\n",
      "Training step:  7966\n",
      "Loss: 928.6456179640044\n",
      "Training step:  7967\n",
      "Loss: 928.6454884344854\n",
      "Training step:  7968\n",
      "Loss: 928.6453598018431\n",
      "Training step:  7969\n",
      "Loss: 928.645230410648\n",
      "Training step:  7970\n",
      "Loss: 928.6451018891343\n",
      "Training step:  7971\n",
      "Loss: 928.6449727652843\n",
      "Training step:  7972\n",
      "Loss: 928.644844512373\n",
      "Training step:  7973\n",
      "Loss: 928.644715510199\n",
      "Training step:  7974\n",
      "Loss: 928.6445871712366\n",
      "Training step:  7975\n",
      "Loss: 928.6444585959009\n",
      "Training step:  7976\n",
      "Loss: 928.6443305349866\n",
      "Training step:  7977\n",
      "Loss: 928.6442020492725\n",
      "Training step:  7978\n",
      "Loss: 928.644074295814\n",
      "Training step:  7979\n",
      "Loss: 928.6439459234249\n",
      "Training step:  7980\n",
      "Loss: 928.6438184455707\n",
      "Training step:  7981\n",
      "Loss: 928.6436901945817\n",
      "Training step:  7982\n",
      "Loss: 928.6435626104055\n",
      "Training step:  7983\n",
      "Loss: 928.6434347974987\n",
      "Training step:  7984\n",
      "Loss: 928.6433074971976\n",
      "Training step:  7985\n",
      "Loss: 928.6431797689852\n",
      "Training step:  7986\n",
      "Loss: 928.6430527793241\n",
      "Training step:  7987\n",
      "Loss: 928.6429251639472\n",
      "Training step:  7988\n",
      "Loss: 928.6427984214957\n",
      "Training step:  7989\n",
      "Loss: 928.6426709526004\n",
      "Training step:  7990\n",
      "Loss: 928.6425442961505\n",
      "Training step:  7991\n",
      "Loss: 928.6424170874022\n",
      "Training step:  7992\n",
      "Loss: 928.6422907195428\n",
      "Training step:  7993\n",
      "Loss: 928.6421636317309\n",
      "Training step:  7994\n",
      "Loss: 928.6420372077673\n",
      "Training step:  7995\n",
      "Loss: 928.6419105042685\n",
      "Training step:  7996\n",
      "Loss: 928.6417843663736\n",
      "Training step:  7997\n",
      "Loss: 928.6416577516883\n",
      "Training step:  7998\n",
      "Loss: 928.6415319149597\n",
      "Training step:  7999\n",
      "Loss: 928.6414054124839\n",
      "Training step:  8000\n",
      "Loss: 928.6412798200545\n",
      "Training step:  8001\n",
      "Loss: 928.641153462959\n",
      "Training step:  8002\n",
      "Loss: 928.6410275669275\n",
      "Training step:  8003\n",
      "Loss: 928.6409020908867\n",
      "Training step:  8004\n",
      "Loss: 928.6407761479073\n",
      "Training step:  8005\n",
      "Loss: 928.6406506720492\n",
      "Training step:  8006\n",
      "Loss: 928.6405251282761\n",
      "Training step:  8007\n",
      "Loss: 928.6403997034281\n",
      "Training step:  8008\n",
      "Loss: 928.6402745086191\n",
      "Training step:  8009\n",
      "Loss: 928.6401491311407\n",
      "Training step:  8010\n",
      "Loss: 928.6400242842957\n",
      "Training step:  8011\n",
      "Loss: 928.6398990211947\n",
      "Training step:  8012\n",
      "Loss: 928.6397744416537\n",
      "Training step:  8013\n",
      "Loss: 928.6396492901222\n",
      "Training step:  8014\n",
      "Loss: 928.6395249347045\n",
      "Training step:  8015\n",
      "Loss: 928.639399943132\n",
      "Training step:  8016\n",
      "Loss: 928.6392757745248\n",
      "Training step:  8017\n",
      "Loss: 928.6391509706448\n",
      "Training step:  8018\n",
      "Loss: 928.6390270163301\n",
      "Training step:  8019\n",
      "Loss: 928.6389023717928\n",
      "Training step:  8020\n",
      "Loss: 928.6387784454218\n",
      "Training step:  8021\n",
      "Loss: 928.6386541130685\n",
      "Training step:  8022\n",
      "Loss: 928.6385304584679\n",
      "Training step:  8023\n",
      "Loss: 928.6384062389494\n",
      "Training step:  8024\n",
      "Loss: 928.638282848433\n",
      "Training step:  8025\n",
      "Loss: 928.6381587484253\n",
      "Training step:  8026\n",
      "Loss: 928.6380351034463\n",
      "Training step:  8027\n",
      "Loss: 928.6379116965618\n",
      "Training step:  8028\n",
      "Loss: 928.6377881603371\n",
      "Training step:  8029\n",
      "Loss: 928.6376647932075\n",
      "Training step:  8030\n",
      "Loss: 928.6375416072536\n",
      "Training step:  8031\n",
      "Loss: 928.6374182894439\n",
      "Training step:  8032\n",
      "Loss: 928.6372954432554\n",
      "Training step:  8033\n",
      "Loss: 928.6371722221816\n",
      "Training step:  8034\n",
      "Loss: 928.6370496579378\n",
      "Training step:  8035\n",
      "Loss: 928.6369265482274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  8036\n",
      "Loss: 928.6368042202719\n",
      "Training step:  8037\n",
      "Loss: 928.6366812533266\n",
      "Training step:  8038\n",
      "Loss: 928.6365591064241\n",
      "Training step:  8039\n",
      "Loss: 928.6364363255963\n",
      "Training step:  8040\n",
      "Loss: 928.6363143378437\n",
      "Training step:  8041\n",
      "Loss: 928.6361917554142\n",
      "Training step:  8042\n",
      "Loss: 928.6360699929111\n",
      "Training step:  8043\n",
      "Loss: 928.6359475576953\n",
      "Training step:  8044\n",
      "Loss: 928.6358256481328\n",
      "Training step:  8045\n",
      "Loss: 928.6357037190262\n",
      "Training step:  8046\n",
      "Loss: 928.635582016506\n",
      "Training step:  8047\n",
      "Loss: 928.6354601376906\n",
      "Training step:  8048\n",
      "Loss: 928.6353387690497\n",
      "Training step:  8049\n",
      "Loss: 928.6352169784418\n",
      "Training step:  8050\n",
      "Loss: 928.6350958954147\n",
      "Training step:  8051\n",
      "Loss: 928.6349742154939\n",
      "Training step:  8052\n",
      "Loss: 928.6348533497328\n",
      "Training step:  8053\n",
      "Loss: 928.6347318259409\n",
      "Training step:  8054\n",
      "Loss: 928.6346109648777\n",
      "Training step:  8055\n",
      "Loss: 928.6344897557232\n",
      "Training step:  8056\n",
      "Loss: 928.6343691713128\n",
      "Training step:  8057\n",
      "Loss: 928.6342480745187\n",
      "Training step:  8058\n",
      "Loss: 928.6341277456686\n",
      "Training step:  8059\n",
      "Loss: 928.6340067671395\n",
      "Training step:  8060\n",
      "Loss: 928.6338862440982\n",
      "Training step:  8061\n",
      "Loss: 928.6337658395296\n",
      "Training step:  8062\n",
      "Loss: 928.6336454806745\n",
      "Training step:  8063\n",
      "Loss: 928.6335251287727\n",
      "Training step:  8064\n",
      "Loss: 928.6334050982018\n",
      "Training step:  8065\n",
      "Loss: 928.6332848142578\n",
      "Training step:  8066\n",
      "Loss: 928.6331650908556\n",
      "Training step:  8067\n",
      "Loss: 928.6330449185807\n",
      "Training step:  8068\n",
      "Loss: 928.6329254483363\n",
      "Training step:  8069\n",
      "Loss: 928.6328053860249\n",
      "Training step:  8070\n",
      "Loss: 928.6326861028003\n",
      "Training step:  8071\n",
      "Loss: 928.6325662128323\n",
      "Training step:  8072\n",
      "Loss: 928.6324470935178\n",
      "Training step:  8073\n",
      "Loss: 928.6323273969072\n",
      "Training step:  8074\n",
      "Loss: 928.632208476646\n",
      "Training step:  8075\n",
      "Loss: 928.6320889445107\n",
      "Training step:  8076\n",
      "Loss: 928.6319700787163\n",
      "Training step:  8077\n",
      "Loss: 928.6318508153659\n",
      "Training step:  8078\n",
      "Loss: 928.631732212478\n",
      "Training step:  8079\n",
      "Loss: 928.631613060157\n",
      "Training step:  8080\n",
      "Loss: 928.631494678519\n",
      "Training step:  8081\n",
      "Loss: 928.6313756703113\n",
      "Training step:  8082\n",
      "Loss: 928.6312571534695\n",
      "Training step:  8083\n",
      "Loss: 928.6311386161029\n",
      "Training step:  8084\n",
      "Loss: 928.631020316244\n",
      "Training step:  8085\n",
      "Loss: 928.6309018315499\n",
      "Training step:  8086\n",
      "Loss: 928.6307838521036\n",
      "Training step:  8087\n",
      "Loss: 928.6306654511776\n",
      "Training step:  8088\n",
      "Loss: 928.6305477514283\n",
      "Training step:  8089\n",
      "Loss: 928.6304294678407\n",
      "Training step:  8090\n",
      "Loss: 928.630311922452\n",
      "Training step:  8091\n",
      "Loss: 928.6301938293947\n",
      "Training step:  8092\n",
      "Loss: 928.6300765002505\n",
      "Training step:  8093\n",
      "Loss: 928.629958550286\n",
      "Training step:  8094\n",
      "Loss: 928.6298410402557\n",
      "Training step:  8095\n",
      "Loss: 928.6297236319426\n",
      "Training step:  8096\n",
      "Loss: 928.629606293643\n",
      "Training step:  8097\n",
      "Loss: 928.6294889394766\n",
      "Training step:  8098\n",
      "Loss: 928.6293719176055\n",
      "Training step:  8099\n",
      "Loss: 928.6292546323846\n",
      "Training step:  8100\n",
      "Loss: 928.6291379068588\n",
      "Training step:  8101\n",
      "Loss: 928.6290207315435\n",
      "Training step:  8102\n",
      "Loss: 928.6289042287153\n",
      "Training step:  8103\n",
      "Loss: 928.6287871836385\n",
      "Training step:  8104\n",
      "Loss: 928.6286708635342\n",
      "Training step:  8105\n",
      "Loss: 928.6285539866128\n",
      "Training step:  8106\n",
      "Loss: 928.6284378397579\n",
      "Training step:  8107\n",
      "Loss: 928.6283211450203\n",
      "Training step:  8108\n",
      "Loss: 928.6282051614899\n",
      "Training step:  8109\n",
      "Loss: 928.6280886421732\n",
      "Training step:  8110\n",
      "Loss: 928.6279728711554\n",
      "Training step:  8111\n",
      "Loss: 928.6278564934075\n",
      "Training step:  8112\n",
      "Loss: 928.6277404763255\n",
      "Training step:  8113\n",
      "Loss: 928.6276248139839\n",
      "Training step:  8114\n",
      "Loss: 928.6275088155676\n",
      "Training step:  8115\n",
      "Loss: 928.6273931756406\n",
      "Training step:  8116\n",
      "Loss: 928.627277528821\n",
      "Training step:  8117\n",
      "Loss: 928.6271619445754\n",
      "Training step:  8118\n",
      "Loss: 928.6270466075064\n",
      "Training step:  8119\n",
      "Loss: 928.6269310932028\n",
      "Training step:  8120\n",
      "Loss: 928.6268160463881\n",
      "Training step:  8121\n",
      "Loss: 928.6267006427838\n",
      "Training step:  8122\n",
      "Loss: 928.6265858145352\n",
      "Training step:  8123\n",
      "Loss: 928.6264705398193\n",
      "Training step:  8124\n",
      "Loss: 928.6263559157366\n",
      "Training step:  8125\n",
      "Loss: 928.6262407829397\n",
      "Training step:  8126\n",
      "Loss: 928.6261263625114\n",
      "Training step:  8127\n",
      "Loss: 928.6260113786544\n",
      "Training step:  8128\n",
      "Loss: 928.6258970651965\n",
      "Training step:  8129\n",
      "Loss: 928.6257822946236\n",
      "Training step:  8130\n",
      "Loss: 928.625668230006\n",
      "Training step:  8131\n",
      "Loss: 928.6255535747034\n",
      "Training step:  8132\n",
      "Loss: 928.6254393516092\n",
      "Training step:  8133\n",
      "Loss: 928.6253252103488\n",
      "Training step:  8134\n",
      "Loss: 928.6252111502023\n",
      "Training step:  8135\n",
      "Loss: 928.6250970645054\n",
      "Training step:  8136\n",
      "Loss: 928.6249833081074\n",
      "Training step:  8137\n",
      "Loss: 928.6248693087182\n",
      "Training step:  8138\n",
      "Loss: 928.6247558182616\n",
      "Training step:  8139\n",
      "Loss: 928.624641928112\n",
      "Training step:  8140\n",
      "Loss: 928.6245286527698\n",
      "Training step:  8141\n",
      "Loss: 928.6244148903886\n",
      "Training step:  8142\n",
      "Loss: 928.6243018160571\n",
      "Training step:  8143\n",
      "Loss: 928.6241882011823\n",
      "Training step:  8144\n",
      "Loss: 928.6240752710083\n",
      "Training step:  8145\n",
      "Loss: 928.6239618224471\n",
      "Training step:  8146\n",
      "Loss: 928.6238490188357\n",
      "Training step:  8147\n",
      "Loss: 928.6237357762658\n",
      "Training step:  8148\n",
      "Loss: 928.6236232266881\n",
      "Training step:  8149\n",
      "Loss: 928.6235100987572\n",
      "Training step:  8150\n",
      "Loss: 928.6233973818477\n",
      "Training step:  8151\n",
      "Loss: 928.6232847702297\n",
      "Training step:  8152\n",
      "Loss: 928.6231722137239\n",
      "Training step:  8153\n",
      "Loss: 928.623059658988\n",
      "Training step:  8154\n",
      "Loss: 928.622947400452\n",
      "Training step:  8155\n",
      "Loss: 928.6228349011027\n",
      "Training step:  8156\n",
      "Loss: 928.6227229397041\n",
      "Training step:  8157\n",
      "Loss: 928.6226105481005\n",
      "Training step:  8158\n",
      "Loss: 928.6224987981649\n",
      "Training step:  8159\n",
      "Loss: 928.6223865332017\n",
      "Training step:  8160\n",
      "Loss: 928.6222749558067\n",
      "Training step:  8161\n",
      "Loss: 928.6221628605092\n",
      "Training step:  8162\n",
      "Loss: 928.6220514302597\n",
      "Training step:  8163\n",
      "Loss: 928.6219394989624\n",
      "Training step:  8164\n",
      "Loss: 928.6218281494204\n",
      "Training step:  8165\n",
      "Loss: 928.6217164637781\n",
      "Training step:  8166\n",
      "Loss: 928.6216053554974\n",
      "Training step:  8167\n",
      "Loss: 928.6214937627532\n",
      "Training step:  8168\n",
      "Loss: 928.6213828553775\n",
      "Training step:  8169\n",
      "Loss: 928.6212714189303\n",
      "Training step:  8170\n",
      "Loss: 928.621160454117\n",
      "Training step:  8171\n",
      "Loss: 928.621049367858\n",
      "Training step:  8172\n",
      "Loss: 928.6209386372952\n",
      "Training step:  8173\n",
      "Loss: 928.6208276365628\n",
      "Training step:  8174\n",
      "Loss: 928.6207171623927\n",
      "Training step:  8175\n",
      "Loss: 928.6206062544943\n",
      "Training step:  8176\n",
      "Loss: 928.6204960051151\n",
      "Training step:  8177\n",
      "Loss: 928.6203852296892\n",
      "Training step:  8178\n",
      "Loss: 928.6202749237284\n",
      "Training step:  8179\n",
      "Loss: 928.6201644958292\n",
      "Training step:  8180\n",
      "Loss: 928.6200544234174\n",
      "Training step:  8181\n",
      "Loss: 928.6199440811349\n",
      "Training step:  8182\n",
      "Loss: 928.6198342630568\n",
      "Training step:  8183\n",
      "Loss: 928.6197240134919\n",
      "Training step:  8184\n",
      "Loss: 928.6196144183762\n",
      "Training step:  8185\n",
      "Loss: 928.619504300584\n",
      "Training step:  8186\n",
      "Loss: 928.6193946556294\n",
      "Training step:  8187\n",
      "Loss: 928.619284881771\n",
      "Training step:  8188\n",
      "Loss: 928.6191754639053\n",
      "Training step:  8189\n",
      "Loss: 928.6190657757364\n",
      "Training step:  8190\n",
      "Loss: 928.6189566101534\n",
      "Training step:  8191\n",
      "Loss: 928.6188470144753\n",
      "Training step:  8192\n",
      "Loss: 928.6187380700222\n",
      "Training step:  8193\n",
      "Loss: 928.618628605424\n",
      "Training step:  8194\n",
      "Loss: 928.6185195842091\n",
      "Training step:  8195\n",
      "Loss: 928.6184104926118\n",
      "Training step:  8196\n",
      "Loss: 928.6183016880411\n",
      "Training step:  8197\n",
      "Loss: 928.6181926685979\n",
      "Training step:  8198\n",
      "Loss: 928.6180841309264\n",
      "Training step:  8199\n",
      "Loss: 928.6179752042556\n",
      "Training step:  8200\n",
      "Loss: 928.6178668862954\n",
      "Training step:  8201\n",
      "Loss: 928.6177580838754\n",
      "Training step:  8202\n",
      "Loss: 928.617649858774\n",
      "Training step:  8203\n",
      "Loss: 928.6175412647519\n",
      "Training step:  8204\n",
      "Loss: 928.6174332783535\n",
      "Training step:  8205\n",
      "Loss: 928.6173247969035\n",
      "Training step:  8206\n",
      "Loss: 928.6172167768711\n",
      "Training step:  8207\n",
      "Loss: 928.6171086184119\n",
      "Training step:  8208\n",
      "Loss: 928.6170008236246\n",
      "Training step:  8209\n",
      "Loss: 928.6168927502853\n",
      "Training step:  8210\n",
      "Loss: 928.6167852027428\n",
      "Training step:  8211\n",
      "Loss: 928.6166772212268\n",
      "Training step:  8212\n",
      "Loss: 928.6165698785669\n",
      "Training step:  8213\n",
      "Loss: 928.6164620379471\n",
      "Training step:  8214\n",
      "Loss: 928.6163546092663\n",
      "Training step:  8215\n",
      "Loss: 928.6162471567691\n",
      "Training step:  8216\n",
      "Loss: 928.6161399269631\n",
      "Training step:  8217\n",
      "Loss: 928.6160325327129\n",
      "Training step:  8218\n",
      "Loss: 928.6159255810921\n",
      "Training step:  8219\n",
      "Loss: 928.6158182738119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  8220\n",
      "Loss: 928.615711544181\n",
      "Training step:  8221\n",
      "Loss: 928.6156043598667\n",
      "Training step:  8222\n",
      "Loss: 928.6154977785825\n",
      "Training step:  8223\n",
      "Loss: 928.6153907511765\n",
      "Training step:  8224\n",
      "Loss: 928.6152842862693\n",
      "Training step:  8225\n",
      "Loss: 928.6151774558849\n",
      "Training step:  8226\n",
      "Loss: 928.6150712222092\n",
      "Training step:  8227\n",
      "Loss: 928.6149645031197\n",
      "Training step:  8228\n",
      "Loss: 928.6148581631952\n",
      "Training step:  8229\n",
      "Loss: 928.6147518735125\n",
      "Training step:  8230\n",
      "Loss: 928.6146456966036\n",
      "Training step:  8231\n",
      "Loss: 928.6145394658919\n",
      "Training step:  8232\n",
      "Loss: 928.6144335631577\n",
      "Training step:  8233\n",
      "Loss: 928.6143274210226\n",
      "Training step:  8234\n",
      "Loss: 928.6142217557294\n",
      "Training step:  8235\n",
      "Loss: 928.6141157048718\n",
      "Training step:  8236\n",
      "Loss: 928.6140102399902\n",
      "Training step:  8237\n",
      "Loss: 928.6139043280552\n",
      "Training step:  8238\n",
      "Loss: 928.6137990103152\n",
      "Training step:  8239\n",
      "Loss: 928.6136932471219\n",
      "Training step:  8240\n",
      "Loss: 928.6135880625693\n",
      "Training step:  8241\n",
      "Loss: 928.6134824811271\n",
      "Training step:  8242\n",
      "Loss: 928.6133774809553\n",
      "Training step:  8243\n",
      "Loss: 928.6132720281751\n",
      "Training step:  8244\n",
      "Loss: 928.6131669212234\n",
      "Training step:  8245\n",
      "Loss: 928.6130619017248\n",
      "Training step:  8246\n",
      "Loss: 928.6129569659256\n",
      "Training step:  8247\n",
      "Loss: 928.6128520054241\n",
      "Training step:  8248\n",
      "Loss: 928.612747339221\n",
      "Training step:  8249\n",
      "Loss: 928.6126424646012\n",
      "Training step:  8250\n",
      "Loss: 928.6125380359642\n",
      "Training step:  8251\n",
      "Loss: 928.6124332661406\n",
      "Training step:  8252\n",
      "Loss: 928.6123290313606\n",
      "Training step:  8253\n",
      "Loss: 928.612224382122\n",
      "Training step:  8254\n",
      "Loss: 928.6121203297228\n",
      "Training step:  8255\n",
      "Loss: 928.6120158177503\n",
      "Training step:  8256\n",
      "Loss: 928.6119118998312\n",
      "Training step:  8257\n",
      "Loss: 928.611807545647\n",
      "Training step:  8258\n",
      "Loss: 928.6117036923747\n",
      "Training step:  8259\n",
      "Loss: 928.6115995814877\n",
      "Training step:  8260\n",
      "Loss: 928.6114959437972\n",
      "Training step:  8261\n",
      "Loss: 928.6113919241834\n",
      "Training step:  8262\n",
      "Loss: 928.6112884932314\n",
      "Training step:  8263\n",
      "Loss: 928.6111845995576\n",
      "Training step:  8264\n",
      "Loss: 928.6110811041634\n",
      "Training step:  8265\n",
      "Loss: 928.6109775586282\n",
      "Training step:  8266\n",
      "Loss: 928.6108742634362\n",
      "Training step:  8267\n",
      "Loss: 928.6107707777667\n",
      "Training step:  8268\n",
      "Loss: 928.6106677464003\n",
      "Training step:  8269\n",
      "Loss: 928.6105643519627\n",
      "Training step:  8270\n",
      "Loss: 928.6104615258049\n",
      "Training step:  8271\n",
      "Loss: 928.6103582568447\n",
      "Training step:  8272\n",
      "Loss: 928.6102555022709\n",
      "Training step:  8273\n",
      "Loss: 928.610152444018\n",
      "Training step:  8274\n",
      "Loss: 928.6100499094362\n",
      "Training step:  8275\n",
      "Loss: 928.6099469549558\n",
      "Training step:  8276\n",
      "Loss: 928.6098445736064\n",
      "Training step:  8277\n",
      "Loss: 928.6097417596447\n",
      "Training step:  8278\n",
      "Loss: 928.6096393064961\n",
      "Training step:  8279\n",
      "Loss: 928.6095368629184\n",
      "Training step:  8280\n",
      "Loss: 928.609434604176\n",
      "Training step:  8281\n",
      "Loss: 928.6093322201373\n",
      "Training step:  8282\n",
      "Loss: 928.6092302214051\n",
      "Training step:  8283\n",
      "Loss: 928.6091279213175\n",
      "Training step:  8284\n",
      "Loss: 928.6090261345303\n",
      "Training step:  8285\n",
      "Loss: 928.6089239532278\n",
      "Training step:  8286\n",
      "Loss: 928.6088223547887\n",
      "Training step:  8287\n",
      "Loss: 928.6087202975514\n",
      "Training step:  8288\n",
      "Loss: 928.6086185983826\n",
      "Training step:  8289\n",
      "Loss: 928.6085169578643\n",
      "Training step:  8290\n",
      "Loss: 928.6084154053384\n",
      "Training step:  8291\n",
      "Loss: 928.6083138200117\n",
      "Training step:  8292\n",
      "Loss: 928.608212531253\n",
      "Training step:  8293\n",
      "Loss: 928.6081110307242\n",
      "Training step:  8294\n",
      "Loss: 928.6080099693224\n",
      "Training step:  8295\n",
      "Loss: 928.6079085588595\n",
      "Training step:  8296\n",
      "Loss: 928.6078076865934\n",
      "Training step:  8297\n",
      "Loss: 928.6077064039789\n",
      "Training step:  8298\n",
      "Loss: 928.6076056872068\n",
      "Training step:  8299\n",
      "Loss: 928.6075045574005\n",
      "Training step:  8300\n",
      "Loss: 928.6074039995062\n",
      "Training step:  8301\n",
      "Loss: 928.6073030121178\n",
      "Training step:  8302\n",
      "Loss: 928.6072023863288\n",
      "Training step:  8303\n",
      "Loss: 928.6071017503504\n",
      "Training step:  8304\n",
      "Loss: 928.6070013083423\n",
      "Training step:  8305\n",
      "Loss: 928.6069007330913\n",
      "Training step:  8306\n",
      "Loss: 928.6068005446067\n",
      "Training step:  8307\n",
      "Loss: 928.6067000554754\n",
      "Training step:  8308\n",
      "Loss: 928.6066000711133\n",
      "Training step:  8309\n",
      "Loss: 928.6064996869263\n",
      "Training step:  8310\n",
      "Loss: 928.6063997075936\n",
      "Training step:  8311\n",
      "Loss: 928.6062996004442\n",
      "Training step:  8312\n",
      "Loss: 928.6061998346241\n",
      "Training step:  8313\n",
      "Loss: 928.6060998140339\n",
      "Training step:  8314\n",
      "Loss: 928.6060002514511\n",
      "Training step:  8315\n",
      "Loss: 928.6059003355208\n",
      "Training step:  8316\n",
      "Loss: 928.6058009692198\n",
      "Training step:  8317\n",
      "Loss: 928.6057011753611\n",
      "Training step:  8318\n",
      "Loss: 928.6056017549105\n",
      "Training step:  8319\n",
      "Loss: 928.605502289515\n",
      "Training step:  8320\n",
      "Loss: 928.6054030601731\n",
      "Training step:  8321\n",
      "Loss: 928.6053036677472\n",
      "Training step:  8322\n",
      "Loss: 928.6052046733561\n",
      "Training step:  8323\n",
      "Loss: 928.6051053706954\n",
      "Training step:  8324\n",
      "Loss: 928.6050065717011\n",
      "Training step:  8325\n",
      "Loss: 928.6049073786223\n",
      "Training step:  8326\n",
      "Loss: 928.6048086919875\n",
      "Training step:  8327\n",
      "Loss: 928.6047096774687\n",
      "Training step:  8328\n",
      "Loss: 928.6046111808346\n",
      "Training step:  8329\n",
      "Loss: 928.6045122756531\n",
      "Training step:  8330\n",
      "Loss: 928.6044136609735\n",
      "Training step:  8331\n",
      "Loss: 928.6043152069668\n",
      "Training step:  8332\n",
      "Loss: 928.6042167059959\n",
      "Training step:  8333\n",
      "Loss: 928.6041183103926\n",
      "Training step:  8334\n",
      "Loss: 928.6040200618233\n",
      "Training step:  8335\n",
      "Loss: 928.6039217271216\n",
      "Training step:  8336\n",
      "Loss: 928.603823724267\n",
      "Training step:  8337\n",
      "Loss: 928.6037254756221\n",
      "Training step:  8338\n",
      "Loss: 928.6036276703339\n",
      "Training step:  8339\n",
      "Loss: 928.6035295369122\n",
      "Training step:  8340\n",
      "Loss: 928.6034319012152\n",
      "Training step:  8341\n",
      "Loss: 928.6033338923169\n",
      "Training step:  8342\n",
      "Loss: 928.6032364258848\n",
      "Training step:  8343\n",
      "Loss: 928.6031385465385\n",
      "Training step:  8344\n",
      "Loss: 928.6030411485123\n",
      "Training step:  8345\n",
      "Loss: 928.6029434697915\n",
      "Training step:  8346\n",
      "Loss: 928.6028462624074\n",
      "Training step:  8347\n",
      "Loss: 928.6027486868837\n",
      "Training step:  8348\n",
      "Loss: 928.6026516214482\n",
      "Training step:  8349\n",
      "Loss: 928.6025541950864\n",
      "Training step:  8350\n",
      "Loss: 928.6024572988815\n",
      "Training step:  8351\n",
      "Loss: 928.6023600061098\n",
      "Training step:  8352\n",
      "Loss: 928.6022631012951\n",
      "Training step:  8353\n",
      "Loss: 928.6021660825369\n",
      "Training step:  8354\n",
      "Loss: 928.6020693751065\n",
      "Training step:  8355\n",
      "Loss: 928.6019724396539\n",
      "Training step:  8356\n",
      "Loss: 928.6018759460002\n",
      "Training step:  8357\n",
      "Loss: 928.6017790991872\n",
      "Training step:  8358\n",
      "Loss: 928.601682794271\n",
      "Training step:  8359\n",
      "Loss: 928.6015860664253\n",
      "Training step:  8360\n",
      "Loss: 928.6014896414978\n",
      "Training step:  8361\n",
      "Loss: 928.6013933299803\n",
      "Training step:  8362\n",
      "Loss: 928.6012970402638\n",
      "Training step:  8363\n",
      "Loss: 928.601200786349\n",
      "Training step:  8364\n",
      "Loss: 928.6011047411242\n",
      "Training step:  8365\n",
      "Loss: 928.6010085483955\n",
      "Training step:  8366\n",
      "Loss: 928.6009127260085\n",
      "Training step:  8367\n",
      "Loss: 928.6008166358996\n",
      "Training step:  8368\n",
      "Loss: 928.6007210006403\n",
      "Training step:  8369\n",
      "Loss: 928.6006250240483\n",
      "Training step:  8370\n",
      "Loss: 928.6005295539578\n",
      "Training step:  8371\n",
      "Loss: 928.6004337046523\n",
      "Training step:  8372\n",
      "Loss: 928.600338359804\n",
      "Training step:  8373\n",
      "Loss: 928.6002426547922\n",
      "Training step:  8374\n",
      "Loss: 928.6001474630566\n",
      "Training step:  8375\n",
      "Loss: 928.6000518895497\n",
      "Training step:  8376\n",
      "Loss: 928.5999566974353\n",
      "Training step:  8377\n",
      "Loss: 928.5998614003033\n",
      "Training step:  8378\n",
      "Loss: 928.5997663986916\n",
      "Training step:  8379\n",
      "Loss: 928.5996711845921\n",
      "Training step:  8380\n",
      "Loss: 928.599576391769\n",
      "Training step:  8381\n",
      "Loss: 928.5994812657317\n",
      "Training step:  8382\n",
      "Loss: 928.5993866573292\n",
      "Training step:  8383\n",
      "Loss: 928.5992916485577\n",
      "Training step:  8384\n",
      "Loss: 928.5991969847369\n",
      "Training step:  8385\n",
      "Loss: 928.5991023000021\n",
      "Training step:  8386\n",
      "Loss: 928.5990078074598\n",
      "Training step:  8387\n",
      "Loss: 928.5989131846488\n",
      "Training step:  8388\n",
      "Loss: 928.5988189248222\n",
      "Training step:  8389\n",
      "Loss: 928.5987243907472\n",
      "Training step:  8390\n",
      "Loss: 928.5986303144451\n",
      "Training step:  8391\n",
      "Loss: 928.5985358926449\n",
      "Training step:  8392\n",
      "Loss: 928.5984419698271\n",
      "Training step:  8393\n",
      "Loss: 928.5983476815153\n",
      "Training step:  8394\n",
      "Loss: 928.5982537455207\n",
      "Training step:  8395\n",
      "Loss: 928.5981597228296\n",
      "Training step:  8396\n",
      "Loss: 928.5980659778338\n",
      "Training step:  8397\n",
      "Loss: 928.5979720377259\n",
      "Training step:  8398\n",
      "Loss: 928.5978784978687\n",
      "Training step:  8399\n",
      "Loss: 928.5977846454139\n",
      "Training step:  8400\n",
      "Loss: 928.5976912871972\n",
      "Training step:  8401\n",
      "Loss: 928.5975975510128\n",
      "Training step:  8402\n",
      "Loss: 928.5975041907052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  8403\n",
      "Loss: 928.5974107067575\n",
      "Training step:  8404\n",
      "Loss: 928.5973175402023\n",
      "Training step:  8405\n",
      "Loss: 928.5972241380305\n",
      "Training step:  8406\n",
      "Loss: 928.5971311607162\n",
      "Training step:  8407\n",
      "Loss: 928.5970378589166\n",
      "Training step:  8408\n",
      "Loss: 928.5969450444785\n",
      "Training step:  8409\n",
      "Loss: 928.5968518639035\n",
      "Training step:  8410\n",
      "Loss: 928.5967589922551\n",
      "Training step:  8411\n",
      "Loss: 928.5966661406039\n",
      "Training step:  8412\n",
      "Loss: 928.5965734356059\n",
      "Training step:  8413\n",
      "Loss: 928.5964806460736\n",
      "Training step:  8414\n",
      "Loss: 928.5963881676312\n",
      "Training step:  8415\n",
      "Loss: 928.5962954626486\n",
      "Training step:  8416\n",
      "Loss: 928.596203168122\n",
      "Training step:  8417\n",
      "Loss: 928.596110563156\n",
      "Training step:  8418\n",
      "Loss: 928.5960184473114\n",
      "Training step:  8419\n",
      "Loss: 928.5959259570662\n",
      "Training step:  8420\n",
      "Loss: 928.5958338200886\n",
      "Training step:  8421\n",
      "Loss: 928.5957416031966\n",
      "Training step:  8422\n",
      "Loss: 928.5956496481003\n",
      "Training step:  8423\n",
      "Loss: 928.5955575137376\n",
      "Training step:  8424\n",
      "Loss: 928.5954657447436\n",
      "Training step:  8425\n",
      "Loss: 928.5953737101275\n",
      "Training step:  8426\n",
      "Loss: 928.5952821185466\n",
      "Training step:  8427\n",
      "Loss: 928.5951901834708\n",
      "Training step:  8428\n",
      "Loss: 928.5950987032934\n",
      "Training step:  8429\n",
      "Loss: 928.5950069316362\n",
      "Training step:  8430\n",
      "Loss: 928.5949156246502\n",
      "Training step:  8431\n",
      "Loss: 928.594823967299\n",
      "Training step:  8432\n",
      "Loss: 928.5947326376439\n",
      "Training step:  8433\n",
      "Loss: 928.5946412557712\n",
      "Training step:  8434\n",
      "Loss: 928.5945501003306\n",
      "Training step:  8435\n",
      "Loss: 928.5944587907442\n",
      "Training step:  8436\n",
      "Loss: 928.5943678446141\n",
      "Training step:  8437\n",
      "Loss: 928.594276621566\n",
      "Training step:  8438\n",
      "Loss: 928.5941858424206\n",
      "Training step:  8439\n",
      "Loss: 928.5940947264496\n",
      "Training step:  8440\n",
      "Loss: 928.5940040394204\n",
      "Training step:  8441\n",
      "Loss: 928.5939130981875\n",
      "Training step:  8442\n",
      "Loss: 928.5938225869209\n",
      "Training step:  8443\n",
      "Loss: 928.5937317444024\n",
      "Training step:  8444\n",
      "Loss: 928.5936412378297\n",
      "Training step:  8445\n",
      "Loss: 928.5935506524023\n",
      "Training step:  8446\n",
      "Loss: 928.5934603255967\n",
      "Training step:  8447\n",
      "Loss: 928.5933698220346\n",
      "Training step:  8448\n",
      "Loss: 928.593279677347\n",
      "Training step:  8449\n",
      "Loss: 928.5931892722278\n",
      "Training step:  8450\n",
      "Loss: 928.5930993010978\n",
      "Training step:  8451\n",
      "Loss: 928.5930089987843\n",
      "Training step:  8452\n",
      "Loss: 928.5929190911113\n",
      "Training step:  8453\n",
      "Loss: 928.5928289774873\n",
      "Training step:  8454\n",
      "Loss: 928.5927392631165\n",
      "Training step:  8455\n",
      "Loss: 928.5926492354749\n",
      "Training step:  8456\n",
      "Loss: 928.5925596252839\n",
      "Training step:  8457\n",
      "Loss: 928.5924697624488\n",
      "Training step:  8458\n",
      "Loss: 928.5923803200018\n",
      "Training step:  8459\n",
      "Loss: 928.592290559598\n",
      "Training step:  8460\n",
      "Loss: 928.5922011276516\n",
      "Training step:  8461\n",
      "Loss: 928.5921116112382\n",
      "Training step:  8462\n",
      "Loss: 928.5920223568902\n",
      "Training step:  8463\n",
      "Loss: 928.5919329219536\n",
      "Training step:  8464\n",
      "Loss: 928.5918438469728\n",
      "Training step:  8465\n",
      "Loss: 928.5917545098349\n",
      "Training step:  8466\n",
      "Loss: 928.5916656058932\n",
      "Training step:  8467\n",
      "Loss: 928.5915763707035\n",
      "Training step:  8468\n",
      "Loss: 928.5914874152601\n",
      "Training step:  8469\n",
      "Loss: 928.5913984959005\n",
      "Training step:  8470\n",
      "Loss: 928.5913096929506\n",
      "Training step:  8471\n",
      "Loss: 928.591220836664\n",
      "Training step:  8472\n",
      "Loss: 928.5911322471317\n",
      "Training step:  8473\n",
      "Loss: 928.5910434745866\n",
      "Training step:  8474\n",
      "Loss: 928.5909550593946\n",
      "Training step:  8475\n",
      "Loss: 928.5908663841885\n",
      "Training step:  8476\n",
      "Loss: 928.5907781384867\n",
      "Training step:  8477\n",
      "Loss: 928.5906895742996\n",
      "Training step:  8478\n",
      "Loss: 928.59060144626\n",
      "Training step:  8479\n",
      "Loss: 928.5905130140895\n",
      "Training step:  8480\n",
      "Loss: 928.5904250139066\n",
      "Training step:  8481\n",
      "Loss: 928.5903367165733\n",
      "Training step:  8482\n",
      "Loss: 928.5902488440519\n",
      "Training step:  8483\n",
      "Loss: 928.5901606813463\n",
      "Training step:  8484\n",
      "Loss: 928.5900729598159\n",
      "Training step:  8485\n",
      "Loss: 928.5899849126309\n",
      "Training step:  8486\n",
      "Loss: 928.5898971228157\n",
      "Training step:  8487\n",
      "Loss: 928.5898094248831\n",
      "Training step:  8488\n",
      "Loss: 928.5897217568023\n",
      "Training step:  8489\n",
      "Loss: 928.589634117937\n",
      "Training step:  8490\n",
      "Loss: 928.5895466642096\n",
      "Training step:  8491\n",
      "Loss: 928.5894590878609\n",
      "Training step:  8492\n",
      "Loss: 928.5893718149425\n",
      "Training step:  8493\n",
      "Loss: 928.5892843472168\n",
      "Training step:  8494\n",
      "Loss: 928.5891972447291\n",
      "Training step:  8495\n",
      "Loss: 928.5891098733156\n",
      "Training step:  8496\n",
      "Loss: 928.5890229291788\n",
      "Training step:  8497\n",
      "Loss: 928.58893567497\n",
      "Training step:  8498\n",
      "Loss: 928.588848845963\n",
      "Training step:  8499\n",
      "Loss: 928.5887617228911\n",
      "Training step:  8500\n",
      "Loss: 928.5886749815259\n",
      "Training step:  8501\n",
      "Loss: 928.5885880254091\n",
      "Training step:  8502\n",
      "Loss: 928.588501449547\n",
      "Training step:  8503\n",
      "Loss: 928.5884145894544\n",
      "Training step:  8504\n",
      "Loss: 928.5883281330342\n",
      "Training step:  8505\n",
      "Loss: 928.5882414126488\n",
      "Training step:  8506\n",
      "Loss: 928.5881551041579\n",
      "Training step:  8507\n",
      "Loss: 928.5880684855942\n",
      "Training step:  8508\n",
      "Loss: 928.5879821177665\n",
      "Training step:  8509\n",
      "Loss: 928.587895844174\n",
      "Training step:  8510\n",
      "Loss: 928.5878095977187\n",
      "Training step:  8511\n",
      "Loss: 928.5877233839877\n",
      "Training step:  8512\n",
      "Loss: 928.5876373470664\n",
      "Training step:  8513\n",
      "Loss: 928.5875511959913\n",
      "Training step:  8514\n",
      "Loss: 928.5874653509426\n",
      "Training step:  8515\n",
      "Loss: 928.5873792960655\n",
      "Training step:  8516\n",
      "Loss: 928.5872936004106\n",
      "Training step:  8517\n",
      "Loss: 928.5872076559203\n",
      "Training step:  8518\n",
      "Loss: 928.5871221148698\n",
      "Training step:  8519\n",
      "Loss: 928.5870362728116\n",
      "Training step:  8520\n",
      "Loss: 928.5869507438372\n",
      "Training step:  8521\n",
      "Loss: 928.5868651353541\n",
      "Training step:  8522\n",
      "Loss: 928.5867797773878\n",
      "Training step:  8523\n",
      "Loss: 928.5866942487066\n",
      "Training step:  8524\n",
      "Loss: 928.5866090600201\n",
      "Training step:  8525\n",
      "Loss: 928.5865236263123\n",
      "Training step:  8526\n",
      "Loss: 928.5864385995874\n",
      "Training step:  8527\n",
      "Loss: 928.586353273733\n",
      "Training step:  8528\n",
      "Loss: 928.5862683255219\n",
      "Training step:  8529\n",
      "Loss: 928.5861831570542\n",
      "Training step:  8530\n",
      "Loss: 928.5860983716985\n",
      "Training step:  8531\n",
      "Loss: 928.5860133017469\n",
      "Training step:  8532\n",
      "Loss: 928.5859285323257\n",
      "Training step:  8533\n",
      "Loss: 928.5858436756054\n",
      "Training step:  8534\n",
      "Loss: 928.5857590868844\n",
      "Training step:  8535\n",
      "Loss: 928.5856743112737\n",
      "Training step:  8536\n",
      "Loss: 928.5855898871926\n",
      "Training step:  8537\n",
      "Loss: 928.5855052059129\n",
      "Training step:  8538\n",
      "Loss: 928.585420942033\n",
      "Training step:  8539\n",
      "Loss: 928.5853363676437\n",
      "Training step:  8540\n",
      "Loss: 928.585252081939\n",
      "Training step:  8541\n",
      "Loss: 928.585167752162\n",
      "Training step:  8542\n",
      "Loss: 928.5850836375812\n",
      "Training step:  8543\n",
      "Loss: 928.5849993787267\n",
      "Training step:  8544\n",
      "Loss: 928.5849154400888\n",
      "Training step:  8545\n",
      "Loss: 928.5848312757267\n",
      "Training step:  8546\n",
      "Loss: 928.5847474961581\n",
      "Training step:  8547\n",
      "Loss: 928.5846634344634\n",
      "Training step:  8548\n",
      "Loss: 928.5845797831947\n",
      "Training step:  8549\n",
      "Loss: 928.5844958391289\n",
      "Training step:  8550\n",
      "Loss: 928.5844121880674\n",
      "Training step:  8551\n",
      "Loss: 928.5843284856514\n",
      "Training step:  8552\n",
      "Loss: 928.5842449916873\n",
      "Training step:  8553\n",
      "Loss: 928.5841613604662\n",
      "Training step:  8554\n",
      "Loss: 928.5840780410193\n",
      "Training step:  8555\n",
      "Loss: 928.583994503345\n",
      "Training step:  8556\n",
      "Loss: 928.5839113415431\n",
      "Training step:  8557\n",
      "Loss: 928.5838278973292\n",
      "Training step:  8558\n",
      "Loss: 928.58374482302\n",
      "Training step:  8559\n",
      "Loss: 928.5836615358327\n",
      "Training step:  8560\n",
      "Loss: 928.583578619698\n",
      "Training step:  8561\n",
      "Loss: 928.5834954256968\n",
      "Training step:  8562\n",
      "Loss: 928.5834125405852\n",
      "Training step:  8563\n",
      "Loss: 928.5833295522744\n",
      "Training step:  8564\n",
      "Loss: 928.5832468356842\n",
      "Training step:  8565\n",
      "Loss: 928.583163931329\n",
      "Training step:  8566\n",
      "Loss: 928.5830813712463\n",
      "Training step:  8567\n",
      "Loss: 928.582998559864\n",
      "Training step:  8568\n",
      "Loss: 928.5829161419517\n",
      "Training step:  8569\n",
      "Loss: 928.5828334399438\n",
      "Training step:  8570\n",
      "Loss: 928.5827509921638\n",
      "Training step:  8571\n",
      "Loss: 928.5826685596694\n",
      "Training step:  8572\n",
      "Loss: 928.5825862586597\n",
      "Training step:  8573\n",
      "Loss: 928.5825038893914\n",
      "Training step:  8574\n",
      "Loss: 928.5824217806756\n",
      "Training step:  8575\n",
      "Loss: 928.5823394899115\n",
      "Training step:  8576\n",
      "Loss: 928.5822575418989\n",
      "Training step:  8577\n",
      "Loss: 928.5821753436142\n",
      "Training step:  8578\n",
      "Loss: 928.5820935401948\n",
      "Training step:  8579\n",
      "Loss: 928.5820114561211\n",
      "Training step:  8580\n",
      "Loss: 928.5819296759106\n",
      "Training step:  8581\n",
      "Loss: 928.5818477887952\n",
      "Training step:  8582\n",
      "Loss: 928.5817661756064\n",
      "Training step:  8583\n",
      "Loss: 928.5816843716484\n",
      "Training step:  8584\n",
      "Loss: 928.5816029122662\n",
      "Training step:  8585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 928.5815212004427\n",
      "Training step:  8586\n",
      "Loss: 928.5814398809936\n",
      "Training step:  8587\n",
      "Loss: 928.5813582772419\n",
      "Training step:  8588\n",
      "Loss: 928.5812769074566\n",
      "Training step:  8589\n",
      "Loss: 928.5811956147139\n",
      "Training step:  8590\n",
      "Loss: 928.5811143570664\n",
      "Training step:  8591\n",
      "Loss: 928.5810331243956\n",
      "Training step:  8592\n",
      "Loss: 928.5809520597435\n",
      "Training step:  8593\n",
      "Loss: 928.5808708896143\n",
      "Training step:  8594\n",
      "Loss: 928.580789989296\n",
      "Training step:  8595\n",
      "Loss: 928.5807089244754\n",
      "Training step:  8596\n",
      "Loss: 928.5806281756609\n",
      "Training step:  8597\n",
      "Loss: 928.5805472023995\n",
      "Training step:  8598\n",
      "Loss: 928.5804665984748\n",
      "Training step:  8599\n",
      "Loss: 928.5803857266284\n",
      "Training step:  8600\n",
      "Loss: 928.580305150884\n",
      "Training step:  8601\n",
      "Loss: 928.5802244770313\n",
      "Training step:  8602\n",
      "Loss: 928.58014406524\n",
      "Training step:  8603\n",
      "Loss: 928.5800634737041\n",
      "Training step:  8604\n",
      "Loss: 928.5799832129514\n",
      "Training step:  8605\n",
      "Loss: 928.5799027126119\n",
      "Training step:  8606\n",
      "Loss: 928.5798225830315\n",
      "Training step:  8607\n",
      "Loss: 928.5797421921945\n",
      "Training step:  8608\n",
      "Loss: 928.5796620593371\n",
      "Training step:  8609\n",
      "Loss: 928.579581900446\n",
      "Training step:  8610\n",
      "Loss: 928.5795019228194\n",
      "Training step:  8611\n",
      "Loss: 928.579421834161\n",
      "Training step:  8612\n",
      "Loss: 928.579342021389\n",
      "Training step:  8613\n",
      "Loss: 928.5792620238359\n",
      "Training step:  8614\n",
      "Loss: 928.5791823607021\n",
      "Training step:  8615\n",
      "Loss: 928.5791024538885\n",
      "Training step:  8616\n",
      "Loss: 928.5790229128942\n",
      "Training step:  8617\n",
      "Loss: 928.5789431234699\n",
      "Training step:  8618\n",
      "Loss: 928.5788636977063\n",
      "Training step:  8619\n",
      "Loss: 928.5787840296431\n",
      "Training step:  8620\n",
      "Loss: 928.5787047193794\n",
      "Training step:  8621\n",
      "Loss: 928.5786251724902\n",
      "Training step:  8622\n",
      "Loss: 928.5785459775628\n",
      "Training step:  8623\n",
      "Loss: 928.5784665516594\n",
      "Training step:  8624\n",
      "Loss: 928.5783874910439\n",
      "Training step:  8625\n",
      "Loss: 928.5783081705946\n",
      "Training step:  8626\n",
      "Loss: 928.5782290502463\n",
      "Training step:  8627\n",
      "Loss: 928.5781500609305\n",
      "Training step:  8628\n",
      "Loss: 928.5780710225233\n",
      "Training step:  8629\n",
      "Loss: 928.577992095045\n",
      "Training step:  8630\n",
      "Loss: 928.5779132423646\n",
      "Training step:  8631\n",
      "Loss: 928.5778343775581\n",
      "Training step:  8632\n",
      "Loss: 928.5777557062627\n",
      "Training step:  8633\n",
      "Loss: 928.5776769189324\n",
      "Training step:  8634\n",
      "Loss: 928.5775983879964\n",
      "Training step:  8635\n",
      "Loss: 928.5775197001589\n",
      "Training step:  8636\n",
      "Loss: 928.577441318813\n",
      "Training step:  8637\n",
      "Loss: 928.577362720667\n",
      "Training step:  8638\n",
      "Loss: 928.5772844792275\n",
      "Training step:  8639\n",
      "Loss: 928.5772059876717\n",
      "Training step:  8640\n",
      "Loss: 928.5771278133163\n",
      "Training step:  8641\n",
      "Loss: 928.5770494735453\n",
      "Training step:  8642\n",
      "Loss: 928.5769714449926\n",
      "Training step:  8643\n",
      "Loss: 928.5768931947196\n",
      "Training step:  8644\n",
      "Loss: 928.5768152804784\n",
      "Training step:  8645\n",
      "Loss: 928.5767371491737\n",
      "Training step:  8646\n",
      "Loss: 928.5766593566678\n",
      "Training step:  8647\n",
      "Loss: 928.5765813358162\n",
      "Training step:  8648\n",
      "Loss: 928.5765035754724\n",
      "Training step:  8649\n",
      "Loss: 928.5764257344722\n",
      "Training step:  8650\n",
      "Loss: 928.5763481401863\n",
      "Training step:  8651\n",
      "Loss: 928.5762703778664\n",
      "Training step:  8652\n",
      "Loss: 928.5761929301786\n",
      "Training step:  8653\n",
      "Loss: 928.576115256805\n",
      "Training step:  8654\n",
      "Loss: 928.5760379352987\n",
      "Training step:  8655\n",
      "Loss: 928.5759603711712\n",
      "Training step:  8656\n",
      "Loss: 928.5758830674297\n",
      "Training step:  8657\n",
      "Loss: 928.575805702302\n",
      "Training step:  8658\n",
      "Loss: 928.5757285521761\n",
      "Training step:  8659\n",
      "Loss: 928.5756512562256\n",
      "Training step:  8660\n",
      "Loss: 928.5755742634499\n",
      "Training step:  8661\n",
      "Loss: 928.5754970561305\n",
      "Training step:  8662\n",
      "Loss: 928.5754201861223\n",
      "Training step:  8663\n",
      "Loss: 928.575343086559\n",
      "Training step:  8664\n",
      "Loss: 928.5752662326548\n",
      "Training step:  8665\n",
      "Loss: 928.5751893304069\n",
      "Training step:  8666\n",
      "Loss: 928.5751126334956\n",
      "Training step:  8667\n",
      "Loss: 928.5750358071284\n",
      "Training step:  8668\n",
      "Loss: 928.5749592579928\n",
      "Training step:  8669\n",
      "Loss: 928.5748825199594\n",
      "Training step:  8670\n",
      "Loss: 928.5748061131341\n",
      "Training step:  8671\n",
      "Loss: 928.5747294736625\n",
      "Training step:  8672\n",
      "Loss: 928.574653169803\n",
      "Training step:  8673\n",
      "Loss: 928.5745766453624\n",
      "Training step:  8674\n",
      "Loss: 928.5745004524481\n",
      "Training step:  8675\n",
      "Loss: 928.5744240442936\n",
      "Training step:  8676\n",
      "Loss: 928.5743479702779\n",
      "Training step:  8677\n",
      "Loss: 928.574271670268\n",
      "Training step:  8678\n",
      "Loss: 928.5741956165115\n",
      "Training step:  8679\n",
      "Loss: 928.5741195171431\n",
      "Training step:  8680\n",
      "Loss: 928.5740436074863\n",
      "Training step:  8681\n",
      "Loss: 928.5739675843553\n",
      "Training step:  8682\n",
      "Loss: 928.5738918210019\n",
      "Training step:  8683\n",
      "Loss: 928.5738158856789\n",
      "Training step:  8684\n",
      "Loss: 928.5737402628779\n",
      "Training step:  8685\n",
      "Loss: 928.5736644150394\n",
      "Training step:  8686\n",
      "Loss: 928.5735888467179\n",
      "Training step:  8687\n",
      "Loss: 928.5735131631191\n",
      "Training step:  8688\n",
      "Loss: 928.5734377369158\n",
      "Training step:  8689\n",
      "Loss: 928.5733621365457\n",
      "Training step:  8690\n",
      "Loss: 928.5732868552216\n",
      "Training step:  8691\n",
      "Loss: 928.5732113426928\n",
      "Training step:  8692\n",
      "Loss: 928.5731360223998\n",
      "Training step:  8693\n",
      "Loss: 928.5730608039694\n",
      "Training step:  8694\n",
      "Loss: 928.5729855701596\n",
      "Training step:  8695\n",
      "Loss: 928.5729104120661\n",
      "Training step:  8696\n",
      "Loss: 928.5728353519445\n",
      "Training step:  8697\n",
      "Loss: 928.5727602558254\n",
      "Training step:  8698\n",
      "Loss: 928.5726853449086\n",
      "Training step:  8699\n",
      "Loss: 928.5726103455938\n",
      "Training step:  8700\n",
      "Loss: 928.5725355760294\n",
      "Training step:  8701\n",
      "Loss: 928.5724606634815\n",
      "Training step:  8702\n",
      "Loss: 928.5723860265325\n",
      "Training step:  8703\n",
      "Loss: 928.5723112060833\n",
      "Training step:  8704\n",
      "Loss: 928.572236701301\n",
      "Training step:  8705\n",
      "Loss: 928.5721619758415\n",
      "Training step:  8706\n",
      "Loss: 928.5720875417455\n",
      "Training step:  8707\n",
      "Loss: 928.5720129622748\n",
      "Training step:  8708\n",
      "Loss: 928.5719386652792\n",
      "Training step:  8709\n",
      "Loss: 928.5718641721744\n",
      "Training step:  8710\n",
      "Loss: 928.571789991927\n",
      "Training step:  8711\n",
      "Loss: 928.5717156073803\n",
      "Training step:  8712\n",
      "Loss: 928.5716415139854\n",
      "Training step:  8713\n",
      "Loss: 928.5715672593697\n",
      "Training step:  8714\n",
      "Loss: 928.5714933015948\n",
      "Training step:  8715\n",
      "Loss: 928.5714191360419\n",
      "Training step:  8716\n",
      "Loss: 928.5713452038756\n",
      "Training step:  8717\n",
      "Loss: 928.5712712108995\n",
      "Training step:  8718\n",
      "Loss: 928.571197434362\n",
      "Training step:  8719\n",
      "Loss: 928.571123517599\n",
      "Training step:  8720\n",
      "Loss: 928.5710498801209\n",
      "Training step:  8721\n",
      "Loss: 928.5709760491694\n",
      "Training step:  8722\n",
      "Loss: 928.5709025419758\n",
      "Training step:  8723\n",
      "Loss: 928.5708288049619\n",
      "Training step:  8724\n",
      "Loss: 928.5707552609679\n",
      "Training step:  8725\n",
      "Loss: 928.5706818001062\n",
      "Training step:  8726\n",
      "Loss: 928.5706083504994\n",
      "Training step:  8727\n",
      "Loss: 928.570534949726\n",
      "Training step:  8728\n",
      "Loss: 928.5704616682804\n",
      "Training step:  8729\n",
      "Loss: 928.5703883291467\n",
      "Training step:  8730\n",
      "Loss: 928.5703151924749\n",
      "Training step:  8731\n",
      "Loss: 928.5702419478768\n",
      "Training step:  8732\n",
      "Loss: 928.5701689483196\n",
      "Training step:  8733\n",
      "Loss: 928.5700957890109\n",
      "Training step:  8734\n",
      "Loss: 928.5700229184495\n",
      "Training step:  8735\n",
      "Loss: 928.5699498495245\n",
      "Training step:  8736\n",
      "Loss: 928.5698770787147\n",
      "Training step:  8737\n",
      "Loss: 928.5698041280415\n",
      "Training step:  8738\n",
      "Loss: 928.5697314791145\n",
      "Training step:  8739\n",
      "Loss: 928.5696586262223\n",
      "Training step:  8740\n",
      "Loss: 928.5695860037656\n",
      "Training step:  8741\n",
      "Loss: 928.5695133226017\n",
      "Training step:  8742\n",
      "Loss: 928.569440840584\n",
      "Training step:  8743\n",
      "Loss: 928.5693682408468\n",
      "Training step:  8744\n",
      "Loss: 928.5692958968036\n",
      "Training step:  8745\n",
      "Loss: 928.5692233818193\n",
      "Training step:  8746\n",
      "Loss: 928.5691511707865\n",
      "Training step:  8747\n",
      "Loss: 928.5690787432343\n",
      "Training step:  8748\n",
      "Loss: 928.5690065218143\n",
      "Training step:  8749\n",
      "Loss: 928.568934314681\n",
      "Training step:  8750\n",
      "Loss: 928.5688622205056\n",
      "Training step:  8751\n",
      "Loss: 928.5687900751153\n",
      "Training step:  8752\n",
      "Loss: 928.568718133042\n",
      "Training step:  8753\n",
      "Loss: 928.5686460688859\n",
      "Training step:  8754\n",
      "Loss: 928.5685742635384\n",
      "Training step:  8755\n",
      "Loss: 928.5685022836185\n",
      "Training step:  8756\n",
      "Loss: 928.5684306101026\n",
      "Training step:  8757\n",
      "Loss: 928.5683587234422\n",
      "Training step:  8758\n",
      "Loss: 928.5682871149527\n",
      "Training step:  8759\n",
      "Loss: 928.5682153647832\n",
      "Training step:  8760\n",
      "Loss: 928.5681438876736\n",
      "Training step:  8761\n",
      "Loss: 928.5680722214739\n",
      "Training step:  8762\n",
      "Loss: 928.568000849163\n",
      "Training step:  8763\n",
      "Loss: 928.5679292917182\n",
      "Training step:  8764\n",
      "Loss: 928.5678580234328\n",
      "Training step:  8765\n",
      "Loss: 928.5677865745723\n",
      "Training step:  8766\n",
      "Loss: 928.5677154256547\n",
      "Training step:  8767\n",
      "Loss: 928.5676440727477\n",
      "Training step:  8768\n",
      "Loss: 928.5675729053736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  8769\n",
      "Loss: 928.5675017944543\n",
      "Training step:  8770\n",
      "Loss: 928.5674307292583\n",
      "Training step:  8771\n",
      "Loss: 928.5673596776924\n",
      "Training step:  8772\n",
      "Loss: 928.5672887733758\n",
      "Training step:  8773\n",
      "Loss: 928.5672177827736\n",
      "Training step:  8774\n",
      "Loss: 928.5671470168896\n",
      "Training step:  8775\n",
      "Loss: 928.5670761197215\n",
      "Training step:  8776\n",
      "Loss: 928.5670054779688\n",
      "Training step:  8777\n",
      "Loss: 928.5669346689392\n",
      "Training step:  8778\n",
      "Loss: 928.566864142037\n",
      "Training step:  8779\n",
      "Loss: 928.5667934299094\n",
      "Training step:  8780\n",
      "Loss: 928.5667229737315\n",
      "Training step:  8781\n",
      "Loss: 928.5666523933203\n",
      "Training step:  8782\n",
      "Loss: 928.5665820716631\n",
      "Training step:  8783\n",
      "Loss: 928.5665115742424\n",
      "Training step:  8784\n",
      "Loss: 928.5664413226245\n",
      "Training step:  8785\n",
      "Loss: 928.5663709571177\n",
      "Training step:  8786\n",
      "Loss: 928.5663008388553\n",
      "Training step:  8787\n",
      "Loss: 928.5662305560242\n",
      "Training step:  8788\n",
      "Loss: 928.5661605510068\n",
      "Training step:  8789\n",
      "Loss: 928.5660903675632\n",
      "Training step:  8790\n",
      "Loss: 928.5660203918704\n",
      "Training step:  8791\n",
      "Loss: 928.5659503667508\n",
      "Training step:  8792\n",
      "Loss: 928.5658805369741\n",
      "Training step:  8793\n",
      "Loss: 928.565810585866\n",
      "Training step:  8794\n",
      "Loss: 928.5657408862273\n",
      "Training step:  8795\n",
      "Loss: 928.5656710175319\n",
      "Training step:  8796\n",
      "Loss: 928.565601440158\n",
      "Training step:  8797\n",
      "Loss: 928.5655316611245\n",
      "Training step:  8798\n",
      "Loss: 928.5654620424401\n",
      "Training step:  8799\n",
      "Loss: 928.5653925552422\n",
      "Training step:  8800\n",
      "Loss: 928.565322992971\n",
      "Training step:  8801\n",
      "Loss: 928.5652535645759\n",
      "Training step:  8802\n",
      "Loss: 928.5651841537652\n",
      "Training step:  8803\n",
      "Loss: 928.5651147914546\n",
      "Training step:  8804\n",
      "Loss: 928.5650455353874\n",
      "Training step:  8805\n",
      "Loss: 928.5649762336036\n",
      "Training step:  8806\n",
      "Loss: 928.5649071119815\n",
      "Training step:  8807\n",
      "Loss: 928.564837902294\n",
      "Training step:  8808\n",
      "Loss: 928.5647689064008\n",
      "Training step:  8809\n",
      "Loss: 928.564699778479\n",
      "Training step:  8810\n",
      "Loss: 928.5646309032555\n",
      "Training step:  8811\n",
      "Loss: 928.5645618642501\n",
      "Training step:  8812\n",
      "Loss: 928.5644930980634\n",
      "Training step:  8813\n",
      "Loss: 928.5644241512232\n",
      "Training step:  8814\n",
      "Loss: 928.564355452502\n",
      "Training step:  8815\n",
      "Loss: 928.5642866434694\n",
      "Training step:  8816\n",
      "Loss: 928.5642180686017\n",
      "Training step:  8817\n",
      "Loss: 928.5641493411046\n",
      "Training step:  8818\n",
      "Loss: 928.5640808816153\n",
      "Training step:  8819\n",
      "Loss: 928.5640122467996\n",
      "Training step:  8820\n",
      "Loss: 928.5639438074996\n",
      "Training step:  8821\n",
      "Loss: 928.5638753413052\n",
      "Training step:  8822\n",
      "Loss: 928.5638070298712\n",
      "Training step:  8823\n",
      "Loss: 928.5637386364897\n",
      "Training step:  8824\n",
      "Loss: 928.5636704598622\n",
      "Training step:  8825\n",
      "Loss: 928.563602147561\n",
      "Training step:  8826\n",
      "Loss: 928.5635340948967\n",
      "Training step:  8827\n",
      "Loss: 928.5634658661014\n",
      "Training step:  8828\n",
      "Loss: 928.5633978877635\n",
      "Training step:  8829\n",
      "Loss: 928.5633297824048\n",
      "Training step:  8830\n",
      "Loss: 928.563261928282\n",
      "Training step:  8831\n",
      "Loss: 928.5631939062504\n",
      "Training step:  8832\n",
      "Loss: 928.5631261336134\n",
      "Training step:  8833\n",
      "Loss: 928.5630582288571\n",
      "Training step:  8834\n",
      "Loss: 928.5629905784407\n",
      "Training step:  8835\n",
      "Loss: 928.5629227568239\n",
      "Training step:  8836\n",
      "Loss: 928.5628551362249\n",
      "Training step:  8837\n",
      "Loss: 928.5627874702703\n",
      "Training step:  8838\n",
      "Loss: 928.562719978561\n",
      "Training step:  8839\n",
      "Loss: 928.562652390223\n",
      "Training step:  8840\n",
      "Loss: 928.5625850250456\n",
      "Training step:  8841\n",
      "Loss: 928.5625175171232\n",
      "Training step:  8842\n",
      "Loss: 928.5624502741681\n",
      "Training step:  8843\n",
      "Loss: 928.562382848955\n",
      "Training step:  8844\n",
      "Loss: 928.5623155902296\n",
      "Training step:  8845\n",
      "Loss: 928.5622483895712\n",
      "Training step:  8846\n",
      "Loss: 928.5621812299192\n",
      "Training step:  8847\n",
      "Loss: 928.5621140878931\n",
      "Training step:  8848\n",
      "Loss: 928.5620470774093\n",
      "Training step:  8849\n",
      "Loss: 928.5619799952827\n",
      "Training step:  8850\n",
      "Loss: 928.561913113962\n",
      "Training step:  8851\n",
      "Loss: 928.5618461209239\n",
      "Training step:  8852\n",
      "Loss: 928.5617793558823\n",
      "Training step:  8853\n",
      "Loss: 928.5617124470201\n",
      "Training step:  8854\n",
      "Loss: 928.5616457982057\n",
      "Training step:  8855\n",
      "Loss: 928.5615789758325\n",
      "Training step:  8856\n",
      "Loss: 928.5615123116435\n",
      "Training step:  8857\n",
      "Loss: 928.5614457156654\n",
      "Training step:  8858\n",
      "Loss: 928.5613791444713\n",
      "Training step:  8859\n",
      "Loss: 928.5613126094486\n",
      "Training step:  8860\n",
      "Loss: 928.5612461829277\n",
      "Training step:  8861\n",
      "Loss: 928.561179707649\n",
      "Training step:  8862\n",
      "Loss: 928.5611134177135\n",
      "Training step:  8863\n",
      "Loss: 928.5610470221067\n",
      "Training step:  8864\n",
      "Loss: 928.5609808520804\n",
      "Training step:  8865\n",
      "Loss: 928.5609145357447\n",
      "Training step:  8866\n",
      "Loss: 928.5608484741898\n",
      "Training step:  8867\n",
      "Loss: 928.5607822477095\n",
      "Training step:  8868\n",
      "Loss: 928.5607162516226\n",
      "Training step:  8869\n",
      "Loss: 928.5606501550069\n",
      "Training step:  8870\n",
      "Loss: 928.5605842773481\n",
      "Training step:  8871\n",
      "Loss: 928.5605182597635\n",
      "Training step:  8872\n",
      "Loss: 928.5604524923824\n",
      "Training step:  8873\n",
      "Loss: 928.5603865641782\n",
      "Training step:  8874\n",
      "Loss: 928.5603207981726\n",
      "Training step:  8875\n",
      "Loss: 928.5602550634637\n",
      "Training step:  8876\n",
      "Loss: 928.5601894069172\n",
      "Training step:  8877\n",
      "Loss: 928.5601237325544\n",
      "Training step:  8878\n",
      "Loss: 928.5600582110444\n",
      "Training step:  8879\n",
      "Loss: 928.5599926127867\n",
      "Training step:  8880\n",
      "Loss: 928.5599272133677\n",
      "Training step:  8881\n",
      "Loss: 928.5598616936394\n",
      "Training step:  8882\n",
      "Loss: 928.5597964122413\n",
      "Training step:  8883\n",
      "Loss: 928.5597309733033\n",
      "Training step:  8884\n",
      "Loss: 928.5596657739551\n",
      "Training step:  8885\n",
      "Loss: 928.5596004458743\n",
      "Training step:  8886\n",
      "Loss: 928.5595353622795\n",
      "Training step:  8887\n",
      "Loss: 928.5594701147876\n",
      "Training step:  8888\n",
      "Loss: 928.5594050220965\n",
      "Training step:  8889\n",
      "Loss: 928.5593399841067\n",
      "Training step:  8890\n",
      "Loss: 928.5592749892119\n",
      "Training step:  8891\n",
      "Loss: 928.5592100115674\n",
      "Training step:  8892\n",
      "Loss: 928.5591451568711\n",
      "Training step:  8893\n",
      "Loss: 928.5590802437748\n",
      "Training step:  8894\n",
      "Loss: 928.5590155073099\n",
      "Training step:  8895\n",
      "Loss: 928.5589506809288\n",
      "Training step:  8896\n",
      "Loss: 928.5588860605998\n",
      "Training step:  8897\n",
      "Loss: 928.5588213120595\n",
      "Training step:  8898\n",
      "Loss: 928.558756803786\n",
      "Training step:  8899\n",
      "Loss: 928.5586921393494\n",
      "Training step:  8900\n",
      "Loss: 928.5586276312107\n",
      "Training step:  8901\n",
      "Loss: 928.5585631615372\n",
      "Training step:  8902\n",
      "Loss: 928.5584987562096\n",
      "Training step:  8903\n",
      "Loss: 928.5584343462851\n",
      "Training step:  8904\n",
      "Loss: 928.5583700726645\n",
      "Training step:  8905\n",
      "Loss: 928.5583057379363\n",
      "Training step:  8906\n",
      "Loss: 928.5582415836172\n",
      "Training step:  8907\n",
      "Loss: 928.5581773263095\n",
      "Training step:  8908\n",
      "Loss: 928.5581132873698\n",
      "Training step:  8909\n",
      "Loss: 928.558049107385\n",
      "Training step:  8910\n",
      "Loss: 928.5579851732699\n",
      "Training step:  8911\n",
      "Loss: 928.5579210827062\n",
      "Training step:  8912\n",
      "Loss: 928.5578571592372\n",
      "Training step:  8913\n",
      "Loss: 928.5577932396511\n",
      "Training step:  8914\n",
      "Loss: 928.5577294339846\n",
      "Training step:  8915\n",
      "Loss: 928.5576655787723\n",
      "Training step:  8916\n",
      "Loss: 928.5576018970743\n",
      "Training step:  8917\n",
      "Loss: 928.557538119132\n",
      "Training step:  8918\n",
      "Loss: 928.5574745518185\n",
      "Training step:  8919\n",
      "Loss: 928.5574108507512\n",
      "Training step:  8920\n",
      "Loss: 928.5573473854453\n",
      "Training step:  8921\n",
      "Loss: 928.5572837727007\n",
      "Training step:  8922\n",
      "Loss: 928.5572203485333\n",
      "Training step:  8923\n",
      "Loss: 928.557156877125\n",
      "Training step:  8924\n",
      "Loss: 928.5570935679453\n",
      "Training step:  8925\n",
      "Loss: 928.5570301717221\n",
      "Training step:  8926\n",
      "Loss: 928.5569669783289\n",
      "Training step:  8927\n",
      "Loss: 928.5569036586236\n",
      "Training step:  8928\n",
      "Loss: 928.5568405785951\n",
      "Training step:  8929\n",
      "Loss: 928.5567773374288\n",
      "Training step:  8930\n",
      "Loss: 928.5567142305839\n",
      "Training step:  8931\n",
      "Loss: 928.5566512326595\n",
      "Training step:  8932\n",
      "Loss: 928.5565881669899\n",
      "Training step:  8933\n",
      "Loss: 928.5565252838256\n",
      "Training step:  8934\n",
      "Loss: 928.5564622964298\n",
      "Training step:  8935\n",
      "Loss: 928.5563995212477\n",
      "Training step:  8936\n",
      "Loss: 928.5563366134827\n",
      "Training step:  8937\n",
      "Loss: 928.5562739207209\n",
      "Training step:  8938\n",
      "Loss: 928.5562111122565\n",
      "Training step:  8939\n",
      "Loss: 928.55614851925\n",
      "Training step:  8940\n",
      "Loss: 928.5560857982066\n",
      "Training step:  8941\n",
      "Loss: 928.5560232858578\n",
      "Training step:  8942\n",
      "Loss: 928.5559606693355\n",
      "Training step:  8943\n",
      "Loss: 928.5558982744983\n",
      "Training step:  8944\n",
      "Loss: 928.5558357372192\n",
      "Training step:  8945\n",
      "Loss: 928.5557733357026\n",
      "Training step:  8946\n",
      "Loss: 928.5557110046868\n",
      "Training step:  8947\n",
      "Loss: 928.5556486885793\n",
      "Training step:  8948\n",
      "Loss: 928.5555864094625\n",
      "Training step:  8949\n",
      "Loss: 928.5555242345902\n",
      "Training step:  8950\n",
      "Loss: 928.5554620282702\n",
      "Training step:  8951\n",
      "Loss: 928.5553999821446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  8952\n",
      "Loss: 928.5553378454803\n",
      "Training step:  8953\n",
      "Loss: 928.5552759101964\n",
      "Training step:  8954\n",
      "Loss: 928.5552138493161\n",
      "Training step:  8955\n",
      "Loss: 928.5551520046373\n",
      "Training step:  8956\n",
      "Loss: 928.5550900395142\n",
      "Training step:  8957\n",
      "Loss: 928.5550282947761\n",
      "Training step:  8958\n",
      "Loss: 928.5549664140135\n",
      "Training step:  8959\n",
      "Loss: 928.5549046931725\n",
      "Training step:  8960\n",
      "Loss: 928.5548429636661\n",
      "Training step:  8961\n",
      "Loss: 928.5547813582443\n",
      "Training step:  8962\n",
      "Loss: 928.5547196970391\n",
      "Training step:  8963\n",
      "Loss: 928.554658203686\n",
      "Training step:  8964\n",
      "Loss: 928.5545966173719\n",
      "Training step:  8965\n",
      "Loss: 928.5545352338194\n",
      "Training step:  8966\n",
      "Loss: 928.5544737223338\n",
      "Training step:  8967\n",
      "Loss: 928.554412436954\n",
      "Training step:  8968\n",
      "Loss: 928.5543510129822\n",
      "Training step:  8969\n",
      "Loss: 928.5542897925479\n",
      "Training step:  8970\n",
      "Loss: 928.554228485404\n",
      "Training step:  8971\n",
      "Loss: 928.5541673704464\n",
      "Training step:  8972\n",
      "Loss: 928.5541061378694\n",
      "Training step:  8973\n",
      "Loss: 928.5540451244063\n",
      "Training step:  8974\n",
      "Loss: 928.5539839753421\n",
      "Training step:  8975\n",
      "Loss: 928.5539229865296\n",
      "Training step:  8976\n",
      "Loss: 928.553861986176\n",
      "Training step:  8977\n",
      "Loss: 928.5538011049838\n",
      "Training step:  8978\n",
      "Loss: 928.5537401767209\n",
      "Training step:  8979\n",
      "Loss: 928.5536794073415\n",
      "Training step:  8980\n",
      "Loss: 928.5536185533799\n",
      "Training step:  8981\n",
      "Loss: 928.5535578922929\n",
      "Training step:  8982\n",
      "Loss: 928.5534971124655\n",
      "Training step:  8983\n",
      "Loss: 928.5534365594553\n",
      "Training step:  8984\n",
      "Loss: 928.553375855652\n",
      "Training step:  8985\n",
      "Loss: 928.5533152822953\n",
      "Training step:  8986\n",
      "Loss: 928.5532548125465\n",
      "Training step:  8987\n",
      "Loss: 928.5531942920552\n",
      "Training step:  8988\n",
      "Loss: 928.5531338807383\n",
      "Training step:  8989\n",
      "Loss: 928.5530734912131\n",
      "Training step:  8990\n",
      "Loss: 928.5530131376034\n",
      "Training step:  8991\n",
      "Loss: 928.5529528622551\n",
      "Training step:  8992\n",
      "Loss: 928.5528925786406\n",
      "Training step:  8993\n",
      "Loss: 928.5528324237015\n",
      "Training step:  8994\n",
      "Loss: 928.552772213997\n",
      "Training step:  8995\n",
      "Loss: 928.552712166068\n",
      "Training step:  8996\n",
      "Loss: 928.5526520298761\n",
      "Training step:  8997\n",
      "Loss: 928.552592084998\n",
      "Training step:  8998\n",
      "Loss: 928.5525320257814\n",
      "Training step:  8999\n",
      "Loss: 928.5524721719939\n",
      "Training step:  9000\n",
      "Loss: 928.5524121974132\n",
      "Training step:  9001\n",
      "Loss: 928.5523524259493\n",
      "Training step:  9002\n",
      "Loss: 928.5522925513498\n",
      "Training step:  9003\n",
      "Loss: 928.5522328845025\n",
      "Training step:  9004\n",
      "Loss: 928.5521730850322\n",
      "Training step:  9005\n",
      "Loss: 928.5521134561241\n",
      "Training step:  9006\n",
      "Loss: 928.5520537892372\n",
      "Training step:  9007\n",
      "Loss: 928.5519942668204\n",
      "Training step:  9008\n",
      "Loss: 928.5519346732303\n",
      "Training step:  9009\n",
      "Loss: 928.5518752565201\n",
      "Training step:  9010\n",
      "Loss: 928.5518157358548\n",
      "Training step:  9011\n",
      "Loss: 928.5517564246419\n",
      "Training step:  9012\n",
      "Loss: 928.551696978736\n",
      "Training step:  9013\n",
      "Loss: 928.5516376691772\n",
      "Training step:  9014\n",
      "Loss: 928.5515784040894\n",
      "Training step:  9015\n",
      "Loss: 928.5515191840577\n",
      "Training step:  9016\n",
      "Loss: 928.5514599765038\n",
      "Training step:  9017\n",
      "Loss: 928.5514008806974\n",
      "Training step:  9018\n",
      "Loss: 928.5513417385746\n",
      "Training step:  9019\n",
      "Loss: 928.5512827505938\n",
      "Training step:  9020\n",
      "Loss: 928.551223681006\n",
      "Training step:  9021\n",
      "Loss: 928.5511647976314\n",
      "Training step:  9022\n",
      "Loss: 928.5511058004685\n",
      "Training step:  9023\n",
      "Loss: 928.5510470127766\n",
      "Training step:  9024\n",
      "Loss: 928.5509880982928\n",
      "Training step:  9025\n",
      "Loss: 928.550929385572\n",
      "Training step:  9026\n",
      "Loss: 928.5508705696599\n",
      "Training step:  9027\n",
      "Loss: 928.5508119596421\n",
      "Training step:  9028\n",
      "Loss: 928.5507532177777\n",
      "Training step:  9029\n",
      "Loss: 928.5506946008448\n",
      "Training step:  9030\n",
      "Loss: 928.5506360534298\n",
      "Training step:  9031\n",
      "Loss: 928.5505775143888\n",
      "Training step:  9032\n",
      "Loss: 928.5505190224814\n",
      "Training step:  9033\n",
      "Loss: 928.5504606079253\n",
      "Training step:  9034\n",
      "Loss: 928.5504021727555\n",
      "Training step:  9035\n",
      "Loss: 928.5503438672947\n",
      "Training step:  9036\n",
      "Loss: 928.5502855084648\n",
      "Training step:  9037\n",
      "Loss: 928.5502273091706\n",
      "Training step:  9038\n",
      "Loss: 928.5501690221089\n",
      "Training step:  9039\n",
      "Loss: 928.5501109257997\n",
      "Training step:  9040\n",
      "Loss: 928.5500527104049\n",
      "Training step:  9041\n",
      "Loss: 928.5499946902667\n",
      "Training step:  9042\n",
      "Loss: 928.5499365724378\n",
      "Training step:  9043\n",
      "Loss: 928.5498786537231\n",
      "Training step:  9044\n",
      "Loss: 928.5498206092035\n",
      "Training step:  9045\n",
      "Loss: 928.5497626925929\n",
      "Training step:  9046\n",
      "Loss: 928.5497048282541\n",
      "Training step:  9047\n",
      "Loss: 928.5496469937185\n",
      "Training step:  9048\n",
      "Loss: 928.5495891863093\n",
      "Training step:  9049\n",
      "Loss: 928.5495314722522\n",
      "Training step:  9050\n",
      "Loss: 928.5494737294468\n",
      "Training step:  9051\n",
      "Loss: 928.5494161202939\n",
      "Training step:  9052\n",
      "Loss: 928.5493584487274\n",
      "Training step:  9053\n",
      "Loss: 928.5493009413457\n",
      "Training step:  9054\n",
      "Loss: 928.5492433408396\n",
      "Training step:  9055\n",
      "Loss: 928.5491859316274\n",
      "Training step:  9056\n",
      "Loss: 928.5491284053531\n",
      "Training step:  9057\n",
      "Loss: 928.549071071558\n",
      "Training step:  9058\n",
      "Loss: 928.5490136415644\n",
      "Training step:  9059\n",
      "Loss: 928.5489564077532\n",
      "Training step:  9060\n",
      "Loss: 928.548899050361\n",
      "Training step:  9061\n",
      "Loss: 928.5488418268211\n",
      "Training step:  9062\n",
      "Loss: 928.5487846290558\n",
      "Training step:  9063\n",
      "Loss: 928.5487275002783\n",
      "Training step:  9064\n",
      "Loss: 928.5486703588213\n",
      "Training step:  9065\n",
      "Loss: 928.548613343094\n",
      "Training step:  9066\n",
      "Loss: 928.5485562699707\n",
      "Training step:  9067\n",
      "Loss: 928.5484993576993\n",
      "Training step:  9068\n",
      "Loss: 928.5484423550548\n",
      "Training step:  9069\n",
      "Loss: 928.5483855431339\n",
      "Training step:  9070\n",
      "Loss: 928.5483286126686\n",
      "Training step:  9071\n",
      "Loss: 928.5482718692045\n",
      "Training step:  9072\n",
      "Loss: 928.5482150383266\n",
      "Training step:  9073\n",
      "Loss: 928.5481583932494\n",
      "Training step:  9074\n",
      "Loss: 928.5481016326146\n",
      "Training step:  9075\n",
      "Loss: 928.548045010375\n",
      "Training step:  9076\n",
      "Loss: 928.5479883918501\n",
      "Training step:  9077\n",
      "Loss: 928.5479318708911\n",
      "Training step:  9078\n",
      "Loss: 928.5478753159049\n",
      "Training step:  9079\n",
      "Loss: 928.547818897315\n",
      "Training step:  9080\n",
      "Loss: 928.5477624124409\n",
      "Training step:  9081\n",
      "Loss: 928.5477060931914\n",
      "Training step:  9082\n",
      "Loss: 928.5476496782135\n",
      "Training step:  9083\n",
      "Loss: 928.5475934581152\n",
      "Training step:  9084\n",
      "Loss: 928.5475371146832\n",
      "Training step:  9085\n",
      "Loss: 928.5474809121339\n",
      "Training step:  9086\n",
      "Loss: 928.5474247116468\n",
      "Training step:  9087\n",
      "Loss: 928.5473686114856\n",
      "Training step:  9088\n",
      "Loss: 928.5473124703138\n",
      "Training step:  9089\n",
      "Loss: 928.5472564759365\n",
      "Training step:  9090\n",
      "Loss: 928.5472004044415\n",
      "Training step:  9091\n",
      "Loss: 928.5471445085462\n",
      "Training step:  9092\n",
      "Loss: 928.547088506542\n",
      "Training step:  9093\n",
      "Loss: 928.5470326897839\n",
      "Training step:  9094\n",
      "Loss: 928.5469767756975\n",
      "Training step:  9095\n",
      "Loss: 928.5469210448267\n",
      "Training step:  9096\n",
      "Loss: 928.5468652109397\n",
      "Training step:  9097\n",
      "Loss: 928.5468095569573\n",
      "Training step:  9098\n",
      "Loss: 928.5467538121482\n",
      "Training step:  9099\n",
      "Loss: 928.5466982550969\n",
      "Training step:  9100\n",
      "Loss: 928.5466425811425\n",
      "Training step:  9101\n",
      "Loss: 928.5465870204551\n",
      "Training step:  9102\n",
      "Loss: 928.546531533914\n",
      "Training step:  9103\n",
      "Loss: 928.5464760385847\n",
      "Training step:  9104\n",
      "Loss: 928.5464206065739\n",
      "Training step:  9105\n",
      "Loss: 928.5463652211166\n",
      "Training step:  9106\n",
      "Loss: 928.5463098504932\n",
      "Training step:  9107\n",
      "Loss: 928.5462545737445\n",
      "Training step:  9108\n",
      "Loss: 928.546199270274\n",
      "Training step:  9109\n",
      "Loss: 928.5461440932587\n",
      "Training step:  9110\n",
      "Loss: 928.5460888571073\n",
      "Training step:  9111\n",
      "Loss: 928.5460337785761\n",
      "Training step:  9112\n",
      "Loss: 928.5459786110663\n",
      "Training step:  9113\n",
      "Loss: 928.5459236259776\n",
      "Training step:  9114\n",
      "Loss: 928.5458685316747\n",
      "Training step:  9115\n",
      "Loss: 928.5458136107328\n",
      "Training step:  9116\n",
      "Loss: 928.5457586127176\n",
      "Training step:  9117\n",
      "Loss: 928.5457037886555\n",
      "Training step:  9118\n",
      "Loss: 928.5456488590264\n",
      "Training step:  9119\n",
      "Loss: 928.545594078203\n",
      "Training step:  9120\n",
      "Loss: 928.5455392673865\n",
      "Training step:  9121\n",
      "Loss: 928.5454845799568\n",
      "Training step:  9122\n",
      "Loss: 928.5454298351805\n",
      "Training step:  9123\n",
      "Loss: 928.5453752462454\n",
      "Training step:  9124\n",
      "Loss: 928.5453205695824\n",
      "Training step:  9125\n",
      "Loss: 928.5452660762891\n",
      "Training step:  9126\n",
      "Loss: 928.5452114680394\n",
      "Training step:  9127\n",
      "Loss: 928.5451569695098\n",
      "Training step:  9128\n",
      "Loss: 928.5451025552385\n",
      "Training step:  9129\n",
      "Loss: 928.5450481115143\n",
      "Training step:  9130\n",
      "Loss: 928.5449937517993\n",
      "Training step:  9131\n",
      "Loss: 928.544939421391\n",
      "Training step:  9132\n",
      "Loss: 928.5448851164359\n",
      "Training step:  9133\n",
      "Loss: 928.5448308863754\n",
      "Training step:  9134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 928.5447766461792\n",
      "Training step:  9135\n",
      "Loss: 928.5447225218319\n",
      "Training step:  9136\n",
      "Loss: 928.5446683494574\n",
      "Training step:  9137\n",
      "Loss: 928.5446143198054\n",
      "Training step:  9138\n",
      "Loss: 928.5445602150126\n",
      "Training step:  9139\n",
      "Loss: 928.5445062767725\n",
      "Training step:  9140\n",
      "Loss: 928.5444522423542\n",
      "Training step:  9141\n",
      "Loss: 928.5443983843691\n",
      "Training step:  9142\n",
      "Loss: 928.5443444308397\n",
      "Training step:  9143\n",
      "Loss: 928.5442906489837\n",
      "Training step:  9144\n",
      "Loss: 928.5442367797514\n",
      "Training step:  9145\n",
      "Loss: 928.5441830854454\n",
      "Training step:  9146\n",
      "Loss: 928.5441292904653\n",
      "Training step:  9147\n",
      "Loss: 928.5440756390592\n",
      "Training step:  9148\n",
      "Loss: 928.5440219573653\n",
      "Training step:  9149\n",
      "Loss: 928.5439683982761\n",
      "Training step:  9150\n",
      "Loss: 928.5439147824718\n",
      "Training step:  9151\n",
      "Loss: 928.5438613185124\n",
      "Training step:  9152\n",
      "Loss: 928.5438077697165\n",
      "Training step:  9153\n",
      "Loss: 928.5437543885183\n",
      "Training step:  9154\n",
      "Loss: 928.5437009166482\n",
      "Training step:  9155\n",
      "Loss: 928.5436476042377\n",
      "Training step:  9156\n",
      "Loss: 928.5435942227999\n",
      "Training step:  9157\n",
      "Loss: 928.5435410019298\n",
      "Training step:  9158\n",
      "Loss: 928.5434876872805\n",
      "Training step:  9159\n",
      "Loss: 928.5434345092862\n",
      "Training step:  9160\n",
      "Loss: 928.5433813000325\n",
      "Training step:  9161\n",
      "Loss: 928.5433282220584\n",
      "Training step:  9162\n",
      "Loss: 928.5432750794075\n",
      "Training step:  9163\n",
      "Loss: 928.5432220940328\n",
      "Training step:  9164\n",
      "Loss: 928.5431690179262\n",
      "Training step:  9165\n",
      "Loss: 928.5431161030962\n",
      "Training step:  9166\n",
      "Loss: 928.5430631139081\n",
      "Training step:  9167\n",
      "Loss: 928.5430102910897\n",
      "Training step:  9168\n",
      "Loss: 928.5429573697993\n",
      "Training step:  9169\n",
      "Loss: 928.5429045535142\n",
      "Training step:  9170\n",
      "Loss: 928.5428517816014\n",
      "Training step:  9171\n",
      "Loss: 928.5427990455273\n",
      "Training step:  9172\n",
      "Loss: 928.5427463311472\n",
      "Training step:  9173\n",
      "Loss: 928.5426936991116\n",
      "Training step:  9174\n",
      "Loss: 928.5426410425141\n",
      "Training step:  9175\n",
      "Loss: 928.5425885124097\n",
      "Training step:  9176\n",
      "Loss: 928.5425359219296\n",
      "Training step:  9177\n",
      "Loss: 928.5424834833256\n",
      "Training step:  9178\n",
      "Loss: 928.5424309588257\n",
      "Training step:  9179\n",
      "Loss: 928.542378608632\n",
      "Training step:  9180\n",
      "Loss: 928.5423261542222\n",
      "Training step:  9181\n",
      "Loss: 928.54227383949\n",
      "Training step:  9182\n",
      "Loss: 928.5422214998481\n",
      "Training step:  9183\n",
      "Loss: 928.5421692768133\n",
      "Training step:  9184\n",
      "Loss: 928.5421170009132\n",
      "Training step:  9185\n",
      "Loss: 928.5420648711971\n",
      "Training step:  9186\n",
      "Loss: 928.5420126609725\n",
      "Training step:  9187\n",
      "Loss: 928.5419606165043\n",
      "Training step:  9188\n",
      "Loss: 928.5419084769532\n",
      "Training step:  9189\n",
      "Loss: 928.5418564638887\n",
      "Training step:  9190\n",
      "Loss: 928.5418044402683\n",
      "Training step:  9191\n",
      "Loss: 928.5417525206515\n",
      "Training step:  9192\n",
      "Loss: 928.5417005606813\n",
      "Training step:  9193\n",
      "Loss: 928.5416487337468\n",
      "Training step:  9194\n",
      "Loss: 928.5415968391483\n",
      "Training step:  9195\n",
      "Loss: 928.5415451023154\n",
      "Training step:  9196\n",
      "Loss: 928.541493272986\n",
      "Training step:  9197\n",
      "Loss: 928.5414415965678\n",
      "Training step:  9198\n",
      "Loss: 928.5413898610375\n",
      "Training step:  9199\n",
      "Loss: 928.5413382728763\n",
      "Training step:  9200\n",
      "Loss: 928.5412866024574\n",
      "Training step:  9201\n",
      "Loss: 928.5412350903117\n",
      "Training step:  9202\n",
      "Loss: 928.5411834978587\n",
      "Training step:  9203\n",
      "Loss: 928.5411320648501\n",
      "Training step:  9204\n",
      "Loss: 928.5410805466064\n",
      "Training step:  9205\n",
      "Loss: 928.5410291802646\n",
      "Training step:  9206\n",
      "Loss: 928.5409777478808\n",
      "Training step:  9207\n",
      "Loss: 928.5409264701908\n",
      "Training step:  9208\n",
      "Loss: 928.5408751040527\n",
      "Training step:  9209\n",
      "Loss: 928.5408238646999\n",
      "Training step:  9210\n",
      "Loss: 928.5407726028644\n",
      "Training step:  9211\n",
      "Loss: 928.5407214573987\n",
      "Training step:  9212\n",
      "Loss: 928.5406702583405\n",
      "Training step:  9213\n",
      "Loss: 928.5406192039507\n",
      "Training step:  9214\n",
      "Loss: 928.5405680694463\n",
      "Training step:  9215\n",
      "Loss: 928.5405170984031\n",
      "Training step:  9216\n",
      "Loss: 928.540466034669\n",
      "Training step:  9217\n",
      "Loss: 928.5404150913095\n",
      "Training step:  9218\n",
      "Loss: 928.5403641431458\n",
      "Training step:  9219\n",
      "Loss: 928.5403132942095\n",
      "Training step:  9220\n",
      "Loss: 928.5402624020194\n",
      "Training step:  9221\n",
      "Loss: 928.5402116421361\n",
      "Training step:  9222\n",
      "Loss: 928.5401608194865\n",
      "Training step:  9223\n",
      "Loss: 928.5401101472393\n",
      "Training step:  9224\n",
      "Loss: 928.540059388749\n",
      "Training step:  9225\n",
      "Loss: 928.540008748318\n",
      "Training step:  9226\n",
      "Loss: 928.5399581018522\n",
      "Training step:  9227\n",
      "Loss: 928.5399075555285\n",
      "Training step:  9228\n",
      "Loss: 928.5398569677734\n",
      "Training step:  9229\n",
      "Loss: 928.5398065112394\n",
      "Training step:  9230\n",
      "Loss: 928.5397559874342\n",
      "Training step:  9231\n",
      "Loss: 928.539705618286\n",
      "Training step:  9232\n",
      "Loss: 928.5396551597113\n",
      "Training step:  9233\n",
      "Loss: 928.5396048506678\n",
      "Training step:  9234\n",
      "Loss: 928.5395544791515\n",
      "Training step:  9235\n",
      "Loss: 928.5395042576578\n",
      "Training step:  9236\n",
      "Loss: 928.5394539498263\n",
      "Training step:  9237\n",
      "Loss: 928.5394037623386\n",
      "Training step:  9238\n",
      "Loss: 928.5393535631624\n",
      "Training step:  9239\n",
      "Loss: 928.5393034652717\n",
      "Training step:  9240\n",
      "Loss: 928.5392533278683\n",
      "Training step:  9241\n",
      "Loss: 928.5392033188837\n",
      "Training step:  9242\n",
      "Loss: 928.5391532449369\n",
      "Training step:  9243\n",
      "Loss: 928.5391033224525\n",
      "Training step:  9244\n",
      "Loss: 928.5390533132436\n",
      "Training step:  9245\n",
      "Loss: 928.5390034434513\n",
      "Training step:  9246\n",
      "Loss: 928.5389535284594\n",
      "Training step:  9247\n",
      "Loss: 928.5389037436157\n",
      "Training step:  9248\n",
      "Loss: 928.5388538919195\n",
      "Training step:  9249\n",
      "Loss: 928.5388041931373\n",
      "Training step:  9250\n",
      "Loss: 928.5387544059188\n",
      "Training step:  9251\n",
      "Loss: 928.5387047133295\n",
      "Training step:  9252\n",
      "Loss: 928.5386550830125\n",
      "Training step:  9253\n",
      "Loss: 928.5386054494259\n",
      "Training step:  9254\n",
      "Loss: 928.5385558709319\n",
      "Training step:  9255\n",
      "Loss: 928.5385063298123\n",
      "Training step:  9256\n",
      "Loss: 928.5384568120033\n",
      "Training step:  9257\n",
      "Loss: 928.5384073689385\n",
      "Training step:  9258\n",
      "Loss: 928.5383579059909\n",
      "Training step:  9259\n",
      "Loss: 928.5383085540548\n",
      "Training step:  9260\n",
      "Loss: 928.5382591537938\n",
      "Training step:  9261\n",
      "Loss: 928.5382098870584\n",
      "Training step:  9262\n",
      "Loss: 928.5381605494666\n",
      "Training step:  9263\n",
      "Loss: 928.53811136072\n",
      "Training step:  9264\n",
      "Loss: 928.5380620937154\n",
      "Training step:  9265\n",
      "Loss: 928.5380129694505\n",
      "Training step:  9266\n",
      "Loss: 928.5379637833928\n",
      "Training step:  9267\n",
      "Loss: 928.5379147429168\n",
      "Training step:  9268\n",
      "Loss: 928.5378656139674\n",
      "Training step:  9269\n",
      "Loss: 928.5378165957663\n",
      "Training step:  9270\n",
      "Loss: 928.5377675860728\n",
      "Training step:  9271\n",
      "Loss: 928.5377186520584\n",
      "Training step:  9272\n",
      "Loss: 928.5376697015726\n",
      "Training step:  9273\n",
      "Loss: 928.5376208606723\n",
      "Training step:  9274\n",
      "Loss: 928.5375719707537\n",
      "Training step:  9275\n",
      "Loss: 928.5375232161771\n",
      "Training step:  9276\n",
      "Loss: 928.5374743883795\n",
      "Training step:  9277\n",
      "Loss: 928.5374257090247\n",
      "Training step:  9278\n",
      "Loss: 928.5373769515832\n",
      "Training step:  9279\n",
      "Loss: 928.5373283336792\n",
      "Training step:  9280\n",
      "Loss: 928.5372796593646\n",
      "Training step:  9281\n",
      "Loss: 928.5372311244246\n",
      "Training step:  9282\n",
      "Loss: 928.5371825120086\n",
      "Training step:  9283\n",
      "Loss: 928.5371340199264\n",
      "Training step:  9284\n",
      "Loss: 928.5370855051547\n",
      "Training step:  9285\n",
      "Loss: 928.5370370977944\n",
      "Training step:  9286\n",
      "Loss: 928.5369886450468\n",
      "Training step:  9287\n",
      "Loss: 928.5369403210357\n",
      "Training step:  9288\n",
      "Loss: 928.5368919299558\n",
      "Training step:  9289\n",
      "Loss: 928.5368436844343\n",
      "Training step:  9290\n",
      "Loss: 928.5367953606042\n",
      "Training step:  9291\n",
      "Loss: 928.5367471492705\n",
      "Training step:  9292\n",
      "Loss: 928.5366989261532\n",
      "Training step:  9293\n",
      "Loss: 928.5366508014341\n",
      "Training step:  9294\n",
      "Loss: 928.5366026382653\n",
      "Training step:  9295\n",
      "Loss: 928.5365545984058\n",
      "Training step:  9296\n",
      "Loss: 928.5365064966155\n",
      "Training step:  9297\n",
      "Loss: 928.5364585393871\n",
      "Training step:  9298\n",
      "Loss: 928.5364105001471\n",
      "Training step:  9299\n",
      "Loss: 928.536362571782\n",
      "Training step:  9300\n",
      "Loss: 928.5363146392065\n",
      "Training step:  9301\n",
      "Loss: 928.5362667949175\n",
      "Training step:  9302\n",
      "Loss: 928.536218919382\n",
      "Training step:  9303\n",
      "Loss: 928.5361711625239\n",
      "Training step:  9304\n",
      "Loss: 928.5361233481311\n",
      "Training step:  9305\n",
      "Loss: 928.5360756733544\n",
      "Training step:  9306\n",
      "Loss: 928.5360279199542\n",
      "Training step:  9307\n",
      "Loss: 928.5359802854315\n",
      "Training step:  9308\n",
      "Loss: 928.5359326302288\n",
      "Training step:  9309\n",
      "Loss: 928.5358850781357\n",
      "Training step:  9310\n",
      "Loss: 928.5358374829041\n",
      "Training step:  9311\n",
      "Loss: 928.5357900137212\n",
      "Training step:  9312\n",
      "Loss: 928.5357424792444\n",
      "Training step:  9313\n",
      "Loss: 928.5356950915866\n",
      "Training step:  9314\n",
      "Loss: 928.5356476189938\n",
      "Training step:  9315\n",
      "Loss: 928.5356002337018\n",
      "Training step:  9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 928.5355528977899\n",
      "Training step:  9317\n",
      "Loss: 928.5355055748228\n",
      "Training step:  9318\n",
      "Loss: 928.5354583152813\n",
      "Training step:  9319\n",
      "Loss: 928.5354110446647\n",
      "Training step:  9320\n",
      "Loss: 928.5353638782564\n",
      "Training step:  9321\n",
      "Loss: 928.5353166632382\n",
      "Training step:  9322\n",
      "Loss: 928.5352695775252\n",
      "Training step:  9323\n",
      "Loss: 928.5352224253486\n",
      "Training step:  9324\n",
      "Loss: 928.5351754099645\n",
      "Training step:  9325\n",
      "Loss: 928.5351283264515\n",
      "Training step:  9326\n",
      "Loss: 928.5350813716478\n",
      "Training step:  9327\n",
      "Loss: 928.5350343655582\n",
      "Training step:  9328\n",
      "Loss: 928.5349874914189\n",
      "Training step:  9329\n",
      "Loss: 928.5349405478618\n",
      "Training step:  9330\n",
      "Loss: 928.5348937114367\n",
      "Training step:  9331\n",
      "Loss: 928.5348468657022\n",
      "Training step:  9332\n",
      "Loss: 928.5348001129952\n",
      "Training step:  9333\n",
      "Loss: 928.5347533206796\n",
      "Training step:  9334\n",
      "Loss: 928.5347066511735\n",
      "Training step:  9335\n",
      "Loss: 928.5346599204305\n",
      "Training step:  9336\n",
      "Loss: 928.5346133246768\n",
      "Training step:  9337\n",
      "Loss: 928.5345666615113\n",
      "Training step:  9338\n",
      "Loss: 928.5345201070866\n",
      "Training step:  9339\n",
      "Loss: 928.5344735356554\n",
      "Training step:  9340\n",
      "Loss: 928.5344270622974\n",
      "Training step:  9341\n",
      "Loss: 928.5343805473267\n",
      "Training step:  9342\n",
      "Loss: 928.5343341589511\n",
      "Training step:  9343\n",
      "Loss: 928.5342877030714\n",
      "Training step:  9344\n",
      "Loss: 928.53424137313\n",
      "Training step:  9345\n",
      "Loss: 928.5341949930972\n",
      "Training step:  9346\n",
      "Loss: 928.5341487447678\n",
      "Training step:  9347\n",
      "Loss: 928.5341024260716\n",
      "Training step:  9348\n",
      "Loss: 928.5340561900091\n",
      "Training step:  9349\n",
      "Loss: 928.5340100110209\n",
      "Training step:  9350\n",
      "Loss: 928.5339638341516\n",
      "Training step:  9351\n",
      "Loss: 928.5339176990761\n",
      "Training step:  9352\n",
      "Loss: 928.5338716244005\n",
      "Training step:  9353\n",
      "Loss: 928.5338255391405\n",
      "Training step:  9354\n",
      "Loss: 928.5337795512762\n",
      "Training step:  9355\n",
      "Loss: 928.5337335251727\n",
      "Training step:  9356\n",
      "Loss: 928.5336876159523\n",
      "Training step:  9357\n",
      "Loss: 928.5336416489212\n",
      "Training step:  9358\n",
      "Loss: 928.5335958181901\n",
      "Training step:  9359\n",
      "Loss: 928.5335499112751\n",
      "Training step:  9360\n",
      "Loss: 928.5335041114458\n",
      "Training step:  9361\n",
      "Loss: 928.5334583090602\n",
      "Training step:  9362\n",
      "Loss: 928.5334125867286\n",
      "Training step:  9363\n",
      "Loss: 928.5333668405015\n",
      "Training step:  9364\n",
      "Loss: 928.5333211962986\n",
      "Training step:  9365\n",
      "Loss: 928.5332755088374\n",
      "Training step:  9366\n",
      "Loss: 928.5332299426129\n",
      "Training step:  9367\n",
      "Loss: 928.5331843138639\n",
      "Training step:  9368\n",
      "Loss: 928.5331388254705\n",
      "Training step:  9369\n",
      "Loss: 928.5330932564453\n",
      "Training step:  9370\n",
      "Loss: 928.5330477743021\n",
      "Training step:  9371\n",
      "Loss: 928.5330023621221\n",
      "Training step:  9372\n",
      "Loss: 928.5329569076582\n",
      "Training step:  9373\n",
      "Loss: 928.5329115735938\n",
      "Training step:  9374\n",
      "Loss: 928.5328661799151\n",
      "Training step:  9375\n",
      "Loss: 928.532820899281\n",
      "Training step:  9376\n",
      "Loss: 928.5327755837153\n",
      "Training step:  9377\n",
      "Loss: 928.5327303823013\n",
      "Training step:  9378\n",
      "Loss: 928.5326851250151\n",
      "Training step:  9379\n",
      "Loss: 928.5326399951766\n",
      "Training step:  9380\n",
      "Loss: 928.5325948020514\n",
      "Training step:  9381\n",
      "Loss: 928.532549709543\n",
      "Training step:  9382\n",
      "Loss: 928.5325046105237\n",
      "Training step:  9383\n",
      "Loss: 928.5324595940513\n",
      "Training step:  9384\n",
      "Loss: 928.5324145496171\n",
      "Training step:  9385\n",
      "Loss: 928.5323696142588\n",
      "Training step:  9386\n",
      "Loss: 928.5323246277844\n",
      "Training step:  9387\n",
      "Loss: 928.5322797720349\n",
      "Training step:  9388\n",
      "Loss: 928.5322348420032\n",
      "Training step:  9389\n",
      "Loss: 928.5321899965602\n",
      "Training step:  9390\n",
      "Loss: 928.532145225873\n",
      "Training step:  9391\n",
      "Loss: 928.5321004143226\n",
      "Training step:  9392\n",
      "Loss: 928.5320557199319\n",
      "Training step:  9393\n",
      "Loss: 928.5320109661347\n",
      "Training step:  9394\n",
      "Loss: 928.5319663478996\n",
      "Training step:  9395\n",
      "Loss: 928.5319216528584\n",
      "Training step:  9396\n",
      "Loss: 928.5318770478608\n",
      "Training step:  9397\n",
      "Loss: 928.5318324764793\n",
      "Training step:  9398\n",
      "Loss: 928.5317879316308\n",
      "Training step:  9399\n",
      "Loss: 928.5317434167614\n",
      "Training step:  9400\n",
      "Loss: 928.5316989566655\n",
      "Training step:  9401\n",
      "Loss: 928.5316544928594\n",
      "Training step:  9402\n",
      "Loss: 928.5316101131394\n",
      "Training step:  9403\n",
      "Loss: 928.5315657067376\n",
      "Training step:  9404\n",
      "Loss: 928.5315214025603\n",
      "Training step:  9405\n",
      "Loss: 928.531477052649\n",
      "Training step:  9406\n",
      "Loss: 928.5314328247922\n",
      "Training step:  9407\n",
      "Loss: 928.5313885330348\n",
      "Training step:  9408\n",
      "Loss: 928.5313443405428\n",
      "Training step:  9409\n",
      "Loss: 928.5313001419333\n",
      "Training step:  9410\n",
      "Loss: 928.5312560271431\n",
      "Training step:  9411\n",
      "Loss: 928.5312118828006\n",
      "Training step:  9412\n",
      "Loss: 928.5311678430012\n",
      "Training step:  9413\n",
      "Loss: 928.5311237556789\n",
      "Training step:  9414\n",
      "Loss: 928.5310797907755\n",
      "Training step:  9415\n",
      "Loss: 928.5310357614663\n",
      "Training step:  9416\n",
      "Loss: 928.5309918180532\n",
      "Training step:  9417\n",
      "Loss: 928.5309478958683\n",
      "Training step:  9418\n",
      "Loss: 928.5309040263413\n",
      "Training step:  9419\n",
      "Loss: 928.5308601519539\n",
      "Training step:  9420\n",
      "Loss: 928.5308163641153\n",
      "Training step:  9421\n",
      "Loss: 928.5307725464811\n",
      "Training step:  9422\n",
      "Loss: 928.530728833053\n",
      "Training step:  9423\n",
      "Loss: 928.5306850720831\n",
      "Training step:  9424\n",
      "Loss: 928.5306414329276\n",
      "Training step:  9425\n",
      "Loss: 928.5305977285639\n",
      "Training step:  9426\n",
      "Loss: 928.530554131738\n",
      "Training step:  9427\n",
      "Loss: 928.5305105159548\n",
      "Training step:  9428\n",
      "Loss: 928.5304669904156\n",
      "Training step:  9429\n",
      "Loss: 928.53042342962\n",
      "Training step:  9430\n",
      "Loss: 928.5303799796792\n",
      "Training step:  9431\n",
      "Loss: 928.5303364752493\n",
      "Training step:  9432\n",
      "Loss: 928.5302930829026\n",
      "Training step:  9433\n",
      "Loss: 928.5302496505541\n",
      "Training step:  9434\n",
      "Loss: 928.5302063308583\n",
      "Training step:  9435\n",
      "Loss: 928.5301629547528\n",
      "Training step:  9436\n",
      "Loss: 928.5301196737781\n",
      "Training step:  9437\n",
      "Loss: 928.5300763851461\n",
      "Training step:  9438\n",
      "Loss: 928.5300331779499\n",
      "Training step:  9439\n",
      "Loss: 928.5299899439939\n",
      "Training step:  9440\n",
      "Loss: 928.5299468117621\n",
      "Training step:  9441\n",
      "Loss: 928.5299036338165\n",
      "Training step:  9442\n",
      "Loss: 928.5298605710227\n",
      "Training step:  9443\n",
      "Loss: 928.5298174525143\n",
      "Training step:  9444\n",
      "Loss: 928.529774426203\n",
      "Training step:  9445\n",
      "Loss: 928.5297313973484\n",
      "Training step:  9446\n",
      "Loss: 928.5296884462092\n",
      "Training step:  9447\n",
      "Loss: 928.5296454696349\n",
      "Training step:  9448\n",
      "Loss: 928.5296025923514\n",
      "Training step:  9449\n",
      "Loss: 928.5295596715073\n",
      "Training step:  9450\n",
      "Loss: 928.5295168668979"
     ]
    }
   ],
   "source": [
    "#china\n",
    "#0217 是最原始的版本\n",
    "##0218是改了Loss的全国模型与参数  死亡率除100\n",
    "#02-19里面存的是  第二版loss  死亡率除10   治愈率乘2\n",
    "#i=2  深圳  1 武汉   0 湖北\n",
    "i=3\n",
    "data=read_data(paths[i])\n",
    "city_name=citys[i]\n",
    "# param_path='models/'+'china/02-12'\n",
    "datetime='02-18'\n",
    "# param_path='models/shenzhen/02-17'\n",
    "param_path=''\n",
    "N=0\n",
    "if i == 3:\n",
    "    N = (max(data['E']) + max(data['I']) + max(data['cured']) + max(data['dead'])) * 100.\n",
    "else :\n",
    "    N = N_inits[i]\n",
    "model_city_date_path = train_with_city_data(data,N,datetime,city_name,max_epoches=10000,is_train=True,load_param_save=True,lr_init=0.000002,param_path=param_path)\n",
    "# model_city_date_path = train_with_city_data(data,N,datetime,city_name)\n",
    "# load_model_predict(model_city_date_path, data, param_pred=True, city_name=city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [0.48950974618058807, 0.5395410968546343, 0.5756041257276714, 0.6314131045740865, 0.6542966999603474, 0.6714439281836274, 0.5594452328316283, 0.48286318442019155, 0.48075274600049717, 0.4746288304705356, 0.4212396308453701, 0.2570364951531042, 0.24669486830743073, 0.24258217476060137, 0.23278147937784743, 0.2238736304721575, 0.2188692460587646, 0.21771995058905788, 0.2140081506949854, 0.211090418324371, 0.20812471984508044, 0.21274403810375775, 0.14931161387404734, 0.10860536974089037, 0.08833339823375518, 0.0850794900548049, 0.08397569832035871]\n",
      "[0.07260608 0.05793254]\n",
      "{'beta': 0.24069179879617109, 'gamma_2': 0.16214446453557896, 'theta': 0.04444591921294164, 'alpha': 0.20658663726775095}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAGACAYAAAAZEJ47AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZzNdfvH8dfHWLNkiZCiUGSvKSQ1SYpEIiVbK+H2q7vN3b5Q2gslKSGplDZUKHs1CpEWUkl2hhljCbN9fn9cc8xum+WcmXk/H495zPl+z3c7023ua67P53NdznuPiIiIiISOIsF+ABERERFJSwGaiIiISIhRgCYiIiISYhSgiYiIiIQYBWgiIiIiIUYBmoiENOdccefc/5xz5bJ4v5xzrkS6fTek3xdKnHM1g/0MIhLaigb7AUREDsd7H+ec2wL0cs4BLPLe/5zqkAZAH2BAqn09gN+dcxu899vTX9M5dxOw3ns/xzlXA+jivR91uOdwzpUBEoHqwA1AHPCC9z7hOD7WV8657t77FYe5X1vgAFARqAKcAFQC2gL7gcu994nHcW8RyQeUQRORkOSce8g5t8A59x3QEzgN2Az8k+7QFcCm5HNOdM49BFQGmgJZZdG2A+UAvPcbgQudc+HOuQaZPMfnzrmuwHXA6ORrrwbuBMocx+c6H9iCBV6HcytQHPgGGAd8BcwAOgJnKDgTKdgUoIlISHHOneuc6wAcBO4GugBDsOzRYu/97lTHFvfe7wdqOudu8d7HAr9h2a1iwGbn3Ampji+XvH0QOHQdYBsWdN2QySP1xjJZM4C13vvFWID3hPd+1zF+Ngc8gAV7xZxz9yXvy8zfyZ+lGTAPuA3Y672PSX5PRAowBWgiEmp+AppgAVYSMBA4HSiPBVKp9XbOlcYCme+dc+dimbGtwEnAKOAl51z55OPDgPeTX6fOQDngbGB++ofx3kcDa7z324DTnXODsUDuu+P4bPcDo733W733s4B/seHOOpkcexBI9N7PAb4GdpKSsYs9jnuLSD6iAE1EQor3PsF7PxzLmG3H5l59CnwJvOyc657q8GuBeGwosCw2H20fMAGoAQzz3vcPZLqSs089ks91zrlbnHP3A+cAtYBf0z+Pc+4coG7y5s/Y781E7/1P6Y77zDm3Nd3XU6nevxvLfJ3inPvAOTcWWIhl5qY75551zlVOfUkgMXlItDEWnJ6dnHHT8KZIAadFAiISUpxzp2OT/psDpYA1wH+BTsB47/0HqQ5/FgvgnPc+0jn3PTAceAW4CMumbU53i2pAZ+BD7/0451xjoCEw1XuflO5Zaiffo51zrkjyNfsAN6V/bu9958N8plbAF977VcnbHYAXgJ3e+5eBlzM5rSQQ573/wTk3G8vuRQC10e9ukQJPGTQRCRnJQ5FPA+OBVd77P4AYbIL8juTvh3jv52IrHA8k7yoF1ARKYxPxS6W6djnn3AgswJoLBFZf9gKeAx7N5JEeA+YkB24PACOTr7k31XWbH+lzee+/9d6vcs6d4pwbBpwFDMYWMmTlRKCuc+7F5ON6YVnCGsmfT0QKMOe9D/YziIik4Zy7FjjgvZ+evP0icJb3/spMju0OlPDeT3LOnQ3cAyzAhgg3ee+/SnXsed77Jc65vsAfwMnAHu/91865W4FLgP/z3u9MPr4aNnzaHIj13s9yzpUFXgRux+bJvQd0997HH8PnG++9z5CFS3fMF977Dsmvw5KftTwWHH7hvW94tPcTkfxHaXIRCSnOuZOA87339zrnimMT8pOAxc65icB9yRP2A04Dfkl+HQ5MweZ2dcUWChzivV+S/PIUYJn3/rtU773pnKsOPO+cG+G9X+G935IckH2VPH8N7/0e59w3wCfYpP2fgcP+pZtcNPdiLLtXG5tL9iY2PFsDyxb2T3daseQFCaWTrx+NZQqLYrXYRKQAUwZNREKKc64dNqyY6Jy7APjHex+oc9YPeByYDjzpvf8nOaja572Pdc41wzJjiVgW7W7v/aJM7nER8L33/mAefazAPLS9wOqjua9zrrr3Pv38ucB7j3vvMxuSFZECQgGaiBRIzrky3vu9Rz5SRCT0KEATERERCTFaxSkiIiISYhSgiYiIiIQYBWgiIiIiIabAldk46aSTfK1atYL9GCIiIiJHtGzZsh3e+8rp9xe4AK1WrVosXbo02I8hIiIickTOuX8y268hThEREZEQowBNRERECrd9+2DOHNi4MdhPcogCNBEREcn/YmOhShVo2RIiIuCnn6B7d2jRArp0gfhU7XL374czzrDX8fHQvj107Qr16sF558GCBXDqqVCuHJx2Gvz7L3zyiV03IsKuefnldv6jj9o5gwalfZ7U9zgOBW4OWmbi4+PZuHEjBw4cCPajFBglS5akRo0aFCtWLNiPIiIiBUVCggU1gcBmxAh48klYvx6qVYMPPrD9vXpBTIwd/9FHUKYMXHIJnHUW7N0Lb74Jv/8Oq1bZeT/+CJMnw4032vnDhsGWLfZ6zRq45hoL7E49FYoVs/tecAFMmWL7770XXn3VAj2A556D2rVh2TL45hv44Qd44gn4+mto2zbjPY5DrgVozrnRwJfe++nOuXHA2cDn3vthye8f975jtXHjRsqWLUutWrVwzmX7sxV23nt27tzJxo0bOf3004P9OCIiktq+fbB4sQUrNWoE+2kgOtoCmWbN4KSTDn/sypXQowc884xtT5sGTZpYYPbAA/DZZ1C8OFxxBdx0kx03aRJceik0bw4LF1qA1q8fXHmlBW4ff2zvrVpl11y92u7TvLltN2hgGbOpUyEqyq69fTtUqGDX2rMHSpdOecb9+2H2bPjqK3jxRcu8OWcZtS+/tAAt/T2OQ64McTrnWgNVk4Oza4Aw731L4AznXN3s7Due5zlw4ACVKlVScJZDnHNUqlRJGUkRkdySkGBDa4EhtaFDMw6v7dwJ115r+/r0saG6+Hjo0MGyOmecYUNvF18M7dpBpUpQsSJ07pwy3JfZ8Nzu3RYEBe7300/QqZMN96UeKjyacxctgjPPhJtvtufZvDnzc+PibDiya1d47TV7r1cvC4BGjrSg7ZdfoG5de5abbrLzoqJsWLNBA7vHSy9BnTpw8skWnJ5xhp2flGTDlwD33GP7UjvvPMuinXuuBVsNGsBvv8H//R9s2GA/34BJk+CGG+z1vn1wyin2umJF2LYt63scoxwP0JxzxYA3gHXOuc5ABJCck2Q2cGE292V2z37OuaXOuaVRUVFZPddxfiLJjH6eIiK5KJBJmj/fvh5+OOV1167Qv79lj7p2tX3VqtkQ3po1Nhx31VUWmN16K9x9twUxd90Ft98OYWGWiUo9PFelig3PJSZa5qlUqZT7/fqrZZ/q1IH69Y/t3EWLoFs3C3Lq14fRozM/d+bMlEzZjTfCkCGwfDmcfbZlpDZtsmAs9ZyutWth7lz7GQA0bmyZw6QkCA+Hv/+261x/PRw8aFmtt9+2n0v60Z/GjW3Yslcvy5BVrw5PPQVFiljw9u67Kce+954FxmAZuv377fXevXbvrO5xjHIjg9YH+A14FjgfGARsSn4vGjgZKJ2NfRl478d678O99+GVK2eo9ZZvLV26lNdff53ffvuNdevWHfbYCRMmHPF62wKR/WG88sorh17v2bPniMeLiEguWLwYZsyA88+HW26xjBqkDK9dc40FY+ecY/urVLFJ8g0aQMeO8OGHEBlpAdHYsbB1qwV9K1fa3K26dW1YL/Xw3KJFdq327e1+gXuXL2/Dk6VLW1bpWM5t1cqGCGfOhL/+svczO7dSJbv2GWfYfLO6dS04KlrUgqzOnS3AGz7c7nPwoAVyY8fanDGA3r3tuBtugHHj4NNPbe7ZjTfafLKiRe05pk2z7N6KFfazmjLFMmc//WTDsWvW2LlxcZa1q1PHnhVg3To48UQLzMDO++Ybe/3TT1CrVub3OA65EaA1A8Z677cC7wALgVLJ75VJvufebOzLt+rUqXNMx5999tksWLCAhQsX8ssvv2R4f+HChcybNw+AdevWMXfuXP79998sr/fII4/w6aefZvn+8uXL2bNnD6+88gq7du3ijjvuYH/gLwMRETk2RzNMGZB+xV+jRvb9hx9sSHH6dLtWkyaWjfr5Zwtynn7a5kKNG2fBSUB0tGWF5syxYGLfPps0v3EjVK5s98pseC4sDC67zM4N3HvHDguCNm60IO1Yzv0nuQbrY49ByZIWeGV2boMGth0RYYFRzZqWkZs82bJX48bZ9QOB0k03WeAVHm7bU6ZYkNq7NzzyiA2rTp1q2cPvv4c//oCBA+1aixZZdq9pUwuCu3SBqlUtiHvySfs5Tp1qw7A//miZvIED7T6zZ8NFF6X8nC+80N6/4w77b9GjR+b3OA65sUjgTyDwv7JwoBY2NLkYaAL8DmzMxr68ERlpP9yICFvBkYcee+wxateuzWeffUbZsmW5+eabiYuLS3NMfHw8a9as4aabbuLTTz9l06ZNTJgwgeaHmZC4bt06rrzyyizf37t3LzExMVSrVo3SpUtTrVo1SpYsyd69eykT+GtBRESOTvoJ72DDjIsXw7x5KdkvSLviLzHRhtf27bPt8HCb/N6jhwU+06db0NWokQU2o0dbcJG6zeHIkfDOOxbY7N5tGbDbb4c//7SgZ/hwC9TSD8+BBVglSqTcOzBU+H//Z0Hh8ZzbuLENC/brZ8N/6c8dOdKOK1LEhknPPBNuu80ycbfeCrt2QdmyNuH/yy+t5MXmzTac2KULDBhgw6Ply9uw6IQJ9jP+99+U/w+fOtUCqYD58+178eI2zJre2rUZ9/Xrl3a7SBE79/PP7drphzUD9zgOuRGgjQPecs5dDxTD5pFNc85VB9oDLQAPLDrOfdlz552Wcjyc2Fj7h5WUZD/8xo0tpZmVpk3h5Zez/WgBxYsXp02bNlx00UXs37+fiRMn8tNPP6UZfixWrBiXXHIJM2bMoHz58vTu3Zvly5dTsmRJ5s6dS5s2bdJcc+bMmdSsWZOiRTP/T75mzRomTpzIrl27aNOmDdOmTaNo0aI8+uijtG3blotS/8UgIlJYpC/7MGqUBUbPPAMnnACDB1vGp1evtKUgZsyA++6zIOLVVy1w+OMPm8AfEWFlHBYvtmtmtuKvaFFb8ZiYaMNtDRtacLJjhwUCr79uxzRtasNwH39s502ZYkN0P/9sJSPq1LHXv/1mw43Ll9t8rnr1bHjugw9sjlZgeA4sC7V3b8q9Y2LsOgDffWcB2NGeu3q1BZ5jxlhwmNV9o6LsOXv2tECuRAnLZiUlWTmLjz+2eWFg2bfMRnc++ijtdvv2mR+X00qVsnl2OSzHAzTv/R7g2tT7nHMRwGXAs9772Ozuy3WxsSl/DSQl2fbhArTj0L9/f37/PSUh2KZNGx555BEA9u/fz7Rp01i+fDk9e/ZkwoQJvJt6gmKyDz/8kAEDBjB+/HgGDRqE957//e9/XHHFFWmOi4uLY+LEiYwZM4bXXnuNgYFUbSo7d+6kd+/elCpVimLFihEXF8cJJ5xA8eLFFZyJSOGVWRbszz8ti7VggW2nnuAeKAXRrZutIqxRwzJZn39u2ax777WgrXNnm7vUoIGt+Bs1KmVlYliYZalatLAArFMnuPpqC7jCwizJ8MUXtn/iRMs4BYKXLl3sedets+G4GjVswcA336SsRGzc2IbsqlWD+++3gG/mTPsCGyJMfe+bb7ZrLltmAc/HHx/9uc8/b/XJ3njDAs7p0+1Z05+blGT36NcvJRiFjJ8vrwRxFC3Aee+DcuPcEh4e7tM3S1+1ahX169c/+otERlpNlbg4S33OmZMj/4Hq1KnDn3/+edhjVq1axdq1a/n999/ZtWsX5513HgCzZ8/m/PPPp3fv3gBs2LCBzZs3ExUVxRdffMGJJ55IjRo1+Pvvv+nWrRstWqQkG5988kmuvPJKmjZtyrJly3jvvfd49tlnKVLEpvT9+++/rF27ljlz5rB161bKlCnDWWedxXfffcfQoUMpnbr+S7pnPaafq4hIfjN6tGXASpe2zNnrr9vcsZo1oU0bCyoWL7bjXn/dMmmPP24B28GDFnh06mRBUny8zYk67zzLvk2YYHOVtm2zwC0iIu2QWOrtgwdThg5Hjky5Vnbt32/B4znnHHvV+2Cde7SyCrLi4ixjt317yte2bSmvV6+2oWTvLTuWQzFAVpxzy7z34en3F4pOAsesZUv7D5LH0XN8fDwbNmygbNmy9OnTh61bt/LXX3/RuXNntm3bxksvvUS3bt0oVaoUcXFxFCtWjPj4eIoWLUrRokXp0KFDhsKxH3/8MWeffTZNmzYF4Nxzz2Xx4sVcfvnlPPvsszRr1oyoqCi2bNnCwYMHOfvss6lduzZnnXUWL774IomJiXny2UVEQtJ559kco2rVLAP1+ec2r+mJJ1KGMR9+2I4dOTJlEj3YcN9ZZ9lQ3uTJll1bt86GAMuUsTlVM2fapP/PP09Z8ZfZpPLeveHBBy279Omndq2ckJ3hubw490iZrIMHbQg2JsYWRgS+//ijBdaJiTZVqWFDOHDAArCYmMzvVby41U9LTLTgDCyYmz8/KFk0BWhZadkyz/+DBIYWw8LCeP/992nfvj2dO3dm8eLF9OzZkypVqlCqlC1qrVmzJpMnT+a0006jdevWNGzYkOeff56TTjqJ7t2706BBA7Zs2cI555xDrdQTR4FBgwZRsmRJpkyZQkJCAueddx41a9YkISGBF154gf79+7Nnzx4++OADrr76ah577DENc4pI4ZR+0vvq1dC3rw0d9u1r87pOPDFlIvzHH9vw5FNPpQz31axpQ5Rt21pZiNtus3PGjUtbXysiIusVf488YuUjvLeMXKCd0NHI7nBdds7P6tyEBFsEsXdv1l+//GJBVkKCBVmtWtm5qQOyw1QuOCQx0RZKhIfbSs8qVSwQC7wObJcta6tE04+iRUQc22fOIQrQ8tCRhjcB2rZtS8mSJWnVqhX33HMPa9asYfPmzdx+++385z//OXTcpk2b6N69O6VKlWLkyJFEREQwYsQIZsyYwdatW6lduzbVqlXL8j633HJLmu2VK1dy8skn8/XXX7N9+3aqVKkCWH21H3/8kR07dnDSkVp0iIgUNOkzVwMH2vAXwNKlFnzFxNgE98aNUybRg2XJ2ra188Am8G/bZhm3F16whQOppV/xl3p7zx7LxF1wgQ0L7thhAURcnGWRAq9Tfx08aM/12GMW5ARqimVW8imr6U5//gnPPmtDqkWL2mrJatUy3jfwOvX37dthyRIb5nXOgqCEBAu+jrUTTWKilQk56yxbNFChgpXoqFAh7evA9z//tFpxgSBr8uSjDy6DNIqWnuagFQDR0dFUrFgxz+9b0H+uIlIAZLYKs3fvlODowQctkLr/ftv23oKo1att++efLQt26qlWYmLHDgu4Dh60umSTJ9t8sh49rOJ+YIL7KadYtmzvXiutARYs9Ohh85+qV7c5aCVLZnzm3bvtWr/8Yvf/9lsbsgs1YWEW/JQokfZ74PWOHVY7LaBpUwt2ypQ5uq9Vq2zRw/HOBw+Bif5HQ3PQCrBgBGciIvlC+lWYO3daqYf33097XCBb9eGHNicsINA6aOZMC5xGjbIAbuxY205dUDa99DWzli2zYbZAwLB/v5W9+OWXtF/r16ecU7q0ZYScs+DROSsf0b592mAo8Dr91+rV9hzx8VZsdtKktPXXUsushd+PP9rCh8D506ZZcdbixS1AO5z0Q4WjRx9boHTaadnLZAVhqlJOUoAmIiIFV6Bl0rx5Fkx17mzB1AUX2NyjSZNs7lHAmDFWwgIsA/TOOzZUBpZ1++svy4qtXGkNyI9GYmJKj8n4eJtPVb261SMLlHQqXtxaGbVubVm4wNdpp1kl/NSBzkMPHX3gcd55NqR5vEHO6afbsx7P+TkxVJjPg6zsUIAmIiIFV/pVmOvWwaxZ1nLokUdg/HirkA9WN+zCC1PmkA0ZYu17Xn/dtqtWtTlno0ZZb8vkMkhpbN9uwdvPP6d8//XXtHOuEhOhXDmrLxYIxOrUsTlemcluoJPdICc75xfiACu7FKCJiEjBlX4V5v79KZPkw8Otj2XAW2/Z6kuw1kqlSllwEQjQhg2z4CrQT/Omm2zifupgbNu2lOtVrWpZu0GD7FrPPWdz4ooXt8Ktx5qNUqBTqChAExGRgiv9KsyYGBtK7NTJejMGSgjt329zvwKLCWbMsDljERE2jyvQcDsx0YY9AwvsZs2yif4NG1obp8aNLShr1MiGUFPr0CFfTFqX0FAk2A8gWdu0aRMPBwogZuGNN944qmttS/1XXSa894wePfrQ9p49e47quiIiIe2RRyxIC6wg/OIL6/HYsKFl1vr2teMWLbKMWsCzz9rqyUcesRWFf/5pwRlYcHbCCdbGaPVqm5O2ZIll4O680+aLpQ/OwO5///0KzuSoKEDLAzfeeCPNmjWjZcuWXHvttcTHx2d57BtvvMGaNWsAmDZtGu3bt8/y2HfffZd//vmHkSNHkhSYaJqFvn37snz58kzfS0hI4NdffyU2Npann36ahIQEbrvttqP4ZCIiIa5hw5ThxyeftLlo339vqyXfeMNWJoJN+B850l7//rtl3WrVsmArKspWTZYoYSsXS5WyeW133211uY60mlHkOChAy0JkpBWDjozMmeuNGjWKyMhIypQpw9dff53lcT169KBcuXJs3bqV4sWLc8EFFzBx4kQWLlyY5rhp06axYcMGmjRpwmWXXUa/fv349ttvM73mgQMHKFKkCM2aNcv0/aJFi7Jjxw42bdpEnTp12L17N82aNSMhIYH9+/cf/4cWEckvoqPhtdes5lm9erY4oEEDeO89WxAwbZqtBB06NNd7M4pAIZyDdued1u7scGJj7Q+upCRbDd24sXXlyErTpvDyy0e+t/eevXv3Urx48Uzff+mll7jtttsoWrQoLVq0oFu3bowdO5Zq1arx6quvHmq39NFHH7Fq1SoqVapE6dKl2bFjB40bN2bChAlMmzaNwYMHU6NGjUPXnTBhAq0CLTIy8eOPPzJ+/Hj+/fdfTj31VN577z3i4+N58sknufrqq2nSpMmRP5yISH4TH2/1zd5+2wKwuDjLuD33nLVVql497fGaqC95qNAFaEcjNjalNE1Skm0fLkA7GoMHDyY6OpqrrrqKkSNHMnTo0EPv3XDDDfTr14+OHTvinKNUqVJ89913VKlSBe89O3bsoEOHDgBs3bqV9u3bs379eg4ePIhzjurVq7NixYpM56Pt3LmT77//nqeeeopJkybRu3fvDMfs2LGDAQMGULJkSRITE2nevDlLliyhXbt21K5dO3sfXEQklHz3nWXFtm+3jFhUFFSubC2M+va1v7gzK9gqkscKXYB2NJmu9MWPj6WFV1ZGjRrFN998Q4kSJXjllVcyPaZu3bq8++67dO/enT59+tC9e3f27NnDk08+yQsvvMA111xD1apVAQu8SpcuzbnnnktMTAy7d+9m9erV1KtXL801hw4dyrBhw6hWrRoVKlTgueee49577z30/q5du6hWrRrvvvsuYWFh1K1bl4SEBP7++28FZyJSsMybZ70xA3+BR0RYG6YrrkiZiyYSIjQHLROBmoA5PdWgf//+jBs3jsTASqB0XnzxRcLCwihatChVq1bluuuu4+abb6ZFixZ06dLl0HF//fUXl1xyCXXr1uWjjz5i+/btdOzYkSVLljBz5sxDx40ZM4Zrr72WU045BYCOHTuyfft2rr/++kON2zdt2sSuXbsoW7YsJ510EhEREbRq1YoVK1YcdjGDiEi+EhcH/funBGdhYbYw4KqrFJxJSFKAloXcWA1doUIF2rRpw0cffZTp+/Hx8Vx99dUAnHDCCbRr144OHTpw5pln4lKl3CdNmkSDBg0oUqQIAwYMoHXr1uzYsYPevXtzxRVXABbEdenSJcPcs+HDh9O8eXPeeust1qxZQ4MGDWjdujVVq1bl888/548//mDTpk0899xzdOzYkZ9++innfgAiIsGQkAA9e1ods2LFUpp8R0QE+8lEsuR8oNheAREeHu6XLl2aZt+qVauoX79+kJ7o+OzYsYOTTjrpsMfMmjWLDz/8kKpVq/LNN98wfPhwWh5HRBkZGUmFChWoV68eUVFRVK5cGYDVq1ezZs0aLr30UkqXLp3hvPz4cxWRQiYpCW65BSZMgBdftFWaKhYrIcQ5t8x7H55hvwI0OV76uYpISPPelu6PHAmPPQaPPhrsJxLJIKsArdAtEhARkXwmIcFaMAXaMI0aZX0xY2LsvY8+ggoVbAVm+fJ2zIMPWj/NkSPh1FOtJVPfvlZ89oorUpqX33KLdRoQCTGagyYiIqFt5Uro0cOGJufPh7//tiBr9my4/HKYNAl27rQCs4FjVqywIO7cc+Gff+COOyxY896+AscpOJMQpQyaiIiEtsWLrXn5vHnWhPz116Fo8v99RUVZD83vv4cffoALLoB//4WffoLrrrM6Sc7ZcVWqwKpV9t6FF1rrpnfesfZPIiFGGbQQt3fvXuLi4rJ8/6233iL9nLvMqFm6iORb551nvS9/+MGq/3/xhe1fuxbmzoWuXW34c9YsGDTIArAGDSyzFhZmQ6Fjx0K/flCuHHz5JXzzja3sfO654H42kSwoQMsDN954I02bNiU8PDzTav+pzZw5k4cffpj777+fe++9l2HDhh221EXHjh156aWXjvgMapYuIvlW48YpWa7wcCuXcfAg3HijBV7FilmA9uuvNs+sUSNo3dr2e2/zzIYNg4oV7TqNGqW9lkgI0hBnFiIjI5k/fz4RERHHVboivVdeeYX69evTpEkTmjdvTuPGjTM9rl27duzfv5+rrrqKXbt2HbHURpUqVXjhhRf49ttv+f333zlw4AA333wzJUuWPHTMsTRLj4iISNMsPT4+nlKlSh3/BxcRya7evW3Sf8OG8Omn8MADcNNNFqCFJy9+69ULPvnEtk8/3eaegR3bqBF06mTbY8ZAYiL83//B1KmgXsMSogpdgHbnnXey4gjd0mNjY1m5ciVJSUkUKVKExo0bc+JhmnE2bdqUl4+ih1SlSpW48sorWdqN+bcAACAASURBVLhwYZYB2qJFi/jnn3/Yvn0799xzDwMHDuSHH37grrvuAmDt2rW8/PLLeO8JCwujYsWKlC9fnmrVqlGrVq1D/TRTU7N0EcnXHnnEmpd7b4FWfLwFY5s3W6Pzpk1tjlqxYtY8uUwZy6StWgXPPmvzzQJ1zx56CDp3hjfegLPOgnHjgv3pRDJV6AK0oxEbG0tScjuQpKQkYmNjDxugHYtKlSpxxx13MHXq1EP7As3SExMTmTp1KosWLWLjxo1UrFiRyMhIBg0adOjYM844g5EjR7J8+XJmz57NkCFDDns/NUsXkXyvYUNbyZna/v32fflyuOQSqFHDymok9ysGoH59y5al9/XXufesIjmk0AVoR5PpioyM5NJLLyUuLo7ixYszefLkHBnmBIiOjmbUqFEMHDgww3vLli3j4osv5uSTT+buu+/m6aefPtTYPDExkYSEBEqUKAFAqVKlqFix4hHvp2bpIlJgrV5tZTbKlbOgK3VwJpLPaZFAJlq2bMmcOXMYOnQoc+bMybHgbNeuXXz55Ze0adMm0/ebNWvG9OnTuf3220lMTEwz9+vTTz9l06ZNh7YPHjxI0eRl5hs2bGDWrFkZFhOoWbqIFFjr1kHbtlCkCMyZA6edFuwnEslRhS6DdrRatmyZY4EZwODBgylRogTPPPMM9erVy/B+bGws06dPZ8SIEZRProS9detW2rVrdyiTN3HixEPH79ixg2nTph3q2VmxYkViYmIOvR9oln7yySenuc/w4cMZNWoUb731FjfeeCMNGjQA4I8//uC9996jYcOGOOcONUt/9tlnNQdNRELLtGm2QCA+Hr79FurWDfYTieQ49eIUNUsXkfxj3jy49FJbMFCihG2r6bnkY+rFKVlKnSkMBGcA9erVyzTbJyISNBMnWnAG1odz/nwFaFIgaQ6aiIjkH87Z97AwKF7cymeIFECFJoPmvccF/mFLthW0oXERySc2bIAzz7Q5aIHaZiIFUKEI0EqWLMnOnTupVKmSgrQc4L1n586daboViIjkusRE68fZuzfcf3+wn0YkVxWKAK1GjRps3LiRqKioYD9KgVGyZElq1KgR7McQkcLkt99gzx5o0SLYTyKS6wpFgFasWDFOP/30YD+GiIhkR2SkfdewphQCWiQgIiL5Q2QknHQSqMuJFAIK0EREJH9YvNiyZ5pLLIWAAjQREQl90dHWe1Pzz6SQUIAmIiKh7/vv7bvmn0khkeMBmnOuqHNuvXNufvJXI+fc4865Jc65V1Mdd9z7RESkkImMtMbo550X7CcRyRO5kUFrDLznvY/w3kcAxYELgfOB7c65ts65c493Xy48r4iIhLrFi6FxYyhTJthPIpIncqPMRgugo3PuEuBn4HfgI++9d87NAtoDsdnY93UuPLOIiISqpCQb4rzhhmA/iUieyY0M2hKgrff+fKAYUArYlPxeNHAyUDob+zJwzvVzzi11zi1VMVoRkQLmt99g927NP5NCJTcCtJXe+y3Jr5cCe7EgDaBM8j2zsy8D7/1Y73249z68cuXKOfhRREQk6FSgVgqh3AjQJjnnmjjnwoCrsSzYhcnvNQHWAcuysU9ERAqTxYutQG2dOsF+EpE8kxtz0J4A3gUcMA0YBixyzo0Arkj++gcYfpz7RESkMImMtPpnKlArhUiOZ9C897947xt77xt57x/03icBbYFFQHvv/d/Z2ZfTzysiIiEsJgZWrVKBWil08qRZuvd+PzA1p/aJiEghoQK1Ukipk4CIiISuQIHa888P9pOI5CkFaCIiEroWL4ZGjVSgVgodBWgiIhKaAgVqNf9MCiEFaCIiEppWrYLYWM0/k0JJAZqIiIQmFaiVQkwBmoiIhKbFi6FiRahbN9hPIpLnFKCJiEhoUoFaKcQUoImISOjZtcuapGt4UwopBWgiIhJ6VKBWCjkFaCIiEnoWL7ahTRWolUJKAZqIiISeyEho2BDKlg32k4gEhQI0EREJLUlJlkHT8KYUYgrQREQktKxerQK1UugpQBMRkdCyeLF9V4AmhZgCNBERCS2RkVChApx5ZrCfRCRoFKCJiEhoUYFaEQVoIiISQmJjVaBWBAVoIiISSn74AbxXgCaFngI0EREJHZGRKlArggI0EREJJZGR0KABlCsX7CcRCSoFaCIiEhpUoFbkEAVoIiISGtasgV27FKCJoABNRERCRWSkfVeAJqIATUREQkRkJJQvrwK1IihAExGRUBEoUFtE/9ckon8FIiISfLGx8OuvGt4USaYATUREgm/JEhWoFUlFAZqIiASfCtSKpKEATUREgi8yEs4+G048MdhPIhISFKCJiEhwqUCtSAYK0EREJLj++ANiYhSgiaSiAE1ERIJLBWpFMlCAJiIiwRUoUHvWWcF+EpGQoQBNRESCKzISmjdXgVqRVPSvQUREgmfPHvjlFw1viqSjAE1ERILnhx9UoFYkEwrQREQkeAILBFSgViQNBWgiIhI8gQK15csH+0lEQooCNBERyRvR0fDVV7Bjh217rwK1IllQgCYiIrkvJgY6drQ5Z5dcAlFREBFhQdsff9gxr71m+yIioGlT6N8f/v4brrwSWreGu++24zLbJ1LAKEATEZHct3IlvPgiPPggXH45vPsu1Ktn75UpA0uXwoABMH++fbVuDbfdBkOGwMMPw6JFsHGjvZfZPpECpmiwH0BERAqBiy+27wsXWhatUSP7Xq4c7N4Np56acuymTbBtG4SHw5o1cM45tr9KFYiNzXyfSAGTaxk059zJzrnlya/HOecinXMPpXr/uPeJiEg+5D1MmQIVKtgw5rp1ULky1K8PFSumHPfqq5ZNA+jWDR5/HKZPh5kz4dJLM98nUsDk5hDn80Ap59w1QJj3viVwhnOubnb25eLziohIbnLOgq/GjS2jFhsLvXrZUOf48XZMUhLMm2cBHMBDD0H79vDmm9C3rw2HZrZPpIDJlQDNOdcG2AdsBSKAD5Lfmg1cmM19md2vn3NuqXNuaVRUVM59EBERSZF+FeaxeOYZePtte71rF+zcaRm1886D77+34A1sXlnz5inbYAsG1q+Hu+46/D6RAiTHAzTnXHHgYeB/ybtKA5uSX0cDJ2dzXwbe+7He+3DvfXjlypVz7sOIiIhJvwpz6NCMKy4DBg604UewLFn79jYUec89Nvk/Pt6CM4BOnSzQ6tHDtmfNgosuSnvv556zQOyEEw6/T6QAyY1FAv8DRnvvdzn7C2gvUCr5vTJYUJidfSIiktcCqzBbtLBg7fzzbSUlwODBNtQIlgHbuhWuusq2J0+2QOqyy2xeWfv2UKOGZeJKlIDffkt7n6eeynjvxx8/un0iBUhuBDxtgUHOuflAU+AqUoYmmwDrgGXZ2CciInnt4ostOAuswgwUl0294jI+3kpj1KoFn31m7w8caMEZWO2zKlWse8A//9j2LbdAQkJQPpJIKMvxDJr3/lBuOjlI6wQscs5VB9oDLQCfjX0iIhIMqVdhFitm+1KvuHz7bWvbdN99MGqUDV0OHmzvRUZa5q1FC5g7FxITLTjbvBm++MKGOkXkkFwdMvTeR3jvd2OT/RcDl3jvY7OzLzefV0REDiP1Ksxp0zKuuFy+HPr1g6pVbXXmvHm2PzraArW33rJA7dFHbf+IEVCpUkonARE5JE/mdHnvY7z3H3jvt+bEPhERyWPpV2GWL59xxWWdOrB2rb1euhRq1oS4OLj2Wpsztngx9OmTMqQZF2eBXpMmef95REKcOgmIiMiR9esH3btb7bGGDaFdO2vblHrF5S23wM03w/vv23y0qVMtMPv2W5u7lpAAJ54IYWE2xOk9XHghtG0bvM8lEqKcDyx1LiDCw8P90qVLg/0YIiKhKToali2DZs3gpJNy5x67dsF778G4cXav4sWhSxcL4C691OqezZ9vQ6OBxQYihZRzbpn3Pjz9fmXQREQKi0AtsyuvtNIXc+fCuefCGWfY+6NGQfXqcPvttsLytNMsyPLe5pStXw/VqsEHH9gigX//hQsugBUrbD7aggV2/EcfwYEDNnQ5ciT07Jm2lVPLlgrMRI5AGTQRkcJiwQKrPdaihRWNrVzZMmrPPJNyzH33WSPy66+HIUNS+mT+/LMNaT7wgL1ftSrcequdf8cdtgBg7VobwuzZ04Y6zzknbUcAEckgqwyaCr+KiBQW6WuZlSoFM2ZY0dlAPbI1ayywAqtZFhtrKy1/+w327rXv+/ZBmzbw+++WaXvoIVsQ8M47sGWLrfQ891wFZyLZoCFOEZHCJHUts2bN4OuvbdiyTx+rR9a1Kzz9tLVeGjfO9pUvb+eOHGnB2QMP2CKAgLvvhuefD87nESmglEETESlMUtcy27zZgjOwTgB//AG9e8N//mNB3AUXWFeAkSPhmmvgu+8soIuJsTloYWFQpIgFdSKSo5RBExEpLJ55JiVbtmuXLQaoV8/KZnz6qWXGwJqf//ILfPyxLQx4/31Ytcrml7VubcOkXbrYSswPP9SEf5FcoAyaiEhh0a8fTJpktcsSE20uWu/eFpC1bJlSj2ziRJtj9tJLcOaZ8NdftiggPh4OHrRFAS1bwv33Q7lywf1MIgWUMmgiIoVFhQrw1Vdp961cmXZ7/36b+P/aa7ZAoG9fKzZ72mmZX3P+/Fx5VJHCThk0ERGxjNpbb0HdulZeo1Ur+OknGD8+6+BMRHKNAjQRkcLMe5g+3RYN3HIL1KhhWbEZM6BRo2A/nUihpQBNRCQ/iY62YcodOzLfPtrzIiNhwACbf9apk9VAmzrV9l98ce5+BhE5IgVoIiL5RaBV0w8/wCWX2Fyx9NuvvWY9LiMiLPjq3z/jeZ9+ak3Kx4yxOWhVqtjCga5dVVxWJERokYCISH6xciW8+KKVuYiJgdGj027/+KNlxQYMsOMHD7ZJ/qnPW7vWhjKTkuyYsDDrxdm/f/A+l4hkoABNRCS/CAw9Blo1zZhhZS4C2488knLspk2wbZsVoA148EGYMAFOOAGKF7eFAcWK2XZ4hlaAIhJECtBERPKT1K2aihXLuB3w6qspmbS9e2HQIHj7bWt8vnixzUWbPx9Wr4YbbwzGJxGRw9AcNBGR/CR1q6Zp0zJugw1fzptn89B++smyY5MmWYbt9tttKLRlSyunsWaNHSciIUUBmohIfvHMM5YFA2vVtG5d2u1AU/NFi+D8823BQPPm1nNzyBArOLt7d9rjmjfXwgCREKQATUQkv0jfqin9drt2dtxnn9mctEGDbNXm0qX2lf64WbNsn4iEHOe9D/Yz5Kjw8HC/dOnSYD+GiEhwREZCjx62SGD4cLjrLiiiv8VFQpVzbpn3PsMqHf2rFREpCJKSbAi0dWsbsvzmG7jnHgVnIvmU/uWKiOS1o63+fzS2bIEPP7Rhy//9D665BpYvt7llIpJvqcyGiEheClT1v/JKG36cO9eyX9262aR9gEcfhQUL7PXWrVZs9sCBjPvOOAPuuMMm/h84AK+8AgMHatK/SAGgAE1EJC+l7wYwdy6MHw/79qUc8/jjKa+7dYM+feCUU9Luq1MHrr/egjvnrJRG27YKzkQKCA1xiojkpYsvtuAsUP2/fXsrNFuuXMZjlyyBGjXSBmdLllgQNmBASrsm52DnTgvaRKRAUAZNRCSvpa/+X6pU5seNGJE2m7Z7N/TsCX/8AdWrQ4kSEB9vAVr9+sqeiRQgyqCJiOS1zKr/p7drF2zfDrVr2/b06VCvngVnd91lHQDmzYNhw2zuWoUKll0TkQJBAZqISF5K3w0gUNU/vc8+gw4dLEi7/nro1AnCwuC//4UXXoDSpe06rVpZ26bDXUtE8h0NcYqI5KV+/aB7d3jzTWjYMKWqf3qzZtmwZf361ux86FD45Rfo1SvlmPvug969LSPXrh2cdVbefAYRyXXqJCAiEmr++Qf697cg7YILLJirXz/YTyUiuUCdBEREQl1iIowaBQ0awLff2utFixSciRRCGuIUEQkFv/0Gt95qvTTbt4cxY+C004L9VCISJMqgiYgE08KFVmC2SRNbmTlpEnz+uYIzkUJOGTQRkWD55BPo2tXqooWFwcSJ1gJKRAo9ZdBERIJh1Sq48UYLzgJWrgza44hIaFGAJiKS177/Hi680LJmJUrY9+LFISIi2E8mIiFCQ5wiIscqNtaKxyYmWsHYMWPgppusqOy558Lrr8Pff8N//mPtmc4/34rLxsTA5ZfDsmV23vLlds78+dZVYOBA2ycihZ4yaCIix2ryZGu3NHs2VK1qfTV79oSlS2HPHvs+ZAg8/LCVydi40YKw//4XfvwRGjWyhQExMdYF4P774f33Yf/+YH8yEQkRxxWgOecq5vSDiIjkGwMHwmWX2euoKAvKfvnF2i1t2ACnnmorMs85x46pUgXee88WAVSrZm2coqLsOIC5cy2jVrVqcD6PiIScwwZozrnSzrkL0+27ELgwi1MCx1R0zl3mnDspB55RRCQ0RUZaFqxXL6v+P3KkFZWtWBG6dYPHH7dm6O++C2PHWtbsggssUAscFxdnbZyefjrYn0ZEQkiWc9CccyW89/uSA61iwOLk4x8H+h7mvArADOBz4EXnXBvgaeBs4HPv/bDk48Yd7z4RkaCLjobBg+GjjywQGzMGypWDF1+E8ePhoYdgwQJbqRkdbXPUkpIsiEt93NatlpFTo3MRSSXTDJpzrgww2jk3FEgCSgDDgC+B3t77jYe5ZmPgLu/9k8AsoA0Q5r1vCZzhnKvrnLvmePflzMcWEcmGuDi49loYPhxq1rQs2s8/26KB77+35uUHD8KIEbBuHdx5J4wbZ4sL0h/39dfw6qu2gnPFCusmICKFXpbN0p1zJwL7gE7ARuBUYB5wrvf+qyNe2LmLsKDuT2Cq9/4L59z1QCmgGTDzePZ578cf7r5qli4iue611+CBB6z6P1hrprfftmHOli3tdZ8+Fnxdd50tAAD44QfLpAWO++QTKFMm5boREbaYQEQKjayapR+uzEZPYC+wFYgDzgQ2AeWccyd573cc5mYOuA6IAXzyeQDRwDlA6Wzsy+x+/YB+AKepPYqI5LYBA+wrtSFD7PuOHdChg63WHD/ehjgDzj8ffv016+sqOBORZFkNcQ4CygENgFuxQK4sUAfof7jgDMCbQcBK4AIsGwZQJvmee7OxL7P7jfXeh3vvwytXrny4RxMRyT3r11sB2p9/ho8/ThuciYgcg6wCnleBmcB0IBYLkrYCVbGJ/02zuqBzbohzrk/yZnlsgUBg1WcTYB2wLBv7RERCz2+/QatWNul/1izo1CnYTyQi+ViWQ5ze+xUAzrltQCVgDlDNe/+1c67RYa45FvjAOXcr8AvwKbDQOVcdaA+0wIY9Fx3nPhGR0BEZaXPOJk+2WmYLFqTMTRMROU5ZLhLIcKBzpYDKQGXv/bJjuomV3rgMWOi935rdfYejRQIikmciI21if1ycrcj84AOrfyYicpSOZ5FAGt77/cnBUlds6PGoee9jgA9yap+ISEh4/nkLzgCKFIE//gju84hIgXHUrZ6SV2Y+B+g3kIgUDtHR8NVXtjIzNe/h0UdtIUCRIhAWBsWLWzZNRCQHHEsvzmeBT49Uh0xEJOTFxlrtsnbtoEuXlCzYwIEwfbq9jomBjh2tdtkll1jvTLA6ZiefDE88Ya9nzIDataFhQ3j22ZRriYhkQ5YBmnOuk3MuLPn1AOA97/3oPHsyEZHcMnky3HUXzJ5tDcpnzoRFi2wF5lVX2TErV1o7pgcfhMsvt7pmkyfbOVFR0LQp/O9/8Pff8MorFsgFriUikk2ZzkFzzlUBOgADnXPrgHu993vy8sFERHLNwIEpr6OioEIFuO02KzD72WfQuTNcfLG9v3ChBV+33WZN0aOj4c03bcXmt99mvFaVKnn7WUSkQMqqDtp27/3t3vsrgE+AMc65xnn7aCIiuSwy0oYy16yBs8+G++6zYGzUKHvfe5gyBYoWhbZtYdcue++WW6BiRdi2LeO1WqgakIhk3xHnoHnvZwE3Ah2dc51z/YlERPJCdDQMHgxvvQXLl0O/fjZE2asXzJtnxzgH3bvDd9/Bnj1WQuOc5I5ze/dCUlLGa4mI5ICjWiTgvY/33j8FFHHOqdmliORvcXFw7bUwfDjUrAl16sDatfbe0qW275lnYNAgW0hQqhSMGGELC775xo776SeoVSvjtUREcsCxrOLEe/8J1jhdRCT/GjfOJv0/+aSVxqhQwbJmF10Eo0fD3Xdb4DV6NJQsaSs9+/SBq6+GSZNsgcEHH8CVV2a81pQpwf50IlIAHHUngfxCnQREJFsSE+G//7W5Ztdea22cSpZMeT8mxmqjXXSRDYmKiGRDtjsJiIgUePv3Q8+e8MknliV77jkrRJtahQo2L01EJBcpQBMRAesW0KkTLF4ML78Md9wR7CcSkUJMAZqIyNSpcPvtsHs3fPghdO0a7CcSkUJOAZqIFG6ffGJDlt5DiRJQvXqwn0hE5NhWcYqIFCg7d0L//hacASQkwPz5QX0kERFQgCYihdW+fVYmY9cuy5yFhUHx4lYqQ0QkyDTEKSKFT3y8DWsuWWJzzqpVs8xZRAS0bBnspxMRUYAmIoWM93DrrfDFFzBmDFxzje1XYCYiIURDnCJSuPzvf1Z89vHHbf6ZiEgIUgZNRPKn2Fi4/nqr/F+6NEyYkHZ7yhTYtAn+8x8rn3H++XDKKfDsszBggDVHb9bMGqWnv9aUKTYfTUQkSJRBE5H8afJkq/Y/e7a1XJo4Me32zJkwZAg8/DAsWgTffms9Nrt2tTZO995rnQMyu9bMmcH9bCJS6CmDJiL508CBKa+joqBvX2jRImW7ShVYswbOOccCrx9+gAYN4J13YMECy5QFemmmv1aVKnn3OUREMqEMmojkb5GR1sA8EJyl3u7WzeaZdeoExYrBrFnWW3PoUHj66SNfS0QkSJRBE5H8KzoaBg+Gjz7KfLt7d5t7VqSI7T/lFHjiCcuYlS9/+GuJiASRMmgikj/FxcG118Lw4VCzZsbtzZuhXTvLnNWqBY8+aud9/TW8+qrVPFuxwkpupD9XRCTInA+0OCkgwsPD/dKlS4P9GCKS2157DR54AJo0se1LLoGXX7bthATYsMFaOfXoARddBL17Z7xGRIQVqE1/rQED4Lrr8uqTiEgh5pxb5r0Pz7BfAZqIFCgHDsDll8N338Hnn1sWTUQkRGUVoGkOmogUHImJ0LMnLFxopTMUnIlIPqU5aCJSMHgPgwbBxx/DSy/BDTcE+4lERI6bMmgiUjDcdhuMGwe9esGddwb7aUREskUZNBHJ/x580IIzsDIZkZHBfR4RkWxSgCYi+dvcuWmLzsbF2cpMEZF8TAGaiORfq1dbb83TToNSpSAszJqcR0QE+8lERLJFc9BEJH+KioIOHSwgmzcPtmyxzFlEBLRsGeynExHJFgVoIpL/HDgAV19tQdm8edYpoFYtBWYiUmAoQBOR/MV7uPlmK0T7wQdqbC4iBZLmoIlI6NuyxXpo7tljPTXfew+eesr6Z4qIFEAK0EQkuLZtg9at7fWPP0LbttCqFbzwgu1bs8b6Yn77LTRqBEOHQrduFrA1bWrbAatWQefOef8ZRERymAI0EQmemBjo2xf27bPtwYNh/Hj45hurZ/b337Bype2LiID166F5c6heHZ54AlasgFmzbMHAX3/BvfdCbGxQP5KISE5QgCYiwRMWBlOmQLlyth0dDaeeCs5BpUqwe7dlyw4ehI4drZTGjBlQpYoFbtu22Xvly0PZshbUiYgUAFokICLBEwjMAlq1gldegYoVYd06aNwYdu604Cw+Hq66yt674goYORI2boQ2baBoUQvaREQKCGXQRCR0vP461KtnQdqQIdYVoEsX2LQJ5syBkiVhyRLrHDBhAjz5JOzfD199FewnFxHJUQrQRCR0hIXBWWfZ6xtugFtvhUWLLFhr1Qp27bLhzL//hg0brB7ajz/akKiISA6JjIThw4Pb1jfHAzTn3InOuS+dc7Odc58454o758Y55yKdcw+lOu6494lIAfbQQ/DMMzBsGLzzDvz3v9Zvs3VrOP98C+Aef9wWDVSubHPW2rQJ9lOLSAERGWm/Uh58EC69NHhBWm7MQesJvOi9/8o59xpwPRDmvW/pnHvLOVcXaHS8+7z3f+TCM4tIMKVubj5xIrz7rtU769PHym2kz5BdeaV9HelaIiLHYNs2Wwx+4IBtx8XZr5RgNCnJ8Qya93609z4wIaQy0Av4IHl7NnAhEJGNfRk45/o555Y655ZGRUXl1EcRkWD45hu46Sa46CIYO1bDlyKS67Zvh3vugdNPtyYlYWH2Vby4JeuDIdfmoDnnWgIVgA3ApuTd0cDJQOls7MvAez/Wex/uvQ+vXLlyDn8SEckzf/1lPTZr1oSPP4YSJYL9RCJSgO3YYVNcTz8dXnrJqvr8/rtNfR061NYmBavFb66U2XDOVQRGAV2Bu4BSyW+VwYLCvdnYJyIF0axZ0KuXjSl8/rnVQRMRyQU7d8Lzz8OoUfDvv7Ym6eGHU9Yo1a0bvMAsIDcWCRQHPgTu997/AywjZWiyCbAum/tEpKCZPRs6dLA/Z+Pi7LuISA6LjrZ1SLVq2Vqkq66CX3+19UiB4CxU5EYG7RbgHOBB59yDwHigt3OuOtAeaAF4YNFx7hORgiQmBm6+GZKSbDshIXizckWkQIqJsSHMESOsQcm119o6pAYNgv1kWXPe+9y/iXMVgMuAhd77rdnddzjh4eF+6dKlufNBRCRnRUfDZZdZ26YiRSAx0WblBnPih4gUCJGRMHOm1bmeOtXa9HbtaoFZo0bBfroUzrll3vvw9PvzpNWT9z6GlNWY2d4nIvnQli02ltC8ufXN3LnTgrNff4XPPoMKFSxzFhGh4ExEsuXrr6F9e0vIgy0KHzkSmjQJ7nMdC026F5Hs27bNCsmmdtVVsGKFvV6zy5ukwwAAIABJREFUBq67Dr79Fi6+GDZvtgqQv/0GTZtC9eoWlF1+uc3UbdXK6p+JiByD3butA9xVV6UEZ2Fh1r43PwVnoGbpIpJdMTHQty/s25eyb/JkqF3bgi+wIczx423f0qVwySWwfj3ccQccPJhy3ODB8P77UKOGBWnXXGPr30VEDmPPHluR+cILNnOiVSv7VZOQENxaZtmhDJqIZE9YGEyZAuXK2XZ0NNx9tw1Zzptn+7p1s9pmkyfbvn/+sdcTJ6Y9LjraWjc5Z2U2du8OzmcSkXxh7154+mn7O+7BBy0Rv2SJ1bueNy/4tcyyQxk0EcmeQGAW8NJLtkSqf3+4/37707ZTJ1i7FgYNsh4qX34JCxdmPK5VK3jlFahYEdatg8aNg/KRRCS07dsHr74Kzz1nVXnat4fHHrN2vQEtW+bPwCxAGTQRyVnLl1sgVrUqdO9uE/+3brUOAfHxNrxZrlzmx73+OtSrZ0HakCFq8yQiaezbZ0HZ6afbr4jwcFut+cUXaYOzgkABmojkrDp1LFsGNgmkQgWoXx/+/tt+i5YsCeXLZzyuZk0bLg1Ui+zZMzjPLyIh599/bX7ZGWfAffdBs2bWM/PLL6FFAa2Qmid10PKS6qCJBElEhGXBNm+GW2+1okNhYVZeY9MmC8hOPBHatbOVmqmPO+EE671ZtqwtOLj11oyrQkWk0Jk3z1oyRUbaeqTLLrOhzAsuCPaT5Zys6qApQBOR3LFpkw1nbtli1SJbtQr2E4lIPrF/v01NHTHCtosUsTlnt98e3OfKDUEtVCsihczGjRacbdtmTdAL0p+7IpJr9u+HsWNtZebWVL2DnLMMWmGiOWgikrPWr7ditNu3WxN0BWcicgT791ul/9q14c47bdrqq69CqVI2UyK/1jLLDmXQRCTnfPyxzR+Li4O5cwvesioRyVEHDsAbb8Dw4TYb4uKL4d13U4KxZs0Kbwc4BWgikjPeeQf69AHvoUQJa3wuIpKJAwfgzTctMNu82Xplpg7MAvJ7LbPs0BCniGS0ZYt1G96z5+iO/+ory5wFFh0lJNifvSIiqRw4YEOXdepYZ7fatS3ZHsiSSQoFaCKSttl5+sbmcXHw6KP22zMiwgrJDh+ecu7jj1uT81NOsYkiAElJVvdMRARruTt6tAVm//mPFZqdMwcWLLD1RKpJnZGGOEUKu/TNzlM3Nv/5Zwu0Hn885fhu3WwoMykJHngAnnnGitEuXw79+lkR2r594d57ISoKKlcOzucSkaBbsABefNHqmEVFWbWdiROhTRsFZUeiAE2ksAs0O+/c2ba7dbMhys8/t+CtTp2UY5csgRo1rFdmjx7wwQe2EKBkSWvf1KiRvXfGGfYnc/nywflMIhJUBw9aPernn7eZD0WKWE2zwYMVmB0tDXGKFHblylmF/9T27rXgq2bNtL9NR4yAG26ASy+192vXhkWLUo654gpYvNjWy7dpA0X1N6BIYXLwIIwZA3XrWs/MwLRU5yxJr+Ds6ClAE5GMype3cYj4eMuaAezaZcOdPXrYcOall8LkySnzzsCqS06YAE8+aYWNvvoqKI8vInkrLg5ef90CswEDLNH+8suFu45ZdilAE5G0BgyAhQvt9a5dKcOUzzxjgdnevbbkav16GDLEfuuuWAEPPWQB3IYNtlTrxx/157JIAZc6MLv9dlsrNGuWrTG64w5bCDB0qH0vrOUyjpfGH0Qkrfvug969Lbhq1w7OOgsmTbIArWZNWxN/+um22jMgIgKGDbPfwBERNhu4Y0cb5hSRAicuLiVZvn49tGhhBWcvuyzt32WFuY5ZdqlZuohkzXtbwfn44xZsTZ1qKzZFpFBKH5g1b26/Htq1U8L8eKlZuogcm4MHrfjsO+/AjTfaOEbq+WYiUihERtoQ5d698P778M8/FpiNHavALDcpQBORjKKjoUsXm4s2bJjVO9NvYZFCZ9EiWw8UH2/bZ58NX35ptan1KyF3KUATkRSRkfDRR1ZCY9s2a47Xo0ewn0pE8lh8vC3kvvfelOCsSBHo2dOq6UjuU4AmIiYy0nqu/H975x0eRbX+8e/ZkiUhdAKKgDQRVIpSI6hBFBVBKSqiIiII4mO76rVgAVQURPGCBeEnKHKBC4J6UVGkBSmhiga4gPTeAySEkOxuzu+Pb2ZbdkMgZdv7eZ55dmb2zOw5yc7sd97zluxsbo8fL+JMEKIMux345hsazvfsARo3Bs6dA5xOejh06BDsHkYPkmZDEAQGA4wc6RZnZjOrCAiCEBXY7cCkSUDDhnQ9TUhgMZHNm5lVR1JllD4i0AQhUvAseA4AW7a4yzcBzGHWrh1w883u2ppr1wLt2wNVqgBz53IOw2SiYJs0iYsgCBGL3Q5MnsxsOgMGAFWrUpitXg107kw/s8RE4LXXRJyVNiLQBCES8C14vnMnnUfOnHG3+eIL4Pvv6fg/axbfGzqUGf9PnaJIW7oUaNSI7bZtYyE9QRAiDrsd+OorXu79+/Py/+knYM0atzATgosINEGIBIyC5+XLc7tcOTr7ezJhAlCtGu/MDgfnLpYu5eu4cXQ2ad8euPFG1tDcvZuP04IgRAyewuzxx4HKld3C7O67RZiFEhIkIAiRgCHMDKpVC9x2zBjGyt96K4ukJyXR4tajB9+/917Ocfz2m3ufIAhhS0oKC4BkZTGP2c6dQIsWwI8/iigLZUSgCUI0sWIFrWWHDlGglS1LyxsA3HMP79Zff82KAZ77GjYMWpcFQbh0Vq5k5GVODrcbNqS7aZcuIsxCHZniFIRo4Y8/mMDo0CHg+edZ0XjrVhZEP32aU51KAamp+fcJghB2pKQADz7oFmcmE11Vu3aVyzocEIEmCNHAX38xwvPsWYZrbdjAeY5XXgGuvZZF0O+5B7jqKv/7BEEIG3bvpjC78UbmMLNa6aZqs0kes3BCiqULQqQzaxbQrx+LnH/3HdC6dbB7JAhCCXDmDPDee8C//kVB9s9/ctm4kbnMkpIkVUYoIsXSBSHacDqBN98E3n+fj9Jz5gCXXRbsXgmCUMw4HCxcPnQocPIk8OijrARQsybfT0wUYRaOiEAThFAlLQ1Yvx64/vqLS3eRksJqxgsXcv2JJ4BPPuH8hiAIEYPWwLx5tJJt2UIL2UcfATfcEOyeCcWB+KAJQiiwezejJW+6CXjxRSaO7dKFyYk6dACOH2e7/v35KPzuu97HHz1KIZeSwujMd97h+ksvMf+ZiDNBiChSU4FOnXibcDiAH35gKg0RZ5GDWNAEIRR45RVOR7ZtC/TqxVQYY8Zw+9QpRmBmZnLaMiWFGSa3b3c78L/0Er2Bhw0Dzp/nPpOJWSglXEsQIobDh3mrmDwZqFgRGDsWePJJFjIXIguxoAlCKPD33+5H32rVgObNKc5+/51WtMREevk+8ADbdOoELF/OdSMD5aFDTC5rNrtDtpKSgjEaQRCKmSVLgNtvB+rVA775hplyduwAnn1WxFmkIhY0QQgF7ruPBczbtgV+/ZWO/VoziWylSoyTz8wErriC7StXplUtI4PWtAMHaDGbPRuoUUNCtgQhQjh9Gnj1VXoqAHz2mjEDuP/+4PZLKHlEoAlCKPDGG7SIjR7NTJLx8dz/2Wecz5g7l/uysrj/7Flgzx4+Tp84wbCtnTuBnj35vggzQQhrDh1iuowvvuBzmCc7dgSnT0LpUmJTnEqp6kqpZXnrVqXUj0qpFUqpx4u6TxAikubNgX37gBdeAEaN4jwGwEfoihVZPG/5clrSRo3iI3VGBtCkCbB3L7BpEzBgQHDHIAhCkdi+HRg4EKhblxGZXbqw+lpsLK1nMTHiuRAtlIhAU0pVAjAFQNm8Xc8AWK+1bgfgPqVUuSLuE4TIY/RoirO4ON6hp04Fbr6ZgQGdOgHdugHjx3MKc80aRnQeP85wruRkCrwvvwz2KARBuATWr6eL6dVX89msf3+6pk6fTqP6okUMzl60SAzk0UJJTXE6AfQC8N+87SQAr+at/w6gZRH3LSmhfgtC8Bg+3L1eqRKwYIF7+8wZRmru2sVks19/DXTv7n18cnJp9FIQhGJCazr/jxzJy718efqbPfts/pzSkmw2+igRgaa1TgcA5Q7vLwvgYN56GoDqRdznhVJqIICBAFC7du3iG4gghAI//sg4+iNHmJFy+HDOdwiCEJbk5jJv2ciRwNq1FGOjRgGDBgEVKgS7d0KoUFppNs4CMH5R4vM+tyj7vNBaT9Rat9Rat0xISCiRAQjCBRk/ns4hSUmcbhw0iPuNJLIGR48yIa0vXbsCf/7J9ZQUBg506sSC5VWqAKtWAR98IOJMEMKUpUsZx1O3Ll/T0uhKuns38PLLIs4Eb0orinM9gPYAZgNoBmBVEfcJQugxeDAXAHjmGTqOAJyaNKIvT53i/sxM72OnTQPq16ewW7mS1QNycvjegAGM5pRkR4IQlpw4wectI1WGUvQne+01Ov4Lgj9KS6BNATBPKXUTgGsArAanLS91nyCELgcP0krWsiWTyJYt63YoMZuZ2+zee93t09JY3mnwYAq14cPd4sxsZioNEWeCEHZs3MhM/9OmuQt8AExZaOSTFoRAlOgUp9Y6Ke91L4DbAawAcJvW2lmUfSXZZ0EoMp99RrGVk8PH5JEj3e+VL59/HuPjj4EePXgH79uXKTOsVompF4QwxOlk2sKOHYGmTd1RmNOmSaoM4eIotUS1WutDAGYV1z5BCElycxmWNWIExdlTTzGHWUEsWkSL265dQLt2wDXXAP36STUAQQgj0tNZH/OTT3gp16rFZ7MnnmDhD4C+Z3JZC4VFKgkIQnGybBnQpg2dTBYu5BTnZ5/R+X/AAO88ZSdO0DM4JYX1N3/6ieWbypeXmHpBCBO2b6co++orFvho147CrHt3wOLzCyuXtXAxiEAThOJk/nwmlwVY6NwgKcktzrRmyoxGjZjf7KmnWLvlvfeYpPa770q924IgFB6tafgeOxb4+WcKsV69gOeeo+upIBQHItAEoTh57z3/+40kslu2MKfZtm3AjTcyrOu660qte4IgXDrJycC4cTSI795Nw/ebb/KSvvzyYPdOiDREoAlCaZCVRb+0Dz5g0fP/+z/g8ccZziUIQkhz7BhTYkyezG2lmDbj9deBMmWC2zchchGBJggGDgdTWtSrx+2OHTmPATDCskIFTmE2b+52/H/9deD224E773TH0ffvD/Tp4z7v/Pmcxty1i/s//JCP3oIghDTbtgFjxgBTpgDZ2e79JhO9EUScCSWJCDRBMEhNBXr3Zs0Vgzff5Ovo0Uwke/Ikfcf+8x93G625eNbCTElhiaY1ayjyGjbk6623lspQBEG4NLSm++hHH/ESttmYJiMpic9eOTmSJkMoHUSgCYLBqlWMpFyyBGjShP5hFgunJ3/7jdWM582j6LrxRlrBpk4F9u8H/voLaN+ed/OnnqLQs9t53gEDgE8/5XuCIIQkDgcwZw4N3OvWAVWrAkOH8nI2DN516kiaDKH0EAcYQTBo1YqpMdasobiaN4/7p04FHnqI6/Xqccpy5UpmofzqK6bF+OUXPnbXq8e2hjgzKgGIOBOEkCQjg7miGzQAHnyQgdVffAHs2wcMG+btjZCYSF80EWdCaSAWNEEwaNrULaRatmSCIwCYMYNzHQDFltXqbrNgAcO3Nm/m9oYNLO2kFB/JZS5EEEKKlBRawa65BlixApg4kaLsppsYodmli8TuCKGBCDRBMOjTh07/110H/PADMGQIsGcPgwPi49nm9dd5J7/nHmD2bKYGv+46YOtW4MormZ2ycWPe5WUuRBBCimXLGNNjOPwrBdx/P0vhtm4d3L4Jgi9Kax3sPhQrLVu21OvWrQt2N4RQIi0NWL8euP56OpYEYtMmTk9qTQE2YgQfr8+eBV54gW0OHwa6dQNOn2ZZpx07GNGZkEBrWaNGwKRJ+ettCoJQ6mgN/P03PRcWLqQngqc4e/FFxv8IQjBRSq3XWudLcSyGXCEyOXqUguzUKVqz1qwBOnQAjh/P3wYAxo8Hnn6aRfPMZpZhAoCBA93iDGBc/S23sKD5/v0s1bRrF38FNm2iVU3EmSAEjaNHWaD88cdp1G7UiJf2n38Cd9zB5yizmZdyjx7B7q0gBEamOIXI5KWXGH2ZmspERm3bUqz98Qfv0p5tAGDwYC4A8MwzjKv3JDubNTXffZfWsz59WAy9du3SG5MgCPnIzGR8jmElS03l/kqVmMrQSFVopDc0fNDE+0AIdUSgCZHH4sV01L/sMlq7AN7B16wB3norfxtPDh7kI3jLlryTL1nCxEdTptAf7Y47mCetWbNSHZIgCERrZvT/z39o6N68mUHTNhsz3YwcCdx2G/NJm835j5eC5UK4IAJNiCxycmjZ+v57+ooBvKPPnMlHaqvVfxuDzz6jJW3lSiaVNRxWrrqKudBuv710xyMIAgDg0CHgm294iR44wH1KAQ8/TIN3u3ZAbGxw+ygIxYn4oAmRxciRzCxplGICeBf/7DOm0Zg7138bgE7/ixfzl6BnT7c4M5mAxx4TcSYIpYzdzueorl2BWrWYg8xi4SUN8NK85hpazEScCZGGCDQhsli4kGIsKYlewUrxsRug71jFivnbDBhAR5bnnwf+9z/gkUc4X2K1co7EZmOAgSAIpcKWLXQRrVmTjvzr1wOvvMJYnOnT6eBvNkuaQSGykSlOIbL4/Xf3elISH78feAD48kvmK+vUyR0kAHBepGZNhnudPAlcfTXwwQeM/Fy9WryJBaGUyMigJ8LkyXT/tFhoOevfn5esJe/X6qqrWNZWLk0h0pE8aEJ0smcPqyFPmsRIzq5d+Yjerl2weyYIEY8RSXnLLfQsmDQJmDULOHeOeZ7796chu3r1YPdUEEqeQHnQxIImhB5nzrAontPJSMuZMzmX8dRTwF13UUz5a3PwIBMepaczLfhHH+U/959/0kI2axYdWB5+GPjnP+nIIghCibNyJdNfGC6eWrNQx0MPUZi1aeP2MROEaEYEmhB6TJvG5LC3386Iyl9/ZQTmkSMUZ4Ha/PvfwJtvMudZr158RLfZmCqjXDngp58YiRkfT3+z55/n9KYgCCWG1nTt/P13YOlSYN484Px59/s9ewJff+2upiYIAhGBJoQeTz3lXj9+nOLsiSeAzp2B//4XuPfe/G2qVaMH8Q03cF+1asCqVcDQoUyrAfA8778PPPlk/ghOQRCKBacT2LiRYmzpUta/NApzXHEFn5+Skzm1GRPDcksizgQhPyLQhNAlJYXZ///+m1OQL78MfPIJsG8fs/17tmnbFrjvPmD4cK7/8AN/AQxxZjIB//gH8OqrwRuPIEQQhh9Z+/Y0VC9dSivZsmX0QACAunWBu++mr9ktt3BbKcnmLwiFQYIEhNAkLY0Rl3PmsJpxly7AnXcy/v7114HvvvNuc+WVPG7WLAqxQ4dYGD09nY/0MTEM/ZJfA0EoEllZwFdf0UPAbvd+r2FDCrGbb+ZrrVrB6aMghBMSJCCUPkeP0qq1bBlrYL78Mu/uPXpwXsNu53paGr2DH3+cU5JLlnCOJD6eSY8aNGBBcgBYt45iLCcHuP9+TlleeSUf2d97D/j4Y8DhAIYM4ZKaKo/qglAETp4EVqwAli/nsm6dtzBTii6fY8YAl18evH4KQqQhFjSh8Bw+zMJ3bdrQ6b4gTp0CevcGjh2jOGvXjsXzatbk+rRpzFGWng4MG0b/spkzed7x4ymuLBaKsyefpIP/0aP8ZZg9mxUBhgxhdYDDhxlAkJHBGpn9+gHPPVcqfxJBiCS0ZgYaQ4wtX04Hf4B5m1u14pRm1apu904xTgtC0RALmnDxeFrA/v6bGfc7dqQlbNUq3pkBRla+8w6rExuWsowM7l+4kG3S0tzzHVWqUJglJ7PsEsA5kXXrmLF/8GAWK582DfjXv/h+377efRs8GKhfn5Gc27fz+DFjgBYtSvzPIgiRQEoKK5vVrMnLddkyCrJDh/h+hQp8lnrkEYqyli29yym1by/GaUEoSUSgCf45dYqiKDOT26mpdDypX5/Tj7t3M+v+tGnc17w52z3zjLelLDeX+9u1Az79FKhcmY/oTZvy3FdcwfcrV6YgNBg7lg7//vjf/1gH5pdf+Nnffcei55I8SRACojXja9auZQzNjBnuyxPgJXvLLRRe7duz8IapgGKAiYkizAShJBGBFul4WsH8+Xzt2wc8+ijvxA0aABMmUHz168d2Z8/yPPfdR9+un3+meGvQgO+/+CKtWUuW0Prlayk7fJjrEyawzVtvMWO/UvQxy8rio/rZs+5Y+9OnOTVav773WE6c4LzKhAls++GHTExrs5XO31IQwojjxynGPJdjx/ieyeQWZyYTn3dGjQpeXwVByI8ItFBm/Hj6ZQEULdWr0y/LN1N+//60Kt19N/DGG+7jfa1gn3zCKUDD5+v++yl2xo9nfZW77qJ17Ouv6XDfrh3F0/HjQEICRdSsWXTKV4oO+fffDwwaBLz2GudJfC1lVarws81mWtwAZu8H2Jflyyn+/vqL6TEA5jrr3JnrKSmcJj16lIloz56lIBw6lI4wghDFGOkqWrXirWHNGrcY27uXbZRyX96tWvHWce4ctw0fsm7dgjoMQRD8IAKtpHE4gHr1uAD04Vq0iOvnz1MAPfkkp/Q8982fTyEyeDD3P/MMHfSNPF9Gpvy0NKaRSEmhRWz7dlYTBiiKZs5kYlfAv8/XiBHuvp48SdFTpQqnNBs04GO2kdS1YkVgyhSgTx/+AmzYQCvWZZexIPmCBfktZV9+6T7/G2/wMd2Yiuzbl0Js2TIKzDZtuH/+fI53/Hg6+xshY4mJLNrXuHFx/GcEISzJyGDFsjlz+CzkdHq/X6cORdjTT1OQ3XCD/5geKTguCIFJSUlBcnIykpKSkBikC0QE2oXwrfn4xRec/jt2jBagCRPyi7BPPgGaNOF6aiqjGT3nD958k6+jR3Mar3t3Lp77PDl4kBaktDTvTPlnzvAO+8AD3NepEy1ShkArX977PAX5fM2cCVx7LVCjBvONjRsHHDjA7PsWC4Vi794UdqdPU6wZ6S8aNXKnv/C1lD3yiPszpkzx7s+VV1LULV9OZ/9ff+X6vn381TCSzAKch+naVcSZEFWcPs3noPXrGX/zxx+M1/ENvleKngqjR9PYXRjEh0wIBy5GKGmtkZ2djXPnziErKwsrVqzA8uXL0aRJE9SvX9+1/9y5cwWuHzhwAL///jtyc3MRGxuLRYsWBUWkiUC7EL41H2fOpPB4+GFW9123juLBV4QZrFrFFBFLllC0TZhAwZOVxbqQCxa42/rbBwCffcbPXrHCbUH79VfmAJs711t0/fFH4LEE8vnatYuWMCPicuRITmUqRVG1YAEjM/v04b5OnSjCXn6ZkZ0jRgBxcXTWB/Jbyvxx8KA7bGzZMk6tas2/TcuWtJwlJNASZ7dzHiYpqcB/lSCEI8Y05fXX8/nmjz/cgmznTne7WrX4fPbww3zNzaUh3ZimHDSo8OJMEC6GoliTUlJSsHjxYrRp0wZNmzZ1iaDCiKUdO3Zg1qxZcDqdMJlMSExMRJkyZQK2z8rKwqWkDjObzYiLi3MtmZmZyM1z0szJyUFycrIItJDEt+ZjzZp0fD99Gti/n3fNOXP8izCAcwwLFzKD46OPslLwPfcAU6dS4Hnib19uLs87YgSd8Jcv52Ny374UWIboAii6PMOyfPHn82XkK5s8mcINYJDA/v200tWpQ6FVty6P9aRGDY7HF19L2cqVzF0WE8MY/uXL+RkA+5+YyD7ddBPnZuLi3MdKLL8QYWRnA9u20WNh/nxe9r6Xbd26FGH9+/P1+ut5Ofoi05RCYfAnsDytTb4ix/M1NTUVo0aNgsPhgMViQe/evVG5cmUvgRRIMKWnpyPT8IG+BCwWCxwOBwDA6XRix44dqFu3LuLi4lC5cmWXoIqNjc23npycjLlz5yI3Nxcmkwn9+/fHE0884bet1WrN9/fq2LEjcnJyEBMTg6QgGQdEoBUWo+bjI4/QIX7cOE63Va4cWIQBTCdhRBm2bEkfMYAx7j/+6P0Z/vYtW0bfLMMa1bw5pwBnzOC2IbratqXoMqYX/eHP52vIEO/alsOHc0lKoiDt0gW49dbC/53S04FNm2gR27iRffvrL/f7FSvyfM8+S0HWrJlbzPpD5mGEMCUnh9ORmzd7Lzt2uP3GlHJPVypF74nRo3lbKQxyeYQXF7JEOZ1OZGdn4/z58zh//rzX+tq1a7F27VpcffXVuPLKK5GZmeklkAItR44cwaZNm6C1hlIK5cqVg8PhuCRrk91ux9SpUxEfH+9XGFWqVAlXXHGFa//mzZuxatUq12d37doV3bp1K1BYGYvNZsPq1au9hNJ3331XaEtW69atMX/+fNex/fr1Q6tWrQp1bGJiIhYtWhR0HzSpJFAYPGs+Dh/O5KnlyzMxanw8hY8hwsaN45Tciy9y+4EHWDvyuus4TTpkCH23nn+eyYgM9uzJvw9g+5YtmR4DYPRigwacbgQoiG66icEHv/zCKVXDEuYPw4J1xx0Ft/PFt7qx3c5fH0OIbdxIfzsjdAygZ3KlSrTGac35m7ff5pgEIUJITuZlW7Uq3VENIbZ9O7cBdxaba6/1XtLSvKMpJSN/4SjqlNulHrtixQosWLAALVq0QKNGjXD27FnXkpGRUeD2/v37sXbtWuTm5kIphRo1akAp5RJg58+fd1mLLoWYmBgvgVO2bFnExcXh2LFj2Jk3V66UQuvWrdG+ffuAAsn3devWrejTpw/sdjtiYmIuyh/L1xJ1Kb5cwfpflyaBKgmIQLsQOTm8g776KgVW9+5MGtS2Lacjb7uNPlq+Iuy223j8pk1spzWtaiNGABMncjryhRfcn+NvX2E5dYp9uPlmRlQWJxkZtOr160dRZjJx/mXfPrcTv8VCy12TJu6laVOgdm0Kxo4d5RdZlMyNAAASSklEQVRICFtycvh137OHM/Oer9u2UWQZKJVfiF1zDS+PMmX8n9/32Ufwj8PhwIkTJ7Bw4UIMGDAAdrsdVqsVI0eOROPGjaG1vuCyZcsWDBs2DA6HA2azGYMHD0bVqlW9hJS/JTMzE2fOnMH58+cL3V+LxYJy5cohPj4e8fHxyMjIwIEDB1zvN2vWDC1atIDNZkOZMmVci7/tn3/+GdOnT0dubi7MZjOefvppPPfcc17iyhJgJkJEUugjAu1SMepCNmvG7bvuAr75hpaixETWk9yzJ78ICzX8/QpkZtK6tX8/Izb9raen5z9Xw4ZMnGSIsUaNCk4WK79AQoiiNZ9B5s9nfE61ajT07tnjFmIHD3pHTVosfPaoU4eXx/r1bgPxW29xiQaKw3G8WbNmqF27No4fP+5ajh075nc9zVMJFzM2m80lpAItmzdvxooVK6C1hslkQs+ePfHQQw+53vcUY/Hx8bD53BOLIpSKKrJEJIU2ItAigcIInfPnmXHfc1m7llOvTicf8evU4WP/6dP5j69enYEPNWvytVYtZrV8/33O14gVTAhRjMvjxhuZqebYscIt2dne51GKX/s6dWgs9n2tUcPtNpmSElwDcXFZNlq3bo2srCy/i+H07bls2bIFn3/+ucsS1a1bN1SsWNE1VZeVlRVw3Zj+C4RSClWrVkVCQgISEhJQrVo113pCQgJOnz6Nd955x2VBGzt2LJo0aQKl1AWX1NRUDBo0CA6HA1arFXPnzkWHDh0CWp98/15iiRJKAhFoocDFWJK0poUrLY3LsmWcWrXb+ajeowdgteYXY4WJmGncmI76niKsVi3+8gSyhIkVTChhAn3FnE5eAr7C6vhx9/qOHfQmKOh2ZrPRQua7bNpEC1puLi+tYcO8C3JciIkTUzBnTjJ69kzCwIEXf22sXLkSixcvRtu2bdGsWTOXY/iFXrds2YKPP/7YJZJ69+6NKlWqePk0+S6GWDpz5gyOHDly0X0NRJkyZVCpUiXXtFxsbGzA9U2bNmH16tUuS1SvXr0waNAglwCrXLkyzGZzgZ8XLKEjIkkoCUSgBROnkw78991HgWWxMM13xYpuAea7nDrlzqDvD5uN+c+qVr3wsns3P1v8wIQSxp/IMp41MjK8l/R09/qmTcAXX6TA6UyGyZSE5s0TkZND8XXihP/sMSYTi15Uq8ZMM7t2pQBIBpCEbt0S0bevW4QlJGjExTlht+cgJ8e9ZGdnY82aHPTtuxYOx2qYzU3x8ccN0aBBtlc7z/ae27t27cL06dNdeZo6deqE8uXLIzs720tQeS6e+7KyspDjmZC5CJhMJpQtW9bLf8lTHHku27dvx59//umKrrv11ltxxx13IDY2tsDF8HfauHEjunfvHpTpOkGINESgFReev0DNmgFHjjAv2uHD7nXf12PHAucnK1eOMfUXWg4dYmSokbT1YkWWWMDCiqI8qRfFojNxYgq+/TYZnTsn4b77EnH2LGNXKKQ00tOdOH3ajvR0B9LT7UhPtyMjw46zZ+04cMCB9evXAlgFoBkqVGgMu92Oc+dyANjzlkDr2wFMBOAAYEZc3AO4/PIE2Gw5sNnssFpzYLHkwGKxw2TKgclkh9Y5cDjsyMnJwaFDp7B//3YAGoBChQpVYLFoLzFVEvc6k8nkSmgJABUrVkS1atVgs9lci+Ho7W97w4YNWL58uUsodenSBV27dvVyFg/0unHjRjz44INBE0liiRKE4iGsBZpSahKAawD8rLV+t6C2JSrQUlIwsf2TmJNbCT1xAgOxOX8bs5l+XJddxrxoxuu5c5g4dhHmOCuip+UMBv7wLlN3+CTIK4iJr/wbc75bip49bsHAUY9c+ADPY4s4DVPUH/1gHFuSn621htPpzGdVMdZnzFiLBQtW4+abm+HOOxshO9uBnBwHzp+3IyfHgexsB7Kzuc7Fvb537w7Mnv0FnE4HTCYzOnbsg4oVa8Bud8Jud+S9OuFwcNvhcLqWEycO48iRxQCcAEyoUCERZcqUh8PhQG6uE06nA04n13NzHcjNdUBrYz0DwCFQ5ACAUSrMAbeQKh0sFivKlo1DTEwMrFar31fP9b1792Lr1q15Ryu0bNkCrVu3drWz2Wyudd9l3rx5+Pbbb70SWvbr16/AY202G6xWa748TZfivB0s528RSYIQGoStQFNK9QBwj9b6MaXUZADva623B2pfkgJtYve3MOiHUeAPlQXtK9yBxs2uYeb72DggLha6TBlAmfIdu2XLDqxY8SH4Y2dBu3Yv4eqrWXPT93/ATe2xDmzbthOrVo1xHd+mzT9w1VX1Xe9rjbxQcngdpzWwc+curF//sevY669/DvXq1XMdY/TBfYz2em/v3t3YuPFT1/HXXvsUatas4wpddx+jPfrB/QcP7sH27V+6jq1X7zFUr14LubkaWue6XrXWyM3N9ThPLk6ePIhDh2aBYsOMyy7rgQoVqgPQHp+hXdvu/TxPevpRnDz5q+v48uVvQWxspTwx4vR6NUSK1tzncJyB07kThkUGqJKXKzgHWmeD1p/SvHZMYF5ps8fibzsdgDvaTanLUaZMTZhMZphMFpjNFpjNZq9Xi8UCi8WMw4e3ITMz1TgSlSq1Rps2bREba0FsrBVxcVzKlrUiLs6CsmWtsNmssFq5TJ36CxYvng0gF4AJnTs/ipdeetRLWPkTW1arFRs2bEDnzl1cQmXJktITOsGOkBOhJAjRTTgLtHEAftVaz1NKPQggVmv9lU+bgQAGAkDt2rVb7PVMllqM3NHmZfy2ZnSJnDu6UaAAUT7rTnhbbWwwmWI92rkXpZTX8UopOJ0Z0NqdJkSpqihTpjqUolgxXg3xohQFi8lkRlrabmRnb3H1Ly6uBerUaQWz2QaLJQZmcwwsFhvMZq5bre79a9fOw/Hjs2AIlRo1+uHuu/siJsYCq9WCmBhrvnVjsdmsmDr1DyxadA8oAmNw770L8dZbNyImBvkWm42vVit9siZOTMGgQR1dx06YsKjQlsOiHAtQaHTo0LFIIitYQkdEkiAIwSKcBdokAOO01n8ppToBuEFrPTJQ+xK1oE1MwaBBt4KiwYoXX5yOrl1b+Olz/mN//HE9PvzwIdexL700A/fc08LVlmHg3udQeTuUAr7/fj1GjerlOn7IkJno3r1lXjv3YjIp17px7OzZ6zBs2AOuY99++1v07t3K9b7JpLz6YHy28d6//70Wr7zSPe/4GHz00fd47LE2Hp/nebz3+uTJq/HMM3fD+NH//PP5eOKJRJhMJq/2gf/ely4YgiVWii50gKSkFNjtybBak5CcnHhRboPBnFIWoSMIgnBxhLNAGwtghtZ6Vd50ZyOt9XuB2pd0kEAk+lOF8mdHa78lpkMQBCE6CGeB9iiAalrrD5VSwwFs01pPD9Q+JNNsCIIgCIIg+CGQQLtw+uTg8wOAZUqpGgDuAtA2yP0RBEEQBEEoUfKHG4YYml7eSWBypQ5a6zPB7ZEgCIIgCELJEg4WNGitTwGYFex+CIIgCIIglAYhb0ETBEEQBEGINkSgCYIgCIIghBgi0ARBEARBEEIMEWiCIAiCIAghhgg0QRAEQRCEEEMEmiAIgiAIQoghAk0QBEEQBCHEEIEmCIIgCIIQYoR8Lc6LRSl1HMDeYPejAKoCOBHsTgSBaBx3uI45XPtdVKJx3NE4ZiA6xx2NYwbCY9xXaq0TfHdGnEALdZRS6/wVRY10onHc4TrmcO13UYnGcUfjmIHoHHc0jhkI73HLFKcgCIIgCEKIIQJNEARBEAQhxBCBVvpMDHYHgkQ0jjtcxxyu/S4q0TjuaBwzEJ3jjsYxA2E8bvFBEwRBEARBCDHEgiYIgiAIghBiiEATBEEQhCKglLpcKXWbUqpcsPsiRA4i0HxQSlVQSv2ilPpNKfW9UipGKTVJKZWilHojUJu8/V7tCviMfO2UUtWVUssucFxtpVSyUmqxUmqiUkrl7W+slPpvtIxZKXWFUupA3v5kpVS+/DEROu4blFILlVKrlFJbSrPfgc5XnGO+QH9K/X9VlDErpSxKqX0e39EmUTLuukqpn5VSy5RSH0XomL2+y0qphgBmAmgHYGlBx0bYuId7fL+3KqVei6QxF/C5RbqXXQwi0PLzMIAxWutOAI4AeBCAWWudCKCeUuoqP23uVEr18NMuH/7aKaUqAZgCoOwF+jYIwGCt9a0AagFoopSqD2A0gArRMmYAbQCM0Fon5S3Ho2TcnwDoB+AbALl5bUql3/7OVwJjLohS/18VZcwAmgKY4fEd3Rgl4x4F4B2t9U0AaiqlkiJszP6+y00B9NNaDwewC0DdSxhz2I1baz3U+H4D2ATelyJmzAE+tzjuZYXGUhofEk5orT/32EwA8AiAf+Vt/wagvZ82xwA8BGCWZzsA2/18RJKfdnMA9AJQoBVMa/26x2YVMDuyA0BPAPMLOvYC5w23MT8CoKNS6gkAv2qthxR0jgLOHW7jrqy13g/gc6XUXQDKl1a/A5zPH/mORSHHXBDB+F8VccyxALoopToA2AhgkNbaEXiE/gnDcTcE8EfevmO4hAfHEB+zEz7fZa31bEWL6d0AKgHYUdD4AhFu4zZQSrUCcEBrfTDAsQEJ5TEHaBfw71ASiEALgFIqEbzY9gAwvnhpAG7wbaO1XpUnFrzaKaUmALja47SLQeXt1U5rnZ53Ps/P/y+8b27TtdYT897rBWCz1vqQR/uiDNdrPAjxMSulfgHwDoBzABYqpZpqrVOjYNwrlFJP552rDoC40up3gPNd8pgvldL8XwU4X2GPXQTgNq31YaXUNwA6A5gbBeOeDWCoUmoVaJm46GmvUB6z1vrtvHa+3Y0H8ABYZrBIqRHCbNwA8ByAoRc/UjchPmZXO49jizLcQiMCzQ9KqcrgdFJPAC+AT8MAL0KTnzYAcNa3ndZ6kJ9zj/V3Pl+01vcG6Fs9AC8BuO2iBnUBwmzMK7XW2XnvbQBwFYBLEmhhNu5BADoAeBvAp6Xdb9/zFWXMl0Iw/ldFGHOq8R0FsA78jl4S4TRurfW7Sqn2AP4JYIrW+mwkjTkQWuvTAPoqpaYCaAVgdWGP9elbWI1bKVURQDWt9c7CHuPnHCE7Zj+fW6qID5oPio6A3wJ4TWu9F8B60HwKAM0A7PHTBv7aBfiIwrbz17dKAGYAeFxrfaawxxXivOE25vmKUVNxADqB/g8XTbiNW2vtBLANgAKf1kut3wHOV6hjCzPeCxGM/1URxzxVKdVMKWUG0A3AX4UcqhdhOG4A+BNAbQBjCjHEfIT4mP31d7xS6ua8zYoATl/M8R7nCatx53EvgHmXcByA0B5zMfxtio7WWhaPBcBgAKcAJOctfcGb6xgAW8CpKN82vUB/IK92Ac4fsB2A5Av0bRSAwx6fe0thj42kMYNWpK2g1ezpaBl33v4pAD4s7X77O19xjznU/ldFGTOA68Dv50YwoCUqxp23fziAPpE4Zn/fZTAoYDmAZQDejJZx521PB90YIm7MBbXz/TuU1CKVBApBnjXjdgC/a62PlFa7YBKNYwbCd9yh1G8Zc8l+v6Nx3KE05tIkGscdjWMOhAg0QRAEQRCEEEN80ARBEARBEEIMEWiCIAiCIAghhgg0QRCEi0QpJfdOQRBKFLnJCIIgFBKlVEOllA2MphUEQSgxJFGtIAgCKL4ANAeQAaAGgOcBPKi13uzRrCWARAAVlVJdANjA++gdWuvHS7nLgiBEMGJBEwRBIE4A5bTWv2itJ4F5zE4abyqlqgC4Nm/fCq31T2AOqJkAzgejw4IgRC4i0ARBEMghABWUUlcppa4CLWlHjTe11icBLAHQGxRzAJCrlGoBd70/QRCEYkEEmiAIAnECuB5ACwB2ALlgWS1PTGARZkfediyAcyhigWxBEARfxAdNEASBlAewSmv9HwBQSgH0McvKCwyoDvqonQFQSynVARRo9SH3UkEQihmxoAmCIJDaAOorpR5SSj0OoCkAc957lwO4G8DNYF2+DAArABzJ80UrV/rdFQQhkpFST4IgCACUUrFg0eUjeduTtNb9Pd5PApCptV7rUd8vFUAagE+01r2C0G1BECIUMcsLgiAA0FpnAcjy2DXQ5/1kj814UKxtVUpdC6BsyfdQEIRoQixogiAIF4lSKjZP0BnbJq11bjD7JAhCZCECTRAEQRAEIcSQIAFBEARBEIQQQwSaIAiCIAhCiCECTRAEQRAEIcQQgSYIgiAIghBiiEATBEEQBEEIMf4f6QI6ajBjMRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAJaCAYAAACbXbvvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXiU1dn48e/JRvYFMjBBdkEERZFFUZGlgoi0traItZXi0rq2rrzV+qpUtHWrWnf0h/pi21ehVq2+VQQVBFGUHRdWMWHLwGQlKwnJ/fvjzCSZZEK22Yj357pyZeY85znPeWbQ585ZjYiglFJKKaUiR1S4K6CUUkoppXxpgKaUUkopFWE0QFNKKaWUijAaoCmllFJKRRgN0JRSSimlIowGaEqpiGaMiTPG3GGMSW3meKoxpkujtF80Toskxpi+4a6DUiqyxYS7AkopdTQiUmWMyQUuM8YArBSRLxtkOQn4FXBdg7RLgW3GmD0icrBxmcaYK4DdIvKhMaYXcJGIPHW0ehhjkoEaoCfwC6AKeFREjrTjtpYaY2aIyMajXG8SUAl0BboDiUA3YBJQAUwRkZp2XFspdQzQFjSlVEQyxtxljPnYGPMp8EugD7AfyGmUdSOwz3NOmjHmLsABDAeaa0U7CKQCiMheYKwxZpQx5iQ/9fiPMeZnwCXAs56ytwI3A8ntuK/TgVxs4HU0vwbigE+AF4GlwP8BPwQGdOrgzJgeGLPS8/o4jNmLMcs9P44medqSz//1YjHmHYxZhTFXBumulGoTDdCUUhHFGDPSGHMBcBi4DbgIuB3berRaRA41yBsnIhVAX2PMVSJSDHyDbd2KBfYbYxIb5E/1vD8M1JUDHMAGXb/wU6WZ2Jas/wN2ichqbIA3V0SK2nhvBrgTG+zFGmN+70nz5zvPvZwGLAN+A5SKSKHnWOdkTAawAEjypJwB/AmRCZ4ft588bcnnz++AdYicDUzHmJSA3pNS7aABmlIq0mwCTsUGWLXA9UB/IB0bSDU00xiThA1kPjfGjMS2jLmATOAp4HFjTLonfzTwmud1wxYoAwwFljeujIgUANtF5ADQ3xjzO2wg92k77u0PwLMi4hKR94FybHfnQD95DwM1IvIh8AGQT32LXXE7rn2sqMEGsN4Aegzwa4xZjzF/biZPW/L5MwFY5Hm9AhjVoTtQKgA0QFNKRRQROSIiD2BbzA5ix169BbwH/NUYM6NB9ouBamxXYAp2PFoZ8D9AL+B+EbnG29LlaX261HOuMcZcZYz5AzAC6Ad83bg+xpgRwCDP2y+x/9+sEZFNjfL92xjjavTz5wbHb8O2fB1njFlkjHkBGwz8H/COMeZh4+2W85wC1Hi6RE/BBqdDPS1unbd7U+QQtiXU6z1sADUaOBNjTvGTpy35/EnC000OFAA9OnILSgWCBmhKqYhijOlvjJmD7bJKALYDtwCzgA0isqhB9oexAZwRkc+Av2NbP74EivCMM2skC/gxNsh6EfgPkA28LiL7G9XleM81FhtjooBxwEvY7lAfIvJjEXE2+rnTU87ZwLsi8qqIvIwNvh4F9ovIX0VkiIj8XkTcDYqMB6pE5AtgCbZ1LxY4nu/XBK9PESnBjrnbQH2w3N58/pRi/62BbaXUZ6MKO/1HqJSKGJ6uyAeBl4EtIrIDKMQOkM/z/K4jIh9hZzhWepISgL7YFpFc6h+63vFnT2BnfH4EeGdfXgY8AszxU6U/Ah+KSC127NiTnjJLG5R7Rkv3JSKrRGSLMeY4Y8z9wGDsuKfhRzktDRhkjHnMk+8ybCthL1oeU9WZvI8xWdixg+cBX3Uwnz/rgLGe16diA3alwur79FeYUirCeboiLzHGXAy87Ul73ROkxIvIPj+nDceOzwIbnJVjW9+KsePQvGUfMsb8XUTWGGNmAQeMMRcBS0Rko2cW5z+AG0XEW97vgThPt+oaEVlm7ADyM40xC7AtWnd4lsyobsX97QPuMsYcJyK/bSF7HxHZAGwwxkRju93SscFhz5au1Ynci50kUQXMQ2Rbh/IZMwo4Fdt66rUAeBdjzsGORfw8QHVXqt2MiIS7DkopVccYkwncLiL/ZYyJww7IPxkbcA0Efu8ZsO/NPxv4SkQWG2N+hR2rtQL4GbYb81U/17gTeFtEvmqUfg92QsIT3jXKPAFZjGf8mjffLE/5ydju1NuOth6aZ9Hc8dgA8nhgoue8RGyL2BYRuabROUuxQWoSINixUZXYP6wfFZGWlulQbWFMT2wr2vutHLemVFBpgKaUiijGmPOw3Yo1xpizgBxvy5kx5mpsS8k7wJ9EJMfYB2uZiBQbY04DdmAH0X+MDZyarIFljBkHfC4ih0N0W95xaKXA1tZc1xjTs/GYuAbH7hURf12ySqlOQgM0pVSnZIxJFpHSlnMqpVTk0QBNKaWUUirC6CxOpZRSSqkIowGaUkoppVSE0QBNKaWUUirCaICmlFJKKRVhOtVCtZmZmdKvX79wV0MppVQHVFd3Zdeuhxg8+DdUVTnYuvV/6NJlLwADBtxObGyRTx6g1fn8EYnm228f4ciRNDIz/01m5tvBv0mlgHXr1uWJiMPfsU41i3PUqFGydu3acFdDKaVUOxUWwqWXwsGDsH49vPEGHDgA113XfB5ofT5/HnsMDh2CP/4RLrgAFi6ElJSg3J5SPowx60RklL9j2sWplFIqYkRH2wAp1bPN/erVMH8+jBgBd97pP09b8vmzfDnMmGFfjxsH+ne+igQaoCmllIoYqamQllb/fupUG0CtWQOffQabNzfN05Z8/pSVwXHH2dddu9qWOKXCTQM0pZRSEeuss2x3Y3Q0nHYa7NjRsXz+JCdDRYV9XVoKtbUdr7dSHdWpJgkopZTqXKZMgVdftS1hS5bANdd0LJ8/I0fCJ5/A9OmwaROMGROYujenurqavXv3UllZGdwLqYgRHx9Pr169iI2NbfU5GqAppZSKWHPmwMSJEBcH114Lgwd3LN/atTYIu+qq+rRZs+zkgJUr4Ztv4IwzAn8fDe3du5eUlBT69euHMSa4F1NhJyLk5+ezd+9e+vfv3+rzdBanUkqp7739+20r2pQprRu31hFbtmzhxBNP1ODse0RE2Lp1K0OGDPFJ11mcSimljikPX7CcZY9t8Elb9tgGHr5geVCu17OnnckZ7ODMS4Oz75f2fN8aoCmllIo4oyelMWN277ogbdljG5gxuzejJ4UogvoemTdvHps3b657//nnn+PtXautrWX16tUAlJaWUl5eTm1tLdOnT6fCO7OiGddee63f9KVLl1JWVgbA/fffz+7du49azoFWTKt9+umn616XlJS0mP9YoAGaUkqpiDPx1tOYd+sOzrvtZG4+7WNmzO7Nor/sYeKtp4W7aqH18MOwbJlv2rJlNj0AVq9eTVRUFCtWrKCiooLXXnuNpUuXcujQIQCioqJ49NFHAdsK9Pzzz7Nx40buuece8vLy6so5cuQIy5cv56GHHmLx4sUsXrwYp9PJjBkzeOONN3yu6Xa7ef3116mqqiI7O5tVq1YdtY733HMPb731VrPHN2zYQElJCU8//TRFRUXcdNNNLQaPxwIN0JRSSkWkhJQYjhDLExvHc93Yr75/wRnA6NG279UbpC1bZt+PHh2Q4svKyhg/fjwZGRnMmzePwYMHc9ddd5HWoK93yJAh5ObmsmjRIvr27cvrr7/OJ598wuTJk31mon733XcMHDiQ8ePHU11dzQ033EC/fv0499xzfa45efJkZs2axSuvvMI111xDjx49uPHGGyktLfVbx+zsbKZNm9bsPZSWllJYWEhycjJJSUlkZWURHx/fbHnHCg3QlFJKRaQV79kH7JRua3juk5ObjEnrFG6+GSZMaP7n3nvtALkpU6BvX/u7Z0+b3tw5N9/c4mXz8vJ466232LZtG48//jiJiYkkJiayadMmZs+ezRNPPEFBQQHvvfceK1euZMuWLezZs4fY2FhKS0tJTEzkkksuIT4+HoCYmBhycnLo0aMHO3bsoLi4mNtuu43zzjuP6dOnA7Bjxw6ee+45xo4dy9q1axk4cCDvv/8+KSkpnHPOOVx99dWsb7Qn1+LFi+nbty8xMf4Xndi+fTsLFixg165dOJ1O3n77bWJiYpgzZ06Tso41usyGUkqpiLPssQ08/fnpAIwcXMbtP9tjuznZ8P1rScvIgKws2L0b+vSx7zsoPT2dzMxMEhMTWbJkCSJCeXk5F110EevXr+emm24CYOrUqWzdupUTTzyRrVu3EhMTw/HHH09sbCw33nhjXXnLli2jqqqK+fPnc9lll2GMoaqqisTERIYPHw7AoEGDGDRoEC6XiyFDhrBx40bGjx/PRx99xO23387FF1/sU8eqqioWLFjAvHnzeO6557j++uub3Ed+fj4zZ84kISGB2NjYumvGxcUxbty4Dn9O4aQBmlJKqYiz5oNiftRnI6/tPptcdzQTbz2NRWxgzQfFTLw13LULoL/+teU83m7Nu++G556rX/StA2JiYoiLi6NXr14MGjQIgIMHD9K9e3cyGgSAubm5bN68mbFjxzJt2jS2bNnCgAEDePfdd7nwwgsB6tb4qqysZMKECSQkJNT9FBUVNWn9Sk9Pp7y8nJEjRzJ//nzOOussv3V85JFHuP3220lLS+OMM85g9uzZPPzww0RF2c6/8vJyUlJS+PDDD3G5XCQnJzN48GA+/fRT7rvvvg59PpFAuziVUkpFnN+/O4HELnbPJVeR7UabeOtp/P7dCWGsVRh4g7NFi2DuXPu74Zi0DvjPf/5DXFwclZWVjB8/vm7cmTeg2rFjB4899hjPPPMMo0ePprKykjVr1hAdHU16ejqJiYl1+WfOnMmcOXO4/PLL2bx5M2PGjGHYsGFccMEFdTM2Afbt28eLL75IdnY2hYWFXHjhheTk5LBo0SKfur3xxhsMHTq0rvVt5MiR9O/fnylTprBhg+3qdrvd5ObmcvjwYYYOHcrEiROZOHEiq1evpqampsOfT7hpgKaUUioiuQ/FAeAqTQ5zTcJozRoblHlbzCZOtO/XrOlw0XPmzCEpKYnTTz+dvLw8rrvuOgC6du0K2C7JRx55pC4QM8bQpUsXioqK+Pbbb+uW4vAGdmlpaVRUVBAbG0vPnj0ZNWoU27ZtY9euXXXXFBEef/xxRo8eTVZWFjk5ORQUFDBjxoy6PLm5uYwYMYKLLrrIp7433HADP//5z1m4cCFr1qyhb9++TJ48mWHDhrFgwQL27dvH2rVrWbRoET/5yU9YsWJFhz+jcNKdBJRSSkWks1K+5LPSYTijDpBb0yPc1QmYLVu2NFlRPpJs3ryZU045pUl6ZWUlRUVFOJ1OXnvtNX7+8583yVNeXl4X0AG4XC4WLlxYN6atoQ0bNlBRUdFsF2dr63rkyBFGjBhR10ULsHv3btavX8/YsWPJzMxsd/mB5O97P9pOAhqgKaWUikiD4rLZWd2PKGqoOgzRcdHhrlJARHqApoKjrQGadnEqpZSKSO7qDLpQSS3RuLfmh7s6SoWUBmhKKaUiTnV5NcWkMTThOwBcWwrDXCOlQksDNKWUUhEnb3sBAMOybMtZ7rZD4ayOUiGnAZpSSqmI495ZDMDJJx4BwJVdebTsSnU6GqAppZSKOHk5du2sYWfaJTZy9x7761odS5pbR+zIkSN1r+fMmeNzLDs7m507d9a9f/LJJ8nP9z92cN68eWzevLnu/eeff07DSYu1tbWsXr0asHttlpeXU1tby/Tp01vcCP3aa6/1m7506dK6Ndnuv/9+du/efdRyDhw4cNTjAE8//XTd65KSkhbzt4UGaEoppSKOe7d9CPcelk4axbgOmDDXKDwefrjpmrTLltn0jvrqq69YuHAhkyZNYufOnbz55pv84Q9/YO7cuXULxx48eJD77ruP+fPns3TpUs4///y6ACkvL8+nvA8++ICvv/4asAHe0qVLSU9Pb3Ld1atXExUVxYoVK6ioqOC1115j6dKlHDpU340dFRXFo48+Ctj1155//nk2btzIPffc43PdI0eOsHz5ch566CEWL17M4sWLcTqdzJgxgzfeeMPnum63m9dff52qqiqys7NZtWrVUT+fe+65h7feeqvZ4xs2bKCkpISnn36aoqIibrrpphaDx7YISoBmjOlhjFnZKO1kY8xSz+tYY8w7xphVxpgr25KmlFKq83PvrwbAMTANZ1w+roK4MNcoPEaP9t04wLuxwOjRHS/75JNPpnv37txyyy0MHDiQ5ORkunfvTmZmJsOHD6eqqoqkpCTuvvtuKioq+OKLL5g6dSoffPABX331FT179qwrq7bW7vrQq1evuj00f/SjH7Fo0SKWLl3qc92ysjLGjx9PRkYG8+bNY/Dgwdx11111C956DRkyhNzcXBYtWkTfvn15/fXX+eSTT5g8eTKVlfVd3t999x0DBw5k/PjxVFdXc8MNN9CvXz/OPfdcn/ImT57MrFmzeOWVV7jmmmvo0aMHN954I6WlpX4/n+zsbKZNm9bs51daWkphYSHJyckkJSWRlZVFfHx8s+W1VcADNGNMBrAASGqQZoDHgFhP0u+AdSJyNjDdGJPShjSllFKdXJ5bMNTS9fgMshKLyT2U2PJJx6Cbb4YJE5r/ufde6NkTpkyBvn3t7549bXpz59x8c+uuXVxczKpVq9i3bx8vvPAC//znP3E4HJx22ml8/PHHREdHM3fuXCoqKqipqaG6upro6GjS0tKorKz02WPz2muvJTo6moceeoh7772XmJgYRowYwdixY3nooYcA2+L21ltvsW3bNh5//HESExNJTExk06ZNzJ49myeeeIKCAjs55L333mPlypVs2bKFPXv2EBsbS2lpKYmJiVxyySXEx9vtv2JiYsjJyaFHjx7s2LGD4uJibrvtNs477zymT58O2C2rnnvuOcaOHcvatWsZOHAg77//PikpKZxzzjlcffXVrF+/3uezWbx4MX379m2yj6jX9u3bWbBgAbt27cLpdPL2228TExPDnDlzmpTVXsHYLL0GuAT4d4O0K4BlwBTP+wnAHZ7XK4BRbUjr+AZkSimlIpo735BhioiJ74oztYK1uT1bPqmTysiArCzYvRv69LHvO6qoqIjVq1dTUVHBpEmTOHz4MC6Xi/Xr1zN8+HDi4uKIjo7mj3/8I59++illZWV06dKFkpISRITo6GifcWq9evVi2LBhiAj9+vWjqKiI448/nujoaEaOHAnYTdIzMzNJTExkyZIliAjl5eVcdNFFrF+/3me3galTp7J161ZOPPFEtm7dSkxMDMcffzyxsbHceOONdfmWLVtGVVUV8+fP57LLLsMYQ1VVFYmJiXX7eA4aNIhBgwbhcrkYMmQIGzduZPz48Xz00UfcfvvtXHzxxT6fjbcFcN68eTz33HNcf/31TT6//Px8Zs6cSUJCArGxsXXXjIuLY9y4cR3/gghCgCYih8D2GXt+dwMuwwZn3gAtCdjneV0A9GhDmg9jzNXA1QB9+vQJ6L0opZQKD3dRHI7YIqArWZlV5O6OjO16Au2vf205j7db8+674bnnYM6c+q052ys9PZ3zzz+fdevW0b9/f0pKSkhPT6eqqoqoqChiY22H19y5c7nzzjvp3r07CxYs4PTTT2fw4MEkJCT4dOV5A5Xa2lpSU1Pp168fq1atYsiQIfToYR/dMTExxMXF0atXLwYNGgRQtz1TRqOoMzc3l82bNzN27FimTZvGli1bGDBgAO+++y4XXnghYIOkvXv3UllZyYQJE0hISKj7KSoqatL6lZ6eTnl5OSNHjmT+/PnNbjH1yCOPcPvtt5OWlsYZZ5zB7Nmzefjhh4mKsp2O5eXlpKSk8OGHH+JyuUhOTmbw4MF8+umn3HfffR37YhoIxSSBB4E/iEh1g7RSIMHzOtlTj9am+RCRF0RklIiMcjgcQai+UkqpUMsrjccRb2fFOXtAGcmUugIztudY4g3OFi2CuXPt74Zj0jqqsrKS6upqEhISSEtLw+l0cvDgQSZNmkRpaSl5eXmkpKTw5Zdfcu211/L666+TlJREWlqazwzN2NhYNm7cyFtvvUVqaioDBgzgBz/4AWvWrOGkk06qy/ef//yHuLg4KisrGT9+fN24s4bB1I4dO3jsscd45plnGD16NJWVlaxZs4bo6GjS09Pr9vqMiYlh5syZzJkzh8svv5zNmzczZswYhg0bxgUXXFA3YxNg3759vPjii2RnZ1NYWMiFF15ITk5O3WQIrzfeeIOhQ4fWtb6NHDmS/v37M2XKFDZs2ADYyQa5ubkcPnyYoUOHMnHiRCZOnMjq1aubnf3aHqEI0MYDDxljlgPDjTH3A+uAsZ7jpwLZbUhTSinVybkrkslMsjPinL3swzv3y7yjndIprVljgzJvi9nEifb9mjUdL3vr1q2sWbOGuLg4tm3bRnl5OTfccAMrV67k7bffJjk5mRdeeIHdu3czbtw4Bg4cyEsvvURycjIPPvhg3XgxgOnTpzNr1iwefPBBTjjhBACeeuop7r33Xs4+++y6fHPmzCEpKYnTTz+dvLw8rrvuOgC6du1al2fQoEE88sgjdYGYMYYuXbpQVFTEt99+W7cchze4S0tLo6KigtjYWHr27MmoUaPYtm0bu3btqitTRHj88ccZPXo0WVlZ5OTkUFBQwIwZM+ry5ObmMmLECC666CKfz+mGG27g5z//OQsXLmTNmjX07duXyZMnM2zYMBYsWMC+fftYu3YtixYt4ic/+QkrVqzo+JfjrXQwfoDlzaUBfYGvgSeANUB0a9OOds2RI0eKUkqpY1+PqAPymxM/FhGRJQ+sFRBZ8dTGMNcqML755ptwV6FOWVmZiIjs3bvXJ33Lli1HPa+8vFw2b9581DyFhYVNym3Opk2bmj1WUVEhubm5IiLy6quv+s3jvQ+v3Nxc+etf/+o37/r162XVqlWtqldzNm3aJOvWrRMRkQMHDtSl5+TkyJtvvilut7vJOf6+d2CtNBPTGGmwMFwoGWN6YlvH3heR4rakNWfUqFGydu3a4FZcKaVUUEmtEBtdw+1nfcKfVk3gy39t55TpJ7Dols+4+LEzw129DtuyZQtDhgwJdzVUiPn73o0x60RklL/8wZjF2Soish9Y1J40pZRSnVdRTjE1pJPpGVacdXI3AHJzqsJYK6VCS3cSUEopFVHc2wsBcGTZmYRdj88ghmpcueHp8QmGcPVeqfBoz/etAZpSSqmIkpdtZ2s6enUBIComCme0m1x3dDirFTDx8fHk5+drkPY9ISLk5+fXLa7bWmHr4lRKKaX8ceeUA5DZt25DGpxdinAVte0BF6l69erF3r17cbvd4a6KCpH4+Hh69erVpnM0QFNKKRVR3PvsWDPH8al1ac6UUvYUpzV3yjElNjaW/v37h7saKsJpF6dSSqmIknfALvaZOah+dfmsjEpcVQHY40ipY4QGaEoppSKKOw8SKSMxs36DdKejFndtN2oOHwljzZQKHQ3QlFJKRRR3YQyO6EKftKzjoqglmoNb8ps5S6nORQM0pZRSESWvpAuOLod80px94gBwbSn0d4pSnY4GaEoppSKKuyyJzMQyn7SsQckA5G4vCUeVlAo5DdCUUkpFFPfhVByph33SnCemA+DKrgxHlZQKOQ3QlFJKRZS8mnQcGb6TAZwnZwKQu7cmHFVSKuQ0QFNKKRUxKgoqKCOZzG6+6fHp8aSbIlwHTHgqplSIaYCmlFIqYtTtw+lsuq2TMzaf3IK4UFdJqbDQAE0ppVTEyPu2GADHcU0DsazEQ7gOJTVJV6oz0gBNKaVUxHBn29mbmb0TmhxzppXjqugc2z0p1RIN0JRSSkUM9147e9MxIKXJsazManKPZCK1EupqKRVyGqAppZSKGHkuO3vTcULTfTedPaCcJEpdpaGullIhpwGaUkqpiOE+KERzhLTeqU2OZfWJBSD3y7xQV0upkNMATSmlVMRwF0STGVVAVEzTx5Ozvx2X5tp+qMkxpTobDdCUUkpFjLziWByxxX6POU+wrWq5O8v8HleqM9EATSmlVMRwlyWQmeB/jFnWSV0BcO2pDmWVlAqLoARoxpgexpiVntd9jDHLjTEfGWNeMFasMeYdY8wqY8yVnnytSlNKKdV5uStTcCT732+z6/EZxFKFK7c2xLVSKvQCHqAZYzKABYB3NcFrgOtE5AdAb2AY8DtgnYicDUw3xqS0IU0ppVQnlVedhiO9yu8xE2VwRrvJdceGuFZKhV4wWtBqgEuAQwAi8t8issVzrBuQB0wAFnnSVgCj2pCmlFKqE6qpqqFAMsjs2vw6Z874IlxF8SGslVLhEfAATUQOiUiTEZ7GmEuAr0VkP7Z1bZ/nUAHQow1pjcu92hiz1hiz1u12B/RelFJKhU7+zkKEKBzdm98QPSullNwy7UxRnV9IJgkYYwYAs4GbPUmlgHcfj2RPPVqb5kNEXhCRUSIyyuFwBOcGlFJKBV3eziIAHD2b78J0ph/GdbhrqKqkVNgEPUDzjEl7FbiyQcvaOmCs5/WpQHYb0pRSSnVC7u/s7M3MXs13YWb1qMUt3ThSeSRU1VIqLGJCcI07gD7AU8YYgDnYSQTvGmPOAYYCn2O7MluTppRSqhNy77GzNx39k5vN4+wZhRDFwW8O0nOEM1RVUyrkgtaCJiITPL9vF5EsEZng+flYRHKAycAqYJKI1LQ2LVj1VUopFV55++3sTcfxTbd58nL27QKAa0tBSOqkVLiEogXNL89kgUXtSVNKKdX5uA/Y9c26DWp+jFnWQLuCU+4O3U1AdW66k4BSSqmI4M43pFFMXHJcs3mcJ6YD4Mr2v5itUp2FBmhKKaUiQl5RDI7YwqPmcQ6zs/Vz9+qIF9W5aYCmlFIqIrhL4snsUnLUPF1Su5BhCnEdbH6tNKU6Aw3QlFJKRYS8iiQcSeUt5suKyyc3v0sIaqRU+GiAppRSKiK4D6fhSPW/D2dDzsRDuEoSQ1AjpcJHAzSllFJhJ7WCu7YrmRktjy1zplWQW5EeglopFT4aoCmllAq7UlcpVXShNTv2ZXWrxnUkE6ltflN1pY51GqAppZQKO/d2O3vT4YxuMa/TCRUkUrLvULCrpVTYaICmlFIq7MAES98AACAASURBVNzf2mDraPtwemX1sZup536VH9Q6KRVOGqAppZQKu7w9FQA4+rY8+N/ZPwEA13ZtQVOdlwZoSimlws699zAAjgEpLebNGmz36sz9tuUlOZQ6VmmAppRSKuzcuUcAyByU0WJe50ndAHDtqQ5qnZQKJw3QlFJKhV1eHnShkmRncot5M/qnE8dhcvfrLE7VeWmAppRSKuzchdE4ogswUS1v4WSiDM5oN668mBDUTKnw0ABNKaVU2LmLu5AZ1/pB/874IlzFLc/4VOpYpQGaUkqpsMsrT8CRUNbq/FkpZeSWpQaxRkqFlwZoSimlws5dmYojpbLV+Z0Zh3EdbnlCgVLHKg3QlFJKhZ37SDqZ6UdanT+rRy1ucVBdrjM5VeekAZpSSqmwqiqt4hBpODJbPyvT2dM+vg5+kxesaikVVhqgKaWUCqu87QUAOHq0PIPTK6tfFwByvykMSp2UCjcN0JRSSoWVe2cxAJk941p9jnOgXS/NtbM0KHVSKtyCEqAZY3oYY1Z6XscaY94xxqwyxlzZ0TSllFKdS16Onb3p6NPyPpxeziF2goAru/UTC5Q6lgQ8QDPGZAALgCRP0u+AdSJyNjDdGJPSwTSllFKdiHuPDbIc/ZJayFmvx1C73VPuvtqg1EmpcAtGC1oNcAngXXFwArDI83oFMKqDaUoppTqRun04B6a3+pwuqV3oagpwHWj9uDWljiUBD9BE5JCIFDdISgL2eV4XAD06mObDGHO1MWatMWat2+0O5K0opZQKgbyDtRhq6Xp829Y1y4rLJ7egS5BqpVR4hWKSQCmQ4Hmd7LlmR9J8iMgLIjJKREY5HI6g3IBSSqngcedH0dUUEh0X3abznIkluEpa3y2q1LEkFAHaOmCs5/WpQHYH05RSSnUi7uJYHLFFbT4vK72c3MrWd4sqdSyJCcE1FgDvGmPOAYYCn2O7LdubppRSqhPJK43HEd/25TKc3Y7g+i4TqRVMlI5FU51L0FrQRGSC53cOMBlYBUwSkZqOpAWrvkoppcLDXZFMZlJFm89zZhkqSaB4z6GWMyt1jAnJQrUisl9EFjWcPNCRNKWUUp2HuzodR1pVm8/L6m07gVxf5we6SkqFne4koJRSKmxqj9SSX5uBo1vb1zNzDrAL27q26d/vqvPRAE0ppVTYFOUUU0MMmY62jyHLGpwKQO6utnePKhXpNEBTSikVNu4ddvamI6vtc9acJ9ndBFx72t49qlSk0wBNKaVU2OR9VwKAo3d8m89N75tGFyrJ3R/oWikVfhqgKaWUChv3bts9mdmGjdK9TJTBGZ2HKz8UK0YpFVoaoCmllAob9z7bPekYmNau850JReQWJbScUaljjAZoSimlwibvgF3eMnNQ2/bh9MpKKcVVlhrIKikVETRAU0opFTbuPEiilISu7WsFc2ZU4apqX3CnVCTTAE0ppVTYuAtjccQUtvv8rB615EkmVaU6k1N1LhqgKaWUCpu8kjgcce3fqsnZ0z7GDn6TF6gqKRURNEBTSikVNu7yJDKTytt9flZ/uzxH7paiQFVJqYigAZpSSqmwcR9OxZFyuN3nOwcmA+DaWRqoKikVETRAU0opFTZ5NRk4Mo60+/ysoXaCQO53lYGqklIRQQM0pZRSYVGeV045SWRmtr+M7kM82z3tb/tm60pFMg3QlFJKhYV7u5296XBGt7uMuOQ4upl8XAfavtm6UpFMAzSllFJhkbfLzt50HBfXoXKy4grILewSiCopFTE0QFNKKRUW7uwyoH37cDbkTDqEqyQpEFVSKmJogKaUUios3Hvt7E3HgJQOlZOVXkFuhe4moDoXDdCUUkqFRZ6rGgDHoPQOlePsdgRXTSZSK4GollIRQQM0pZRSYeE+CDFUk9YnrUPlZPWEw8RTlFMcoJopFX4aoCmllAoLd0E0mVEFmKiOzcB09raTDFxf5weiWkpFhJAEaMaYDGPMu8aYtcaY5z1pLxpjPjPG3NUgX6vSlFJKHfvyDsXiiO14q5dzgJ1kkLut/Xt6KhVp2hWgGWO6tvGUmcA/RGQUkGKM+T0QLSJnAgOMMYOMMT9tTVp76quUUiryuEsTyUwo63A5WYNTAXDtav+enkpFmqMGaMaYJGPM2EZpY4GxzZzSnHzgZGNMOtAb6A8s8hxb4ilvQivTlFJKdQLuyhQcKRUdLsd5kmc3gT3VHS5LqUjRbIBmjOkiImXAZGPMRGNMgjEmBbgXWN/G63wC9AVuBLYAccA+z7ECoAeQ1Mq0xvW82tN1utbtdrexWkoppcIl70gajrSOB1VpvVOJp4Lc3ABUSqkI4TdAM8YkA88aY+4DaoEuwP3Ae8BMEdnbxuvMAa4VkbnAVuAXQILnWLKnHqWtTPMhIi+IyCgRGeVwONpYLaWUUuFwpPIIBdKVzG4dXxrDRBmcMXm48mICUDOlIoPfAE1ESoFbsa1lX2Jbrz4FLgROasd1MoBhxpho4AzgQeq7K08FsoF1rUxTSil1jMvf6dmHs3tg9tDMii8it7hjOxIoFUmO9ufGL7EtWC6gCjgB292YaozJFJG8NlznAeBlbDfnZ8DjwEpjTE9gKjAGkFamKaWUOsblfVsMOHD0jA1Iec6UMrYXdAtIWUpFgua6OG8AUrGtZb/GBnIpwEDgmjYGZ4jIFyJykogki8hkETmEnQCwGpgoIsWtTWvHPSqllIow7u9KAcjsndBCztZxdq0it0oDNNV5NNfF+QywGHgHKMaOA3MBTuAxY8zwjl5YRApFZJGIuNqappRS6tjm3mNnbzr6BWaT86wetRRIVw4fOhyQ8pQKt2a7OEVkI4Ax5gDQDfgQyBKRD4wxw0JUP6WUUp1Q3n7PPpwDO7bNk5fzuGgADn6TR+8xxwWkTKXCqcWFakVkh4isBnYB240xI0Xky+BXTSmlVGflPlALQLdBbV333L+sfl0AyN1SFJDylAq3Vu8kICIV2NmYPwtedZRSSn0fuPMN6aaI2MQATRIYmAyAa2dpQMpTKtxaHaAZYwzwCLAjeNVRSin1fZBXFIsjpjBg5WUNzQAgN1vHoKnOoS17cT4MvCUiLwerMkoppb4f3CXxZHYJXGtX96GZGGpx7a8NWJlKhdPRtnq60LOwLMaY64BXReTZkNVMKaVUp+WuSMKRHLjNzWMTY8k0+eQeaEu7g1KRy+8sTmNMd+AC4HpjTDbwXyJSEsqKKaWU6rzyqlIZnXogoGU6uxTiKuwS0DKVCpfm1kE7KCLXisj5wJvAPGPMKaGtmlJKqc5IagV3bTcyMwLbHelMKiG3JDDrqikVbq1ZZuN94HLgh8aYHwe9RkoppTq1kv0lVBOHwxHYcrPSKnBVpge2UKXCpFWd9SJSLSJ/BqKMMX2CXCellFKdmHu7Z6P0rOiAlut0HMFV40BqJaDlKhUObRpNKSJvYjdOV0oppdqlbh/O4+IDWm5WlqGKLhR+p4vVqmNfm6e76J6YSimlOiIvpwwI3D6cXs7edtFb19f5AS1XqXDQ+chKKaVCyr3XLibrGJAS0HKzjk8EIHfboYCWq1Q4aICmlFIqpLz7cGYOyghouc4TUgFwfVcR0HKVCgcN0JRSSoVUnluIp4Kk7gHu4jw5E4Dc3dUBLVepcNAATSmlVEi5C6NxRBdgokxAy009LoUEynHpSGnVCWiAppRSKqTch+LJjAv8ODETZXDG5OHK97tJjlLHFA3QlFJKhVReWQKOxLKglJ2VUERucWJQylYqlDRAU0opFVLuwyk4UiqDUrYzpRxXWWpQylYqlDRAU0opFVLuIxlkptcEpeysbofJre4WlLKVCiUN0JRSSoXM4UOHKSEVR7fAbpTu5ewuFEoGhw8dDkr5SoVKSAM0Y8yzxpgfeV6/aIz5zBhzV4PjrUpTSil1bMrbXgCAwxnYfTi9nMfZcl1fuoNSvlKhErIAzRhzDuAUkXeMMT8FokXkTGCAMWZQa9NCVV+llFKB5/7Wzt7M7BkXlPKz+tv9PV1bdT9OdWwLSYBmjIkF/h+QbYz5MTABWOQ5vAQY24Y0pZRSx6i6fTh7B3ajdC/noGQAXDtLg1K+UqESqha0XwHfAA8DpwM3APs8xwqAHkBSK9N8GGOuNsasNcasdbu1SVsppSKZe4+dvRnofTi9sobY7aNyc6qCUr5SoRKqAO004AURcQF/B1YACZ5jyZ56lLYyzYeIvCAio0RklMPhCN4dKKWU6jB3rt2GKXNgelDK7z40E0Mtrn3BmSWqVKiEKkDbCQzwvB4F9KO+u/JUIBtY18o0pZRSx6i8g0IUNXQdEJwALSY+BofJJ/dgcCYhKBUqodoP40XgJWPMz4FY7Niyt40xPYGpwBhAgJWtSFNKKXWMcudH0c0UEBUbvB6PoXHbuX3nb4BtcNVV8M03MG0a3NVgMYADB+D882HDBnjuOVi40KYXFcEZZ8Dzz/svvLnylAqwkLSgiUiJiFwsIuNE5EwRycEGaauBiSJSLCKHWpMWivoqpSJAQQEsXQp5eeGuiQogd3EcmbGB34ezobvkT0TVVMMbb0BNDXz2GezaBTt21GeaPRsqKuzr666D5cvtzznnwG9+47/go5WnVICFbaFaESkUkUWecWltSlNKdXKFhfDDH8IXX8DEieB2wwUXwKhRcM019Xkap3ldfz28887Rr3HVVXDmmXD//cG5B+VXXmk8jviS4F3go4+Iio8jV3rYgGvGDJt+3nnwySd1eUhKAqfT99x9+2zL2qhR/sturjylgkB3ElBKRZ7Nm+Gxx+C//xumTIH//V/45S9h7VooKbG///a3pmkAK1eCywU/+lHz5WtLSNi4K5PJTA7OPpxUVcF99/HxCb+mijiktBSOO84e69rVBl+ePDz4YNPzn3nGtqY1p6ysaXlKBYkGaEqpyDN+PIwZAytW2Fa09HT46is7PmjPHujdG7p1a5pWXW27p/r1g7//vfkuUm0JCRt3VTqOtCAtgfHgg3D99WT0TkEwVNbE1ndjlpZCbW1dHtIbTVKorYVly2DChObLT05uWp5SQaIBmlIqMonYgdsZGfahmZMDTz4JQ4bY1ouxY5umvfIKDB0KV18Nd9wBTzxR30UK9V2fZXaxVKZNs12cL73ke+0DB+C0045eP+0ibbPaI7XkSwaOrkFaAuODD+CZZ7j0i1sYzkai33+3PvjetMkG7p48TJgAGzfCr39tj69caScHGNN8+SNHNi1PqSAJ1SxOpZRqG2Psg/Tuu+3DdNMmSE21XZ8vvwyrV8O8eb5pmzfb4OzAAfjLX2DRIttFun49JCbWd31+8AE8+ij86U+wfz/88Y+2Vc3betJwALk/DbtIr7zSdpEO0p3oWlL4XRG1dCWze5DaBlasAGDrU5uovfEm5Pq5TPzb7+x3/N579t/ML35Rn3/CBJg/375+/30YN67+WE4OvPqqDfS9fvITO4mgYXlKBYm2oCmlIs9DD9nWMLBdmEVF8OWXNij6/HMbvBUWNk0bONCOKRs/3nZ3RkfbLtIxY+q7Pv/9b9sSsmULjBhhA7+sLCj2TBJvbgB5Q9pF2i7unfYzdmQFt23AeUIqE1nOvv1R9rsaM8Z2X6al+WZcvrz+9Z//DD/9af37vn19gzOwfwwcrTylAkhb0JRSkefqq20ANH8+nHwyLF5sW6pycmy34qWXwqmnwhVX+KaJ2HyvvWYHg594InTpAr/6le36/P3v4amn7Pij2lrbGrJvn81z7rn1A8jffNO2ljSn8WDx9etD87kc4/K+s7M3Hb26BPU6WcMyAcjdc8R2kXuD6UAIdHlKNUMDNKVU5MnIsAP8G/r6a9/3p5/eNA3gn//0fX/33fD66/D447ZV7LLL7OzQLVtssPbpp3Y8W3IyzJ3rfwB5Y60ZLF5QAOvW2bFsmZlN338PuXPKAcjslxzU6yQ7k0mkDJdOslTHMO3iVEp1Po27SC+/3HZ9gl2Oo29fGwTeeqsdr3brrfZYcwPIG2tpsLi/ddwav/e3jtuRI9Cnj73+hAm2C7c5c+bA6NFwww1t/njCxb3f7sPpGBjcrkETZXDG5JObFxvU6ygVTNqCppQKjta0GPnLE4iWpsZdpNdfX9/1WV1tW9QAHnnEBmeJifa9Z5A5UD+AvD2Dxb3ruI0ZYwOxZ5/1fb9+PWzbZtdx++Uv7cD1tWshKsp21T700NHvb906GyB+8YVt9fvgA5g0qX2fVQjlHbCzNzMHZQT9WlkJRbiKE4N+HaWCRVvQlFKB17gFKScHpk61A+ovusiO9fLXyuQvrTlHW+bC20W6YoUNjlJSbNfnihV25qV3/Ni998LMmf7Lf+MNW0ZSUtsGi+fm2iDwpJPq13G75Rbfdd3OPNP/Om6rV8P//Z/tvr3qKtui5s/HH8PPfmYnRkyZYpeIOAa48wzJlBCfHh/0azlTy3GVpwT9OkoFiwZoSqnAa7wTwFtv2ZaqJUvsOLDFi5vmWb/ef5o/wd4JwF+geOCAbTXz8g4Wz8uDyZNt2vbtcMklsGqVXbLhf//X5ouN9V3XDezaa/Pn2+5X7zpuo0fb1rAvvrBB3rvv+q/fMbqivbswBkdMYUiuldX1MLnV38+xfqpz0ABNKRV4jXcCuOKK+iDG7Ybu3ZvmOfNM/2n+BHuZi8aB4kcfwaxZ9QvceonYwLO6uv68l1+248OOP962nJ1yCrz9dv26bqecYseNFRTAt9/a1sT+/e15p5xil/wAOzatucDzGF3RPq+kC44uwd0o3cvZQyiSdCoLj7KenVIRTAM0pVRwNGwxivUM1v7sM9s6NWZM83n8pTUW7BakxoHi1Km2Tqmpvvleftm2sHlNn24nIFxxBXzzjV2XragIsrN9Jy3s2GG7OL/80s4gXbLEBnAzZ9pJBzU1ttXx1FP91y9YK9oXFDS/PVYAuMuTyEwMfsB04AA8v95ueD5rZq3fnnB/m0V4N5o4Gt1AQoWKBmhKqeBo2GL09tv24f+73/luq9Q4T4O0ikGnsPn+t/3HCqFoQWocKDZelDQ/3+73OXu2b3ppqa1bcbEN3mpq7KSFv/3NdnvW1NhJCXfeadPnzrUB0aWXwj332CBt+HAbBUyaZDeC/6//8r3G2LGwYQPcdJPdW/LSS+uPFRf7jvfbts1uaXXOOXDbbTbPc8/VzxQdPtzOIg3U+L+jcFel4kg93KZz2mP2bBATDUBpQZXfnvDGm0WsXFm/0URzgt2zrlRDGqAppQKv8TIX6elw8cXwwAO2ham5PJ60wkL4v38U8fW+9LpYwWdFipEjKV/yCRdcAC/8dhPzP+wH+I87mtNijOEveGzojjvs/TRu5UtPt7NFf/ADO0v02Wf9T1oYOtSu4/bnP8Mf/mCDzpNPtt2kX35pt6ECm/eRR3yvERVlx6qdc46dRdq/f/2xf/zDd7zfmWfateBWroS9e2338HXX2d/Ll9syfvObkIz/y6vJwJHRzMSHAPFuBNGjuwBwWk/butqwJ7zxZhHV1b4bTTRHN5BQoaQBmlKqqcatMAcONF2zq3Geqqr6dbzeftu27owcaR/mu3bZB/6f/mSjp4ULbQvUb38LPXvaPOedV9fSZCaM45yzarj05fP4+Zk5bL/yQX75S7sSRUkJrO/zE8qe/xuPyq1cnbaIzzKmsXat/7jDnxZjDH/BY2Mffwy3316/Ztpdd9kKeJfqaO48CEwXZUKC7VIdMMA3/frrfcf7lZfbLa3Ajv3zbmkFdheFAwfs9xrk8X9lB8uoIDGoa/R6N4J48EGIS7SrSEmpHTfo7QlvmMfrlVfqN5r44gu7frHfezg252aoY5Sug6aUasrbCjN5sg06Fi5sumbXF1/45lm8GHr1an4dr+uuq3+9bh288IINFubOhbPPti1WnpYmb1izYgW8v7Uvva66g60NVqQ4bkgqy+csp/rdpfR86/ds/3UavXvXF79vn81XWGh7DxsHBf5iDJ+9zhuvo3beeU3vZ/v2+tcTJtimuO++s12UxthzBg+2n9WmTbbJzmvWLBvwrlxpx6qdcUbL30lbecf73XWXXU5kzBj7HT3wQH2eZ57x/V7aM/6vldtcubcXAkk4nNHtu59WePDB+o0gYhNjAcHlsse8PeEN83ht2GC/8oYbTfzud03LP0bnZqhjlAZoSqmmrr++/rXbbQOv3FzfNbtGjfLN0717/Tpey5bBsGHw/PMQ4+d/M43X8XrvvSYLrTaMFSZMgPffhyefrF+R4vQpGfxh+Qx2LqxP8/rLX2yrmDeG/OgjcDjsbU2dWj8Zc9o0u0RbRoYd13/kiG2QGjAgA1jKU8/Y26jTYHPtOXPsKhinnw7PeNP792/aojRqlO9nBbabd+lSm3fuXLupeyB5x/v961/2Wp98YrtJZ82yUQbY6GLZsvquVKjv1r37btsKesklTctuZ5SSt8vO3nQcF9eROzuqDz6w3/Uzz8CmzYZoavh6v13WZNMmGy/Pm1efx7tZxMknN91owh9vw+eYMfXlKRUs2sWplGqetxXmsstsJNMwQmqcZ8yYgK7j1XAI2IQJ9sF6zz12//OXX7aNQo3TwMYLS5bYxq+Gw6kaDgJPToZHH7VxyNy5tiFv+XI7DOvSS+u7SX2CswYaLuTfvbu95Tbr2dO20jWefOCv6xh8pxj62xKqutoGVJMm2SU+7ryzPtIYPhx2767f0mrOHNunV15uP2hoXbcutLt7tm4fzj7BW91/xYr67274cBjSZRdbCntw662waJENyBvnmT/fNm4uW2bncCx4spgHNk6lYtx5bD/J9/Of3uUd/vY36sr74ehGU0Ebr5XnT3W1/Ud49tm+E2aUakQDNKU6I38P+cYP9KoqGyCMGWPzVFfbcWEXX2zzXHKJHSP20kv+o6E5c+zD6cc/rn/QBGgdr8axQlGRrXJNDXz+uY0pCgubpoENxCZPtkOovMOpxozxHQQ+cqTdK33ECBtjZGXZjywiFvJvPMh/8eKmUwz9RZLvvQfnn28rVllZPz5u4ULfLa280eVFF9nv0htdNp5pet55NihvOFgL7DZXDaOUadNadVvuvXb2puP41BZyBsby5dArpYgBsXv8bvjgzQO+G018cMU/iL/zVhJWLOGEcb6ff+IlP/LZQCJ1boOpoIWF/tfKa+ypp+w/wFWr7JZjJSUBvnPVWWiAplRn1Pgh712KoeEDffFiu87W6tW2Vezf/7aR0c9+Zs9bvdrOROzbt2k0tHu3fZp17WqDAm8gFqB1vBrHCosX27S0NNt7d+mlduJj4zSwXaHjxtV3kXbpAr/6le8g8AMHbEx4zjnw4ouwcyece26ELOTfeJB/RkbTKYb+IskLL7T9tNddZxfCve8++11fconvllbe6PKBB+xCut7o0jvT9J137Fi6KVPg5pvrW928C4c13ObqjDPqJ0W0MIU2z9Vgo/QgLyb28AXLWfbYBpzpleRVpTJjBmz53w08fMHylk9u4fP3biDh/KbRVNDoaP9r5TXWcADkuHG2T1UpP0IaoBljehhjNnhev2iM+cwYc1eD461KU0q1oPFDJiam6QO9Wzc7QL201P4eNMgOfB8xwkYtbje8+aZ94I4Z4xsNJSVBjx627/Crr+xAnoULA7OOF01XpTjjDLsiRWmpTU9OtrfSOA3sqhU//Wl9F+mYMfa2Gg4C/+wz24I2bZodf3TFFfb8QC7k33jN1zavAevtOt6+vekUw6NFkrt22UFWP/uZ/3Jbii79teCB78JhGRn2gzp0qL5Vr4UptG43xFJF6poPg76Y2OhJacyY3Zuq6ihcNQ4+fGQ9M2b3ZvSktJZP9jra5+9vKmhqatMmOn90KqhqpVC3oP0FSDDG/BSIFpEzgQHGmEGtTQtxfZU6tnkfMpMnN32gn3SSzfPkkzbgGjDAPtQffNCugN+vnz1n+XLbXdYwGjpyxAZVhYV2za/zz7ctNYFYx6sBb0tIQ8sea7klpHEX6eWXNx0EnpFh45ADB+obiQK1kL+/NV/97QvfeOUS79CyH51dwLbzfsfW37/UdIrhsmVwyinMmZfF6NHwz+8aRJKHD9ubfeGF5mdhthRdNg7uu3dv28JhDZfuaMCdH01mVAFmxcdBX0xs4q2nsegve/h3zqkcIZYZt/dj0V/2MPHW01o+GXwXVfb3+fubCtpaOhVUtVLIAjRjzA+AMsAFTAAWeQ4tAca2IU0p1RoNHzL+moaefNIGXnfeWd/lNXOmHXe2cCGcdVbzA8Bb8ZBpscUoIYGCH0xn6bcDms3jbQnxBmnLHtvQqpaQxl2k119fPwj82WfrF/9vODQLAtYA2GTN12efbboG7N/+hs/abmvX2vMum1HFO/EXM/iNBzhxSl8bLDeKLgt+OJP9723ii89qGLX3LdbXeCLJK66wAVrjWaMNtXaQvze4HzGibQuHNV66wyPvUByOuOKQtSBNvPU0Zp20DoC0qFLG/faU1p1YVeW7qLKfz58PPrD36V0D79e/bn3FgrVNl+p8RCToP0AcsAxIB5YDLwKneo6dB9zR2jQ/ZV8NrAXW9unTR5RSInL4sMgPfiCyZIl9f/HFIhs3ihw5IjJxosjSpSI33yzy97/b47fdJnLnnfZ1TY3IGWeI7NvXfPkffyxyww329UsvifzpTz6HCwpEzjxT5P77RU4+WSQ7W+T880UmTxb5yU9s9RrnOXhQpKioab4lD66TFA7Jxb0+la6mQD54ZJ2IiFx5pciYMSL33RfID65efr79+Nxu/8fLy0X++U+Rb79tvoyPPxY55xyR4uKm7//+d5E77hApLBQZO1bE5RJ55hmRe53PSnF0umxxjpfaceNF/ud/RKZPtyeOGSOyd6/8z+wvJa/nMJGTT5a9s+6Ue+4RkXffFYmPFxk/3v789a8ihw6JzJ7tW6maGpGzzhK58UaRE04Q2bXL/82PHGm/uHvvFVm0yKaPH29/33CDyHvv2dfffCNy0UX1ZY8ZIGZlFgAAIABJREFUI1Jb26TIs1I2yQ8y1tnrfvaZTfzXv5r82wmUjx5dL5nGLT/s/rmAyOXHf9y6E599ViQ9vf5z9PP5+/B+Jv7er1kjMn++7/HsbJGhQ+3nMGqU/W9SfW8Ba6W52Km5A4H8Ae4BLva8Xg48AYzxvP8pcGdr0452nZEjRwbrM1Tq2NL4IfPHP4oMsw/0ukBs506R0aNFEhNFTj+9/sHz0ksic+fWl9WOh/zy5fXP4Ntus7GCN1a89lqRf/+7aZ7Fi22A0jDfQzfkyCnx28QO+bc/KRTL4IRsGZzukud+uVKmnV0g6z8t9/sxPDR1mXz06HqftI8eXS8PTV121I/PX/DoctlAqrEvvxSZNKn+/TffiFx4oY1Rrr/evi4v932/f7/96DMzRS67TOQ3vxGpqhL54gt7TERk5kz7Ofkzd67IW2/Z19u2iVxzzVFvp6mjRZeNg/tzzqn/d5SWJnLVVSKPP26/LBGRV16xwb6I/VJvusnvJQfF7pJLeq8SWbBA5JFHbOI994j84x9trHzLvMHZR4+ul9pakUld1wrUyl9++FHAr9Uu+/aJLFxo/yJR32uREKCt8ARmy4EiYBcw23PsXuAXwK9ak3a062iApjoVf81JjZuNdu0SueACGzncemvzac3pSDNUK5qQGrcgiYj87Gf1gVlzefK/LZT+KW4BkUxzUFIplisHfizJHJIf9/hUesYelERKfAK3AbE5ctFxq2XOxI/lX3d8ITs/3isfPLKu7kEt4vvgPprGweNrr4lMmSJy2mm++Wpr7dfjbTTZuVNk2jTfRpS77rLnN3w/ZYr9egoKRCZMEPnLX0Sef16ksrI+3xNP2HR/HntM5NVX7et162yAFzCNg/uGlffe2KFD/luV/vAH2yrmlZ0t8sADIiKSYQrkt8OW2y/6lFNEbrlF5MQTgxKkNA7MS1yl0jtqryRzSHI3ugJ+PaXaK+wBms8FbZCWCmwCHgO2AGmtTTta2RqgqU6lcXPSggUis2bZ91dcIbJ9u+269EYSM2aILFvmP82ff/2raXkB1LgFSUTk009t40xzeWprauWVa1dJOoUCNXLxcZ9IN5PXJMCaenqebFhXI9kfZ8u9l3wtkwfslIuP+0ROiP1WDDV1QVsSJTIkbofEUy5XD1nRquCsoYbBY1FR096sF18U+fOf69MPHLBBVv/+9usSEfntb0UefND3ff/+Ij/8ocgnn9jgato0kRde8N8T3Vy9jtLD3G4tdeu2ip8/LGp+dbl8yhj5sN+VNk9BgY1ITz+9/ry9e0WOO64+MDx4sPlrtOMPiy/f2ikJlMnE9HVypLK6XbfWotb8USXSNK2gQGTqVJHhw0V69z76+d73t99u8zc8f+RIkauvPnodgz02QLXJ0QK0kK+DJiITROQQdgLAamCiiBS3Ni3U9VWqQxquLL5+vR11fvbZdhl7sIOPzz3Xjkq/777687ZssQt6NZxN9/e/+85+W7LEzsa85RY7E9K7EbZ3qQxoujl2Q+3c9Lq1Gu4E8PbbvnMW/OV57t6DnNttI7+adxbVUXG8+9QuRp1SzT//srtu9p13dt6hAxVUVkXRd1xfTp4xlAlXHc+ivWezrWoApa4yvpi/mf/3y+VcOWwN3eNLqCGaF7acQ4+4Qnqd0vX/s3fe4VFVWx/+7YSSAAFC6L333jsJTSmKCgYQhAsICB9cpApIuaCIIHBFKWJHRSEXBKQIAknoJUDo0juEmoSE9LK+P9aczJnJmWQgPVnv88yTOXv2Pmfvk1PWXnsVGz22hKzSUlpHUHj6lP8lmsMBwKc7b172x9A7KVg7Lbi6chaDESOAn34CHj1iR4PUcFKwjlF86RKHE2nXDpg4kesYhSwz8jy1RZJhzKzDdKxdi6jgCLTGYZRCgNnj9I8/2BtU4+hR9qLQQnUUK2Z88GQz3RtTt1cVrBjuD5/gxpjTOTUjC+swGHuivhr1X/MYGT6cs0B8+qlx+2XLzNvr15vvbSOPEyNe8twJGYQtyS0rfkSDJmQqAgMt18Vatya6fZvVRq1a8VLk+PGsRiEiatOGtQbW62Sa2mnoUFavEBHt3Mn7ePNNtjSvW5eoalWi0FCeGU+fTvTnn+YyI6z3Z1qKSg2sNUY7dliaNenrhD8Np6al7pAjoqkQgqhGiUDasT1pw+kXMWPyXnyS3NQTauNyioB4ckAsDa+5j24fvW/XWPRLlHoN2nvvER05krjcaNsaveJo7Fiigwft6ooFtlaYrRWvrq5JK1THjGFbdiObQCNeSPHauzdRly5046NvCCA63G0Oq/yMVJKTJxM1bsz3y7Rptvc5dizRtm38/fffeX8vwL+qHSCFONo5z++F2r0wprEn6qtR/408Rozad+rE23v28PcaNfg36/Znz5oNJq9d45uvQQN2/tm2jcvq1GFtnWZvqq+nt0G1Jjqa1b+tW7MKWUgRyEwaNEHIdgQEsNu9dcoW68jigYGcZFwpDhIbEsJ/z5xhTVtUFMdVcnHhJNdaG03tZB3a4sYNDnfQowcf+/XXuc6MGaxC+e47y+TY1iQRKsNaC/PwYeKYXUbZpLQ4Xn/+ydqdJk14wn79OisQ580zZx96+hQYNSIOLm65cTygLPpVPIppMxzxMMoV8xc4JtRLSbYhLSzH/xbdxoGQBlg/4TDyIBo/XmyBai1cMb7xXjw6n1hVZE9ayr17zdmUTp3i064nqRhudeqYlRynT9tOzp0Uzs5Anz4cvk6PdRiz8HDbClV9yLIOHTior5Yeq1Ur4+ParXjVwnSUK4dHkXwPOJUrygc0CurarRvv3M+P2545Y7zfFIbpWH64MerkvYaBMyrg/vH7L9TWbnRjT9RXo/63bWuZ6/byZeP2wcH8T/z4Y/5Ha3lC9e0rV2ZVqZZyatkyTjh76hQ/M5yduWzYMN7Hzp18oejraWVGSKqqdEMENCHzo18mnD3bvDZTsybHKjIqA3iZsFevpPcdHMzrTm3a8DLhix778mUO0HrwIL/hoqPN9V5/nUPg377N7du04Yfgb78BN2/yg3jHDq4/bBinVcqVy7xOFh9vGY/JOn6SszMLWQ0bcu5FLaI7kDg5thFJxGOyXqlZty7xCopRwHktReTBg/x+OXGCY4CNGsXb2upV4dgnWP1lMMKjHFHYIRQLR1zFrzfa4sOPXSzq9e3LQ5861bLr+mxDRjkWNfx2P7MIUNp7cWtsX3wRk1oexIBqfvjSvy0q13XGzLY+CL4ZnNDOKC2lNZcvWybdtl7u02K4zX/vGrZutYzhNmoU/8tHjGB5XHsHpyaajDBjBmd62rKF/0edOpnrWIcss17WNcIu+chqYhFyN4TrF4q3HZi1dWs+GY6OnFIqJWkckiCfmzP+tzEXwskZ/To9QmykjYSrL0tSk6r4eOMyfa7b8uU5IK5R+zx5gFWrWLDSo29fowbPprSJoX4SCPA/1s2Nn48hIeaJodFk0QhJVZV+2FKtZcWPLHFmQ6yXCfX07p04JpFWZuROZ8TYsUQ//shW2e7ulvGb7Dn2//7Hx9LKLl5MXK9lS/4eG8tW361aEf3yC9HixRwPKT6eDXxHjuSlRo1q1RLHY9J7vzVuzPVmzeKlEP062axZHP5AQ+dNl4Cd3nS9e3O4CesVGOs6hw/z8lrt2hxCYuhQok9f8bUwyo+NjKGx9X3IEdGUC9E0t6MP7d0dxXG8MoCLf12nvuUPEsBehvO77KHnD2wsCb8AAace0PpJh6hPmUOUC9FUQj2kQgi2OBdXrvDlo/fcTC30YcyIiPbvZ0cMvV14EiHLEnme6kk2jJl1mI7Vq+lgg/cJIAodOdFyPVp/f3bowDFGwsJ4+c36XtJIpTAdv47m//vUlqkYesNg7In6alT2xhts6hAeTlS8uDlsiXXd999nD5MOHYgqVOAQOcOGmdvHxvI69jffmM/t8eNEgwax2UP37kQLF3JZ/fpEvXoRTZnCF4G+nlZmRMeO5mfFqlVmd2LhpUBm8uJMy48IaNkQW+5zx44ljrekL9Pc6ZIT0Bo0MNtojRxpGc/L3mPHxBBt3coPLn3QSa2evv3t2yygxccTvfYav4hu3WKbj7p1LY20jPoeGMjxkwIC2ADIz2RH0759YmHVHvT7M0Azf7t5k6h/f45ZqsXssq6jDVkfx+vjIVcTPCdP/HyOque+RgBR6dwPaeWch0T0knG8Uhn/tRepR/FjBBCVUA/pqzf30LzO3nbFUIuLjqWz6y/S1/186N1K+6hyrpsJXqROCKdyjndM2/E0sYkPRQRFJNkXI0dAIqJRo9iskIgvuXLlzLL7mTP8P/H0ZNOkwoUto12EhrLDX1gYb8+axeZL9eub6xjZDRqRrHxkEOg1IH9lWozxFF+jhuVEQH+Ne3tzp+rVI/rqKy5LwcTCHobX3EcA0bbZRxPK7Dn/Gg8emB0piYiefbaCQhyTmFQFB1P0k2d03aU+/V5qPAWVMvX/6FGe2eTJQ5QrF8+CWrTgUCb69rdvW263acMH1trnz89B+UJDuf38+bwPTdgaOZIFvGrV+FwHB/MkdedOy3pamRGvv25+XixenCZx7HISIqAJWR9rYWXAALPmKqmy5AQ0/TUzbZplgC57jx0UxDPPIUNYLWFdT99+0CCiffv4e8eOLBxVqkSUNy8LbnoBT99u61aiLVss+3HsGD+stTgNOoxeMtYv9KgoDuvQogXXiY62LOvenZV0N2/y0LQ4ZYsX88R51ix+ORUrZtbUJIrj9Xk8fTvQh5wQTkAcKcTRjLbetHhxfNrF8UoBB1edpQ6FT5kEtQdUACG067PjRGQO8bFt9hHyXuhHn3jspm5uR6kwAhMEsuIOj+jN0kdo0eu+dPi7c7TzUz8qqh7Thy28TeeAqG7ey+S/1oZ2iBIb+W/ezJeMFqyfiM/ZlCmW7TZvZnvzFSs4oUDVquYwZnqF6vHjfOlNncoCnRbKIzCQ3+3t2rEwEh+fevLRpNpbaQi+tzkReGGSmVjYS/jTcGrgdJGKqKd0+zBPcOw5/xoDB5rt9G0q3K36ungx0fwpXPZOxwAKCUmmk9ZjtXfs2vOjSROeBEZEsEC3YQNR5co8udPK/v47cT39ZFHPnDms+iXi59nLeLgICYiAJmR99MJKUBBLHnqMyqzbGWGPO11yx9YYONDs1pdUPY3UmInaWCezfsnMmWP8Qv/kE/4+bRrvRiuLiuIVlBkz+HfrFZSPPuIV4Y4dWVOmveS1OF6PLz2l6sUCqWoe1iY5IIYAosnNfYgo7eJ4pQbx8UR/L/SnpvkvEEDkiBh6pchRckY4Vc99lXIhOkEgq+N0hYbX2k8/jThIV7xvU3yceVnIOiiu9+KTVBDB5IqnlBtR9GlXH4qNStpbtXdvFg5q1GCBSMseYL2UHGMV1mviRNsrT4sXm5MAHD5MiZaXbWmQ9NoiTUYYPNisVVqxwjwBaNDAMhxX33IHqXpus7tpZgrFdWnnDSqAEGpV4AxFh0Vb/Gbr/BOxI+XIkebHgy2FuzWvvUZ0/jx/nz+fFYdpgtaRrVt5EligAFG/fnwT21smqarSnKQENHESELIemzezEWxyZRp6Q3+Nc+fY1a1OHY4lVrYsu+1NnMjeSzdumINHXbtm+zijRnG9Vq3Y+0wzrE2qPxqpkTS5alV25cub16LY2pMvVy5g61ageXM2To+NZZvgCxfY9vjCBaBaNXPZihXA/fvsN+Huzsb4I0awMX5gIJA/P1CiBHtmnjvHuaJ/XxOPLqXPoUOzMBSvURiXH7vCJVcERtY9gDyIwcx2vvjRry58lvgnm2w8I1EK6DK5IY6F1MQf04/DVQVjZ2BzxCAXShV4jintjmDbJ/4IvBmCcxFV8c2Fthi8qjWqepSDclAJ+7F2UPCY0AibFl/H2Pan8UbZE5j+tzvaFz2Pa963DPuhGflfvpw4L3mzZuw4fOwYhxLbvt3c7vp1wNsbuPHTXkMv0h1f30jSyN/I+QPgeG+avbqrK8d6Cwkx+6aMGmV2mmjXjkN6aTx+7oSiTs8BZL5QXNW7VsR3487h8PN6mN7hYEJ5Uuc/Ojpx/ngjx1Qj0ilXPP8jAH4+Xb/O3j2//85OGPaWNW3KDww9FSoAu3ax09Pu3VxPSBtsSW5Z8SMatGyMflravz+v8egxKiPiWD3auoO2TKjPz3PsGKuK2rSxXCbUR+MvVswcPMr6OCtWsFFv27Z8DC0olHW9DJqJavZhRjkeg4KI3nmHtVfvvMPZe4zKjNDngvRec5+alLpLFRxvJxjbj6m/l06uvWSoRdK27Uk2ntFo/R1dbx8V1WU0SCnxcfH066gDVAjBlB+htGrAXgvtm97I3ygvua2UUJGRvETp52eswSuqHtOo1+/YvbysOX9Ya4uio421SkRsCvn225Zl9ZwuUa+SfD+lMIxZmjG6ri8BRH9+dCTZ82+UP14jOQ2amHAJeiBLnEKOxWjdwTo/z3vvsWq/YUNzgMwGDcxrO2PGJH4LaaT0bZOGSZP1LxmjF/qcOUSnT3PZhg08dOsyj8o3DQ3lu1W7TGO7XqQuRfwIiCMgnrq4Haffxx2miGDzwV42WXlmICnhMrW4feQedXI9QQBRj+JHKeD0w0SOgEZ5yW2lhOrf3xw79PHFJzS1hTflRQQ1zXeeiqhA8l580u7lZU24j4ri5eygIPMt8913LKgEBLDT35dfmttNm5Z42a6UQwC9V30vEaVpfOQUEfkskho7X6DCCKTWjSOSPP9G+eM1khPQxIRL0CMCmiBoT80nT/iNFh1tLvP2ZlWRFmrj9OlMEY0/JVi/5I1e6B98wAHIidhmafr0xGUDOgVYCCWr3vElJ4STE8IIIKqY6za9UfMfmjzymUEvsjbpJVzGxcTR0rf4vLqpJzS887VE0VWs85KfPcvOjnXr8v+NiGj7dqK8eeKocpEgKugYmpCTNDeiTDZzcTSg4gE6vf4ytW7Nitvq1S0dlzX0wr2RtshIq0RkHLojPi6eciOKprbk85ZsmI4M5Oqem+SEcHJELLVvG2fz/OtJSoMmJlxCcoiAJgh6bZl1fh69emn8eKL16/m7UfAoazLp28Y60sF//pP4hX71KhuZ58vHvhJa+Dh92ZXTYTS/+z7KhSgqoR4kvPD7lz9AdSqE0tgx8TZf8sKLcWHLVWqS7zwBRIMq76fgW8lrVWMiYsj3C3+a2MSHquW+nuC80ND5H5rZzodW9t9LRdVj+qCRDzkjLMGTtGeJo/Tp6NuGy8vWwr2RtshIq0TE6aKso98E3QwmgGjxaz5ElGphzNKM9ZMOEUA0rqFvmh0jDRXnQhZDBDRB0ISxatUs3zYffWQ7QKZ18Cgj0vBtY+RNZ+39dv06h8No25ZowgTL9kZxm6zR7y8+Lp6u+96iNaMP0Jh6vtTY+QI5mrwvtU+3osco8HoQEdnOBSm8PNFh0TSrvQ85IoYKI4gWv+5j8bv34pM0x8Ob1n1wkAZUPECuikN85EEkvVr0GC3v60u3Dt1NqGu9ROumntKgyvsS2nUucpy8F5+0sH+zFu71AWu12ygkxFirNG2aZfy1mzeJJg3jY/08Yj8RpWoYszSjjctpAog2TDaH3ckqS/NC1kIENEEwMgzRL3FaB8gkStVo/C+DdaiM1asTJ6nW+zLoE2FrcZuSWqb77adIerX5E1rYbQ+Vd35IbupJgiBWACHU0fUEfdTGhz7t6k1u6inNbOeT6jZYgjFHvjtLZRzuEUDUp8whurj9Go2p50u5EZUQssRNPaHBVfbThsmHKeReYm+OpP73IfdC6PMePlTSgbWiLQucoT9nHLUQ1F4W64nF3hXnCCCqWTY0YWIRGMix9PRRbmbNMguFNWqwmagR6ZGre+enfpQL0ZQfoXTN55bd9of2TKqIbE+0WrYkqlgx6fba9ocfWgbJffDAnB/dFpLnPPMhApogpCVJBI7UPzRPnOAo761bm73url3j5aQGDdgzkoi1EWXKmF9Wjx6xN12XLon9EYoU4Zfcxx+bfRn0HnYfD7lGRdVj2rPoBN3af5NmttlDzginGrmvkgNiEwSyEo6PqFWxy7Si317yX3uRYiLZMCY9DOUFY54/fE69Shy20GCWd7hDU5r70IEVp5ONoWYPEUERtKLfXqqYiz1w6ztdpN/HHkzRvq0nFh+8fpUAIr+fziVMLJLKokZknMVNY/Fiotmz+Xu3brY9jVPKb2MOkEIcFVOPyFUF2XXN2zOp2rDB9kRr+XJOCuLjY9z+q6/M21WqsG8TUfLnUyO9zp1gPyKgCUIGYP3QbN2aM7XEx3PSgOvXWYg6cIB/b9OGhbENG3iZSUPzprP2RxgwgGfQ06ez4FehAq/K6j3spk6Jo1cqXbQIrpoHEdShsD/VL3afvhh+lh5eeGLTvyEre2FmF96ttJ8Aov+r65tmx4gOi6afR+6nWnlYmKqa+wb1Ln2IdnxyzKLei/7ve/cmql2alzhv7r+dMLFIKqirURY3PekW6JWIBlQ8kOBgMba+LwXdtF9DbmtSZeT4beQ0btS+Uyfe3rOHv2tZDKzPp62JYe3afO6io1nhX6eOWZNmr3Ytu2rhnj5l4fr8+aQn1UTsGPP665bto6P5GX7vnu1jBAWxWUDr1uzUQ5S0gCaBaoVsQUAAx0wMDc3onphxdATWreMAlgAHeC1XjgOhurlxkE83N+DMGQ5WGRXFcW6PHAG++w5o3BgYPx4YOxb44QegQAFzoNDnzzl+7rx5QLduQHAw1y9QgAPADu4biU3jfLBmcQB23qiBguAT816N/Xgengu+QQ3h3r8UWgyti+K13PD8ORAfn3gMU7a7JwRa1fCY0AhTtrun4ZkTNHyW+OOvmzUxs50v1p2vkyjwbGqRO19uvPt1W5wLq4QNk4+gUO5wbLjfCt1nNMaYensR9igMPkv84TmpHJp1tiMaK8yBXvM5RAIAilYvkhCYNamgrkuX8jVvi/QK9OqzxB87b9XApKa+cEIUlp1pi+qVYvDjsAOIjzW4WXRoYy9XLnFfjfrfpw8wZw6wZQsHBi5QwLh9cDBQvDgHyR09mgPmApbnMygIGDyYjwPwufzxR46JffcuBzb+6iuOcT1jBrB+PT83v/qKY2cfPGguM8LeehmFPi759etAp05Aw4Z8zgDg3j2OS+7uzp/Hj/mc9ewJ7N0LtGgBPHvGdfXnbsMGjl/+9ttA69b83NazcCH/H0uXtt23WbOAoUOBffu4PlHSYxEBTUg7Vq403wUNGwIjR3L56NH8JAIsI/ZPnGi4m4Qbbtgw3CnbCt9X+gTu7kDNmsD8+Rzpu29ffmB06GB+aAEc5fzUKdtdjInhOm3asBBk89gAZs82D0c7ttHNrjF1Kt+IGm3aAMuWAb/9Bty8CdSvz5HJZ80CPD2Bjh054n+3bhwE/OBB4KefOCJ7hQqJEw/kzcsP74YN+cHdsCEQdPUpbvx9GQP7xWCUlwdy5yK0LHsHDioeM9v5YtPlWjiw8iyA1ElkIKQdmkDktegO5u5zh9eiO/CcVC7NhDQAcMjlgLcWtoRfaC3s/PQE6jpdwfJzHeBWwhE9JtbEf9+/lEhgNyIw0DyxiI+OQ15EIn+xfDYnAhrBwcCjR0CVKrbrWE9Uktrfy6I/95/7uWP74osohFAUzx2EoT+0RRvXCzix5h/DtvqxG/XVqGzGDL7vv/uOBYAPPzRunycPsGoVP0JtkdTE0NkZePKEny+1avGx27cHjh/nMk9PbqOVGWFvvZcluWeukdCl8corwFtvmYXTZcuAuXP5HbBzJ2dH6dWLn52DBvFYihVjYWvJEs4W8a9/mfdnPaneuBFwcAAePAAiI81ZMK5cAf77X373JHU+9u1jIc7REahRg98DSSECmmAfmlAVFMQpjJo2NQtcRmWAce6XHj2AtWtZIgD4STRzJrB/P0/vtPQkMO968GCgxT3OD1Pu7mEM87gO32+voG5dvsnOnOFZzuzZQOXKLPMBnLKmShW+kW2R1GzQeiY6Z455ONqxjx4FPvrIXF6sGNfdv59vYi0NDsAP1po1+aHx4Yd8s58+bX4hBQRwBpXWrQEXFxbOIiKAL7/kBxQR8MsvnIbHy4v3FREBfP450L5xCHZ9fRXlq+XB9ivVkT9vLOpXCUPekq64dDc/vpz+APm6W77k33jDcn89eth/OQhpj1GqKK9Fd+C3+1maH1s5KHSd1gSnI2piSNX9iIITIpEHg1a2Qs8Sftgx7wTi44yn/9HRLGTMn88Ti3wIh7OKBJRKdiKQXhnSksPo3P+x+Abe7XgXq4fvx43w4mg2sAZG1d2PwGtBCe2sx27UV1v9b9iQX9iHDtlu36ABsGcPsHw537cPH3KaNT3W2kn9xJCIhY6wMODOHT52Upo9I5Krl5yABQD//MOCkp6YGE4p16+f7Wdur14sFD56xPvaudM8KV6zhp//27ebhVPrFYo1a1g4K1yYVycmTeJ6HTrwsU+d4vOsnT/rSfWNG/xOyJuX051p/5u5c4HJk4EBA3jM/jbmULlysdCd3DlOwNbaZ1b8iA1aGqG5BBJxGHotkmn//hyJ0ahMj5b7Zd06ooIF2fCqY0e2jk0mYr9mW7G+jKXhxvWZP1jYqcTEcCanjh058OPTp0QlSnD8r6RsVJKyZ7FlJ6O3kZk8mahxY7Yz05IQWKfB0be/fZvtz+Lj2RalalWiW7fYGLhqVbaBsBX1g8jSH2H1aqJJ7z6gf1XyIQfEkkIsvVP5EJ3acDWhfnI2ZEn4NwhCglPIzHY+VMQUoqOEw0MCiKrlvkFL++yj4DuWlubWYTrqu1wjZxVh6OhsfW9lkgxpyRJ8M4g+aMjhUNzUE1r17j6KjY5LNPaffkrs5G3L8XvWLHYA0Nq3aMGhTPR1b9+23G7TxrJf+vPZuDGfu9hYDkzdqhXHr6tdm50LGjTg37R0U1oKqgcP+Hd9xKBwzpgmAAAgAElEQVSePYn8/fm7Vu/sWY5apNW7cIE9WG05K/Tuzc/apk2JXF3ZaV7PJ5/wMzipZ+7YsURvvUW0bBnbcTVtys9b6+e91v74cc7WMH060ZQpPI4ffmDniHnz2IZXy5wSH080ejSPr107LtOfu19+sbQDrl/fbLdbpw6HHSLi63/pUoOLhiy9lseO5SwSECcB4aWxljZ+/ZVo6lS2dmzblu9mozI9Wu6Xjh35Sg8IYB/yd96xO2L/1pKWFvJrG86nq2Y5hIKC+EYcMoSjmc+YwfJeQADRv/7FuSeN6NjR/IBctYoSchTqsX5YDBhACcc2SkJgnQanalVz20GDWN4l4pv9yy/5YejszDd8bKxl1I9etS+T9+KTFhE+vBedoNG1vKmb2xECiBwRTa55w+j0LqvzLggpwJYH7855x2jNqP3UMv+ZhJAso+vtowvbbxjup3n+s9TR9WSqTgQyS6DXM+svUfuC/gQQNc1/no7+dCFRHaNJ0ItMjKzr2tvW1sTw3j2eL69ezb9p6abmzCH68UcWsIoUMaeg+vVXS6cNLbNEly4sFB08yM/DHj1YYExOwFq6lCefhQqZM05cvkzk5ka0YAEL5baeuQ0a8PNz0CAWAkeM4H1YP+/r1uV2ffqYjzF2LLd/+JC3V63i0CZaXHKNGTOIatUyPnf6uOR16pjjkvfqZZ7oDx1qOzPgkCFm/UX79qy7EAFNeHmspY3//IenuXPmcJbl6Gie0lqXaehzv9SqZQ4//u23fIUT2RWx/39lzHfG85830PdVjSP2DxzIiQJ69CD65x8uW7OGqHRpy3pnzxJ17syH3bmTPXUqVmSZkcgy1EWhQuxdScSCYJcu5v1ERprjErVuzTe7rTQ41tiThED/koyLiqF57n8neGQWUU9pSvtD9O3SMNGACamOPR68fj+epcGV91JeRBBA1MntJG2a4Uex0XEJ7SvlukUDK+43bJ8diI+Lp99G76fSDvcJIBpWYz/NbOedIu/n1PCe1gs5+okhkbEW8uZNnhiOHElUoACX7d7Nix76lYibN4lKlWKhRav38CE/C7VjJiVgaXPwUqXMGUgGDiT67DN+7nbvzmnGNPTP3CZNzELXtGksaO7cafm8376dqGxZc/1bt4giIlh4bNmS+33/Pk94y5blFYrPPjMLrGPGWGr39OdOH5e8QgWz9vD8eU6h17w5Ud++5hWdLVssz8OxYzwRHz6c+0yUCQQ0AIUA/AXgbwAbAeQB8D2AwwBm6OrZVWbrIwKaDR48YF1uTAxRuXJm/fuZM0R//GHebtGCqGtXy7Z6aWPUKCIXF06XRMS68VWreFrw7JllmYY+90u7dkSTJvH3sWNZoiGyK2L/vBrmO8O/1yzaPtCsf3//faK9nIeZevbkG27cOF4RDQxkDZZ2wxLxzd2lCw95zhx+KN2+TfTuuzzzun7dMtSF/mHz00+8TKBRpw4/JMLCeGlixw7LNDh961+g3u0fWoxFe9AaJSGIj4unZ7eC6MKmS7Rr3lH66V/eNKyKNzkhnIrhEQFExR0e0dJ+h+j5kwib50sQ0pNHZx/Qp512U1lTcN0Kue7QiNr7yU09JSeE0QeNfLN9DL2Qu89ocpM9pgC3IVQAobRrwXEievH4gekRf9BIC6mVaUunRisRT57wo3vNGttLrPpnprWApVG+vKU2Sr9EqF910D9zmzc3C12jRrGw8/ff5uc9EceTrFKFv2/dyisUBQoQ9evHMeBmz+ZnfuHCvDBExO+Jzp35FTVqFL8j0iou+ZUrnIFFyzCYGQS00QC6mL6vBDAIwE+m7R8AVAPwlj1lSR1HBDQbDBzIV+SJE7wQb4uFCy3ztBCZpY3jx1kD9sYbrDLasYND13/zDZcdOMBTKa1MQ5/75euv+epu147VU1rUfjsi9ndrY74z7hasSf6+5jvj+nV+ULRtaw72eu8eB2Js3pyXHtu2NduzfP89Rynv0IEPlSePeSbZowevpOpty8qXN/fD2kbmzTdZ+KtXjx9gmn2DlgandoXn5Iqn9NtHZ+mTT+Jp7WQ/KqyC6D+d9tGCt45QsXyhVLPQPcrnEEFVct+g/Ai1CEyqfbQcim+UPkrRkXHJ/MMFIWOICYuiDR/sI/eCx015WyMJIPIofCJbC2d6Lmy+TJ0KHzeZH8RQz+JHqQBCaUxdH1rw6h6a22E3TW+xiyY02EWja+ymYZX20IAy3tS72F7qUfgAdS5wmNo6+VF1h8vkiBgqq+5QXkTQoHLetHrQbtr/xXG653eP4mJtZ31IqQZOE7CsNVPjxxunM7ZuZ2tSq7fBKlPGvIxqvUSoLa4QWT5zhwzhfVWqROToyO1iY83P+9atWdAKCXl5+8UFCxLbLXt7czlR6tvtZriAZnFAYL1Jk9bdtN0PwBAAX9pTltS+s6WAZpQ7xFoL9uQJSwQdOrAaSL/EuGcP66w7dGBBq1gxzoRdsyZr1DTCw/nKtkaTNipX5rvC15f/5s7N9UNDiY4e5as+f35zWVpMP1JwZ2gPjCdPWBUdHW0u69+fb/xvv2UNWny8sW2ZEdbBY7Uhx8URnTv0jL7/4Az1LH3ClNMyLpHglRuRVEw9pqb5ztPbZQ/SB4186fOevvTbvw+R7/JzdGXffdo+70SCoXZOeckJWZ8za8/RyOre5IwwAohmtvPJ6C6lG/Fx8fS/cfupIIINJ1y5EE0FVCgVdXhCZXIFUJU8t6lOvmvU2OUytS5ygToWP0vdy56mGnlvEEBUEM9IWT0/nBBOtfJeox6lTtDY5ofpvwP9aPOiy3T2cChtn38qRRo47dlorZn64gvjdMbW7fQCmrWApdlgFSpkzhaRkiVCa5ITsJKzX/T2JipalP9q7wJtOy3INAIagFYA9piWLRuYyroCmGpvmcE+RwA4DuB4eb2qIzNz/z67htiTZ8M6d8icOYm1YJMnm63bp0xhS08iFubc3VnH3KEDL6C3acNXXf36vC+NVatY/WOLuXPNlo+XLrHQ9zK8hJCVmvYYRrM/a08dIrP6mYiobcXb9J/BlhnBteNrdmQPH8TT1PcDqUPNAOpU5gIVdAhJeJAWRiBVduAHbQ+3w7T1w33k/6M/PfK/S3GR0ZQUkmpJyMrovUBz2nXLY39CY+qxB+ym6Uco7GkExcbYl+/U+tzt+OwkXdobQH/N96flfffSxMZ76M0SB6hBnvPkgmeJhEBXhyDKhWhqVuQquagQWv+fM3b3XXs2GmmmjOoZbaeVgGW9RGiNJlDt2UP0/Dm/blxdecHmr7/4Vfn117y/6dPZc3PAADaPadeO+1e8OJFSrAtJS+GMKJMIaACKmASpCgCWAmhpKn8LwHR7y5I6Rppq0Iwy0WqW5kS2c0JYtz13jl1kypXjtTMtxIRR7ghrXn+dLROdnYmqV2f1TUwM63kvXeI6ixbxNIfI7G5DxHfOggVm46jx4y2t3d3dbXpQEhHRkiVmIfDECb7D0onUEFK0B4et2Z/eU0err4W6qFgynAojMOF4OxacosIqmEa3O0Mtyt8j19xmYUwhlho5nKJR5f6kn97cRP/8eJh2zzv80i8pSbUkZFVy8uQipWN/0fbxEZH0+MBFOrrAh37vt4nmNf4fDSv+J5XHTQuhrWZN9nxcs4bozp3UGas1qSlghYdzXU3A2raN+758OTtVTZ7Mr6I+ffhV3LQp268VLJhYa2n0cXTk13GlSmwG3aEDv04HDSJq1ozrzJyZNudJI8MFNJNTwB6dHdogAJNM3+cAeMfesqSOk2YCmlEmWr2lOZFxokWjtoMGsYE8Efsonzhh9lE2SkyncegQGzvNnMl3lrs7L2du3sz2W0OGsKatVi2iGze4Tbt2ltJIpUq8gB8byw4B2hTmxg2+KpNi7152GCBiTZuRy2Ea4v3ZUSqCJzS6yO9UFI/Je+7+F2pvdGqT8nLSh7r49FOi2f0vUl5EkItDKAHxCTd4GdymQuoZtSv2D1UoEkL3d5+zMGzIyS8pIWeTkycXKR17apw77VkzvbUPFVZBNKLnXerRw1J4qVyZbWd//JFfWdoENTkhK8njWi0RbtvGQtC337KFzMaN/ApZsoRfZ2PGsAare3d+ddasyQKZPQKWkxNRyZLcplUr1vb178+G/m3acJ3u3Vm38Ndf/Bo9f56XVkNDzeO1NYaZM3OABg3AKABBAHxNn8EATgNYAuAfsJdnQXvKkjpOmgloRhFL9ZbmRHyFaPTsaTZMsm772mts0LR1K7ua7NqV2EfZmqdP2XWlVi02oiLiJcZZs8zauhMniIYN448RHTrwdKNcOTa0GjrUrAVbtYq9LzVCQszelhpxcSyE/vvfrL3TBND0ICSEttabSo6m8BLOCKOe2ELzK6ykvSN+pbCjZ23faS/B/ftEv/8cTe+/fo9qFX2osxuJIoCode6j9EeP7+je138S3buX5KptTn5JCYKQMSQ1MYyN5dfFf//LZs1FipgFnrJlWViaMIGFpD17eH979nCcsl9/ZRuynTtZ6Fm+nKMjjR/PQXZfe41fE+XK8RKhUkkLWEqxN2WlSqzD6NiRA9q+9x4LXNYC1uHD7LTw4AGHzrA5/hQIWNY2ZznGBs3iwIArAE8AJV+0zNYnzZ0EkrI0HzaMdbBr1pgtzY3aduzIBvSDBpl9la3r6ImK4jZ//81C2ttvs/D34Ye8vWsX14uLY63YvXu2+59SLZimb752Lfm6qcXTp/Rr5ZnkgFjKhWjqUfUfckIElcv32MLgtlkefxpXbw95TT1Od6+EW+wiudng7dtEv6yOo/feeEzVij5N2K8LnlE3bKfPyn5Fy5r+wMuUrXeLBkwQhEzNi0wM4+LYWmfZMnbCL1HCUoBydk5ek5U/PwtlDRrwq7FPH/aCB/j1tWoVW9vs2sUBAa5d48UlW1kgMlLASon28GXIlAJaWnzSTUCz19LcqK2WJ4OIBSy9ob6RgKbPHeLiwhED69Xj6cygQeZ6P/xgjjFBlPm0YC9DQAAtLTXf5O0YRVvmsVZSmw1unHuGtvz0hKZ186cObmcTvMUAovLOD6lf08v01Zyn9PWbO6hooagElfuaNUQFnGPolYr/UCU3s3FtYQTSa9hMi4ovID/PhRSzYTNRUJAsUwqCkGOIj+dYkt98w3ZZAC8XLlrES6GbN3Ns8fPn+VVmZEuWkwSslCICWmrxopbmRm2bNjULZWXLEv32W+I6tjDKE/GiZIQW7CWIv3mLZhX5igCiOoXv0o4Fpyx+N5oNRodG0rEvD9MX7TeQZ/6tVAZ3EoSvvAinXA6xVNA5KqHMDY/pTWygLwrPJv/XZlLs6l8NNZCyTCkIQk7jZYWsnCZgpZSkBDTFv2cPmjZtSsePH0+7A7i7A76+tssGDwbeew9o1463jx8HTp8Ghg0z1ztwAOjaFXB15Tq3bwOOjon3tW0byxE9e5qP5efH+2/RArh/H9i6NfXHmIqsXAmsW8ffg4OBJk2AXbuAypW57KuvgKtXgaVLeTsyEihUCPjryyv4d9ODWP78Xxja8yFWbSyBXLmA2bOB7duB5s2B5cuTOTgRcOkS7qzZh0N/PMDBC674A2/iHsriVfyFhY3Xoc7QFnDo2hmoWhVQKs3OgyAIQlbCxwfw9AS8vAAPj8TbSbFwIdCsmWU9Hx9+fU2Zkrb9zooopU4QUVPD30RAywDu32dB7ZVXWCJ5Ea5eBU6dAl57DcibN236lwaMHQu8+y6wYQOwYIFxnc8/ByrgFjbNOoHfI9/CpHcfYuHqElAKOHGCb+7du4G5c4E2bYDOne0/vs+W5/B8Ox6jor7AynwT4bU1f7IPGkEQhJyICFnphwhoQoZy7x4wfjwrCJcvB/LnB+rVA1atAnLl4joREUCPds/gdPoY/ortgs8mPMKHi4sn7GPJEsDJCRg9GjhyBPjrL2DOHPuO7+MDeL4ZDS/yhMe4+vBZegaeygteG/OIkCYIgiBkGEkJaA7p3Rkh6xAbC5Qvz4KVuztw9izQsKF5e9curjdqFGu0PDx4KdOa5cu5zr17vJJYpQoQFcXLlRpfT7qC2yefYGdsR3zz6RML4QwAwsKAMmX4e5EiwMOH9o/Db+01Fs42jQPmzoXHpnHwIk/4rb32AmdDEARBENIPEdAEm5w5A/Tvz2Zxvr5A6dJAzZrm7S5duE5sLHDwINf97jvLfcTHswarenVgyxZeqnz1VSAuDrhyhesE/LIbM1eUwm0qh3WrnmH4tKKJ+lKgAGvZAOD5c96vvUypsoGFM01d5uEBj03jMKXKhhc8I4IgCIKQPoiAlgMIDGRt15MntuuEhQF79gB375rLjhxhP4TmzdnP4eBB4NgxoHVr4I03gNBQoHBh4No1FprOnGFBTM/+/ezTcPQoEB0NXLzItmO+vkCDBsC1L7eh+aDqiIQTtq+PQJ8RRQz716QJm+0B7HdRseILnIApUxJbtnp4iDGFIAiCkGkRAS2VsEcIygiCgtgR9NgxlkkeP068bBkTA3TvDhw+zL4H589z22bN2Cj/2DGuc/Mm14uJ4eXKH38ESpYEKlRgj8wHD7iNnp07gfbtWQB84w12FHjlFSBfPqD4wY1oO64xghyKYsz7cejcmx0mQkOByZMt99O2LeDvD4wbB3z2GWvrBEEQBCG7Ik4CyfDsGdCvHy/J5c/PwsGECUBICGuWFi9mIahHD/6sXQt4ewPFihnvb9gw4MIFrjtjRqp21ZC9e9nZs2VLYNIk7ldgoKUn5fnzwI0bLMgtWwbkzg2MHMl2Ypqj6Jdf8pLk+fOsaXvnHV5yfOst1qK9/jpw8iSwaBHw22+J+7FxI3DpEjB1Kh//1YYPcPmOEwrkjcGuQwVQq7FzsmOJiODoI40bm0N1CIIgCEJWRZwEUsCaNSyQ/f03a4tatQJmzuSlu7t3eanuzBn2MvzoI9YOnTxpbv/sGdCtG4c+a9GCl/k2bWJBSLPBOnmSl/3atGGBT4++fa9eLNjlzcu2YJoGDADCw9mA35oOHVg427ePNWEbN7K2q2xZFhZjY4E6dVg48/fn37t25bbvvsvLiXFx3Oc//uAlTKXYGSAujoVTrQ8HDxqHE1vY3RdRJ8/xEiURVvXdgxN3iiK3YzwOnilol3AGAM7OQJ8+IpwJgiAI2R8R0JJh9Gg2hgd4eTA8nDU4AFC8OAtQ1kJQq1bm9noBLzycNViDB7OwodlUjR3Ly4UHDnCcsBs3jNtrx//gAxZStmzhcBVxcRxE0MiDEuCYrevWcSBYV1e2GevaFXj61NKTcssWNr53ceHtWbNYSGtY9jFalb6JAQNYO1i3LuAS8RAlH57CwIFc5uICfP01a8i086YpZ5t1LoSx80oi9HYQPCpcw/TdHaEArProDipUzzqx3ARBEAQhvRABzU4OH2Zt0YwZHH9ryxZgxw6gUyf+XROCXF15iVBDL+A9f87Czbp1QMGC5lARgYFAuXKsfXJz4+VTo/Y3b7Jh/datrLXq25c1YADwzTe2DeeVMkfeb9AAKFWKBbR8+cxaPIAFsoEDge+/5+26dVk7ePa3c5i3sxlKPb+CuXOBc1/5YOrpd6CKF4ebG7BnRwxCrz7E+f9dQL2gfcDGjVjR6FuoBZ8hZvwUFNu7HsNLbcXRs07wvVMVuRCLTR+fw1tzGrzsv0MQBEEQsjW5MroDWYHAQNZybdjABvEHDnDU+8GDOfwDYBaCZs4E/vyThSc9hw+zMFW7NicPiIszh4po04aXPIsUYSGsfv3EfTh8mDVgvXoBH37IAuKvv7IG7PXXOQSGEQsWsEA2aBALiCtWsIF9oULsWTl0KAuMly9z34OD2aZMz8IDrdHs7RVo8sP/wctrKPqFDsba/Mtx2/sKULg2qxEBhMAFZ1Afp9DQ9OmMc6iLKDgBABzB0uTk1ofQc0aHl/lXCIIgCEKOQAS0ZIiOBt5+G5g/n4UzgG29bt8Gfv+dt/VCkJGAowl448ezcNeyJQtLmsZr1SqOFTZrFgtf1nZcWvsmTXhps1Qpc3u9BsyIESN4+fO77zhq/4oVvGz57BlQqRLbvkVHs9DWvj1QuhThp6kXEbrcD3O/KYHPMQXNzhaFJ63FWqyEf1Q5vJX3D2wOehUTam7HvMK/4lRIJfg/KotrT8xpq9xc49CoITC2iSMaNgSiT/+DKYuKY1Tbs1h5oC66LPGHx4RGL/1/EQRBEITsjAhoyfD992zEP28ef0aNYi/MCRN4iRCwFILq1uXlw1u3WICbMMEs4LVowXnU798HHj1ig3+Ac6XXqMHfBwywPL5eQDx8mAWplSvZoP/CBRYKk8LVFdjVhROr/XzHAw8e8LLl7ME3UCP6HPCkFfIcPYoNtY+wSm3HUcArBE4APi9cGPHNW6J0u+4YeeEyXvPZhuKFInDoWWEADlh08TUAnGu8kTswpCELrw0bAqVLOyYImj5L/OG5qBy8Ft2GxwR3eCzxh+ekcvCCCGmCIAiCYISE2UhjVq4Epk9n2y+AtVcuLsAXXwCHDpnrDR4MvPceC3AAcPw4e1BGR5vbR0YC16/z0mh4OMcEmz/fvA93d/YqBcwC4tSpwMKR19Bs7UQ0+XEM2k1tjU75j2LDqSoYWmAdZj83BWt1dER0nUa4UP0N+Bdyx8nI2vC/WRinTimEhXEVBwdCfLxCw6qhGBYwD43me6Le4MYoWDDpc7Cwuy+adS5kIYz5LPGH3+5nmLLd/WVPrSAIgiBkaSRZeiqwkJVQFgHpfXwAP7/0DUh//z4vk77yCtuR2eTpU5bwTp2Cz44oeO4ZAa/4PmiIU/gCH2AZxmJu/fVQlSvCP6YeTt4rjnMXHBEdzc0LFGBNWKNGQOMH2xFbvhKmra6FUaNY6PSa5g+P2F0SjV8QBEEQXhIR0FIBHx9exvTyYiHNejs5UiLgJamB2tqe1WomYUz7RNx9ggCUwgOURIBrHewt2BPf33kFleMv4x9VB/FwABGvQbq5mQSxxua/VasCDg6pM3ZBEARBEBKTlIAmNmh24uG3EF7TuuDVVxuhenXg6lXg7fYBOPPfC7hzpxOKFIHFxzrcRrNra+H56Vvw2pjHLOS8GQ2vvn8A6JfksZt1LgTPSeXwc/AhNGvrhC2LL2P8390wqqgXPnfejYDoIiZhrBMC8gzBAyqBZ8hv3kEQfxTicQ71UU1dRf+Bjmj8ViU0amQO8WELPz9LYczDg7f9/ERAEwRBEIS0QDRo9uLjg7i3+6E8buP+07xwyhOHqGgFSiKUnIuLWVgrooIQe/YCjjm0RM3ajvjnfDya01G4NKmOqAJuiIwgRIbGICosBpFh8YiMJERGKUTFOCIyLjdikNvmcfLliUGp4nEoVT43SpZ2RKlS7OlZsiT/LXX3GK5OWIH3Hb7BqH/nwcovo+FFnvDYNE4kLEEQBEHIIESDlhp4eGDf9B2InhiCmWW3YuXdntjS5Qc0bp4bgdEFEBSdH4HRBRAYmQ+BUfkQGOGMwHBnBEY4ITDMCYFheRDkWgOOjyNw6lQBuCIYgflLIfz8EzjF3EDe6BAUogg4IRJ5EQUnRMIpL5DXLS+cCjvBqUh+7LtUHN5BjfFW5VP493f1UaqMA0qWBFxcckMp2wKcz8jreN/hmwTtnYdHHni+6QWvtX+IfCYIgiAImZAsIaAppb4HUBvANiL6JCP64OMDeM5vBC/HLvC4uxsecIfnLi947fKEB3zt2wfc4QkvTMASrMQofOU8BR7V73GANYtPLaB8eXMUXLDN2bJJ5TCznS9WHqiLMf6nUd3DvhAVflX6wWuj1RLlxjzw8+sHkc8EQRAEIfOR6QU0pdRbAByJqJVS6gelVDUiSiY8a+rj52fyXJx/Chg1Ex4rV8Jr6h34Re2Cx7goThMQGwvExBh+9zmUl2N/kSc8hlaCx+rh8IzxgtcneZLVYvloccMW3XmpOGJGTgisSXvJkyEIgiAIQpqS6QU0AO4AvEzf/wbQFkCCgKaUGgFgBACUL18+zToxpZmV66KHBzw8X4GHlxeQP3lJx2/ZNXg59IfHpgnc9k0feL3hCb+1i+HhUSXptrufwWsREoQxjwmN4AX24vSYkCrDEwRBEAQhE5HpnQRMy5tfEtFppVRXAI2J6DOjumnqJJDSQGiZJZCaIAiCIAiZgiwdB00ptRTA70R0xLTcWZOIPjWqmxkzCQiCIAiCIBiRlIBmO0ZE5uEEeFkTABoAuJlxXREEQRAEQUh7soIN2iYA+5VSpQF0A9Ayg/sjCIIgCIKQpmR6DRoRhYAdBY4A8CCiZxnbI0EQBEEQhLQlK2jQQERBMHtyCoIgCIIgZGsyvQZNEARBEAQhpyECmiAIgiAIQiZDBDRBEARBEIRMRqaPg/YiKKUeA7iVDocqCuBJOhwnM5KTxw5k7fFn5b6nBjl5/DL2nEtOHn9WGHsFIipm9EO2EtDSC6XUcVuB5bI7OXnsQNYef1bue2qQk8cvY8+ZYwdy9viz+thliVMQBEEQBCGTIQKaIAiCIAhCJkMEtJfjm4zuQAaSk8cOZO3xZ+W+pwY5efwy9pxLTh5/lh672KAJgiAIgiBkMkSDJgiCIAiCkMkQAU0QBEEQXgClVCmlVGellEtG90XIvmQ7AU0pVUgp9ZdS6m+l1EalVB6l1PdKqcNKqRm26pjKLeolcYxE9ZRSJZRS+5NpV14p5auU8lZKfaOUUqbyWkqpzSkffdYbv1KqjFLqrqncVyllGA8mm469sVJqt1LqoFJqYkb039b+UnPs9pDVxq6UyqWUuq27buvloLFXUkptU0rtV0otftlxZ6HxW1zjSqnqANYBaANgb1Jts+HY5+iu+YtKqWkvO/bMPv4kjpsqzzx7yHYCGoABAJYQUVcADwD0A+BIRK0AVFZKVTOo86pS6i2DeokwqqeUcgWwGkD+ZPo2EsAoIuoIoByAekqpKgA+B1AohePWyFLjB9ACwDwicjd9HuegsTea6bUAACAASURBVH8FYAiAtgB6A/h3evffaH9pMHZ7SPf/XUrGDqA+gN911+3ZHDT2BQA+JqJ2AMoqpdxTMPbMPn6ja7w+gCFENAfAdQCVcsrYiWi2ds0DOAfg5xSMPVOP38ZxU/OZlyy50uMg6QkRrdBtFgMwEMAXpu2/AbQ1qPMIwDsAvPT1AFwxOIS7Qb0NAPoCSFILRkQf6TbdwBGOY8Ev551JtbWXLDj+gQA6KaWGA9hBRNOT2kcy+89qYy9CRHcAQCn1FMCfRHQ6PftvY39GJGoLO8duDxnxv0vh2J0B9FRKeQA4C2AkEcXaHqFtsuDYqwM4aSp7hBROLjP5+ONgdY0T0XrFGtQeAFwBXE1qfEmR1cauoZRqBuAuEd2z0dYuMvP4bdSzeU7SgmwnoGkopVqBb56bALSLKBBAY+s6RHTEJCBY1FNKrQJQQ7dbb7DkbFGPiEJM+9MffzMsH1y/EdE3pt/6AjhPRPd19VMy3ERklfErpf4C8DGAcAC7lVL1iehMDhn7QaXUGNO+KgI4k979t7G/lx57SskqYwewB0BnIgpQSv0MoDuAP1Mw9Kw09vUAZiuljoC1Dyla5rLuCzLR+IlorqmedXcLAPAEpxZMcSiELDZ2ABgHYPaLj9SYTD7+hHq6tikbsJ1kSwFNKVUEvHzUG8AE8GwX4JvKwaAOADy3rkdEIw32vdRof9YQUS8bfasMYBKAzi80qBcgi43/EBFFmX7zB1ANJkHlZchiYx8JwAPAXAALiIgyov/W+0vJ2FNCFhv7Ge26BXAcfN2+NFlp7ET0iVKqLYDJAFYT0fOXG7XFcTLl+G1BRMEABiulfgHQDMBRe9sa9C9LjV0pVRhAcSK6Zm+bZPaXacdvcNx0JdvZoCk25PsfgGlEdAvACbD6EwAaALhpUAdG9Wwcwt56Rn1zBfA7gKFE9Mzedi9CFhz/TsUeUfkAdAXbNbwUWW3sRBQH4JKpypqM6L+N/dnVNrkxvwhZcOy/KKUaKKUcAbwB4LSNtsmSBccOAKcAlAewxI4hJkkmH79Rf1cqpdqbNgsDCH6R9lb7ylJjN9ELwPaXaJeIzDz+VDhPKYeIstUHwCgAQQB8TZ/B4IfnEgD/gJeerOv0BVDQup6N/dusB8A3mb4tABCgO24He9tm1/GDNUgXwVqzMTlp7Kby1QDaZVT/jfaX2mPPrP+7lIwdQF3wNXsW7OSSY8ZuKp8D4N2s+syyd/xG1zjYKeAAgP0AZuaksZu2fwObOGTr/31S9azPSVp9ckQmAZP2oguAfUT0IL3qZRZy8viz+tgzU/9l7DL29LrfM9P405ucPHZAxq8nRwhogiAIgiAIWYlsZ4MmCIIgCIKQ1REBTRAEQRAEIZMhApogCMILopSSZ6cgCGmKPGQEQRDsRClVXSmVF+x9KwiCkGZky0C1giAIL4riJNgNAYQCKA3gAwD9iOi8rlpTAK0AFFZK9QSQF/wcfYWIhqZzlwVByMaIBk0QBIGJA+BCRH8R0ffgOGdPtR+VUm4A6pjKDhLRVnA8qHUAIjOiw4IgZF9EQBMEQWDuAyiklKqmlKoG1qQ91H4koqcAfAD0BwtzABCvlGoCc74/QRCEVEEENEEQBCYOQCMATQDEAIgHYJ0V2QGchDnWtO0MIBypkDBbEARBj9igCYIgMAUBHCGitQCglALYxizC5BhQAmyj9gxAOaWUB1hAqwJ5lgqCkMqIBk0QBIEpD6CKUuodpdRQAPUBOJp+KwWgB4D24Lx8oQAOAnhgskVzSf/uCoKQnZFUT4IgCACUUs7gpMsPTNvfE9Ew3e/uAMKIyE+X3+8MgEAAXxFR3wzotiAI2RRRywuCIAAgoggAEbqiEVa/++o2C4CFtYtKqToA8qd9DwVByEmIBk0QBOEFUUo5mwQ6bduBiOIzsk+CIGQvREATBEEQBEHIZIiTgCAIgiAIQiZDBDRBEARBEIRMhghogiBkapRSeZRSU5VSBW38XtAUp0xf9o51WWZCKVUho/sgCELmRgQ0QRAyNUQUDSAAwECl1GilVD2rKnUAfGFV1h9AXaVUcaN9KqWGKKU6mb6XVUqNTa4fSqkCSilnpVQVpdRMpdSHSqmX9YTfpZRqmMzxOiul2iqlXldKvaeU+rdSao5S6qBSardSyjGp9kIORqkSUGq/6fscKOVr+lyEUtOgVG4otQVKHQTH/AOUqgyl9kCpU1BqZkZ2X2BEQBMEIVOilJqhlNqrlDoEYAA4kOx9ALesqp6CKRemUqqQUmoGgGLgqP+2tGiPwJkDQER3AbRVSjU1hcyw7sc2pVRvAH0BrDDt+yKAD8DhNl50XM3BAmeRZKq+ByAPgAMAvgewC8BWAD0BVCaiuCTaCjkVjtG3GlroF6LZIHIHkTuAcwB+BjAWwAkQtQHQB0q5ABgDYBaIGgJ4BUoVy4juC2ZEQBMEIVOhlGqilOoOIArARABvAvgQgBs4FVOIrm4eU7iLCkqpYUT0DMAFANEAcgO4r5TKp6tf0LQdBSBhP+Ck6BcBvGPQpXcBRIKFo+tEdAQs4M0louAXHJsCMB0s7OVWSk0xlRlxwzSWRuAk7cMBPCeiINNvgmBEHPj6CrEoVaoZgLsgugfAHYCX6Zd9AJoCeAqgPpQqAZ7YvNC1LaQ+IqAJgpDZOA2gAVjAigcwGkAlAIXBgpSed5VS+cGCzFGlVBOwZuwBgKIAvgLwX6VUYVN9RwBrTd/1GigFoDY4jZMFRBQI4DIRPQRQybQc+g6AQy8xtmkAVhDRAyLaCU60vkspVdWgbhSAOCLaA2A3+AWqaeyevcSxhZwAUQh4omLNOPD9ALB27Z7peyA4z+wOAC0B/BuAN4DYNO6pkAwioAmCkKkgolgimg/WmD0CkA/AJgB/AfhCKeWpq/42gBjwUqAL2B4tDMBPAMoC+ISIRmqaLpP2qb+prVJKDVNKTQPQGEBFAOet+6OUagygmmnzLPi5GUdEp63qbVZKPbD6fKr7fSJY81VGKeWllPoGrL3YCmCLUmqhslxWUgDiTEui9cHCaW2Txk2WNwX74QlKcRBdM5U8B+Bs+l4AfE1PBfAvEH1k+q1LuvdTsEAENEEQMhVKqUpKqdkAWoBfFJcBjAcwGIA/EXnpqi8EC3CKiA4D+BW8XHMWvERj5PlZCkAvsJD1PYBtAG4CWE9E9636UsV0jB1KKQdwsvQfwMuhFhBRLyIqafWZbtpPGwDbieh3IvoRLHwtBnCfiL4golpENIWIHut26QQgmoiOAfgbrN3LDaAKJE2f8GL0ArBdt30CQFvT9wbg678SgHJQygk8YZEo9hmMCGiCIGQaTEuRnwH4EcA/RHQFQBDYQP6J6W8CROQNoDjYRgxgga4CeAknAGYtgWZ/thTAIFgu4QwE8DmA2QZd+g+APaY0TtMBfGna53PdflskNy4iOkhE/yilyiilPgFQA2yonZQnZyEA1ZRSS0z1BoK1hGUhuT+FF+MVsLZWYzWAOeD7oTaAo+Dr3xfAYwB3wPeIkIFIqidBEDIdSqm3AUQS0RbT9hIANYioh0FdTwB5iegXpVRtAJMA7AVrqe4R0S5d3WZE5KeUGgzgCtj2JpSIdiul3gPgAeDfRPTUVL8UePm0BYBnRLRTscfbEgDvgzVavwPwJKKYFxjfj0Q0JJk624mou+m7o6mvhcHC4XYiqmvv8QQhEUqVBmvRdtqwWRMyGFGTC4KQqVBKFQXQnIgmK6XygA3y4wEcUUqtBjDFZLCvUR4cPgDg5c11YG1Bb7CjQAJE5Gf6WgbACSI6pPvtO8UvrUVKqaVEdIqIAkwC2S6T/RqIKFQpdQDARrD9zlkksxxkCprbAazdqwK2JfsOvDxbFqwtHGnVLLfJISG/af+BYE1hLgClkzqeICQLL+d7JVtPyDBEgyYIQqZCKdUVvKwYp5RqDeAWcWgAKKVGAJgDYAuAeUR0yyRUhRHRM6VUI7BmLA6sRZtIRPsNjtEewFEiikqnYWl2aM8BXLTnuEqp0tY2cbrf5hCR0ZKsIAjZBBHQBEHIliilChDR8+RrCoIgZD5EQBMEQRAEQchkiBenIAiCIAhCJkMENEEQBEEQhEyGCGiCIAiCIAiZjGwVZqNo0aJUsWLFjO6GIAiCIGQYMTFFcP36AtSoMRz3749AaGgTU7kb3Ny2omTJX3Dt2ueIjS2EokU3o2jRPw3rlSr1UwaOImdw4sSJJ0RUzOi3bOUk0LRpUzp+/HhGd0MQBEEQMoSgIKB/f+DRI+DkScvf+vQBli4F1q0DQkKA//wH6N6dt11cEtcrUyZdu54jUUqdIKKmRr/JEqcgCIIgZBMcHVngKmiVhdbPDyhbloUuX1/A05PL27cH9HoNfT0hY0k3AU0pVUIptd/0fY5Sytf0uaiUmmbKUXdXV17MVPd7pdRhpdSM9OqrIAiCIGRFChYEChVKXL50KTB2LH8PCzMLYEWKAA8fGtcTMpZ0EdCUUq7g5Kz5AYCIZhOROxG5g1O0/AzOdTdPKyeix0qptwA4ElErAJWVUtXSo7+CIAiCkF0IDuYlzypVeLtAASAigr8/fw7ExxvXEzKW9HISiAPQF8BmfaFSqhmAu0R0TynVEkAnpdRwADuIaDoAd5hzhf0NTux65UUOHBMTg7t37yIyMjKFQxCyCk5OTihbtixy586d0V0RBEHIcDZvZlszjSZNgAMH2Nbs9GmgZUvjekLGki4CGhGFAIBSyvqncQC0fHJ/AfgYQDiA3Uqp+mCN2z3T74EAGlvvwJSbbwQAlC9fPtGx7969CxcXF1SsWNHo+EI2g4jw9OlT3L17F5UqVcro7giCIGQ4O3cCkyaZtwcPZkFs/37gwgWgRQvjekLGkmFOAkqpwgCKE9E1U9EhIgolojgA/gCqgRMLO5t+LwCD/hLRN0TUlIiaFiuW2FM1MjISbm5uIpzlEJRScHNzE42pIAg5Gl9f8/fffgMa69QbFSoAu3YBbdoAu3ezY4FRPSFjyUgvzl4Atuu2dyqlSiml8gHoCrZNOwFe1gSABgBuvsyBRDjLWcj/WxCEnMzC7r7wWeJvUeazxB8Lu/smbJcuzZ6cRg4FQuYgIwW0VwDs023PAeAD4AiAr4noEoBNAN5VSi0B4AlgW7r3UhAEQRCyEM06F4LnpHIJQprPEn94TiqHZp1FGstKpKuAZvLa1L6/Q0Qndds+RFSTiOoT0TJTWQjYUeAIAA8iepae/U0Lvv76a5w5cyZh++jRo9CCBcfHx+PIkSMAgOfPnyM8PBzx8fHo06cPIjSXGwPi4uIwfPjwJI/77bff2tW/h3p/axssW7Ys4XtoaKhd+xUEQRDSB48JjeC16A76TKyAGU3/guekcvBadAceExpldNeEFyDTB6oloiAi8iKiB2l+sIULAR8fyzIfHy5PBY4cOQIHBwfs27cPERERWLt2LXbt2oWQkBAAgIODAxYvXgyAl+lWrVqFU6dOYdasWXjy5InFvv744w8cPnwYALBt2zZ07drV5nF9fX1x+fJlfPrpp8naZs2aNQubNm2y+bu/vz9CQ0OxbNkyBAcHY9y4cUkKj4IgCEL6U69TcYQiP+ad6Ib325wT4SwLkukFtHSlWTNelNeENB8f3m7WLFV2HxYWhg4dOsDV1RVff/01atSogRkzZqCQzgigVq1aCAgIwP+zd+dhVVXrA8e/m3kQxRkVZ83ZRFHUVKCc0LQsh8pr/Zo0LetG3gYrTZvUzCbHsrxWVqJpw9WcEsQRQXDMGUWcEAWUUab1+2NxmFGQw6C+n+fh4Zy11957naM9vq291vv6+fnRuHFjVq5cybZt2+jXr1+e4Gro0KHUq1ePxMREwsPDGTFiBGvXrmXlypV57rl9+3YCAgJwd3dnxIgRvPrqq6xZU/ST4tOnTzN48OAijyckJBAbG0uVKlVwdHSkXr162NnZkZCQUIpvRgghhDm99ehR0rAF4IvtXQqsSROV3x1VLP2m/v1v2Lv3xn3q14cBA6BePbhwAdq0gWnT9E9hOnWCzz+/4SUvX77Mtm3bOH/+PCtWrGDAgAE4ODiwb98+li1bRsOGDRkzZgxBQUFs3boVLy8vIiMjqVWrFgkJCTg4ODBq1Cjs7OwA+Pbbb/Hx8aFRo0a4ubnRq1cv5s+fj6urK0uXLmX48OEAbNiwgW3bttG0aVNq167NpUuXqFevHv7+/qxdu5aJEyfSunXr7HGuW7eOxo0bY2VV+F+LY8eOsXTpUuLi4rj//vv5448/sLKyYurUqfTt25c+ffrc+LsVQghR5jZ9HMx3Jz3p5HgUm3atOHLQjhGTGrOCMJlJu43cXQFacVSvroOzM2egUSP9vpScnZ2pVasWDg4ObNiwAaUUSUlJDBs2jNDQUF555RUAfHx8OHLkCK1bt+bIkSNYWVnRvHlzrK2tefnll7OvN3jwYCwsLEhJSWHt2rU0yKrZcenSpezZr9jYWLp27Up4eDh2dnZcv34de3t7bG1tmT17doExpqamsnTpUhYuXMiCBQuYMGFCgT5XrlxhzJgx2NvbY21tTWpqKg4ODtjY2EhwJoQQlcTShclkYsn0N1No/gi4uVnTqYNB8KarePtW9OhEcd1dAdpNZrqAnMea774LCxbA1Kng7V2q21pZWWFjY4OrqystW+pqVZcuXaJOnTpUzxUAXrhwgf3799OrVy8GDx7M4cOHadasGWvXrmXo0KHZ/VxcXFi9ejUDBgzgzTffZPDgwSQnJzN37lxGjx6Nr69v9nWvXLmCjY0NrVq1wsXFhejoaI4ePUrLli2xsMh5wv3JJ5/wxhtvUK1aNTw8PJg0aRKzZs3K7pOUlISTkxN///03Fy9epEqVKrRq1YodO3bw/vvvl+r7EUIIYSZKERFThWbWkQx6syOWVvDeezB5cnVeeserokcnSkDWoOVmCs78/GD6dP0795q0UlizZg02NjakpKTg6emZve7M9Djx+PHjzJkzh3nz5tG1a1dSUlIIDg7G0tISZ2dnHBwcsq/l5+dHeHg4Dg4OVK1alccee4ynn36adu3a5Zn5io2NpU2bNtStW5dDhw5x6NAhhgwZQkREBD/++GN2v1WrVtG2bVs6deoEQJcuXWjatCkDBgwgLEyvW4iOjubChQtcv36dtm3b4u3tjbe3N7t27SIjI6PU348QQojSC1u6n60JnXlxaCSWVjon5H/+o8s7vfgiREdX8ABFsd1dM2g3ExysgzLTjJm3t34fHFzqWbSpU6cSHx9Pt27duHz5MuPHjwegRo0aALRs2ZJPPvkku79hGNja2hIXF8fJkyezU3EAXL16lSeeeAKAZs2a0b9/fwzDoEWLFtja2mb3W7ZsGYMGDWLHjh2MGTMGgL///jvPjs8LFy7QuXNnmjRpkme8L774InZ2dixfvpz09HS6du1K48aNSU9P59NPP2XcuHHEx8fj5+fHww8/zHvvvSePOYUQooJ9NT0WBxJ55vOO2W1WVrBkiQ7SJk6EX36pwAGKYjNy/8N/u3N3d1chISF52g4fPkybNm0qaEQ3t3//fjp27FigPSUlhbi4OFxcXPjll1947LHHCj3/8uXL1KpV64b3CAkJYcGCBdStW5e9e/fyzDPPZG8kKOlY09PT6dy5c/YjWoAzZ84QGhpKr169bjqW8lLZ/9yFEMLcLh+8iGsHZ565dw/z995X4PgHH+jVO7/+Co88UgEDFAUYhrFHKeVe6DEJ0MSdSP7chRB3m4/v38hk/34cWhdJ2wENCxxPS9OF0c+d00XSa9asgEGKPG4UoMkaNCGEEOI2l5Zwnflb2tKvVlihwRmAtbV+1BkTA1nJA0QlJgGaEEIIcZv77a0gzmY24OWJN34qdu+98PbbsGwZ/PFHOQ3uDhMTAxs3Qr4CP2YnAZoQQghRmURFQe/eedsOHoR+/fTrM2fAywvuvx/GjgWl+Om7FM5Tj8F/++pjN9iuOXkydOwI48bpYONuc6MAK/dXf+4cuLrqr9P0lcbGwoMPwu7deu9g7q95wgT480/zjVMCNCGEEKKyiI2Fp56CxMScNqXA11cvIgNYtEjn6dy8GSIjOfzRKoykBP659wmMLQEQEAC1axd5Cxsb/agzOhpefbVMP02J3SxAunoVfHygf38YNgxSU/VXNmgQuLvDmDG3FmBFRUGPHnm/+qAgPdsYEJDzle7fD3Pm6PYBAyA0VPfduhUuXoQhQ8z3XUiAVgkUlUcsPT09+/XUqVPzHDt9+jQnTpzIfv/ll19y5cqVQq+zcOFC9u/fn/0+KCgoT9qOzMxMdu3aBeham0lJSWRmZjJ8+PAbFkLPyMjg+eefv8Eng2+++eaGx02ioqJu2mfu3LnZr+Pj44t1XSGEuK1YWsLy5VC1ak7bkiV5Uz19+KEuQwhw5QrffAO9CcQzYzN07qynyG6ic2d46y34/nvIXZ75VgKk9HRdeMfLC3r21Ne+lfPvu09/LNPMVmEB0rJlOlbdsAFcXGDdOvjhBxg9Ws+KbdqUE3QVN8AyxcRJSXm/+l27YPHivF+ppyd07w6BgTrI69FDx83PPw9NmsDvvxfrT7lYJEDLZdasgjlp/f11e2kdPHiQ5cuX07dvX06cOMHq1at56623mD59On5+foCuLvD++++zePFiNm7cyMCBA7MDpMv55mI3bdrEoUOHAB0obdy4EWdn5wL33bVrFxYWFgQGBpKcnMwvv/zCxo0buXbtWnYfCwsLPv30U0DnX1u0aBF79+5lypQpBe67atUqdu7cCejku7lzquUXEBDAsWPH+Oijj/IUei/MlClT+O2334o8HhYWRnx8PHPnziUuLo5XXnnlhsGjEELclqpWhaxE5gBcuQI//giTJhXsu3w5KQ2aMz9iMEbTpljtCNR5O3fu1JHITbzzDrRrp5+SxsUVnLwrboC0fz88/jisXp03rizp+X/9BadOQd26+vzCAqQJE3Ke9EZHQ506ejfqwYMQH6+DpKz0osUOsEwxcfXqeb96Hx897vxfqVI5/a2tdZDbti28/rq+5ldf3fSrLxYJ0HLp2jVv4QBTYYGuXUt/7fbt21OnTh1effVVWrRoQZUqVahTpw61atWiU6dOpKam4ujoyLvvvktycjK7d+/Gx8eHTZs2cfDgQerXr599rczMTABcXV2za2gOGTIEPz8/Nm7cmOe+iYmJeHp6Ur16dRYuXEirVq145513sisZmLRp04YLFy7g5+dH48aNWblyJdu2baNfv355gquhQ4dSr149EhMTCQ8PZ8SIEaxdu5aVK1fmud727dsJCAjA3d2dESNG8Oqrr7Im9/+m5XP69OnsOqKFSUhIIDY2lipVquDo6Ei9evWws7MjISHh5l++EELcrt58Ez7+WEcCuYWHw+zZzIt9nOvYMfDzgeDkpKMNNzc4fvyml7a1hf/+V8+a+foWnLwrboC0axf873/Qt68Owpycbv18X18dAEHRARLo97GxOtjq1QsiIvRn6dAh56sqboCVPyY26dmz8K/UMGDePL2O748/ICxMB7kuLvCvf5ml+BBwlwVo//53zlRrYT/TpkH9+nras3Fj/bt+fd1e1Dn//nfx7n316lW2b9/OuXPn+Prrr1mxYgW1a9fGzc2NLVu2YGlpyfTp00lOTiYjI4O0tDQsLS2pVq0aKSkp2SWhAF544QUsLS2ZOXMm06ZNw8rKis6dO9OrVy9mzpwJ6Bm33377jaNHj/LZZ5/h4OCAg4MD+/btY9KkSXzxxRfEZK0O/euvv9i6dSuHDx8mMjISa2trEhIScHBwYNSoUdjZ2QHw7bffcunSJRo1akTPnj05fvw48+fPJz09naVLl2aPb8OGDaxfv57GjRtTu3ZtLl26RL169fD39+fFF1/kyJEjeb6bdevW0bhx4zyfMbdjx46xdOlSwsPDcXFx4Y8//sDKyoqpU6cSaloAIIQQd6ItW+CNN/Q/OHv36mmv2Fh4/HHS5i3is61d6VdzD63njIMLF/Rzug0boH37Yl3e3V3P/CxZAjt2FG8GCfIGSF276keLe/bo4MW08aCk5+/erR8Xms4vKkCKidEVEb77Tr+fNg0WLoQpU6B1a70W7Ebn5w+wijJgQMGvdOZMPWMGetbR2RlatNDxMkBIiI4fzEFKPeVTvTrUq6c3yTRqpN+XVlxcHLt27SI5OZm+ffty/fp1Ll68SGhoKJ06dcLGxgZLS0vee+89duzYQWJiIra2tsTHx6OUwtLSMs86NVdXVzp06IBSiiZNmhAXF0fz5s2xtLSkS5cuADg7O1OrVi0cHBzYsGEDSimSkpIYNmwYoaGhvJIrCY6Pjw9HjhyhdevWHDlyBCsrK5o3b461tTUvv/xydr/BgwdjYWFBSkoKa9eupUGDBoB+NGua/YqNjaVr166Eh4djZ2fH9evXsbe3x9bWltmzZxf4bkwzgAsXLmTBggV5aomaXLlyhTFjxmBvb4+1tTWpqak4ODhgY2Mj5aWEEGXvwgU4dEhneTVND5WmX0kcO5bz2stLlwN44w04c4bYR57jx8yq2Ax+HP5vql6nZmMDL7wArVoV+xZTpsBvv+l1VAcP5rT37Kln2SAnwOnYMSdA+vVXfaxjx5x+7u6wfbt5zh8wAH7+WQeNGzboXaepqTBihJ5UNAVCsbFw4IAO9oKCcsZf2PkzZ+p/4598MifAKsrUQr7SsWP1k7XFi3XA1r+//pzPPKNLaKWlQb4HSrfsrgrQPv/85n1MjzXffVdvkjH9AZWGs7MzAwcOZM+ePTRt2pT4+HicnZ1JTU3FwsIC66z52OnTpzN58mTq1KnD0qVL6datG61atcLe3j7PozxToJKZmUnVqlVp0qQJ27dvzy6MDroIu42NDa6urrRs2RIguzxT9XxR54ULF9i/fz+9evVi8ODBHD58mGbNmrF27VqGDh2a3c/FxYXVq1czYMAA3nzzTQYPHkxycjJz/uXf2AAAIABJREFU585l9OjR+Pr6Zl/7ypUr2NjY0KpVK1xcXIiOjubo0aO0bNkSC4ucidtPPvmEN954g2rVquHh4cGkSZOYNWtWdp+kpCScnJz4+++/uXjxIlWqVKFVq1bs2LGD999/v3R/MEIIUZioKBg+XG/NO3YMnnsOHnhATzXt2qUX6W/ZovtevKgXbj36aMF+Nja3PoaAgKLbZs6EmTN5tNo+Llg5c+zbhmBlAfmeThSXnZ2eQevZUxdWNylugDRmjF5r1r69DvSqVDHP+YUFSAsW6IX9H36of8aP15sdnn5aP+bs0UM/Ni3q/MICrKK+Zm/vgl9p9ep6M0JuTk6wYsUtffU3dFcFaDdjCs5M9dK9vfO+L62UlBTS0tKwt7enWrVqWFhYcOnSJfr27UtCQgKXL1/GycmJAwcO8MILLzB58mR8fHxwcnLKs0PT2tqavXv38ttvv9GnTx+aNWuW/eivXbt22f3WrFnDuHHjSElJwdPTk2NZ/yeW+1Hi8ePH+frrr5k3bx4ODg4cPXqU4OBgunTpgrOzMw4ODtl9/fz8iIyMxMHBgapVq2bXB/X3988z8xUbG0ubNm2wtbXl0KFDXLlyhSFDhhAREUFQUBBPPvkkoDcctG3blk6dOgHQpUsXdu3axYABA5g1axZubm5ER0dz4cIFrl+/Ttu2bWnevDmtWrVizpw5Re5+FUKIW5Z/pfz+/Tp6ad5cT9OcOqWfqZkMH66nY3buLNivBLNYJRX60xG2XbuXzx4KwMKq9M/UPDzgtdfgk0/0jBYUP0CaMgWeeEKv7Ro6NGcG7FbP//BDfX5hAdL48fonv6w9c3kUN8AyKSwmrlBKqTvmp0uXLiq/f/75p0BbUWbOVGrz5rxtmzfr9tI6fPiwGjBggFJKqQMHDqj58+erzMxMNX36dLVw4UKllFKZmZkqIiJCRUZGKqWUio+PV5mZmerjjz9Ww4cPz76W6fiBAwey22bMmKFat26t4uPjs9syMjJUXFyc+v7779WRI0dUXFycUkqpuXPnFjnOo0ePqpkzZ6ply5apESNGqLS0tOxjX3/9tTp//rxSSqnZs2erfv36qf79+6sJEyaozMzM7H5fffWVOnnypPrhhx+y2zZt2pTnPufPn1enTp0qdAyLFy9Wb7zxhtq9e3d229q1a9UDDzyg/Pz81Lp161RkZKTy9vZWW7ZsKfQaJflzF0KIbFevKhUXp5SnZ05bWppS//ufUvffr1R6ek777t1KvfLKzfuVgf9rsVU5Eq/iTsea7ZpJSUq1aqVUo0ZKXbtmtsveVsoyDigMEKKKiGkqPKgy509pA7SylpiYqJRS6uzZs3naDx8+fMPzkpKS1P79+2/YJzY2tsB1i7Jv374ijyUnJ6sLFy4opZT6+eefi+wXHR190/sEBwerZ555Rr311lvKx8dHrVixoljjy2/fvn1qz549SimloqKistsjIiLU6tWrCx1LZfpzF0LchnIHaLGxSj35pFJPP61URkZO++jRSp04cfN+Zhb1z2VlQ4qa0C7A7Nfevl1HBkOG5G0vbpBS2gCnos/fvFmpWrVyrpH/vblJgCbuOvLnLoQoldwBmsm//qXUrl36dWysUv36FX5u7n5l4IP+AQqU+uf3Y2Vy/eHDdXQwe7Z+X5IgpbQBzq2en5mpVGqqUmvWKFWzplIrVyp16pRS332nlLOzUnPm6MlNPz+llixRau5cpWbNUmrqVKX+8x+lJkxQ6qmnlBoxQikPD6WsrZVycyvb4EypGwdosgZNCCGEKMr48TqLap8+ebf9/f67ri90s35g1l2gacnpLPj7HvrXCKbNUDMk6SzE0qU65YZpr8OGDTo/WWwsrFp18/NfegkefljnO9uwQX81x4/rj3b9ut4okJqa8zp/W5s2MHCgrkIQGQktW+rNC4X1zf07t+HD87739S16vHZ24OgIDg76t6OjzmkWFqY3DJpjDfqtuCsCNKUUhmFU9DBEOdH/UyKEEGbw+ut6m6Fh6C1/poX/69fnze6fu1/PnnpHZ1G7QC9e1BsLLCx0Eq1Fi3QEU4xdoKvf2cO5DA8WjT9dZh/ZwUEncu3TJydlxHvvlfw6pjQaRVXjsbLS6TVsbPSP6bWtra4GEB6u013Vr5/3eP6++dtsbHRguHat3lz7f/+XE3iZgrDcvy3yZYTNn83BtGmw3BU1tWbuH6AusDXrdQPgLBCQ9VM7q/1bYCfwTq7zCrQV9VPYI87w8HAVHR2dZxG7uHNlZmaq6OhoFR4eXtFDEULcjWJilBowQD8fU0qpFSty1qk9+qhSR44oNXmyUqZlGAMHKrVvX+H9CnFf1f2qudUplZFatpsQNm9WqkYNpcaOVap6daW++UYPszg/33yjzxk3Tv9etkyps2eVio7WezBSUm68RM/0WPPdd2/tEWNpzq9Ma9DKZQbNMIzqwFLAMavJA/hQKbUgV59HAEulVA/DML4zDKMl0CF/m1Lq5vUrcnF1deXs2bNEm6qnijuenZ0drq6uFT0MIcTdyFQv6aGH9Pvhw3U18DVr9DPCFi1y8kiArrVZq5bObZHV73pULP2fbcGWbTndDh6EZ59IYve1Dkx5YBv392uSZwLO9JBoyBB4/33Iyl50S0wzSCtX6pmjxx4rfsopf3+dl+zXX3XfUaNKlq6qtOmuSnt+cHDevt7e+n1wcPnPopXXI84MYBRgqvPeHXjAMIzngXVKqcmAF+CXdXwD0AtwK6StRAGatbU1TZs2LdXghRBCiGLJXS3cJCFB/yvfuHFOJAU6kGvXTj/Dy+p3/Uc/Ak41JqF2Tj+l9BqqiBNpOJJAYqsuLHhJr9Xy8dFp1zp21IXImzcvXXAGpQtSShvgVPT5r79esK2iHnEaqhzX6xiGEaCU8jIMwxsIAZKATcArWT9fKqX2GYbRH+gMtMzfppSake+aY4GxAI0aNeoSERFRbp9HCCGEKJSXV8HMp2PG6BX0Hh56gdWoUboIZa4CmNeugd3zY3jl+EssCPUAdM3Jk4eS+XiOLRPaBDD3n/uz+3frprPv29lB27Z6QX6fPhW3sF2UjGEYe5RS7oUdq6hi6TuUUvFKqQwgDB2IJQD2WcerZI2tsLY8lFJfK6XclVLutWvXLvuRCyGEEMU1fjwEBurXpt2dWcXO+e67nOAsq1/VqmCTFEeCld4FeuUK/Pgj2B7cg8KClz6qn33p3BNwn32mSyiNG6eLed+oCLi4PVRUgLbeMIx6hmE4AP2Bg8Ae9CNMgHuB00W0CSGEELeH11+HyZOhd2893dWqFcyYAWfO6IrhXl66rme+fpEOerfom2/C++9lsOjvFlS3ukbrh1sDegJu9uycGtNhYfDiizo9xMiRlbBskSixikqzMQ3wB1KBhUqpo4ZhXAC2GoZRH/BBr1NThbQJIYQQlZspQmraFLZty3ssq9h5Abn7/a1/bdkC29clcT7DBUfbdN55R9fMzD8B16KFDtpat4aQkJxC5OL2Va5r0G4ma7dnPyBQKXWxqLaiuLu7q5CQkLIfqBBCiLtGcfPMmlPuJWz3OR/iUoIDDXo2JiDQgjfe0I8xTSnZpk3TyVyfew6uXtW5vVatKr+xilt3ozVolSpAKy0J0IQQQpRWVJTOjpE/z+zvv+v8sR9+qGe2QOecfeopnVoCdDqMV1+FjRvNM5Y9K0/hPqIpnw/awCtr+pvnoqLSqIybBIQQQohKJzZWB1yJifr9/v2wZAlMnQrNmsGpU3rGKiBA/7Rvr4sCQE46jLS00o1h1iydzwvgq3eiqEI8zR7vVmRGfnFnkgBNCCGEyGLKM2tKZzZ8uF7PlTvPrElwsK4X2aCBfr9kiXnSW3Q9+Qsjh6Wy6sdEfj7qRt+GR3nmJQe6nvyl9BcXtw0J0IQQQogsVavmSUsGFJ1n9osv9EZMyEmHkbs8563yfqwufmokY562IhVbtlxpj58aifdjdUt/cXHbkABNCCGEuAFnZ1i6VD+6DA7WbXFxcOmSztwPOh3Gxx+DtbUZbujtTczwsVxP1/9Ev6Tm4v3bK5J99i4jAZoQQghRhMLyzILeMDBoUE6/LVvgjTf07su9e+Gdd3KOXbigCwbEx9/8fkrBp6P3MPy7gRiAL7NZYIzHHwnO7jYSoAkhhBBFKCzPLMD69bqkksmxYzkbB9q2zdnleeyYrui0fTt4ekJqqs5R6+UF998PY8fqoOzMGfD0VLhWu8akn7pgQzr/c3qCT9+9hp/VaEYOS83eOCDuDhWVqFYIIYSotG6UZxbgp58KPy82Vq9ju3RJvzftAm3eXBc1P3VK5zBbsCBvsfMfvktD/XOc8/FtqWF9jRk2Uxjw+wTw9sbb2x+/h0cS/MuneHs3L5PPKyofmUETQgghcpk1KAD/OWF52vznhDFrUMBNzy3OLtAPP9TBGejNBakXr7Dxm1PsuHwPXz+yjuZ1Exi8ZETOmjNvb7x/e4XXm/9qxk8pKjuZQRNCCCFy6dq3GiMnNcSPMLx93fCfE6bfz775uabALLeidoEuXw71HK/x0KA04jNcWDsliNi2A2lXFeqPqJ/3It7eskngLiMBmhBCCJGLt68bfoQxfFJjPL/YQ2BkE1bMPoO3r9stXc+0C3TMGL0L1MND18181zeRc+ctqGmZwfZfzuLY9T5GjdIbCoSQR5xCCCEql6govSrf5PBheOihnPfjxulV9l5e0KQJ/Pyzbt+yBZ5/3ixD8PZ1o6l9FKvPdCFBObLmjwxO740r8XUK2wUaG6O43/0aJ87b0do+kl1BFrj2b1ugALq4u0mAJoQQovLIX2vp5En4z390FXCTRYv0Kv7Nm+Gee2DoUF0kc9q00tdZyuI/J4y9SS2pa0QB8NkWN5q7OTGscSgBi45S3DLW+XeBtmyaTv/WEUTEVqWGdSIOne7heEI9ZszQOzknTtRxp2kXqLh7SYAmhBCi8si/yt7JCX4tYnH8r7/qZGSOjtCwISxebJYh6DVnjVAYPO9xgL8+PYyzcZXH6gey9UxjvF9oxb2Ox1n89HaSY5ILvUb+XaBbt8Jrz11leMNdhEQ3YWLn7UQlVmHrDks8PWHmTJ0vzZSqw9PTLB9F3MYkQBNCCFF55K+1VKcO2NoW3nfxYnjmGf26QQOwMM8/acGbrvLuo4fIxJJunvZ4+7qxcnYE995rEHnRmm9Hb8bIzOD5/96Ha61k3vLYTOTW0ze8ZtTuCLybRfDbpZ58/tguvtxzH5bW8k+wKJr87RBCCHH7OXIEXFwK3zZZSq+v9SItq8ySx6gmgF6T9vpaL+zrVuWZH+9nb1IrAj4Lw6v+cWbt9qRpH1dG1gtk+8xtzPTxz5Om459lYdzrYUtYSmtWv3+IV37ubvYxizuP7OIUQghx+1m+HIYNK7PLB4Va08TyDHU6NSz0uGFh4PlvNzz/DaeDopjve4JvdnZkxZvOtLQ4wYfr6rIibjvW6ckM/bg7Sdgz/6lgHnpHgjNRPDKDJoQQ4vazcWPenZ5mFnTeFQ+XiLyJy4rQxKMus7bfx9kYRxaODcXa3op4nPB5vwd9P/YmBTuW+Ybywn8lOBPFJwGaEEKIyse0yr6o99u2Qc2aeduaNIH//rfUt774Twxn0hvg0Sm1ROc5OlszblFnDsY3YePiCFraRqKwxNdjB49/2rXU4xJ3FwnQhBBCiFyCfjkFgMcA51s63zDA8moMMamOvNs7gCW72xYoHSXEzUiAJoQQQuSy2z8RK9JwG3XPLZ2fUxoqkumBXvjNjmTkpIYSpIkSkQBNCCGEyCXosBMd7Y5jX8fpls4P3nQVv9mR2aWhvH3d8JsdSfCmqzc5U4gchipuOuTbgLu7uwoJCanoYQghhLhNZWYoqlvHM7rVHuYfluLkomwZhrFHKeVe2DGZQRNCCCGyHNlwhmuqKh7db757U4iyJAGaEEIIkSVo9TkAPB6uV8EjEXe7cgvQDMOoaxjG1qzXjQzDCDAMY7NhGF8bWgPDMM5mtQcYhlE7q++3hmHsNAzjnfIaqxBCiLvT7p0ZVCOOewa1qOihiLtcuQRohmFUB5YCjllN44DxSqn7gYZAB8AD+FAp5ZX1E20YxiOApVKqB9DMMIyW5TFeIYQQFScqKm8O2sOH4aGHct6PGwdeXvqnSRP4+WcIC4P77oM+fWDatFu/d1B4bbo6n8DC2vLWLyKEGZTXDFoGMAq4BqCUelspdTjrWE3gMtAdeM4wjFDDMD7KOuYF+GW93gD0KqfxCiGEqACxsfDUU5CYqN+fPAn/+Q9czbUBctEinbd282a45x4YOhQWLoTVqyEwEPz88vYvrqSYFPYntcCjjey2FBWvXAI0pdQ1pVSBv/GGYYwCDimlzgN/oQOyrkAPwzA6omfczmV1jwHqFnKNsYZhhBiGERIdHV1WH0EIIUQ5sLTUZTZNNdCdnODXXwvv++uvMGgQODrqoK1OHUhLg/R0cHAo+b1DV5wkAys8PO1v/QMIYSYVVizdMIxmwCSgb1bTDqXU9axjYUBLIAEw/ZdShUICSqXU18DXoNNslPGwhRBClCFTYGZSp07RfRcvhhUr8rbNmQNPPAHW1iW/d9BfVwDoNqppyU8WwswqZBdn1pq0n4Fncs2srTcMo55hGA5Af+AgsIecx5r3AqfLe6xCCCEqnyNHwMUlb0AXFARr18Lkybd2zd1h1jS2jKRuJ9nBKSpeRc2gvQk0Ar4yDANgKjAN8AdSgYVKqaOGYVwAthqGUR/wQa9TE0IIcZdbvhyGDct5f/o0TJgAf/xxa7NnAEHnG+LhEoHeuyZExSrXAE0p5ZX1+w3gjUK6tM7X/5phGF5AP2BWYevYhBBC3H02boSXXsp5/8YbEBMDo0fr94sWQatWxb9e1KHLRKS78nKnY+YdqBC3qMLWoBWXUiqWnJ2cQggh7gIBATd+v21b3vfLl5fufkHLTwG18BhYvXQXEsJMpJKAEEKIu17Q5iQsSafzKEm3KSoHCdCEEEJUOrMGBeA/JyxPm/+cMGYNCiiT++0+7ERHu+PY165SJtcXoqQkQBNCCFHpdO1bjZGTGmYHaf5zwhg5qSFd+1Yz+70y0zPZHdMCj6ZRZr+2ELeq0q9BE0IIcffx9nXjq3PB9H+tE+O+38ry/W3wmx2Jt6+b2e91dEME12iKR3eZsxCVh/xtFEIIUSmdO51GOtbM29eb8b0OlklwBhC0+jwAHg9L/jNReUiAJoQQolL6aX0NAKobsSzY1r7AmjRzCdqZSVWu0sqnWZlcX4hbIQGaEEKISmftB6GEJraiJpeJVdX56KmjedakmVNQeG26Vj+BhbWl2a8txK2SAE0IIUSls+KHZMDgq2f2Ykk6p8LBb3YkwZvMm688OSaZ/ckt8GhzzazXFaK0JEATQghR6VRxBAcSGTazO/c7h7Jilyter7rx+lovs94n1O8EGVjh4eVg1usKUVoSoAkhhKh01h1yxbvmAexqVWHkwHhOpDZm76pws98n6K8YADwea2r2awtRGhKgCSGEqFRObLvIidTGDOyVAMDDb7fDknRWfHHe7PcKCrOhsWUkdTvUMfu1hSgNCdCEEEJUKusXngJg4NhGANRq78ID1UPxC2qEUua9V9D5hnSrd9a8FxXCDCRAE0IIUams22xNc8vTtPDJqYs5wieBk6mN2PvrSbPdJ+pgNBEZrnh0um62awphLhKgCSGEqDSuJ6az+UIbBt4TDoaR3T4s6zGn3+fme8y5e7meqfPwqWG2awphLhKgCSGEqDS2fnOEJBwZ+JBtnvaabevyQPUwVuxujMo0z3POIP8kLEmn88gWZrmeEOYkAZoQQohKY90vcdhwHa8X2xU4NmJQIifTGhG20jyPOYMOO9HR/jgOtSTFhqh8JEATQghRaazbV4/e1Q5QxdW5wLFhb7c1227OzPRMdse0wKNpdKmvJURZkABNCCFEpRAZdplDKc0Z2COu0OM129ThgRph+AU3KfVjzmPrT3GNanTrLv8MispJ/mYKIYSoFNbPOwHAwKfrF9ln5OBEwtMaEbbiRKnuFbRaz8J5PFyvVNcRoqxIgCaEEKJSWLfBggYW52n3aOsi+zw8OWs35xcXSnWvoJ2ZVOUqrX2kgoConCRAE0IIUeHSUjLYeLY1Ps2OYVgW/U9Tzda16VsjjBUhpXvMGXSqDl1rnMTCSv4ZFJWT/M0UQghR4YJ+OMY1VZWBgy1v2nfE4CTC0xoR+suxW7pX8pUk9ie3wKP1tVs6X4jyIAGaEEKICrfux8tYks4DE9vetO/Db7fDijRWfHXxlu4V5necdKzp5iXpNUTlJQGaEEKICrduTy16VDmIc/OaN+1bs1UtHqi5F7+Qprf0mDNoXQwAHo83K/G5QpSXcgvQDMOoaxjG1qzX1oZh/GkYxnbDMJ4pSZsQQog7y6WjsexJbMPArleKfc7IB5M5ld6I0J+PlPh+QWE2NLI8h0v7WiU+V4jyUi4BmmEY1YGlgGNW00Rgj1LqPmC4YRhOJWgTQghxB9kw9ygAA8fULvY5D7/THivS8PsqKu+B2FgYNAjc3WHcON0WFQW9e2d3iTxnyVqrIXD//TB2LCjzlI4SwpzKawYtAxgFmFZkegF+Wa8DAfcStOVhGMZYwzBCDMMIiY6WjNBCCHG7+WutorYRjdu/CpZ3KkqNFjXoW2svK/Y0y/uY84cfYPRoCAmB+HgIDoannoLERAAuHbzEoMw/2d3z37B5M0RGwoED5v5IQpRauQRoSqlrSqmruZocgXNZr2OAuiVoy3/tr5VS7kop99q1i/9/X0IIISpeRrpi/alWDGh0BAvrm+/gzG3Egyn6MedPuR5z1qwJBw9CXJwOvurUgeXLoWpVAIJ+DucdPqTFcDfd/8oVqCWPOkXlU1GbBBIA+6zXVbLGUdw2IYQQd4jQ5ce5omowcEDJHzMW+pizVy+IiIAvv4Q2baB+fahWLfvw7oAkLEmny6gWOnBr1073EaKSqaiAZw/QK+v1vcDpErQJIYS4Q6xbGoVBJv0ntirxuTWaV6dvrX2sCM31mHPaNFi4EKZMgdatYcmSPOcEHa5KB/uTOFy9ALNnw+efm+NjCGF2FRWgLQWmGYbxBdAWCCpBmxBCiDvEuiBn3B3+oXb7AitYimXEEP2Yc88P/+iG2Fi9piwjA4KCwDCy+2amZbA7tgXejU7C44/Dd9/lmV0TojIp1wBNKeWV9TsC6AdsB/oqpTKK21ae4xVCCFF2YiOusetaWwZ2irp55yKYHnOumHdJN7z1lt6ZWa0axMToQCzLsXXhXMWZp22WwZkzMHEieHnBli2l/CRCmJ9VRd1YKXWenB2aJWoTQghx+9s09wiZdGPgEzVu+Ro1mjnTt3YIfqEtmJGpMLp1g0OHCnYMCCDo2UCgJRYffQAPSpF0UbnJonshhBDms2CBnpXy8oJOnfLmInNzy9N1x+oo9tGRbs+0L9UtRw69zumMhuz5vpDALJfduzJx4hqtBzQu1f2EKA8SoAkhhDCf8eMhIED/9O4Nzz+v2ydNguTk7G4qU9ErfCk1ra5iZW9dqls+9HbWbs55N86FGXSqNl1rnMTSWv7pE5Wf/C0VQghhfufO6Vkzd3edENbREVxcsg+f+nAZ0aoWFjWrl/pWNZpWo1+dfawIa47KyCy0T/LlRPYl34NHm/hS30+I8iABmhBCCPObN0/PpqWmwvvvw4wZOcdSU7H64lPeZAY16tsXfY0SGPFQKqczGhHy34OFHg/zO0461nh4O5jlfkKUNQnQhBBC5ChsDVm+WpacOweurjn98pfZy8wEf399bMYMmDABnJ1zjs+YwZKUJ2hkG4VtVVuzDPvht9tjTSorFlwu9HjQXzEAdBslmwPE7cFQZioSaxhGDaVUjFkudovc3d1VSEhIRQ5BCCHuHBMnwpNPwrvvwqVLEBqq21et0kHb+PGFn7dlC6xerZPA9ukDFllzAXv3wvDhpB88zPYgK1yrXKW55WkYPhwWLy71cAfV3cM/V+pw6noDDMu88w+PN9zG9gvNOJMuVQNE5WEYxh6lVIE643ALM2iGYTgahtErX1svcjL+CyGEuN2Z1pC1apWnliUAu3bpgKpzZ5g8ueC569frwAwgMDBn00CnTrB4MWv7f4EXW4h4d3F2mzmMfDiViIyGhCwpWPw86EJDPOpHmuU+QpSHEgVohmHYKqUSgX6GYXgbhmFvGIYTMA0ILZMRCiGEKH+mNWRVqxbMtu/jowOu4GDYuRP27897/KOP4JFHCl4zIACAdb8l40gCvV5on91mDg9NbocVqYx6rQHu7jkZPg4FXOJURmM83FKz+x4+DA89ZLZbC2F2xQ7QDMOoAsw3DON9IBOwBT4A/gLGKKXOls0QhRBClKvca8gK07MnODmBpaXObXb8eLEvrRT8dbgJD9Q5iE1VO/OMN0v1xlW5x+ki1+INgoMyiY/XMeSTz9oA4OGjE+KePAn/+Q9cvWrW2wthVsUO0JRSCYAverbsABAD7ACGAu3KZHRCCCHK39at4OGRp45lHgMGwIULkJQEGzZA++Inmj2+KYLT6Q0Z6JVipsHm1avrda6ommz+8iCRkVCnDtxfcy+g6DyiOaBjy19/LZPbC2E2JV2DNhp4AkgAUoF7sn6qGoZRy8xjE0IIURFyryErzNSp4O0N3bvDCy/odWrFtO7rMwAMGNeklIMs3Ivv18MggymzHGnTBurXh/0nHHG0SMaxpp6xq1MHbM2zeVSIMlPsWpyGYbwIOAGNgQeBWVnvWwBPKqXk/0eEEOJO8NFHBdtyrxXz9oYjR27p0uu22HOPdTjN7m92a2O7ic8XV6Fv7TCOXarFIy0z+XYx7I5tQVWHtDK5nxBlpSSPOOcB64A/gauAPXARcAHmGIbRqUxGKIQQ4o6QHJtCQHRbBraJKLN7xMZC1542RGQ2ZN3yq0QfukQc1fNsQhXidlCiR5yxi5OgAAAgAElEQVRKqb1KqW3o2bM04G9gr1JqHZBRBuMTQghxh9i66B+ScWDgI45ldo+33oJf/2kNKI4dzaTuVb2Bwam2PNMUt5dbqiSglDqulNoFhAPHDMPoopQqmHhGCCFExYuJgY0b4XLhWfbLy7qV8diSgueEsttX1q0bHDlmySCXMEhKYm9IGk7Esyu0YIBmxgwfQphdqUo9KaWSgerAo+YZjhBCCLOYMAH+/FM/83vwQdi9W68di47W+SV8fKB/fxg2TNfLNJPCKkWBznk7P7Q7njUO4lDbMbvNzc1st842a1AAHZolcCazIT8d6Yx7jZMEfrmXWYMCzH8zIcpIqQI0wzAM4BOg+ElwhBBClK2tW+HiRRgyRCeRnTMH3n5bp8cIDYVly8DXV6fIcHGBdevMduvx43MKB/TuDc8/n9X+VBLXlS0DeyVk9500CZKTzXbrbF37VmPxznZYksZVnHGpmszISQ3p2rfazU8WopIobbH0WcBvSqkl5hiMEEKIUkpL01FRkybw++/g6anTYQQG6lm0Hj307Fq/frp/dLTOO2FmpkpR7u6weTNcPqmzwg58zhXQbY6OOj40N29fN1bMPoMlmQCsOd0Ov9mRePuWwXSdEGWkpKWehhqGYZn1ejzws1JqfpmMTAghRMl9/z20bQuvv64Dsq++0un7ly+H6tXB2jqn786d+hFo9+5mH4apUlRqKrz/PjjFn8OWFFoPbp7dNmOG2W+bzdvXjYca7wXgOfcwCc7EbackpZ7qAIOANYZhLAR+VEpJ/U0hhKhMwsJg7Fg9NfWvf+mSTYahI6aOHeGPP3S/mBiYOBG++y7P6YWtIYuK0o8rTc6dA1fXnH7R0XmHkLtS1IwZMPaZdLZG3UMN+xQMC4MZM/QknrNz2X0N/nPC8D/TnHd6BfD9nnb4zwkru5sJUQZKkgftklLqBaXUQGA1sNAwjI5lNzQhhLgLpadDo0Y50c+WLTBihH795JP6EeaVKwXbTFq0gPBw/TokBFav1rNqAHFxOipKTdXnf/wxNG6c5/b515A99xw89RQkJub0CQrSS9pM/WrXzvsRcleK2rQJZk5PIZ6qXM2swnPP6bZ58/Tw9+7V9zAn/zlhjJzUEL/Zkby/1Qu/2ZGMnNRQgjRxW7nVNBvrgf8DHjQM4yGzjkgIIe5m+/fD44/nRD9r1sCjj+rX9erpBf4zZxZsM3n2WT191acPzJ8PZ8/CDz/o9xkZeufmt9/qzQIffqijpOXLCwzDtIasVSt9OHei1127YPFi6NwZJk8u+BFyV4oKDASf2iFYkUZnN31eYGDOx+vUSbeZU/Cmq3nWnHn7uuE3O5LgTVIdXdw+DKVU6S5gGMOAPUqpM+YZ0q1zd3dXISEhFT0MIYS4dfPn6+klR0fo0EFHSXPmwD33wKefgpWVDsBmzcrb9sorZh3G5Ml6H4G3t37v5ZWTN8zfXy/+d3CAvn3hiy/009OiuDkcoZpNMgFxsg5MiNwMw9ijlHIv7Fhpd3GilFqNLpwuhBCitLp21c8Ad+/Wjy5HjNALuTZu1DNfDz2kZ8/yt5lR7jVkhenZE5ycwNJS5zE7foNESxf2XWJvcmsGdo8z6xiFuNMVu1j6jSilLpb0nKxdoKOy3joDe4B+6OoEABOVUgcMw5iG3pywWyn1ojnGK4QQlVbHjmCblfXe3V1n/3/pJT2z1rOnTp/RpAm0a5e3zYxyryErzIAB8PPPUK2aTqVmSkab26xBAXTtW40zhxOBOgx8uj7+c8II3nSV19d6mXW8QtyJSj2DdquUUguUUl5KKS9gK7AInbbDK+vngGEYXYBeQDfgkmEYfStqvEIIUS7GjIF9+/R6sd9+g3vv1Qu1Dh6E6dNz+hXWZia515AVZupU/eize3d44QW9Ti2/rn2rMXJSQ5audMDFIoqYs4mSLFaIEij1GrRSD8AwGgCfAQHAi0AicAAYB7wMpCil5huG0R3wUUpNzXf+WGAsQKNGjbpERESU4+iFEMLMDh6EJ57QucuGDtUL+Zcs0Yv93303p19hbZVIZNB5Fvoe5eMdnnSwO8756zUlWawQ+dxoDVplCNA+AjYCCcBZpdQFwzC+B1YC9wL7lVK/G4ZxD+CrlHqhqGvJJgEhhCh/KlNxfONpAn86y9ZtBoFnGnM6vSEAtiRzHXve7R3A9ECvCh2nEJXNjQI0s6xBu1WGYVgA3sDbgI1S6nrWoRCgJTpos89qq0IFPpIVQoi7iWkNWe4ZL9Mastd+682B1SfYuuIigbts2HqhOVGZTYGm1Dai6VP/BP/uFo69g8HbP7Xl9V5BLNjWHu85ktFfiOKq6ICnNxCk9DTeD4Zh3JtVSuphYB9640CvrL73AqcrZJRCCHEbi4nRGz4vXy7+OaY1ZP5zwkhNSGXuiC0Mee0eVgXWoqZtAm6PteLlXz0JvtiQfo2P8fWYQI6sDScqvRYrz/agY6+qvP1TW/xmRzI9UJLFClFSFTqDBgwAArNeTwd+AgzgD6XUpqwZto8Nw/gCGJj1I4QQ4iYmTAAfH+jVCx58EAYPBl9fXaTcxgYee0zvQ3B01IlobWzynu/t68bciO0MfM2dzNcM0vEE4GqaPaNa76OPtyW9xzShUQ9XwLXA/XWyWPImi0XPwHn7lvWnF+L2V+Fr0G7GMAx7YDAQqpQKv1FfWYMmhBA6TcZnn8GqVbpSlK2t3nE5aZJOPnvyJLRsqV+PH68DuaFDc85XmYofJ2znpUUdSMaONGwZ3mAH89a3pE672kXfWAhRImWaqLasKaWSlVIrbxacCSFEpZC/luaBA5CUpNNi5Pbss9CjB3zwgVlvn5YGzz+vU6P9/jt4eurgLDBQ577t0UPPrvXrp/tHR0OdOjnnRx++zPCGQTy5qBeNbC/iZCTxbu8AAs7fw6H1Z806ViFE0Sp9gCaEELeV/LU027aFkSN1oXKTVav088WdO3Vh8xul4i+h77/Xt3z9dR2QffWVztixfDlUrw7W1jl9d+6E2FgdwAH8+e5uOrTP5H/n3RjbOpCLqTVZOfu0rCETogJIgCaEEOa0axf873/QrZueJUtPh6+/zpvtPyBAB22gi5dv22a224eFwdix4OIC//qXLtlkGLq8Z8eO8Mcful9MDEycCN99B9fOXuO5VlsZ+kE3XGxiCVkZQfOmmVJwXIgKJAGaEEKYU/5amuvXQ/36efskJkKDBvp1jRq6IHqW/E9It2zR5Ti9vODJJ/Ulr1wp2GbSooWelAMICYHVq/WsGuhJPGdnSE3V53/8MUT8sY97m15lybGevNUjgKCoJnR49B5eX+tVICWGt6+blGkSopxIgCaEEObUsSPUq6dfu7sX/viyShVITtavExJ0dfIs+Z+Qrlmja6MHBOjLLlsGM2cWbDN59lk9a9anjy7VefYs/PCDfp+RoSfsvv0WQvconnkkDs+XO5KcacfWhf/w0Q4vbKvaltEXI4QoiYpOsyGEEHeWMWPg7behfXtdS3Py5IJ9unTRjzW7d9d1N3MVszQ9IfX3hw4d9OTac8/pY3XqwNWrcOxYwTYTJydYsSLv7TZuzPu+u/MRGqRYcuh6S15oG8gnf3emiksHM3x4IYS5SIAmhBDmNGVK3lqaffsW7PPww9C7N5w/D3/9paOyLKYnpPXq6ceXI0bAjBl6Vu3bb2HtWv1UNH9bcaSnpDNr6Dbe29iTWhYxrJ0WjM+UG1RFF0JUmEqfB60kJA+aEOK2ERurp7b69NEr+rNcv67zlgF8+aVeX+btrR9XAixerH+HhhZsyy1/qabjG0/z0IPpHE5twciGO5j/d2tqtqxRVp9OCFEMlbYWpxBC3LWqV8/ZyZlLYU9IO3WCgwd1dg6TwtpyM5VqWq5CORIcj+/ybqRiyzu9/Hl/q3cZfSghhLlIgCaEEJVIYU9IlyzRpZpybwZdurRgm0laUhrWdpb4NDnCgEkepGONNan88u9djPxMgjMhbgfyiFMIIe4AJ/6OYMM3p9mwxY7NF9sQT1UsyKCeRRTnMuvLzJkQldBtXepJCCHuRrMGBRTI2u8/J4xZgwIAiIu4yuo3djG+XSDNrSNo2bcxLy73ZG90Ax5vvZeVk3ayenII15UN7/YOYOH2DlIFQIjbiARoQghRCZnWkJmCqk2zQnnktab8c8yS+6rup1YTRx6Z1Z0f/3Gjfa2LzB2xhWMbTnMqtQGLDvehRj07nv24OX6zI6VUkxC3IXnEKYQQlZT/nDCGvdaMetaXOZrWFIUFBpl0dfyH/m6X6T+qOt2faYu1g3WBc/Pv4jRdL3jTVakGIEQlcaNHnBKgCSFEYWJiYM8ecHODWrXK/fZpSWm8472dWbu9AHCzP8xbL8Rx//hWkh5DiDuErEETQoiSiI2FBx/U9TS9vSE6GgYN0qWbxo3TfRYsyCmY2alTdnv+WpoHDkBSku6S27PPQo8e8MEHBW9/ettZetc5yqzdXtiRzJvd/YlMqU0tVzsJzoS4S0iAJoQQ+e3fD3Pm6IRkAwbATz/B6NG6+nh8vP49fnxOwczeveH557NPzV1Ls21bne4sLi7n8qtW6bqYO3fqwua5y3X++p+ddOrtxIHEJjhxjbWfHuHjnd6yhkyIu4wEaEIIkZ+np66TGRioZ9GcnXVW2Lg4iIyEhg1z+p47pwtmuuunFKZamt266Vmy9HT4+mto0iTnlICAnBy1/fvrspwpcSm82GELw2f34B7Hs7zULZjfPz2ZvYbM29cNv9mRBG/KVXhTCHHHkkS1QghRGKVg+XKd8d/LC9av17WX2rTRxTBN5s3Ts2lZ8tfSXL9eJ5zNLTERGjTQr2vUgPU/X6H7hMvsS/FkknsAH/r3xKZKuwJD8vZ1w9u3DD6rEKLSkRk0IYQojGHo4KtjRx2gLVyo0/y3bq1T+wNkZoK/vz6epWNHHZyBnlTL/fjSpEoVSE7Wr/+cdZiv/luFs9drsea9YD4J9sKmik2ZfjQhROUnAZoQQuQ3cyZ8/71+HRenfw4c0AvHgoJ08AawdSt4eOS8R9fS3LdPd/3tN7j33oKX79IF/v7rOk8238bcv9vQ3P4C+3anMmhq13L4cEKI24EEaEIIkd/YsfDDD9Cnj4601q3TbdWq6fQbjz+u+61fr/vkMmWKDtI6ddK7NPv2LXj5ZhnHmT4dfgjvSS2HRLZHNKSBe71y+GBCiNuF5EETQohyojIV8x8L5LUVHjgbVxk3JpnxM5vg4lLRIxNCVIQb5UGTTQJCCFEG8mfyjz0Vx0OdIth6zROf2sEs3dKU2m2aVOwghRCVlgRoQghRBky1NP0Iw66KFcNeqEuU6si4NoHM398LCytZYSKEKFqFBGiGYVgB4Vk/ABOB4cAgYLdS6sWsftPytwkhxO3A29cNP8IY+loLEnHEQDFvZCATlntW9NCEELeBivpfuI7Az0opL6WUF2AD9AK6AZcMw+hrGEaX/G0VNFYhhLglZ/5JIIEqKCx4retWCc6EEMVWUQFad+BBwzB2G4bxLfAA8KvSOxbWA70Bz0LaCjAMY6xhGCGGYYRER0eX0/CFEOLGfnlxK09/2xNr0nirRwBLQtpLmSYhRLFVVIAWDPRVSnUDrAF74FzWsRigLuBYSFsBSqmvlVLuSin32rVrl+2ohRCiGH59dRuj5/fEigx+n76Pj3Z4SS1NIUSJVFSAtl8pdSHrdQiQgA7SAKqgx1VYmxBCVGp/vrmdxz73wNXyAqun7sPnXZ18VmppCiFKoqKCnh8Mw7jXMAxL4GH0bFmvrGP3AqeBPYW0CSFEuYiJgY0b4fLl4p+z/r0dDJ/pjluV4+w/XY3B7+WtDODt68bra73MO1AhxB2pogK06cAPwF5gJ/AB4GYYxhfAm8DPwLZC2oQQoszFxsKDD8Lu3eDtDdHRMGiQrq05blzevhMmwJ9/wuYPd/LwNDfaOpxm/UFXqrk6VczghRB3hAoJ0JRSB5VSHZVSHZRSbyulMoG+wFbARyl1qrC2ihirEOI2dPUq+PhA//4wbBikpup2UzRlEhUFvQvuP9q/H+bMgbffhgED4KefYPRoCAmB+Hj9G3QpzosXwflYEEPe6UgL+3Ns3O9C9cZVy+FDCiHuZJVmXZdSKlkptVIpFX6jNiHEXaC4Adazz+qClx98kPf8ZcvA1xc2bAAXF11L0xRNDRmi+8TGwlNPQWJigdt7ekL37hAYqGfRnJ3h4EFdMz0yEho2hLQ0eP55sI29SP9JHWloe4lNoTWp1bxaGX0pQoi7SaUJ0IQQIltxAqxVq3Qh8507ITwcjh/POX/CBOjXT7+Ojobq1XU01aQJ/P67bre0hOXLoWrhs11K6cPVq4OXF0REwJdfQps2UKMGfP891LePZU2APXYWqYx+tS51W1cvs69ECHF3kQBNCFH5FCfACgiAkSP16/79Ydu2gtfZuVPPlB07Bm3bwuuv6ymxr77SgVm1ome7DAPmzYOOHXWAtnAhTJkCrVvDkiWw8adogvdaUdM6npV+mYQddTDnNyCEuMtJgCaEqLxuFGAlJkKDBrpfjRp6PVluMTEwcSJ89x2EhcHYsXo27v/bu/PwqIqs8ePfIiQQIIQQQFRWERhlhwDBYUkQF9ARcYkb6qg/YdAZdRBRFOTFGRcQmXFc0HlFX8UFI+7IIpiERQMkECUgioqyL0JCgBCynt8flSadTnfS2buT83mefkx337q3qmnioaruOePHQ3x8qZedPdvOkIFd1jx2DFJT7YTdhg1wYONulsQF07BBAXHrGrH/VBgdO1bD+JVS9ZYGaEop31RWgNWsGWRl2WNPnoSCgqK2OTlw/fXw9NPQsSOcf75dBgW7w7+MaGrCBFi4EIYPt0HZ8uX2tdBQ2Lv9BC8vaESzBqeIHN6I26e05uWXYcqUavoclFL1Uq0US1dKqVJ5E2D162eXNSMj4bvvoHv3ovYLFsDmzfDkk/Zxxx2wZAksWmR39y9eXOrlw8JsDjRn27bBL59uZcS4MKRBIxJW5nLByMZVPHCllLKMLXVZN0REREiy4/53pZT/mj8fHn0U+vSxzx0B1qFDRQFWSIhNkXHxxbBsGaxfX+qesvKaMyaBgaNCiZ7cD4Bdy75n0JhwThDC+mXH6H35OVV2LaVU/WSM2SQiEW7f0wBNKeW30tPtVNfw4Xb5swrFz0shZkp7YufuoWvvYAZdEspBzmL+HRuZ+HpklV5LKVU/lRag6RKnUsp/hYUV3clZxaIn9yOWFK6b0hFESCeMF29P0uBMKVUj9CYBpZTyoOfQFjSQfNII5/buG7jn/wbXdpeUUvWEBmhKKeVGWuo+hgyBI7Ti1q7rWbKjK/HzUmq7W0qpekIDNKWUcnHsx0MM6ZfFLwWdmDNuPW/tiCR27h5iprTXIE0pVSM0QFNKKScnfjvK6H4H+Tm/E09dmchDHw0BCvekzd1D0qqMWu6hUqo+0ABNKVV9Dh2yqTAA9u2Ddu1s3aSoKFvCaf78oud9+8LEibXXVyBzfwZjeu0mKasHi//ne6Z9flGx96Mn92Pq0qja6ZxSql7RAE0p5ZlzgOWwdWtRncyZM4sCrD/8wSaWdUhPh9tvtyWZwNZIeuwxW0MzIQFat4ZJk4qeDxtm621WgYwMGD3alugcN87mvQVb4vPzz90fk7E/k6su/IlvTvbm3Ye3MG5m7yrpi1JKVYQGaEop91wDLAARmDzZJosFmDWrKMDq2RNuu63o2IAAeP99W5QcbCLZ116D/v1tElpn+/bZYDDCpgPyJsACuOsuGDIE/vnP4qd75x3bzS+/tOnRli+HtWvh4EH4059KHtO6ZR4j/7CP+Iz+vPm3TcQ8079SH51SSlWWBmhKKfdcAyyAN96A6OiSxyYl2eVLR/FysO2cM/uPHm0DuaQkWwR9y5ai9156yc6mFfImwProI1snMzHRVoH66aei091zT9Ek3++/23Rpd98NnTrBp58WPybnZA5L3jnO5hPdeO2u9Yz/z6AKfVxKKVWVNEBTSrnnGmAdPQpvv+2+Kvjzz9vC5qW56CJbnikgwNbRdERUBQW2+HlU1JlDvQmwEhKKctReeqkty+kqMdFOBO7YARdeCFOnwsaN8MIL9v2803lc1nkHB7Jb8vJNa7nztYtKnkQppWqBBmhKKe888ojdYxYYWPz1Y8fg8GHo0qX09pddBgcOwKlTdmqsZ0/7+tq1MHgwGFOiSWkBVmZm0YRdy5Z2hdRZWpqNGV9/HVJSYMIEOxs3fryNB/NzC4jplkLCkZ48fsk3THp3WInrK6VUbdEATSnlndWr4eGH7UzXt9/C9On29U8/hTFjym4/c6ZdHo2MhL/8Bbp3t6+vWGFrabooK8Bq1gyysuyxJ0/aiTiHnBy4/nobT3bsCOefb5dBAZKToUN74c89NvLxnoHc1X8zs77UmTOllG/RWpxKKe/s2FH0c1RU0c78FSvcL3s6JCTY/0ZHww8/lHz/qadKvFRWgNWxo10lXbfOxnvffVcU7wEsWACbN8OTT9rHHXfAkiWwaBHk5gjnZWzm3Z8iaRyQy88h/YiKslvgbrihPB+IUkpVHyMitd2HKhMRESHJycm13Q2lVCXNn29v9OzTxz53BFiHDtkbSBcvttvZhg2Diy+GZcvsTaLOW+bcEYH7Bq/nxaRIHo1YwT83XIppUHJpVSmlaoIxZpOIRLh9TwM0peqg9HS45Ra7N2zAAHuX5Hnn2QfYTVy9etVuH6tAejqsXGlXSNu2Lf1YEXhoxEaeWzuIB3uu4NlvL8EE6C4PpVTtKS1A099OStVFCxfaAC05GU6csOt9N91UlLPMT4KzOWMSStS+jJ+XwpwxCYC9uzMmxnNw5mgvAtMvT+K5tYMY12oNrdsFaXCmlPJpugdNKV81f77NQwb2Tsl+/WwisPx8aNrUvhcU5L5teLjN+H/sGOzZY9cAlyyxu+t79YJXX4WGvv/Xf+CoUGKmtCeWFKIn9yN+XgoxU9rz7mxDVhbk5Qq52QXk5RQ+coXc0/nk5Qp5OQW07BzKNVM6M+Z/N/HuDwO5Mmwda49eyN8u2VPbQ1NKqVLV2hKnMSYUWAQEAJnADcDPQOFWYP4mIqnGmFnAGGCjiNxb2jl1iVPVWX/7my2NNGSITRA2aZJN/HrVVe6P37ULpk2z5Zf27rVJxNq1g7PPttn+r7vOc1sfM//G1fz1/T9igHwCgIrtGesT+D378toQO3cP0ZP7VWkflVKqIkpb4qzNf0LfAswTkZXGmPnAI8B7IvKw4wBjzABgKDAIeNwYM0pEVtVOd5WqJY4ySI7sqmCzt7Zp47nNrFnwyis22ey8eXaJc+BA+15ERPG0+z7sk4cTefD9gYSQSQahDA35lov7HKVhgBDYUGgYUPwRGIj9uSFFxzSExUub8NbekcwYlkD05KjaHpZSSpWp1gI0EXnZ6WlrYA9wpTEmGkgFJgIjgA9FRIwxK4DRQLEAzRgzAZgA0KFDh5rouvJnaWmwaZNdLmzVqmaueegQXH65TeTlvGQ5eLBdaiyLSxmkM9lbIyM9t0lPh9RUe8yGDTYxbGSkTQ77yScla2H6GCkQnh8bx+Ql0XQP/JXDeWHMGJrA/HU9eWKclGsGLH5eCkv/tz0zhtn20fNSdAZNKeXzan2XrDFmCBAGrARGicggIBC7rNkU2Fd4aBpwlmt7EfmviESISETr1q1rqNc1LC3N3qp25Eht98Q/HTpkA7L0dLjySpuKPjrazkLVhClTbEbVSZOKNukPG2aXHcviWgbJOXtraaZNswFhaKhts3Yt3Hor9O1rl0lHjarkoLxz6JAdKtiJwHbt7FCioop//M5F0POycrmvVzx/X3IxQ5unciSvBYvn7uKJNVHEzt1DzJT2JW4c8MSxZy127p4KtVdKqdpSq7uEjTEtgReAa4GDIpJd+FYy0BU4CQQXvtYMHwgoa5wjqLjiCls9Oi7O7kVyzMqk6P9oyuQIkLZssct9kZH2c9282ZYfqk5xcXZDv/Ntho4lywi32w6Kcy6D5Jq9tTSDBsG2bcVfcy5O7qVDh+x2tbVri17buhX+/nf7b4aZM22BAbD3L9x+u40NwX7Et99uSzKBnch77LHik4GOITqKoJ/ce4wb+/7AF0dH8mDkOlq3yGXWJQVnZryiJ/cjlhSSVmUQPbns/ietyiB2LhVur5RStUZEauUBBAFfAZcUPo8F+mBvGogDRgHDgRcL378DeLS0cw4YMEDqnIQEkcRE+/ODD4osX25/Hj9epHv32uuXv/jqK5GJE0VGjCh6bfVqkWHDRDIyqvfa2dkiUVEi6enFrz9tmkhcnHfnmDZN5MMP7c8vvyzSooU914gRIosWVXGHi0tLE7nsMpF+/YpeKygQueSS4sNxuPZakb17i55nZIgcO1Z07EMPifTvb883bZp9LSfHfo3//neR12cfln6NtkkD8uTl2xKra1hKKeUzgGTxENPU5ozUXUB/4DFjTAKwDVgIfAskir0ZYB3QzxjzPIU3EdRSX2vPiBF2xmfNGrs0N2SI+1kZVVJODvzjH/DMM0Wvidh9YGFhJYt+u8rIsHdKXnopjBtnz+e8ZleWZ56xa3ctWhS95rpkWZannoJrrrE/T5pkp6Ucy6TVXJcoIMB+VM2bF732xht2ddhVUpJdvnQULwfbzjmz/+jRtttJSXYb3ZYt8NZbtgj6lZ23cf/DjdmWfR6fP72NSW+Wsr9OKaXqgVoL0ERkvoiEiUhU4WOWiPQWkV4i8ljhMQXYmbS1wGgR+bW2+lurnIMKkZJBR3VzDUq2b4exY6v/ur/+apd2hw2DBx8sf3t3AZIxdtN9797w2Welt3/nHbus/OWXNhh+773ia3ZlWbXKXstRXPz//b/iS5Y+zjXAOnoU3n7bfdnN55+3W+NKc9FFtjxTQIDdEvjTT3aFfkDgFq6+rz3BDU4zNLKAMY/0rtqBKKWUH/L5PX7DSW0AABsMSURBVF0ikiUii0VkZ9lH11HOQcW//10y6CiLY5N8RbhuJPrlF3joITu7VBZ3M1Dl8fDDMGOGDWr27i0quu0t1wDJGDtlA/YuyrI+w3vusTnHwO5o79y55JRSadasKZrt6tsXXnvNFhYfPrx84/ARjzxit7+5TjweO2YrSnXpUnr7yy6DAwfg1Ckb8/bsIRxe/T0zYntwXtNDPPpEML0jm1TfAJRSyo/4fIDmE+66yy4t/vOfNd9+9uziQcXy5SVnZcri2CRfEa7rXCEh8OGH3rV1nYFavrx8196xA/r3tz+3aeNdUOjMNUBKS7MlkIYPt9n4L73Uu/M40loMH152NW5PHMGl85Kln1m92sbMjq/e9On29U8/hTFjym4/c6ZdHo2MhIl35fH69Uv5YOuFnNX4BE17dWHRkmZuZ+eUUqo+8v1aL7Xto4/s/8wTE+HOO+26TNeuNdd+wgRbbPC112wOq2++KVoei4qyr5emsvvVXGeLSkuO6uqee4p+LiuxqjvXXWcTrkZG2uDu6afL196ZI0BaubJ87RxpLbwNSuuwHTuKfo6KKvr3xooV7pc9HRwffXQ0/PADZO1L47a+W1h85AomRSTxn28iaBjo+0u+SilVkzRAK0tCgg2QwM64rFtXvgCrsu3DwjwHFWUt+Tk2yX/8MVx9tffXrGreJFZ1Z/p0+3k9+6xdZm3WrHr650l50lrUYe6+Zs6vvfuu57ZzxiQwcFTomTQXv2/YyYihuWzPG85zN2/i728P9IfteEopVeN0ibMsmZlFt6a1bGn3c9Vk+8pwt0m+pnmbWNWTvn1h9267VFrTFiywudKefNJOGTmqAPiB9HS77BgRARMnQl4edOhQlCQ2NbVm+uEodh4/L4Uf3k6mT2Qw2/O68T+jNzL5nQEanCmllAcaoJWlWbOi/VsnT9o0CTXZvjLc3UVYk6piBurZZ21w1qQWNo97SmtR3psVqpC3RSUWLoRbboHkZDhxwsaZN91UNJRevby73pwxCSWy7sfPS2HOmATPjUTg+HFOf7+TbucX8PRViYx9sAv9bu3BQc7ipds2MnOpptFQSqnS6BJnWQYMsMtskZHw3XfQvXvNtq+MNWuKfvZmv1ppXIMSb4IU5xmoJ5+0AU95c3fNmlW+4+uQ+fNLlu5MTS1ZVMKd8HCb8f/YMdizB5YtgyVLbAq2Xr1sCdCGXvztd8yAvZOdTJdBrVjx6q9M+6A/9w5K4vkrV3L0iHA0zXD0RCBHMxtz5HQzjuY25yjhnOK8wrMMOHO+v/Vbxz1vDq3cB6OUUvWAsYls64aIiAhJTk6u2pMeP27zcF18sf2/3Pr15buTr7LtlcKuEl93HTRqZGP9KVNsBhBPlap27bIll/7wB5uh5O67bSLZs8+G226z57rqqrKvm308m6nDEnlxyzAKCCjxvqGAsAYZhAeeoFVwJuHNsgkPzSO8pRDeJoDwswM5sPM0/17WjUlDvuO1xAuJnbtHi5UrpRRgjNkkIm7r/ukMWlmaN7ezRStXwtSp5Q+uKtte1XuO0p0jRtjnjqISjz/uuc2sWfDKK/brN2+encgcONC+FxFhbyYuTe6pXN6ctJ5/vNOZ3flRtA/Yy578dtzQ4RvunxlGeOfmhJ8fRotzmhAQEAaEuT1P/LwUpr/UmY/n7iR68nAudRQvJ0WDNKWUKoXuQfNGWJi9E7OiqSoq215ViiNPb21tlHfNE3zPPfD55963f+mlogLj3laqSk+348vPt0XKH3nErrDn58Mnn0CfPu7b5efks/Av67ggdD93vzWMto2PMWdMPFkFjZkxLIGv9nTj9LHTdIs+l/D2TQgoOalWjC1Wvqd4sfK5e0haVc6cdkopVd94KtLpj486WSxdVZqjrvymTSJTp9be9UVE1qwRGTfO+7b5+SKRkbZIubPp00uvlb5hg8iFF4o0bSoyapRIaqpIr14iPXuKPPqom+vk5sv7D3wtFwT9LCDSN3i7fD5jg3w1d5O0Mr9L3HObRUQk7rnNxZ4rpZSqOHy0WLpS1c45T+/69Xaj/KBBtrhDXl7NXj831+4F69TJZt/3hnPpTteiEqVlTxk0CLZtszcOr1xpcxxv2WJn1Z58sug4KRA+e2wD/UJ+4oZ/X4QxwuIpiWw63o0rnxhE8lfHdQZMKaVqgQZoqs5y5Ol11JUfONBmHtm40QZLS5fW7PXfegsuvNBuRdy4EV54oexzOJfunDChYpWq3JECYcWTyQxu/j1jnxrMqfxGvD3pa7Yc78y1zw6hQUP7q2Hq0qgSe8WiJ/dj6tKoil9cKaVUmTRAU9Xu0CF7IyvAzp32hta+fW3wUp1c8/T27m3vYgTvNsq7q/VenrKqrtdPSbFBVtu2MH68TXlRFufSnY6iEmvWwMsv41WSV3d5zP519Wo6B+3l8ukRHDodyoI/r2X78Xbc8vIfCQgqY1OZUkqpGqEBmh9wDnAAtm+HsWO9a+uaUb6y19+9226wHznSBhtlZWlJT7dVmjIz7fMXX4QnnrB5c1essCU6q4trnt7Ro73bKO/gWut90aKisqo7d5Yd4Lle/5VXbDuwCWS9yd07Z07JQC4+3r7uDedM/on/TaV/8HYmfzqCk/lNeOmG1exIa82dbwyjYWO9oVsppXyJ/lb20qFDNnfU2rUVb3/55XYWpTxcA5xffoGHHrJ7i7zhyCh/yy1w8802MIhwm3HFu+u/+qpNoHrBBTbgSU21M1OeBATYuw4dAWV4uN0Ldf75kJ1d+j6qvDw47zz7ALsk6G0GfCiZp/c//7GfgYjNATZqVOntXWu9v/02PPCAfe5NWVXX63/+Odx5pw30cnNh8eKyxzDwl0XEPHUNsR8HER1tg7OYcTnE3vARcCNgi1McOZDLgS2/s//7Yxz4OZP9v+Vw4ADsPxJIq8BjjHqwNwUEYChgUo/VPLdmEMEtR5TdAaWUUrVCAzQvuAYpFTFlSlHFp/JwDXBCQuDDDz0nKHXlmlG+ffvKXd95g/nRo9CqVentmzcv/vzyy22gtHevnYUrLZv9li22PNHs2eXrszuOwgdbtpS/raPWe6dOxcuqbt5c/ut/8EH5rh1941m8u+gmrvnTewztdZy45OaMKljB85915pHYHezPbM7B3HDyCATOKXwU9pGjnB10lPZNjxFkfmZLdnemDl7DM+ujytcJpZRSNU4DNC+4Binl5XwnX3m5Bjht2pSv/dCh8MUXNii64AIbWFTm+g7vvw89esA557h/35NnnoHYWLt/6r777J4qT5vdHXddlrc8UVVy1Hr/8EOb8LUmyqoe+uk4ie/9RmLcKRK3nUXS8bc5TRBL1tto+GuGcPbvhzkn+HcuaLOLc1rlcvY5hnM6BnJ212ac0yOMtr3b0LhtSzDhxM9LIWZKODOGJTB/XU8um6dJYpVSytdpgOYFT0GKNxx38n38MVx9ddX1yVuuGeXfeMPuHauMnTth7ly7x6q8fv3VzuS1aWNnoP70J8/HOu66dJQnWrrUu/JEruaMSWDgqNBiQUn8vBSSVmWUejeia633ipRVLevaeSdPk/rhDhK/SOObpEAS97VnZ24HoDeB5NCv0fdc0e47vjzQi9vzF7Co8Z3EftSM6NFlTF06XStmSvvCVBlRRGsmf6WU8gt6k0A1c72Tr6a5ZpT35s6/ss53003w+usVq1o1a5bdj9W6tV1uHTnS87HlvevSE+eN8lAUtAwcVfoAnGu9R0XZvWsLF9obB2JjbdHycl07L49P7v2Sqx88j+++E0aGJNEiJI/+f+7NvR9E8dXu8+kTvo9nL13Jurnrydh9nGeW9WX1if582vQWXphxhNig8cTc1MCrO0BBM/krpZTf8pTB1h8f1V1JYMSI8rcZNsy2GzFCJDRU5K67KnDh2bNlRJ+04n3pkyYye3aZTV0zyp84UYHrS9HYp04Vadu2aEwJCRU7nzeuv17k229F8vJEoqNFVq6s2HlOnRJ5IiZVGpMlQ8J/kBAy5N3HUktk5/dGWprI+++LHDhQxoEFBZLzy25Jfmal3N/1C2lElrTkd7FhnkgAuTIg5Ef564Bv5J0HNsqv3+yXgvySHZo94WeJaz5WJC7OvhAXJ3HNx8rsCT+Xv/NKKaV8CqVUEjBSVp4EPxIRESHJycnVdv6oqKLN3jXaPj7e1vJ8+227ke3gQZtIKzYWoqMr3iEft3Vr8bsunW9QKEtWRg7L/v0jHyzKZ8mOrpwsaEojTpNN4zPHtA5MZ+C5BxjYO5uBI0MYOK4dbTo0LnEub5ZI5cRJ9ixNZf1nh9mw0bBhV1s25fbiNMEANCWTTJoystUWHv9XGBFjz6VpiBcT2HPm2LVe5z/n+HhISrIZb5VSSvktY8wmEXGbW0EDNF/388+wbJlNyrVhQ9HrvXvb7KlRUXZTVOOSgUVVqWyMUFMxxqntu1j2rx/44IsmLNnfj0yaEc4Rrjl7PV07nGbOxiju7pnI/NRh3N4pgYyTDUk62pnv5QIcVc86BO5nYNs9DOyRxaCoJgwY14FNn+8n5qEOZ5YK4+du4vqpnXh0xNdkZ+ax4ccWbDh+AQex67GNTDYDwncxuGcmg0eFUHAik/vmnMukoVuZv65nsSVHpZRS9VdpAVqtL0tW5cOXi6XPnl20SuUQF+dmlfLkSZHPPxe5916RLl1EQGbzkMSdO15k4EC7PhYZKXHdJspsM9U+DwoSGT5c5PHHRb76yq7pOV97dHyJ4tZxz22W2aPjvep73IT3pFVotvMqm30+4T2v2q9aJRIebpcGDx+2XWzVquTn4YnH/l+2SjI/+VI+GPO6xIR8IU05ISDSqsERmXDBGlk562vJTTteosB3sed5eXJi8w5Z/T9xMvfipXLDOavlvIa/nVmKNOTLHwJ+lEuafSNNOSl9A7dKALkC+WeO6dpkj9zaO0VenLRVklamS3Z28X5qsXGllFLu4O9LnMaYBcCFwBci4rHITnXOoFX0TsAzx05cRMz7bhKOxnxI9P29Yfly+1izxt4+2KQJXHwxctnlLA++mvEPtGZewQP0vKknKe/9yFTzLC/8K4cRgesJ2riORokJBH27kUaSRYOgQFthOyoKRowgPqkZMY92KZoBKnZnXz9EbFLYrCw4fdo+HD9nZRZwevUG1j/xJU8zjZFDTrEqsSk3yzucFRPFyVadOHGCM4+TJynx3F3+uLYts+kaeph2ke0591xo144z/23Xzq7kOlJqnOnvs7uJvrIpS6d8xY1LxtOfFJKI4BRNaR10jGsi9nD93S0YcUs7GgYW3Q1RkT+7o78cI/mj3SStziQptTEbD7TnYK69c7JL0B5uHXOUwVe0YtC4c2kZ7vnOi8p+b5RSStVdfr3EaYy5BrhKRP5sjHkdeFpE3N7PV50BmmtQ4/x8+P39yMmxmfFzcij285nX1m9mw7RPeILHGXWx8OWKAm7OW0jrxsfJOBVIBqFkhLQnI7QDxxu3JiM/hIzjhowMGzyVR4DJJ8jk0qggiyByCCKHgoZBHMoLp2VQJkdzmtGy8SmkQQCncwPIygukQMp/Q6+hgGYmk2YBWYQEZRPSKIeQ4DyaNRFCQiAktAEhYQ1pln2UkPjPiO9xL18kt2VI19/pvCuBfR2GsDczjH1HGnE6t3jGlwamgLaN0jk38DDtGuyH06dZkR1FR3axnQsAQ5vgE1w7Mp3r7j2L4Zc0qtYcaXHPpRDzUEcm/XELr3yty5RKKaUqz98DtP8Ay0VkqTHmRiBYRN5wd2x170GLn5fCqAd705jTZBFMILnkE0B+JdLJNSCf5k3yCG0ZQGjLhoSGUvLxbQLNu53Nyt3d+fhjm5vrmu7byNnxGzmXXOE5MDyZTc7uQ2TvOUzO/iNsPtqe7fSgB6kMZiONOU1wg2waN4LgYKFxcAOCmxoaN21IcLMAGjcPIrh5II1DG/F9xrlMX9yXm3P/j/cCb2PhTcu4vFUyDdKO2JICzo+0tBJZXOOJIoZYJjGf+UwilhiiSQBAgDRaspd27GvQgb2Nz2dfYCf2BnRgr5zLvryz2Hu6FRm5TQGIaLObZ9/vwLBhNolwdSstONcgTSmlVEX5e4C2APiPiHxnjLkU6C8izzi9PwGYANChQ4cBu3btqtb+9A/aSkpuTwYFfcvws36kUYNcO1vVIJegBnlOP+cSZPKKvb81sxOzdt7KjQXvEBt0Gws/aMzoPzX0KjeZ40bOSZNsLczy3sDpCCom9U1k/rdDiJ35PdEPD/Lq5oIzy7ESQ/T9vYl/fgsxJvbMcm0JBQWQkQFHbPAWHw8xT/clttsMojfNJX7wI8R8P5PY6alED88vHo02aeI2WVv8vBSun9KBv/wxlVdreAZLlymVUkpVB7++SQB4Hogs/Pka4FFPx1b3TQKODd4zhsWXe6P3mY31zceKzJghcc3HFtt4X2bbVlJ8k345NtlXdqN6ZXNxzZ5trymtWonMmCHSqpXd5F92Grcq6b9SSinliyjlJoFaD8DKegC3AVMKf54F3Ozp2OoM0GozyPH6DlBP7St5F2elO1DJCLPS/VdKKaV8UGkBmj8scTYH1gJfAaOxs2lu69T48l2c9TrhaH0eu1JKKeWBX+9BAzDGhAGXAGtE5KCn4+pkolqllFJK1UmlBWjVmJig6ohIOhBb2/1QSimllKoJ5U9+pZRSSimlqpUGaEoppZRSPkYDNKWUUkopH6MBmlJKKaWUj9EATSmllFLKx/hFmg1vGWN+B6q31pPVCjhSA9fxRfV57ODf4/fnvleF+jx+HXv9VZ/H7w9j7ygird29UacCtJpijEn2lLekrqvPYwf/Hr8/970q1Ofx69jr59ihfo/f38euS5xKKaWUUj5GAzSllFJKKR+jAVrF/Le2O1CL6vPYwb/H7899rwr1efw69vqrPo/fr8eue9CUUkoppXyMzqAppZRSSvkYDdCUUkqpcjDGnG2MGWWMCantvqi6q84FaMaYUGPMMmPMl8aYj40xQcaYBcaYRGPMdE/HFL5e7LhSrlHiOGPMWcaYtWW062CMSTDGxBlj/muMMYWvX2CM+bTyo/e/8RtjzjXG7C18PcEY4zYfTB0de39jzCpjzNfGmAdro/+ezleVY/eGv43dGNPQGLPb6Xvbqx6NvbMx5gtjzFpjzHMVHbcfjb/Yd9wY0w14H/gjsLq0tnVw7LOcvvM/GGOmVXTsvj7+Uq5bJb/zvFHnAjTgFmCeiFwKHARuBAJEZAhwnjGmq5tjLjfGXOPmuBLcHWeMCQPeBJqW0beJwCQRGQm0B3oZY7oAzwKhlRy3g1+NHxgMPCkiUYWP3+vR2F8A7gCGAtcC99V0/92drxrG7o0a/7OrzNiB3sB7Tt/b1Ho09tnAP0RkGNDOGBNVibH7+vjdfcd7A3eIyCxgJ9C5voxdRGY6vvPAVuCtSozdp8fv4bpV+TuvTA1r4iI1SURednraGhgP/Lvw+ZfAUDfHHAZuBmKdjwN+cnOJKDfHfQjcAJQ6CyYijzk9DcdmOM7D/s95RWltveWH4x8PXGyMuRtYLiKPlnaOMs7vb2NvKSJ7AIwxR4HPROS7muy/h/O5U6ItXo7dG7XxZ1fJsQcDVxpjooFUYKKI5HkeoWd+OPZuwObC1w5TyX9c+vj483H5jovIYmNnUK8AwoCfSxtfafxt7A7GmIHAXhHZ56GtV3x5/B6O8/iZVIc6F6A5GGOGYP/y/AY4vkRpQH/XY0RkfWGAUOw4Y8yrQHen08ZhI+dix4nI8cLzOV//U4r/4npXRP5b+N4NwDYR2e90fGWGW4K/jN8Yswz4B3AKWGWM6S0iW+rJ2L82xvy18FydgC013X8P56vw2CvLX8YOfAWMEpEDxpi3gDHAZ5UYuj+NfTEw0xizHjv7UKllLte+4EPjF5EnCo9z7W4zIAZbWrDSqRD8bOwA9wMzyz9S93x8/GeOc2pbuQF7qU4GaMaYltjlo2uBydh/7YL9S9XAzTEAJ12PE5GJbs79vLvzuRKRsR76dh4wBRhVrkGVg5+N/xsRyS58LwXoSmGgUhF+NvaJQDTwBDBbRKQ2+u96vsqMvTL8bOxbHN9bIBn7va0wfxq7iPzTGDMUeAh4U0ROVmzUxa7jk+P3RESOAbcbYxYCA4EN3rZ10z+/GrsxpgXQRkR+8bZNGefz2fG7uW6NqnN70IzdyPcBME1EdgGbsNOfAH2A39wcg7vjPFzC2+Pc9S0MeA+4U0QyvG1XHn44/hXG3hHVBLgUu6+hQvxt7CKSD/xYeMg7tdF/D+fzqm1ZYy4PPxz7QmNMH2NMAHA18J2HtmXyw7EDfAt0AOZ5McRS+fj43fV3vjFmeOHTFsCx8rR3OZdfjb3QWGBpBdqV4Mvjr4LPqfJEpE49gElAOpBQ+Lgd+8tzHrAdu/TkeswNQHPX4zyc3+NxQEIZfZsNHHC67ghv29bV8WNnkH7Azpr9tT6NvfD1N4FhtdV/d+er6rH76p9dZcYO9MR+Z1OxN7nUm7EXvj4LuNVff2d5O35333HsTQHrgLXAjPo09sLn72K3ONTpP/vSjnP9TKrrUS8qCRTOXlwCrBGRgzV1nK+oz+P397H7Uv917Dr2mvr77kvjr2n1eeyg43dWLwI0pZRSSil/Uuf2oCmllFJK+TsN0JRSSimlfIwGaEopVU7GGP3dqZSqVvpLRimlvGSM6WaMaYS9+1YppapNnUxUq5RS5WVsEey+wAngHOAB4EYR2eZ0WAQwBGhhjLkSaIT9PXqZiNxZw11WStVhOoOmlFJWPhAiIstEZAE2z9lRx5vGmHCgR+FrX4vIEmw+qPeB07XRYaVU3aUBmlJKWfuBUGNMV2NMV+xM2iHHmyJyFIgHbsIGcwAFxpgBFNX7U0qpKqEBmlJKWflAP2AAkAsUAK5VkRtgizDnFT4PBk5RBQWzlVLKme5BU0opqzmwXkQWARhjwO4xyyq8MeAs7B61DKC9MSYaG6B1QX+XKqWqmM6gKaWU1QHoYoy52RhzJ9AbCCh872zgCmA4ti7fCeBr4GDhXrSQmu+uUqou01JPSikFGGOCsUWXDxY+XyAidzm9HwVkikiSU32/LUAa8IKI3FAL3VZK1VE6La+UUoCIZAFZTi9NcHk/welpM2yw9oMxpgfQtPp7qJSqT3QGTSmlyskYE1wY0DmeNxCRgtrsk1KqbtEATSmllFLKx+hNAkoppZRSPkYDNKWUUkopH6MBmlJKKaWUj9EATSmllFLKx2iAppRSSinlY/4/Z1Y2aYTjezEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新增治愈： [   1    4   11    8   12   18    5   45   20   46   73   85  147  156\n",
      "  260  262  386  510  599  632  715  744 1172  811 1374 1322 1426 1707\n",
      " 1525 1525 1528 1531 1536]\n",
      "新增确诊： [  293.   219.   251.   353.   558.   757.  1736.  1495.  1756.  1985.\n",
      "  2096.  2588.  2825.  3232.  3887.  3695.  3141.  3385.  2652.  2973.\n",
      "  2467.  2017. 15151.  4046.  2641.  2009.  2041.  1900.  1641.  1716.\n",
      "  1786.  1853.  1916.]\n"
     ]
    }
   ],
   "source": [
    "model = load_model_predict(model_city_date_path, data, param_pred=True, city_name=city_name,pred_date_len=5)\n",
    "# plot_param(model,city_name,data,xlen=15)\n",
    "# model_city_date_path 1618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "'''\n",
    "1.某个地方第一次训练设置load_param=False,之后默认为True  \n",
    "2.默认使用参数预测，use_param_pred=false\n",
    "3.param_date指定加载哪一天的模型参数,默认为''\n",
    "4.多次训练的时候可指定训练轮数和学习率，默认为2000,0.001\n",
    "'''\n",
    "def train_predict(N_init,city_name,param_date='',load_param=True,use_param_pred=True,eprochs=2000,lr_rate=0.001):\n",
    "    def get_today():\n",
    "        today = datetime.datetime.today()\n",
    "        today+=datetime.timedelta(days=-2)\n",
    "        format_datetime = lambda x :f'0{x.month}{x.day}' if x.month<10 else f'{x.month}-{x.day}'\n",
    "        return format_datetime(today)\n",
    "    city_pinyins={'北京':'beijing', '上海':'shanghai', '重庆':'chongqing'}\n",
    "    #获取今日日期的字符串  '02-13'格式\n",
    "    model_save_time=get_today()\n",
    "    city_pinyin=city_pinyins[city_name]\n",
    "    data=read_data('./ncov/data/'+city_pinyin+'_截至'+model_save_time+'_24时.csv')  ##这里需要把allcity里面的update_time 改成time\n",
    "    param_path=''\n",
    "    #默认为空 直接加载最近的参数 如果指定日期，则会加载指定日期的参数\n",
    "    if param_date!='':\n",
    "        param_path='models/'+city_pinyin+'/'+param_date\n",
    "    model_city_date_path = train_with_city_data(data,N_init,model_save_time,city_name,max_epoches=eprochs,is_train=True,load_param_save=load_param,lr_init=lr_rate,param_path=param_path)\n",
    "    model = load_model_predict(model_city_date_path, data, param_pred=use_param_pred, city_name=city_name,pred_date_len=5)\n",
    "    plot_param(model,city_name,data,xlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(model_city_date_path, data, param_pred=False, city_name='深圳',c='confirmed', features=['I','cured','dead'], pred_date_len=5, data_dict={'累计':{},'新增':{}},data_dict_report={'累计':{},'新增':{}}):\n",
    "    I_name,recover_name,dead_name = features\n",
    "    model_pt = os.path.join(model_city_date_path,'model.pt')\n",
    "    model = torch.load(model_pt)\n",
    "    I = model.I_tensor_cur\n",
    "    R = model.R_tensor_cur\n",
    "    D = model.D_tensor_cur\n",
    "    I_pred_old = (I.detach().numpy()).astype(np.int)\n",
    "    R_pred_old = (R.detach().numpy()).astype(np.int)\n",
    "    D_pred_old = (D.detach().numpy()).astype(np.int)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    # print(confirm_origin)\n",
    "    new_confirm = cal_new_confirm(np.array(data[I_name]),np.array(data[recover_name]),np.array(data[dead_name]))\n",
    "    cal_acc_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "    new_confirm_pred = cal_new_confirm(I_pred_old,R_pred_old,D_pred_old)\n",
    "\n",
    "    if param_pred:\n",
    "        beta = []\n",
    "        theta = []\n",
    "        gamma_2 = []\n",
    "        alpha = []\n",
    "        for i in range(len(model.SEIR_cells)):\n",
    "            beta.append(model.SEIR_cells[i].beta.detach().numpy()[0])\n",
    "            gamma_2.append(model.SEIR_cells[i].gamma_2.detach().numpy()[0])\n",
    "            theta.append(model.SEIR_cells[i].theta.detach().numpy()[0])\n",
    "            alpha.append(model.SEIR_cells[i].alpha.detach().numpy()[0])\n",
    "\n",
    "        param = model.param_pred(beta,gamma_2,theta,alpha)\n",
    "\n",
    "#         print(param)\n",
    "        S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(param=param, pred_date_len = pred_date_len)\n",
    "    else:\n",
    "        S_pred_tensor, I_pred_tensor, E_pred_tensor, R_pred_tensor, D_pred_tensor = model.pred(pred_date_len = pred_date_len)\n",
    "\n",
    "    I_pred_new = (I_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    R_pred_new = (R_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    D_pred_new = (D_pred_tensor.detach().numpy()).astype(np.int)\n",
    "    I_pred_total = np.concatenate((I_pred_old,I_pred_new),axis=0)\n",
    "    R_pred_total = np.concatenate((R_pred_old,R_pred_new),axis=0)\n",
    "    D_pred_total = np.concatenate((D_pred_old,D_pred_new),axis=0)\n",
    "\n",
    "    # plot_SEIRD(data, I=I_pred_total, R=R_pred_total, D=D_pred_total, city=city_name, pred_date_len=pred_date_len)\n",
    "\n",
    "    confirm_pred = cal_acc_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    confirm_origin = get_data_acc_confirm(data,c=c)\n",
    "    # plot_daily_acc(data, confirm_origin, confirm_pred, city=city_name, pred_date_len=pred_date_len)\n",
    "\n",
    "    new_confirm_pred_total = cal_new_confirm(I_pred_total,R_pred_total,D_pred_total)\n",
    "    new_confirm_pred_total\n",
    "    # plot_daily_new(data, new_confirm, new_confirm_pred_total, city=city_name, pred_date_len=pred_date_len)\n",
    "\n",
    "    T_name = 'time'\n",
    "    time_val = data[T_name].values\n",
    "\n",
    "    max_time_val = data[T_name].values.max()\n",
    "    pred_time = []\n",
    "    for i in range(1, pred_date_len + 1):\n",
    "        pred_time.append(max_time_val + np.timedelta64(i, 'D'))\n",
    "    if pred_time == []:\n",
    "        merge_time = time_val\n",
    "    else:\n",
    "        merge_time = np.concatenate((time_val, pred_time), axis=0)\n",
    "    # pd.to_datetime()\n",
    "    def format_datetime(x):\n",
    "        xd = x.date()\n",
    "        fxd = ''\n",
    "        if xd.month<10 and xd.day<10:\n",
    "            fxd = f'0{xd.month}-0{xd.day}'\n",
    "        elif xd.month<10 and xd.day>=10: \n",
    "            fxd = f'0{xd.month}-{xd.day}'\n",
    "        else:\n",
    "            fxd = f'{xd.month}-{xd.day}'\n",
    "        return fxd\n",
    "    dates_list = [format_datetime(pd.to_datetime(d)) for d in merge_time]\n",
    "    data_dict_report['累计'][city_name] = dict.fromkeys(dates_list)\n",
    "    data_dict_report['新增'][city_name] = dict.fromkeys(dates_list)\n",
    "    temp=[]\n",
    "    for i,p in enumerate(confirm_pred):\n",
    "        data_dict['累计'][city_name].append([dates_list[i],p])\n",
    "        data_dict_report['累计'][city_name][dates_list[i]]=p\n",
    "    for i,p in enumerate(new_confirm_pred_total):\n",
    "        data_dict['新增'][city_name].append([dates_list[i+1],p])\n",
    "        data_dict_report['新增'][city_name][dates_list[i+1]]=p\n",
    "    return data_dict,data_dict_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cured_ratio: 4.6625\n",
      "dead_ratio: 186.5\n",
      "{'beta': [1.1144036673161293, 1.0313712742559524, 0.9440478628729808, 0.7392976878675228, 0.6549396559330318, 0.6249162761748509, 0.5688449805350521, 0.549097888971826, 0.5423572551867236, 0.5298103579456542, 0.5337236052059547, 0.4527958824210194, 0.42337530364707454, 0.4342297419034859, 0.41621180027949667, 0.41148633369029364, 0.38080570962513455, 0.3332032762324669, 0.3425667127573697, 0.3346689006017409, 0.2649156173240452, 0.26452654033584444, 0.25130252544778575, 0.23613569550193084, 0.19995002673285134, 0.19674105909428388, 0.19667111449934102], 'theta': [-6.186870448159784e-06, 8.532919709545764e-06, -0.00019515736629323595, 0.0004303652831614029, -0.17398172568562645, -0.0005213921612508391, 8.327109241288152e-06, -1.9316829392759105e-05, 1.4573753690809278e-05, 9.424978868173384e-06, 7.72838064144831e-06, -7.14569381063755e-06, 6.8120241180138894e-06, 6.535928373884283e-06, -6.327529226134537e-06, 6.186062979900576e-06, 6.156385408427503e-06, -6.31388647283583e-06, 6.612627154420434e-06, 7.070454313054406e-06, 7.783758821500159e-06, -8.32830395381625e-06, -9.917747266889657e-06, -1.4518590771492489e-05, -6.040479703061024e-05, 4.253553504752157e-05, -6.139438038788202e-06], 'gamma_2': [3.830191507898429e-05, 6.882955663341792e-05, 0.00012345171134744466, 0.019211264416933778, -0.16449879622734093, 0.0697470016418378, 0.19301667111096504, 0.12680805432192996, 0.1147927470173533, 0.009210500571824577, -0.1813290993500685, -0.08418776470725009, 0.0030730756297409514, 3.440825919911563e-18, 0.10040731976171834, 0.11675614648456052, 0.20504165847159725, 0.14346144669617963, 0.20970557105573373, 0.10952857004096768, 0.12666875286023516, 0.14043931942703228, 0.12598153351907118, 0.1400515203354038, 0.33146459649864574, 0.3752373273803827, 0.2961942865942754], 'alpha': [0.9914360409947169, 1.1663955182205443, 1.0571637099424724, 1.1958853246824395, 1.012119996553708, 0.9661864028564016, 0.9046362659224871, 0.8498203309231787, 0.9333843019070157, 1.0355043106480757, 1.0026326041948106, 0.8324677495511814, 0.6333169388120594, 0.5286438456071667, 0.5846842986908966, 0.5052146951750519, 0.3901436380327939, 0.3186528485295882, 0.2876329972354759, 0.14080664078761726, 0.19990677024308537, 0.14570977098997007, 0.18674237677905378, 0.1546621722562232, 0.1924141553069939, 0.06894944929085248, 0.1382639932112387]}\n",
      "(29, 3)\n",
      "29\n",
      "Training step:  0\n",
      "Loss: 0.028281869292034422\n",
      "Training step:  1\n",
      "Loss: 0.02785318761091818\n",
      "Training step:  2\n",
      "Loss: 0.027287968146248703\n",
      "Training step:  3\n",
      "Loss: 0.026936865923489824\n",
      "Training step:  4\n",
      "Loss: 0.02653193085691763\n",
      "Training step:  5\n",
      "Loss: 0.02627494677604844\n",
      "Training step:  6\n",
      "Loss: 0.025967444240834445\n",
      "Training step:  7\n",
      "Loss: 0.025757384360640623\n",
      "Training step:  8\n",
      "Loss: 0.02546405065304592\n",
      "Training step:  9\n",
      "Loss: 0.025281245656421647\n",
      "Training step:  10\n",
      "Loss: 0.02500127315116187\n",
      "Training step:  11\n",
      "Loss: 0.024850490822484913\n",
      "Training step:  12\n",
      "Loss: 0.02458090608138192\n",
      "Training step:  13\n",
      "Loss: 0.024458799067305748\n",
      "Training step:  14\n",
      "Loss: 0.024200707903426304\n",
      "Training step:  15\n",
      "Loss: 0.024113531335576418\n",
      "Training step:  16\n",
      "Loss: 0.023859521712521852\n",
      "Training step:  17\n",
      "Loss: 0.02379391201083544\n",
      "Training step:  18\n",
      "Loss: 0.023533585641412426\n",
      "Training step:  19\n",
      "Loss: 0.02350015154131552\n",
      "Training step:  20\n",
      "Loss: 0.023239076799827885\n",
      "Training step:  21\n",
      "Loss: 0.023225830012581505\n",
      "Training step:  22\n",
      "Loss: 0.022966214995221106\n",
      "Training step:  23\n",
      "Loss: 0.02296761710028853\n",
      "Training step:  24\n",
      "Loss: 0.022709659106235732\n",
      "Training step:  25\n",
      "Loss: 0.02272706421407568\n",
      "Training step:  26\n",
      "Loss: 0.022472533647135567\n",
      "Training step:  27\n",
      "Loss: 0.02250221723683904\n",
      "Training step:  28\n",
      "Loss: 0.022250446365642083\n",
      "Training step:  29\n",
      "Loss: 0.022289798729186388\n",
      "Training step:  30\n",
      "Loss: 0.022041455495795777\n",
      "Training step:  31\n",
      "Loss: 0.022090795241711324\n",
      "Training step:  32\n",
      "Loss: 0.02184891753385622\n",
      "Training step:  33\n",
      "Loss: 0.021894694962467164\n",
      "Training step:  34\n",
      "Loss: 0.021665166301309255\n",
      "Training step:  35\n",
      "Loss: 0.021713951291056365\n",
      "Training step:  36\n",
      "Loss: 0.02149046905352827\n",
      "Training step:  37\n",
      "Loss: 0.021540583302192617\n",
      "Training step:  38\n",
      "Loss: 0.02132238741024142\n",
      "Training step:  39\n",
      "Loss: 0.02137028934469587\n",
      "Training step:  40\n",
      "Loss: 0.021161918673971075\n",
      "Training step:  41\n",
      "Loss: 0.021205370555445267\n",
      "Training step:  42\n",
      "Loss: 0.021007528627434296\n",
      "Training step:  43\n",
      "Loss: 0.021044974084534866\n",
      "Training step:  44\n",
      "Loss: 0.020858588366723763\n",
      "Training step:  45\n",
      "Loss: 0.020892916477099312\n",
      "Training step:  46\n",
      "Loss: 0.020715454304690923\n",
      "Training step:  47\n",
      "Loss: 0.020749966221462975\n",
      "Training step:  48\n",
      "Loss: 0.020576836228156647\n",
      "Training step:  49\n",
      "Loss: 0.020611311884630987\n",
      "Training step:  50\n",
      "Loss: 0.020443287301029754\n",
      "Training step:  51\n",
      "Loss: 0.020476127994826444\n",
      "Training step:  52\n",
      "Loss: 0.02031503056099963\n",
      "Training step:  53\n",
      "Loss: 0.02034747469606556\n",
      "Training step:  54\n",
      "Loss: 0.020191395419418695\n",
      "Training step:  55\n",
      "Loss: 0.02022570091115885\n",
      "Training step:  56\n",
      "Loss: 0.020072738245297768\n",
      "Training step:  57\n",
      "Loss: 0.020108906984914594\n",
      "Training step:  58\n",
      "Loss: 0.019958985017174895\n",
      "Training step:  59\n",
      "Loss: 0.01999706658247473\n",
      "Training step:  60\n",
      "Loss: 0.01985369128914896\n",
      "Training step:  61\n",
      "Loss: 0.01988407487774814\n",
      "Training step:  62\n",
      "Loss: 0.019755386225650637\n",
      "Training step:  63\n",
      "Loss: 0.019782821726353244\n",
      "Training step:  64\n",
      "Loss: 0.01965843783300552\n",
      "Training step:  65\n",
      "Loss: 0.019685291441319915\n",
      "Training step:  66\n",
      "Loss: 0.01956099338547522\n",
      "Training step:  67\n",
      "Loss: 0.019586638441147348\n",
      "Training step:  68\n",
      "Loss: 0.019464773525587696\n",
      "Training step:  69\n",
      "Loss: 0.019488348956173088\n",
      "Training step:  70\n",
      "Loss: 0.01936971747598536\n",
      "Training step:  71\n",
      "Loss: 0.019391789388760287\n",
      "Training step:  72\n",
      "Loss: 0.019275554177373297\n",
      "Training step:  73\n",
      "Loss: 0.019296331804863297\n",
      "Training step:  74\n",
      "Loss: 0.01918247512807512\n",
      "Training step:  75\n",
      "Loss: 0.019201971319425384\n",
      "Training step:  76\n",
      "Loss: 0.019090475534284796\n",
      "Training step:  77\n",
      "Loss: 0.019094741602683298\n",
      "Training step:  78\n",
      "Loss: 0.019000240737573816\n",
      "Training step:  79\n",
      "Loss: 0.019002173105114945\n",
      "Training step:  80\n",
      "Loss: 0.018909754074790893\n",
      "Training step:  81\n",
      "Loss: 0.01891046516106555\n",
      "Training step:  82\n",
      "Loss: 0.018820334023400248\n",
      "Training step:  83\n",
      "Loss: 0.018820796951044175\n",
      "Training step:  84\n",
      "Loss: 0.018731935671018503\n",
      "Training step:  85\n",
      "Loss: 0.018731440675491057\n",
      "Training step:  86\n",
      "Loss: 0.018644635907075963\n",
      "Training step:  87\n",
      "Loss: 0.018643680060421546\n",
      "Training step:  88\n",
      "Loss: 0.018558121151339427\n",
      "Training step:  89\n",
      "Loss: 0.018536498864714805\n",
      "Training step:  90\n",
      "Loss: 0.01847348829845428\n",
      "Training step:  91\n",
      "Loss: 0.018449602899156613\n",
      "Training step:  92\n",
      "Loss: 0.01838778559212722\n",
      "Training step:  93\n",
      "Loss: 0.01836370764188898\n",
      "Training step:  94\n",
      "Loss: 0.01830307252324289\n",
      "Training step:  95\n",
      "Loss: 0.018271616227801775\n",
      "Training step:  96\n",
      "Loss: 0.018217307693496537\n",
      "Training step:  97\n",
      "Loss: 0.018187067891781167\n",
      "Training step:  98\n",
      "Loss: 0.018131984636948414\n",
      "Training step:  99\n",
      "Loss: 0.018096091160220398\n",
      "Training step:  100\n",
      "Loss: 0.018047273182521736\n",
      "Training step:  101\n",
      "Loss: 0.018012769383896236\n",
      "Training step:  102\n",
      "Loss: 0.017955339340350956\n",
      "Training step:  103\n",
      "Loss: 0.01792289656525906\n",
      "Training step:  104\n",
      "Loss: 0.017871539631662405\n",
      "Training step:  105\n",
      "Loss: 0.01783363491687903\n",
      "Training step:  106\n",
      "Loss: 0.017788446667578825\n",
      "Training step:  107\n",
      "Loss: 0.017751794152394806\n",
      "Training step:  108\n",
      "Loss: 0.017698003563762325\n",
      "Training step:  109\n",
      "Loss: 0.017663594265286256\n",
      "Training step:  110\n",
      "Loss: 0.017615818668467037\n",
      "Training step:  111\n",
      "Loss: 0.017582882055289656\n",
      "Training step:  112\n",
      "Loss: 0.017534271015515076\n",
      "Training step:  113\n",
      "Loss: 0.017495665046708967\n",
      "Training step:  114\n",
      "Loss: 0.01744535874239542\n",
      "Training step:  115\n",
      "Loss: 0.017409122950519496\n",
      "Training step:  116\n",
      "Loss: 0.017364765619597326\n",
      "Training step:  117\n",
      "Loss: 0.01732986839092444\n",
      "Training step:  118\n",
      "Loss: 0.01728465097783388\n",
      "Training step:  119\n",
      "Loss: 0.017244324932964683\n",
      "Training step:  120\n",
      "Loss: 0.017197367253643667\n",
      "Training step:  121\n",
      "Loss: 0.017166229811906644\n",
      "Training step:  122\n",
      "Loss: 0.01711835524027192\n",
      "Training step:  123\n",
      "Loss: 0.017081626194084244\n",
      "Training step:  124\n",
      "Loss: 0.017039646828995857\n",
      "Training step:  125\n",
      "Loss: 0.016997737992283293\n",
      "Training step:  126\n",
      "Loss: 0.01695397276073403\n",
      "Training step:  127\n",
      "Loss: 0.01692105797094425\n",
      "Training step:  128\n",
      "Loss: 0.016876372400905098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  129\n",
      "Loss: 0.016838100223240348\n",
      "Training step:  130\n",
      "Loss: 0.01679172270134777\n",
      "Training step:  131\n",
      "Loss: 0.01676261813284692\n",
      "Training step:  132\n",
      "Loss: 0.01671520914371254\n",
      "Training step:  133\n",
      "Loss: 0.016680585642812863\n",
      "Training step:  134\n",
      "Loss: 0.016638939348286294\n",
      "Training step:  135\n",
      "Loss: 0.016599256089774885\n",
      "Training step:  136\n",
      "Loss: 0.0165558721477993\n",
      "Training step:  137\n",
      "Loss: 0.01652517339956195\n",
      "Training step:  138\n",
      "Loss: 0.016480750043164936\n",
      "Training step:  139\n",
      "Loss: 0.01644476012756277\n",
      "Training step:  140\n",
      "Loss: 0.016406011648605758\n",
      "Training step:  141\n",
      "Loss: 0.016365065865989813\n",
      "Training step:  142\n",
      "Loss: 0.01632451077012013\n",
      "Training step:  143\n",
      "Loss: 0.016292377132766427\n",
      "Training step:  144\n",
      "Loss: 0.016250729032294277\n",
      "Training step:  145\n",
      "Loss: 0.016213553401038475\n",
      "Training step:  146\n",
      "Loss: 0.016177450994814303\n",
      "Training step:  147\n",
      "Loss: 0.01614236081631499\n",
      "Training step:  148\n",
      "Loss: 0.016104726797963057\n",
      "Training step:  149\n",
      "Loss: 0.016065002436032354\n",
      "Training step:  150\n",
      "Loss: 0.01602498816423439\n",
      "Training step:  151\n",
      "Loss: 0.015988273395359163\n",
      "Training step:  152\n",
      "Loss: 0.01595311963744675\n",
      "Training step:  153\n",
      "Loss: 0.015918347793587306\n",
      "Training step:  154\n",
      "Loss: 0.015881648456872392\n",
      "Training step:  155\n",
      "Loss: 0.015842459397929012\n",
      "Training step:  156\n",
      "Loss: 0.01580342733645125\n",
      "Training step:  157\n",
      "Loss: 0.015773656979537993\n",
      "Training step:  158\n",
      "Loss: 0.0157329371861173\n",
      "Training step:  159\n",
      "Loss: 0.01569859099374433\n",
      "Training step:  160\n",
      "Loss: 0.01566271320783683\n",
      "Training step:  161\n",
      "Loss: 0.015624153550131865\n",
      "Training step:  162\n",
      "Loss: 0.015592580669430551\n",
      "Training step:  163\n",
      "Loss: 0.015556800917536273\n",
      "Training step:  164\n",
      "Loss: 0.015516254582269339\n",
      "Training step:  165\n",
      "Loss: 0.015483254045840826\n",
      "Training step:  166\n",
      "Loss: 0.015447340934044906\n",
      "Training step:  167\n",
      "Loss: 0.015410191461407848\n",
      "Training step:  168\n",
      "Loss: 0.015379013002671634\n",
      "Training step:  169\n",
      "Loss: 0.015343840076723951\n",
      "Training step:  170\n",
      "Loss: 0.015311078502926994\n",
      "Training step:  171\n",
      "Loss: 0.015271665402271452\n",
      "Training step:  172\n",
      "Loss: 0.015236501947071409\n",
      "Training step:  173\n",
      "Loss: 0.015206379254778992\n",
      "Training step:  174\n",
      "Loss: 0.015169519832233008\n",
      "Training step:  175\n",
      "Loss: 0.015135000018906372\n",
      "Training step:  176\n",
      "Loss: 0.015102747746119255\n",
      "Training step:  177\n",
      "Loss: 0.015064230793911238\n",
      "Training step:  178\n",
      "Loss: 0.015036583388705572\n",
      "Training step:  179\n",
      "Loss: 0.01500006832410608\n",
      "Training step:  180\n",
      "Loss: 0.014970814121473632\n",
      "Training step:  181\n",
      "Loss: 0.014930163299858721\n",
      "Training step:  182\n",
      "Loss: 0.01489843712053573\n",
      "Training step:  183\n",
      "Loss: 0.0148669996305782\n",
      "Training step:  184\n",
      "Loss: 0.01483357167425644\n",
      "Training step:  185\n",
      "Loss: 0.014797877364368592\n",
      "Training step:  186\n",
      "Loss: 0.014768962530357036\n",
      "Training step:  187\n",
      "Loss: 0.01472934440773044\n",
      "Training step:  188\n",
      "Loss: 0.014704915197507096\n",
      "Training step:  189\n",
      "Loss: 0.014667326947846311\n",
      "Training step:  190\n",
      "Loss: 0.014634360285875305\n",
      "Training step:  191\n",
      "Loss: 0.014599667514932363\n",
      "Training step:  192\n",
      "Loss: 0.014571045294694066\n",
      "Training step:  193\n",
      "Loss: 0.014538568007278176\n",
      "Training step:  194\n",
      "Loss: 0.014508286228435939\n",
      "Training step:  195\n",
      "Loss: 0.014471650756017349\n",
      "Training step:  196\n",
      "Loss: 0.014445763299975718\n",
      "Training step:  197\n",
      "Loss: 0.014405311023162526\n",
      "Training step:  198\n",
      "Loss: 0.014376960795742171\n",
      "Training step:  199\n",
      "Loss: 0.014345466521827263\n",
      "Training step:  200\n",
      "Loss: 0.014315379707379857\n",
      "Training step:  201\n",
      "Loss: 0.014279880522417195\n",
      "Training step:  202\n",
      "Loss: 0.014254121325950624\n",
      "Training step:  203\n",
      "Loss: 0.014220865722856166\n",
      "Training step:  204\n",
      "Loss: 0.014193427815938306\n",
      "Training step:  205\n",
      "Loss: 0.014156107002799815\n",
      "Training step:  206\n",
      "Loss: 0.014132950141016114\n",
      "Training step:  207\n",
      "Loss: 0.014091914358882924\n",
      "Training step:  208\n",
      "Loss: 0.014066249721789869\n",
      "Training step:  209\n",
      "Loss: 0.014034105270474996\n",
      "Training step:  210\n",
      "Loss: 0.014006710299184771\n",
      "Training step:  211\n",
      "Loss: 0.013970651041124748\n",
      "Training step:  212\n",
      "Loss: 0.01394747046499198\n",
      "Training step:  213\n",
      "Loss: 0.01391367861651894\n",
      "Training step:  214\n",
      "Loss: 0.013888807617865116\n",
      "Training step:  215\n",
      "Loss: 0.013851033236917581\n",
      "Training step:  216\n",
      "Loss: 0.01383032217572194\n",
      "Training step:  217\n",
      "Loss: 0.013788942791014846\n",
      "Training step:  218\n",
      "Loss: 0.013765687996148043\n",
      "Training step:  219\n",
      "Loss: 0.013733136308462542\n",
      "Training step:  220\n",
      "Loss: 0.013708154711971532\n",
      "Training step:  221\n",
      "Loss: 0.013671769338316372\n",
      "Training step:  222\n",
      "Loss: 0.013650893109852083\n",
      "Training step:  223\n",
      "Loss: 0.013610953866600517\n",
      "Training step:  224\n",
      "Loss: 0.013594121639421376\n",
      "Training step:  225\n",
      "Loss: 0.013556215932172265\n",
      "Training step:  226\n",
      "Loss: 0.013531150702896793\n",
      "Training step:  227\n",
      "Loss: 0.013496231438386009\n",
      "Training step:  228\n",
      "Loss: 0.013475090523369591\n",
      "Training step:  229\n",
      "Loss: 0.013442350609200331\n",
      "Training step:  230\n",
      "Loss: 0.013419518443988093\n",
      "Training step:  231\n",
      "Loss: 0.01338480666961037\n",
      "Training step:  232\n",
      "Loss: 0.013364121152981074\n",
      "Training step:  233\n",
      "Loss: 0.013333479725738992\n",
      "Training step:  234\n",
      "Loss: 0.013309229304913217\n",
      "Training step:  235\n",
      "Loss: 0.013276650328247317\n",
      "Training step:  236\n",
      "Loss: 0.013254519935939258\n",
      "Training step:  237\n",
      "Loss: 0.01322034618313561\n",
      "Training step:  238\n",
      "Loss: 0.013200321542883219\n",
      "Training step:  239\n",
      "Loss: 0.013168124466975614\n",
      "Training step:  240\n",
      "Loss: 0.013146405790309566\n",
      "Training step:  241\n",
      "Loss: 0.013112497981940068\n",
      "Training step:  242\n",
      "Loss: 0.013092859172773492\n",
      "Training step:  243\n",
      "Loss: 0.013062793785492924\n",
      "Training step:  244\n",
      "Loss: 0.013039617014845833\n",
      "Training step:  245\n",
      "Loss: 0.013007870649870846\n",
      "Training step:  246\n",
      "Loss: 0.012986746790506078\n",
      "Training step:  247\n",
      "Loss: 0.012958874645149237\n",
      "Training step:  248\n",
      "Loss: 0.01293425264161678\n",
      "Training step:  249\n",
      "Loss: 0.012904642633725831\n",
      "Training step:  250\n",
      "Loss: 0.012882055258539457\n",
      "Training step:  251\n",
      "Loss: 0.01285635294728502\n",
      "Training step:  252\n",
      "Loss: 0.012830280535998181\n",
      "Training step:  253\n",
      "Loss: 0.012802811830488248\n",
      "Training step:  254\n",
      "Loss: 0.012778751801850933\n",
      "Training step:  255\n",
      "Loss: 0.012753479753558157\n",
      "Training step:  256\n",
      "Loss: 0.012727703072916267\n",
      "Training step:  257\n",
      "Loss: 0.012700600630617506\n",
      "Training step:  258\n",
      "Loss: 0.012676808757474064\n",
      "Training step:  259\n",
      "Loss: 0.012648226954199959\n",
      "Training step:  260\n",
      "Loss: 0.012626406367702611\n",
      "Training step:  261\n",
      "Loss: 0.012601517568352904\n",
      "Training step:  262\n",
      "Loss: 0.012576238187870714\n",
      "Training step:  263\n",
      "Loss: 0.012549822873330264\n",
      "Training step:  264\n",
      "Loss: 0.012526493291755057\n",
      "Training step:  265\n",
      "Loss: 0.012502082528956864\n",
      "Training step:  266\n",
      "Loss: 0.012477035993503263\n",
      "Training step:  267\n",
      "Loss: 0.012451038978097025\n",
      "Training step:  268\n",
      "Loss: 0.012427914561496323\n",
      "Training step:  269\n",
      "Loss: 0.012405724082643892\n",
      "Training step:  270\n",
      "Loss: 0.012379164478295747\n",
      "Training step:  271\n",
      "Loss: 0.012355347056408669\n",
      "Training step:  272\n",
      "Loss: 0.012330692335099931\n",
      "Training step:  273\n",
      "Loss: 0.012310716046808822\n",
      "Training step:  274\n",
      "Loss: 0.012282639479312796\n",
      "Training step:  275\n",
      "Loss: 0.012261005000724206\n",
      "Training step:  276\n",
      "Loss: 0.012234812572881108\n",
      "Training step:  277\n",
      "Loss: 0.012215367703636286\n",
      "Training step:  278\n",
      "Loss: 0.012187461557177355\n",
      "Training step:  279\n",
      "Loss: 0.012166293529148171\n",
      "Training step:  280\n",
      "Loss: 0.012140246081556822\n",
      "Training step:  281\n",
      "Loss: 0.01211770606520248\n",
      "Training step:  282\n",
      "Loss: 0.012093075399101419\n",
      "Training step:  283\n",
      "Loss: 0.012074838643234003\n",
      "Training step:  284\n",
      "Loss: 0.012046635281796819\n",
      "Training step:  285\n",
      "Loss: 0.01202684363792726\n",
      "Training step:  286\n",
      "Loss: 0.012000466829253568\n",
      "Training step:  287\n",
      "Loss: 0.011984464557671591\n",
      "Training step:  288\n",
      "Loss: 0.01195468616825314\n",
      "Training step:  289\n",
      "Loss: 0.011937122673295674\n",
      "Training step:  290\n",
      "Loss: 0.011909147801590086\n",
      "Training step:  291\n",
      "Loss: 0.011893748044122488\n",
      "Training step:  292\n",
      "Loss: 0.01186409282580222\n",
      "Training step:  293\n",
      "Loss: 0.011847022869265506\n",
      "Training step:  294\n",
      "Loss: 0.011819148611464053\n",
      "Training step:  295\n",
      "Loss: 0.011800774809267743\n",
      "Training step:  296\n",
      "Loss: 0.011774670294465338\n",
      "Training step:  297\n",
      "Loss: 0.011758255570159668\n",
      "Training step:  298\n",
      "Loss: 0.011730440668381192\n",
      "Training step:  299\n",
      "Loss: 0.011712623095764098\n",
      "Training step:  300\n",
      "Loss: 0.01168655719133309\n",
      "Training step:  301\n",
      "Loss: 0.011672413289879061\n",
      "Training step:  302\n",
      "Loss: 0.011643004962901453\n",
      "Training step:  303\n",
      "Loss: 0.011627412869849073\n",
      "Training step:  304\n",
      "Loss: 0.011599733521027781\n",
      "Training step:  305\n",
      "Loss: 0.01158785529357189\n",
      "Training step:  306\n",
      "Loss: 0.011556847326579767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  307\n",
      "Loss: 0.011543485994222126\n",
      "Training step:  308\n",
      "Loss: 0.011514188350541216\n",
      "Training step:  309\n",
      "Loss: 0.01150296380187029\n",
      "Training step:  310\n",
      "Loss: 0.011471961499573328\n",
      "Training step:  311\n",
      "Loss: 0.011459196425827352\n",
      "Training step:  312\n",
      "Loss: 0.011429881897814319\n",
      "Training step:  313\n",
      "Loss: 0.011415889587610034\n",
      "Training step:  314\n",
      "Loss: 0.011388250488335054\n",
      "Training step:  315\n",
      "Loss: 0.011376194879639685\n",
      "Training step:  316\n",
      "Loss: 0.011346873060272591\n",
      "Training step:  317\n",
      "Loss: 0.011333482159115138\n",
      "Training step:  318\n",
      "Loss: 0.011305815163646362\n",
      "Training step:  319\n",
      "Loss: 0.01129603446076413\n",
      "Training step:  320\n",
      "Loss: 0.011265054673849586\n",
      "Training step:  321\n",
      "Loss: 0.011253939459117148\n",
      "Training step:  322\n",
      "Loss: 0.011224594673090811\n",
      "Training step:  323\n",
      "Loss: 0.011217119043149712\n",
      "Training step:  324\n",
      "Loss: 0.011184504285164345\n",
      "Training step:  325\n",
      "Loss: 0.011175634169980048\n",
      "Training step:  326\n",
      "Loss: 0.011144638851915693\n",
      "Training step:  327\n",
      "Loss: 0.011137879191119797\n",
      "Training step:  328\n",
      "Loss: 0.011105187823218935\n",
      "Training step:  329\n",
      "Loss: 0.011096978946603001\n",
      "Training step:  330\n",
      "Loss: 0.011065884313846613\n",
      "Training step:  331\n",
      "Loss: 0.011056523578679119\n",
      "Training step:  332\n",
      "Loss: 0.011027015016561203\n",
      "Training step:  333\n",
      "Loss: 0.011019571590196594\n",
      "Training step:  334\n",
      "Loss: 0.010988387195859537\n",
      "Training step:  335\n",
      "Loss: 0.010979692027722655\n",
      "Training step:  336\n",
      "Loss: 0.010950074273300397\n",
      "Training step:  337\n",
      "Loss: 0.010944930260647473\n",
      "Training step:  338\n",
      "Loss: 0.010912076052747336\n",
      "Training step:  339\n",
      "Loss: 0.010905648537131184\n",
      "Training step:  340\n",
      "Loss: 0.0108758914878855\n",
      "Training step:  341\n",
      "Loss: 0.010871497819837728\n",
      "Training step:  342\n",
      "Loss: 0.010838513020676316\n",
      "Training step:  343\n",
      "Loss: 0.010832790522072182\n",
      "Training step:  344\n",
      "Loss: 0.010802898031500932\n",
      "Training step:  345\n",
      "Loss: 0.010799239651781789\n",
      "Training step:  346\n",
      "Loss: 0.010766136913094668\n",
      "Training step:  347\n",
      "Loss: 0.010761103342537135\n",
      "Training step:  348\n",
      "Loss: 0.010731067433992969\n",
      "Training step:  349\n",
      "Loss: 0.010723381377331481\n",
      "Training step:  350\n",
      "Loss: 0.010696382777445276\n",
      "Training step:  351\n",
      "Loss: 0.010690572994140439\n",
      "Training step:  352\n",
      "Loss: 0.010660371236064673\n",
      "Training step:  353\n",
      "Loss: 0.010653415180749559\n",
      "Training step:  354\n",
      "Loss: 0.010626245603890352\n",
      "Training step:  355\n",
      "Loss: 0.010621197538204265\n",
      "Training step:  356\n",
      "Loss: 0.010590842154392283\n",
      "Training step:  357\n",
      "Loss: 0.010584600206828583\n",
      "Training step:  358\n",
      "Loss: 0.010557232210335669\n",
      "Training step:  359\n",
      "Loss: 0.010552972200713924\n",
      "Training step:  360\n",
      "Loss: 0.010522434099117368\n",
      "Training step:  361\n",
      "Loss: 0.010516930961162097\n",
      "Training step:  362\n",
      "Loss: 0.010489371670959643\n",
      "Training step:  363\n",
      "Loss: 0.010485885371689894\n",
      "Training step:  364\n",
      "Loss: 0.010455173618116525\n",
      "Training step:  365\n",
      "Loss: 0.010450396875725876\n",
      "Training step:  366\n",
      "Loss: 0.010422639173986871\n",
      "Training step:  367\n",
      "Loss: 0.010415310066527848\n",
      "Training step:  368\n",
      "Loss: 0.010390479586049009\n",
      "Training step:  369\n",
      "Loss: 0.010384985113899544\n",
      "Training step:  370\n",
      "Loss: 0.010357010914184148\n",
      "Training step:  371\n",
      "Loss: 0.010350443226267974\n",
      "Training step:  372\n",
      "Loss: 0.010325391294231216\n",
      "Training step:  373\n",
      "Loss: 0.010320691900865864\n",
      "Training step:  374\n",
      "Loss: 0.010292510889673624\n",
      "Training step:  375\n",
      "Loss: 0.010286692559429248\n",
      "Training step:  376\n",
      "Loss: 0.010261390544348398\n",
      "Training step:  377\n",
      "Loss: 0.010257513676586772\n",
      "Training step:  378\n",
      "Loss: 0.010229096363212188\n",
      "Training step:  379\n",
      "Loss: 0.010224052635289867\n",
      "Training step:  380\n",
      "Loss: 0.010198508038581447\n",
      "Training step:  381\n",
      "Loss: 0.010195439400118515\n",
      "Training step:  382\n",
      "Loss: 0.01016679773682473\n",
      "Training step:  383\n",
      "Loss: 0.010162513392539273\n",
      "Training step:  384\n",
      "Loss: 0.01013671976368569\n",
      "Training step:  385\n",
      "Loss: 0.010129974576241358\n",
      "Training step:  386\n",
      "Loss: 0.010107002173612089\n",
      "Training step:  387\n",
      "Loss: 0.010102060405377882\n",
      "Training step:  388\n",
      "Loss: 0.01007600023196454\n",
      "Training step:  389\n",
      "Loss: 0.010070050093746879\n",
      "Training step:  390\n",
      "Loss: 0.010046804995632604\n",
      "Training step:  391\n",
      "Loss: 0.010042693093034275\n",
      "Training step:  392\n",
      "Loss: 0.010016377925530938\n",
      "Training step:  393\n",
      "Loss: 0.010011207916543153\n",
      "Training step:  394\n",
      "Loss: 0.00998766558507916\n",
      "Training step:  395\n",
      "Loss: 0.009984406326760694\n",
      "Training step:  396\n",
      "Loss: 0.009957807920243112\n",
      "Training step:  397\n",
      "Loss: 0.009953442161441662\n",
      "Training step:  398\n",
      "Loss: 0.009929612142927154\n",
      "Training step:  399\n",
      "Loss: 0.009927190024125808\n",
      "Training step:  400\n",
      "Loss: 0.009900322950155735\n",
      "Training step:  401\n",
      "Loss: 0.009896743704146161\n",
      "Training step:  402\n",
      "Loss: 0.009872601699606662\n",
      "Training step:  403\n",
      "Loss: 0.009866669666575878\n",
      "Training step:  404\n",
      "Loss: 0.00984526320500608\n",
      "Training step:  405\n",
      "Loss: 0.009841094037685905\n",
      "Training step:  406\n",
      "Loss: 0.009816662179420146\n",
      "Training step:  407\n",
      "Loss: 0.009811533441935045\n",
      "Training step:  408\n",
      "Loss: 0.009789811528886638\n",
      "Training step:  409\n",
      "Loss: 0.009786500403535061\n",
      "Training step:  410\n",
      "Loss: 0.009761752858357082\n",
      "Training step:  411\n",
      "Loss: 0.009757449321011144\n",
      "Training step:  412\n",
      "Loss: 0.009735385911999635\n",
      "Training step:  413\n",
      "Loss: 0.009732953537487278\n",
      "Training step:  414\n",
      "Loss: 0.009707902432776493\n",
      "Training step:  415\n",
      "Loss: 0.009704405364011515\n",
      "Training step:  416\n",
      "Loss: 0.009682016387422693\n",
      "Training step:  417\n",
      "Loss: 0.009680444668600548\n",
      "Training step:  418\n",
      "Loss: 0.009656495855338424\n",
      "Training step:  419\n",
      "Loss: 0.009652390146945328\n",
      "Training step:  420\n",
      "Loss: 0.009629656511502008\n",
      "Training step:  421\n",
      "Loss: 0.009624704460867363\n",
      "Training step:  422\n",
      "Loss: 0.009604601333333403\n",
      "Training step:  423\n",
      "Loss: 0.009601400121103635\n",
      "Training step:  424\n",
      "Loss: 0.00957833447654004\n",
      "Training step:  425\n",
      "Loss: 0.00957420971255403\n",
      "Training step:  426\n",
      "Loss: 0.009553750914583558\n",
      "Training step:  427\n",
      "Loss: 0.009551431949419252\n",
      "Training step:  428\n",
      "Loss: 0.00952942587414144\n",
      "Training step:  429\n",
      "Loss: 0.009524725629885688\n",
      "Training step:  430\n",
      "Loss: 0.009503897129172326\n",
      "Training step:  431\n",
      "Loss: 0.00950247744518753\n",
      "Training step:  432\n",
      "Loss: 0.009480115317756976\n",
      "Training step:  433\n",
      "Loss: 0.009476255044677627\n",
      "Training step:  434\n",
      "Loss: 0.009455062538179\n",
      "Training step:  435\n",
      "Loss: 0.009450396636434696\n",
      "Training step:  436\n",
      "Loss: 0.00943174099501343\n",
      "Training step:  437\n",
      "Loss: 0.009428782729363393\n",
      "Training step:  438\n",
      "Loss: 0.009408606246356447\n",
      "Training step:  439\n",
      "Loss: 0.009403398231716372\n",
      "Training step:  440\n",
      "Loss: 0.009384363926564176\n",
      "Training step:  441\n",
      "Loss: 0.009382305446515733\n",
      "Training step:  442\n",
      "Loss: 0.009361735090424376\n",
      "Training step:  443\n",
      "Loss: 0.009357397446495025\n",
      "Training step:  444\n",
      "Loss: 0.009337960642992929\n",
      "Training step:  445\n",
      "Loss: 0.00933681814237044\n",
      "Training step:  446\n",
      "Loss: 0.009315862423506845\n",
      "Training step:  447\n",
      "Loss: 0.00931238053225856\n",
      "Training step:  448\n",
      "Loss: 0.009293928333786622\n",
      "Training step:  449\n",
      "Loss: 0.009292310691149757\n",
      "Training step:  450\n",
      "Loss: 0.00927095260679197\n",
      "Training step:  451\n",
      "Loss: 0.00926834397664886\n",
      "Training step:  452\n",
      "Loss: 0.00924946747040678\n",
      "Training step:  453\n",
      "Loss: 0.009244721792236643\n",
      "Training step:  454\n",
      "Loss: 0.00922831433066831\n",
      "Training step:  455\n",
      "Loss: 0.009225273321063925\n",
      "Training step:  456\n",
      "Loss: 0.009205988071260685\n",
      "Training step:  457\n",
      "Loss: 0.009202112785259411\n",
      "Training step:  458\n",
      "Loss: 0.00918527970571923\n",
      "Training step:  459\n",
      "Loss: 0.009183163277256965\n",
      "Training step:  460\n",
      "Loss: 0.009163454608316569\n",
      "Training step:  461\n",
      "Loss: 0.00916046633601081\n",
      "Training step:  462\n",
      "Loss: 0.009143187389657524\n",
      "Training step:  463\n",
      "Loss: 0.009142010982532114\n",
      "Training step:  464\n",
      "Loss: 0.009121888951457123\n",
      "Training step:  465\n",
      "Loss: 0.009119774043582338\n",
      "Training step:  466\n",
      "Loss: 0.009102045763269269\n",
      "Training step:  467\n",
      "Loss: 0.009097868845108374\n",
      "Training step:  468\n",
      "Loss: 0.009082539785806271\n",
      "Training step:  469\n",
      "Loss: 0.009080019997782416\n",
      "Training step:  470\n",
      "Loss: 0.009061863957527918\n",
      "Training step:  471\n",
      "Loss: 0.009058568904854656\n",
      "Training step:  472\n",
      "Loss: 0.00904278912569577\n",
      "Training step:  473\n",
      "Loss: 0.009041207462229283\n",
      "Training step:  474\n",
      "Loss: 0.009022603492419871\n",
      "Training step:  475\n",
      "Loss: 0.009020208441309414\n",
      "Training step:  476\n",
      "Loss: 0.00900395883163267\n",
      "Training step:  477\n",
      "Loss: 0.009003329694398625\n",
      "Training step:  478\n",
      "Loss: 0.00898561462706136\n",
      "Training step:  479\n",
      "Loss: 0.00898277133301615\n",
      "Training step:  480\n",
      "Loss: 0.008966056902329217\n",
      "Training step:  481\n",
      "Loss: 0.008962543605109083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  482\n",
      "Loss: 0.008948153278063791\n",
      "Training step:  483\n",
      "Loss: 0.008946256919234077\n",
      "Training step:  484\n",
      "Loss: 0.008929088531697674\n",
      "Training step:  485\n",
      "Loss: 0.008926470922025425\n",
      "Training step:  486\n",
      "Loss: 0.008911606470035641\n",
      "Training step:  487\n",
      "Loss: 0.008910660239670397\n",
      "Training step:  488\n",
      "Loss: 0.008894329585371112\n",
      "Training step:  489\n",
      "Loss: 0.00889130471949421\n",
      "Training step:  490\n",
      "Loss: 0.00887595897753468\n",
      "Training step:  491\n",
      "Loss: 0.008875975437631306\n",
      "Training step:  492\n",
      "Loss: 0.008859175473479537\n",
      "Training step:  493\n",
      "Loss: 0.008857051329192362\n",
      "Training step:  494\n",
      "Loss: 0.008842529961681608\n",
      "Training step:  495\n",
      "Loss: 0.008838447723424864\n",
      "Training step:  496\n",
      "Loss: 0.00882487617772734\n",
      "Training step:  497\n",
      "Loss: 0.008823695552080735\n",
      "Training step:  498\n",
      "Loss: 0.008808674526168798\n",
      "Training step:  499\n",
      "Loss: 0.00880551806550757\n",
      "Training step:  500\n",
      "Loss: 0.008792746205535001\n",
      "Training step:  501\n",
      "Loss: 0.008791234486101451\n",
      "Training step:  502\n",
      "Loss: 0.008775713891281086\n",
      "Training step:  503\n",
      "Loss: 0.00877348120178614\n",
      "Training step:  504\n",
      "Loss: 0.008760192179318796\n",
      "Training step:  505\n",
      "Loss: 0.008759657903372192\n",
      "Training step:  506\n",
      "Loss: 0.00874364968049515\n",
      "Training step:  507\n",
      "Loss: 0.008742329540054137\n",
      "Training step:  508\n",
      "Loss: 0.008728532818526135\n",
      "Training step:  509\n",
      "Loss: 0.008728963710140196\n",
      "Training step:  510\n",
      "Loss: 0.008712454423696997\n",
      "Training step:  511\n",
      "Loss: 0.008712057621667664\n",
      "Training step:  512\n",
      "Loss: 0.00869773661822172\n",
      "Training step:  513\n",
      "Loss: 0.008695450515707396\n",
      "Training step:  514\n",
      "Loss: 0.008683035741473742\n",
      "Training step:  515\n",
      "Loss: 0.00868283365756199\n",
      "Training step:  516\n",
      "Loss: 0.008667572211280224\n",
      "Training step:  517\n",
      "Loss: 0.008666605845590472\n",
      "Training step:  518\n",
      "Loss: 0.008653514285047247\n",
      "Training step:  519\n",
      "Loss: 0.008650683463358433\n",
      "Training step:  520\n",
      "Loss: 0.008638491879155361\n",
      "Training step:  521\n",
      "Loss: 0.008638478988341617\n",
      "Training step:  522\n",
      "Loss: 0.008624857176472212\n",
      "Training step:  523\n",
      "Loss: 0.008622964336979087\n",
      "Training step:  524\n",
      "Loss: 0.008611483209431147\n",
      "Training step:  525\n",
      "Loss: 0.008611205689795358\n",
      "Training step:  526\n",
      "Loss: 0.00859706375335584\n",
      "Training step:  527\n",
      "Loss: 0.008596099136875403\n",
      "Training step:  528\n",
      "Loss: 0.008584068713776443\n",
      "Training step:  529\n",
      "Loss: 0.00858478308573376\n",
      "Training step:  530\n",
      "Loss: 0.00857010993932992\n",
      "Training step:  531\n",
      "Loss: 0.00857008297026214\n",
      "Training step:  532\n",
      "Loss: 0.008557509928199626\n",
      "Training step:  533\n",
      "Loss: 0.008555670579551203\n",
      "Training step:  534\n",
      "Loss: 0.00854519477751015\n",
      "Training step:  535\n",
      "Loss: 0.008544895004998115\n",
      "Training step:  536\n",
      "Loss: 0.008531781196749386\n",
      "Training step:  537\n",
      "Loss: 0.00853088797209029\n",
      "Training step:  538\n",
      "Loss: 0.008519847041850015\n",
      "Training step:  539\n",
      "Loss: 0.008520546638013368\n",
      "Training step:  540\n",
      "Loss: 0.008508112059912533\n",
      "Training step:  541\n",
      "Loss: 0.008506929677676373\n",
      "Training step:  542\n",
      "Loss: 0.008495333732070474\n",
      "Training step:  543\n",
      "Loss: 0.00849702864905663\n",
      "Training step:  544\n",
      "Loss: 0.008484046103781319\n",
      "Training step:  545\n",
      "Loss: 0.008483801684587197\n",
      "Training step:  546\n",
      "Loss: 0.008472859482275961\n",
      "Training step:  547\n",
      "Loss: 0.008470864333058242\n",
      "Training step:  548\n",
      "Loss: 0.008460741595580523\n",
      "Training step:  549\n",
      "Loss: 0.008461490221573777\n",
      "Training step:  550\n",
      "Loss: 0.00844998762559346\n",
      "Training step:  551\n",
      "Loss: 0.008448937898054294\n",
      "Training step:  552\n",
      "Loss: 0.008439448257780402\n",
      "Training step:  553\n",
      "Loss: 0.008439991181358077\n",
      "Training step:  554\n",
      "Loss: 0.00842792062410512\n",
      "Training step:  555\n",
      "Loss: 0.008427824280103139\n",
      "Training step:  556\n",
      "Loss: 0.008417758298036464\n",
      "Training step:  557\n",
      "Loss: 0.008419354037770934\n",
      "Training step:  558\n",
      "Loss: 0.008406660498002384\n",
      "Training step:  559\n",
      "Loss: 0.008407629457263002\n",
      "Training step:  560\n",
      "Loss: 0.008396861679986059\n",
      "Training step:  561\n",
      "Loss: 0.008396175273308283\n",
      "Training step:  562\n",
      "Loss: 0.008387331903758241\n",
      "Training step:  563\n",
      "Loss: 0.008388212608524803\n",
      "Training step:  564\n",
      "Loss: 0.00837795007205102\n",
      "Training step:  565\n",
      "Loss: 0.008377135785132193\n",
      "Training step:  566\n",
      "Loss: 0.008367593190713915\n",
      "Training step:  567\n",
      "Loss: 0.00836959165408945\n",
      "Training step:  568\n",
      "Loss: 0.008358636929953532\n",
      "Training step:  569\n",
      "Loss: 0.00835888479541678\n",
      "Training step:  570\n",
      "Loss: 0.008349816579724667\n",
      "Training step:  571\n",
      "Loss: 0.00835174885971414\n",
      "Training step:  572\n",
      "Loss: 0.008340101007810734\n",
      "Training step:  573\n",
      "Loss: 0.008341415876543511\n",
      "Training step:  574\n",
      "Loss: 0.008331642215444395\n",
      "Training step:  575\n",
      "Loss: 0.00833134895034384\n",
      "Training step:  576\n",
      "Loss: 0.008323436569164917\n",
      "Training step:  577\n",
      "Loss: 0.008324707945430679\n",
      "Training step:  578\n",
      "Loss: 0.008314237195920551\n",
      "Training step:  579\n",
      "Loss: 0.008315014242451887\n",
      "Training step:  580\n",
      "Loss: 0.008306389335739189\n",
      "Training step:  581\n",
      "Loss: 0.008308773258118655\n",
      "Training step:  582\n",
      "Loss: 0.008298756852047002\n",
      "Training step:  583\n",
      "Loss: 0.008299432914954316\n",
      "Training step:  584\n",
      "Loss: 0.008291258234533529\n",
      "Training step:  585\n",
      "Loss: 0.008293598075713464\n",
      "Training step:  586\n",
      "Loss: 0.00828287592292193\n",
      "Training step:  587\n",
      "Loss: 0.008284619766986087\n",
      "Training step:  588\n",
      "Loss: 0.008275722245315437\n",
      "Training step:  589\n",
      "Loss: 0.008275902093462866\n",
      "Training step:  590\n",
      "Loss: 0.008268821541938441\n",
      "Training step:  591\n",
      "Loss: 0.008270550402192775\n",
      "Training step:  592\n",
      "Loss: 0.00826094248732599\n",
      "Training step:  593\n",
      "Loss: 0.008262194280505413\n",
      "Training step:  594\n",
      "Loss: 0.008254382000672092\n",
      "Training step:  595\n",
      "Loss: 0.008257232543601218\n",
      "Training step:  596\n",
      "Loss: 0.008248048935610795\n",
      "Training step:  597\n",
      "Loss: 0.00824922187516927\n",
      "Training step:  598\n",
      "Loss: 0.008241827696524064\n",
      "Training step:  599\n",
      "Loss: 0.008241471124534279\n",
      "Training step:  600\n",
      "Loss: 0.008234720348952828\n",
      "Training step:  601\n",
      "Loss: 0.008236992587750222\n",
      "Training step:  602\n",
      "Loss: 0.008228868910421837\n",
      "Training step:  603\n",
      "Loss: 0.008229587599641949\n",
      "Training step:  604\n",
      "Loss: 0.008223229558983651\n",
      "Training step:  605\n",
      "Loss: 0.008225492780417369\n",
      "Training step:  606\n",
      "Loss: 0.008216649896391336\n",
      "Training step:  607\n",
      "Loss: 0.008218438706335865\n",
      "Training step:  608\n",
      "Loss: 0.008211342095011748\n",
      "Training step:  609\n",
      "Loss: 0.008214724399859931\n",
      "Training step:  610\n",
      "Loss: 0.008206277333104913\n",
      "Training step:  611\n",
      "Loss: 0.008208006983619872\n",
      "Training step:  612\n",
      "Loss: 0.008201298900794003\n",
      "Training step:  613\n",
      "Loss: 0.008201542347269558\n",
      "Training step:  614\n",
      "Loss: 0.00819544841279326\n",
      "Training step:  615\n",
      "Loss: 0.008198298611676303\n",
      "Training step:  616\n",
      "Loss: 0.00819085295337007\n",
      "Training step:  617\n",
      "Loss: 0.0081921702263264\n",
      "Training step:  618\n",
      "Loss: 0.00818644208693386\n",
      "Training step:  619\n",
      "Loss: 0.00818930128329575\n",
      "Training step:  620\n",
      "Loss: 0.008181128068578725\n",
      "Training step:  621\n",
      "Loss: 0.00818351398164663\n",
      "Training step:  622\n",
      "Loss: 0.008177038042653833\n",
      "Training step:  623\n",
      "Loss: 0.0081810155480223\n",
      "Training step:  624\n",
      "Loss: 0.008173208816411408\n",
      "Training step:  625\n",
      "Loss: 0.008175555611847837\n",
      "Training step:  626\n",
      "Loss: 0.008169440971579943\n",
      "Training step:  627\n",
      "Loss: 0.008170341728834648\n",
      "Training step:  628\n",
      "Loss: 0.008164808566468498\n",
      "Training step:  629\n",
      "Loss: 0.008168302403036131\n",
      "Training step:  630\n",
      "Loss: 0.008161443810468915\n",
      "Training step:  631\n",
      "Loss: 0.008163415560874073\n",
      "Training step:  632\n",
      "Loss: 0.008158220320636818\n",
      "Training step:  633\n",
      "Loss: 0.008161741433099034\n",
      "Training step:  634\n",
      "Loss: 0.00815414346594673\n",
      "Training step:  635\n",
      "Loss: 0.00815718696711605\n",
      "Training step:  636\n",
      "Loss: 0.008151237966330245\n",
      "Training step:  637\n",
      "Loss: 0.008152865545749073\n",
      "Training step:  638\n",
      "Loss: 0.008148563781765348\n",
      "Training step:  639\n",
      "Loss: 0.008151633324690379\n",
      "Training step:  640\n",
      "Loss: 0.008146022004655064\n",
      "Training step:  641\n",
      "Loss: 0.008147635693232503\n",
      "Training step:  642\n",
      "Loss: 0.008142585724799168\n",
      "Training step:  643\n",
      "Loss: 0.008146771039651168\n",
      "Training step:  644\n",
      "Loss: 0.008142043654646765\n",
      "Training step:  645\n",
      "Loss: 0.008145828171554112\n",
      "Training step:  646\n",
      "Loss: 0.008141519860175129\n",
      "Training step:  647\n",
      "Loss: 0.008144901005375056\n",
      "Training step:  648\n",
      "Loss: 0.008139931739323555\n",
      "Training step:  649\n",
      "Loss: 0.008143981364853019\n",
      "Training step:  650\n",
      "Loss: 0.008139425421823325\n",
      "Training step:  651\n",
      "Loss: 0.008143100761927088\n",
      "Training step:  652\n",
      "Loss: 0.008137866517094564\n",
      "Training step:  653\n",
      "Loss: 0.008142228209840435\n",
      "Training step:  654\n",
      "Loss: 0.00813737707797427\n",
      "Training step:  655\n",
      "Loss: 0.00813845050660565\n",
      "Training step:  656\n",
      "Loss: 0.00813704822642297\n",
      "Training step:  657\n",
      "Loss: 0.008137592637081466\n",
      "Training step:  658\n",
      "Loss: 0.0081355105670895\n",
      "Training step:  659\n",
      "Loss: 0.00813674345180832\n",
      "Training step:  660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.008135035286048363\n",
      "Training step:  661\n",
      "Loss: 0.008135904199992891\n",
      "Training step:  662\n",
      "Loss: 0.008133521370422305\n",
      "Training step:  663\n",
      "Loss: 0.008135076289304833\n",
      "Training step:  664\n",
      "Loss: 0.008133062172711059\n",
      "Training step:  665\n",
      "Loss: 0.008134255391294355\n",
      "Training step:  666\n",
      "Loss: 0.008131568388226821\n",
      "Training step:  667\n",
      "Loss: 0.008133448625807154\n",
      "Training step:  668\n",
      "Loss: 0.008131124652352963\n",
      "Training step:  669\n",
      "Loss: 0.008132645712867636\n",
      "Training step:  670\n",
      "Loss: 0.00813069212422011\n",
      "Training step:  671\n",
      "Loss: 0.008131856029393031\n",
      "Training step:  672\n",
      "Loss: 0.00812923199602109\n",
      "Training step:  673\n",
      "Loss: 0.008131074569577783\n",
      "Training step:  674\n",
      "Loss: 0.008128814401646894\n",
      "Training step:  675\n",
      "Loss: 0.008130302604262087\n",
      "Training step:  676\n",
      "Loss: 0.00812737348085829\n",
      "Training step:  677\n",
      "Loss: 0.008129541743062612\n",
      "Training step:  678\n",
      "Loss: 0.008126971777913819\n",
      "Training step:  679\n",
      "Loss: 0.008128787146350687\n",
      "Training step:  680\n",
      "Loss: 0.008125558872922654\n",
      "Training step:  681\n",
      "Loss: 0.008128046395103363\n",
      "Training step:  682\n",
      "Loss: 0.008125171969872358\n",
      "Training step:  683\n",
      "Loss: 0.008127309046111374\n",
      "Training step:  684\n",
      "Loss: 0.008124795314741006\n",
      "Training step:  685\n",
      "Loss: 0.008126584392619766\n",
      "Training step:  686\n",
      "Loss: 0.008123406170176983\n",
      "Training step:  687\n",
      "Loss: 0.008125868121205346\n",
      "Training step:  688\n",
      "Loss: 0.008123044325562634\n",
      "Training step:  689\n",
      "Loss: 0.00812516023619579\n",
      "Training step:  690\n",
      "Loss: 0.00812168179353215\n",
      "Training step:  691\n",
      "Loss: 0.00812446355503049\n",
      "Training step:  692\n",
      "Loss: 0.008121334690028318\n",
      "Training step:  693\n",
      "Loss: 0.00812377231342603\n",
      "Training step:  694\n",
      "Loss: 0.008120996125688944\n",
      "Training step:  695\n",
      "Loss: 0.008123093388398396\n",
      "Training step:  696\n",
      "Loss: 0.008119657439939592\n",
      "Training step:  697\n",
      "Loss: 0.008122420396507254\n",
      "Training step:  698\n",
      "Loss: 0.008119335181601909\n",
      "Training step:  699\n",
      "Loss: 0.008121757653681455\n",
      "Training step:  700\n",
      "Loss: 0.008118022827275908\n",
      "Training step:  701\n",
      "Loss: 0.008121103799595854\n",
      "Training step:  702\n",
      "Loss: 0.008117713919476077\n",
      "Training step:  703\n",
      "Loss: 0.008120457118797476\n",
      "Training step:  704\n",
      "Loss: 0.008116423116913029\n",
      "Training step:  705\n",
      "Loss: 0.008119822283323289\n",
      "Training step:  706\n",
      "Loss: 0.008116127777982029\n",
      "Training step:  707\n",
      "Loss: 0.00811919142606348\n",
      "Training step:  708\n",
      "Loss: 0.00811583889604794\n",
      "Training step:  709\n",
      "Loss: 0.008118572353737235\n",
      "Training step:  710\n",
      "Loss: 0.008114574887259076\n",
      "Training step:  711\n",
      "Loss: 0.008117959986327613\n",
      "Training step:  712\n",
      "Loss: 0.008114303019275966\n",
      "Training step:  713\n",
      "Loss: 0.008114689687810189\n",
      "Training step:  714\n",
      "Loss: 0.008114186104894103\n",
      "Training step:  715\n",
      "Loss: 0.008114088789567335\n",
      "Training step:  716\n",
      "Loss: 0.00811293983151709\n",
      "Training step:  717\n",
      "Loss: 0.008113494920999663\n",
      "Training step:  718\n",
      "Loss: 0.008112677694452135\n",
      "Training step:  719\n",
      "Loss: 0.008112909162581113\n",
      "Training step:  720\n",
      "Loss: 0.008111453814665005\n",
      "Training step:  721\n",
      "Loss: 0.008112333568295977\n",
      "Training step:  722\n",
      "Loss: 0.008111201991027602\n",
      "Training step:  723\n",
      "Loss: 0.008111762928810528\n",
      "Training step:  724\n",
      "Loss: 0.008110961527408134\n",
      "Training step:  725\n",
      "Loss: 0.008111203476831775\n",
      "Training step:  726\n",
      "Loss: 0.008109761897149091\n",
      "Training step:  727\n",
      "Loss: 0.008110649427960099\n",
      "Training step:  728\n",
      "Loss: 0.008109535481933335\n",
      "Training step:  729\n",
      "Loss: 0.008110104654931546\n",
      "Training step:  730\n",
      "Loss: 0.00810835362755921\n",
      "Training step:  731\n",
      "Loss: 0.008109568486147857\n",
      "Training step:  732\n",
      "Loss: 0.008108139878144922\n",
      "Training step:  733\n",
      "Loss: 0.008109038109170384\n",
      "Training step:  734\n",
      "Loss: 0.00810698179812025\n",
      "Training step:  735\n",
      "Loss: 0.008108519448614527\n",
      "Training step:  736\n",
      "Loss: 0.00810677996551743\n",
      "Training step:  737\n",
      "Loss: 0.008108003345780629\n",
      "Training step:  738\n",
      "Loss: 0.00810658775062569\n",
      "Training step:  739\n",
      "Loss: 0.008107498113443195\n",
      "Training step:  740\n",
      "Loss: 0.008105450901195344\n",
      "Training step:  741\n",
      "Loss: 0.008107000126081149\n",
      "Training step:  742\n",
      "Loss: 0.008105270963875652\n",
      "Training step:  743\n",
      "Loss: 0.008106508779842389\n",
      "Training step:  744\n",
      "Loss: 0.008104157060394012\n",
      "Training step:  745\n",
      "Loss: 0.008106027888747779\n",
      "Training step:  746\n",
      "Loss: 0.008103988377369586\n",
      "Training step:  747\n",
      "Loss: 0.008105550304745286\n",
      "Training step:  748\n",
      "Loss: 0.008103825969851488\n",
      "Training step:  749\n",
      "Loss: 0.008105083295835931\n",
      "Training step:  750\n",
      "Loss: 0.00810273629807043\n",
      "Training step:  751\n",
      "Loss: 0.00810462238262561\n",
      "Training step:  752\n",
      "Loss: 0.0081025880294259\n",
      "Training step:  753\n",
      "Loss: 0.008104168752261276\n",
      "Training step:  754\n",
      "Loss: 0.008101517723221324\n",
      "Training step:  755\n",
      "Loss: 0.008103724551283715\n",
      "Training step:  756\n",
      "Loss: 0.008101381347214266\n",
      "Training step:  757\n",
      "Loss: 0.008103284195413287\n",
      "Training step:  758\n",
      "Loss: 0.008101250043545978\n",
      "Training step:  759\n",
      "Loss: 0.00810285406216175\n",
      "Training step:  760\n",
      "Loss: 0.008100203091606396\n",
      "Training step:  761\n",
      "Loss: 0.008102429224626518\n",
      "Training step:  762\n",
      "Loss: 0.00810008598693625\n",
      "Training step:  763\n",
      "Loss: 0.008102012021553457\n",
      "Training step:  764\n",
      "Loss: 0.0080990559973944\n",
      "Training step:  765\n",
      "Loss: 0.008101603507945369\n",
      "Training step:  766\n",
      "Loss: 0.008098950331200144\n",
      "Training step:  767\n",
      "Loss: 0.008101199044627487\n",
      "Training step:  768\n",
      "Loss: 0.008098851963016213\n",
      "Training step:  769\n",
      "Loss: 0.008100804566166889\n",
      "Training step:  770\n",
      "Loss: 0.008097846755587683\n",
      "Training step:  771\n",
      "Loss: 0.008100414906848886\n",
      "Training step:  772\n",
      "Loss: 0.008097757551405946\n",
      "Training step:  773\n",
      "Loss: 0.008097900920776686\n",
      "Training step:  774\n",
      "Loss: 0.008097813906534253\n",
      "Training step:  775\n",
      "Loss: 0.008097511932544706\n",
      "Training step:  776\n",
      "Loss: 0.008097722996408959\n",
      "Training step:  777\n",
      "Loss: 0.00809742100655395\n",
      "Training step:  778\n",
      "Loss: 0.008097616424840297\n",
      "Training step:  779\n",
      "Loss: 0.008097330338855355\n",
      "Training step:  780\n",
      "Loss: 0.008096629637527103\n",
      "Training step:  781\n",
      "Loss: 0.008096954200773948\n",
      "Training step:  782\n",
      "Loss: 0.008096541567099396\n",
      "Training step:  783\n",
      "Loss: 0.00809686362692269\n",
      "Training step:  784\n",
      "Loss: 0.00809645151929745\n",
      "Training step:  785\n",
      "Loss: 0.008096773320453115\n",
      "Training step:  786\n",
      "Loss: 0.008096361762472516\n",
      "Training step:  787\n",
      "Loss: 0.008096683280287786\n",
      "Training step:  788\n",
      "Loss: 0.008096272042183168\n",
      "Training step:  789\n",
      "Loss: 0.008096593495139408\n",
      "Training step:  790\n",
      "Loss: 0.008096183406637026\n",
      "Training step:  791\n",
      "Loss: 0.00809650398503913\n",
      "Training step:  792\n",
      "Loss: 0.008096094436892111\n",
      "Training step:  793\n",
      "Loss: 0.008096414738434135\n",
      "Training step:  794\n",
      "Loss: 0.008096005647420669\n",
      "Training step:  795\n",
      "Loss: 0.008096325753305446\n",
      "Training step:  796\n",
      "Loss: 0.00809591732723042\n",
      "Training step:  797\n",
      "Loss: 0.008096237029159696\n",
      "Training step:  798\n",
      "Loss: 0.008095829140561723\n",
      "Training step:  799\n",
      "Loss: 0.008096148563397087\n",
      "Training step:  800\n",
      "Loss: 0.00809574150802564\n",
      "Training step:  801\n",
      "Loss: 0.008096060362283804\n",
      "Training step:  802\n",
      "Loss: 0.008095653720168709\n",
      "Training step:  803\n",
      "Loss: 0.008095972419099887\n",
      "Training step:  804\n",
      "Loss: 0.008095566319166579\n",
      "Training step:  805\n",
      "Loss: 0.008095884731949684\n",
      "Training step:  806\n",
      "Loss: 0.008095479172520521\n",
      "Training step:  807\n",
      "Loss: 0.008095797303851952\n",
      "Training step:  808\n",
      "Loss: 0.008095391924389633\n",
      "Training step:  809\n",
      "Loss: 0.0080957101245557\n",
      "Training step:  810\n",
      "Loss: 0.008095305369951001\n",
      "Training step:  811\n",
      "Loss: 0.008095623205568187\n",
      "Training step:  812\n",
      "Loss: 0.00809521676363519\n",
      "Training step:  813\n",
      "Loss: 0.008095536528399156\n",
      "Training step:  814\n",
      "Loss: 0.0080942784706616\n",
      "Training step:  815\n",
      "Loss: 0.008095176924333784\n",
      "Training step:  816\n",
      "Loss: 0.008094193482208125\n",
      "Training step:  817\n",
      "Loss: 0.008095090362542263\n",
      "Training step:  818\n",
      "Loss: 0.00809410820016746\n",
      "Training step:  819\n",
      "Loss: 0.008095004052325381\n",
      "Training step:  820\n",
      "Loss: 0.008094023575150664\n",
      "Training step:  821\n",
      "Loss: 0.008094917996533633\n",
      "Training step:  822\n",
      "Loss: 0.008093938870462187\n",
      "Training step:  823\n",
      "Loss: 0.008094832191167266\n",
      "Training step:  824\n",
      "Loss: 0.008093854394978789\n",
      "Training step:  825\n",
      "Loss: 0.008094746636349218\n",
      "Training step:  826\n",
      "Loss: 0.008093770088530145\n",
      "Training step:  827\n",
      "Loss: 0.0080946613256767\n",
      "Training step:  828\n",
      "Loss: 0.008093686580193141\n",
      "Training step:  829\n",
      "Loss: 0.008094576262108412\n",
      "Training step:  830\n",
      "Loss: 0.008093603143591536\n",
      "Training step:  831\n",
      "Loss: 0.008094491449757288\n",
      "Training step:  832\n",
      "Loss: 0.008093519706727309\n",
      "Training step:  833\n",
      "Loss: 0.00809440688387372\n",
      "Training step:  834\n",
      "Loss: 0.008093436470160897\n",
      "Training step:  835\n",
      "Loss: 0.00809432256102557\n",
      "Training step:  836\n",
      "Loss: 0.008093353448770341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  837\n",
      "Loss: 0.008094238479127998\n",
      "Training step:  838\n",
      "Loss: 0.008093270610656917\n",
      "Training step:  839\n",
      "Loss: 0.008094154635376556\n",
      "Training step:  840\n",
      "Loss: 0.008093188055696664\n",
      "Training step:  841\n",
      "Loss: 0.008094071026325637\n",
      "Training step:  842\n",
      "Loss: 0.008093105730832426\n",
      "Training step:  843\n",
      "Loss: 0.008093987649156585\n",
      "Training step:  844\n",
      "Loss: 0.008093023507566294\n",
      "Training step:  845\n",
      "Loss: 0.008093904498779492\n",
      "Training step:  846\n",
      "Loss: 0.008092936309644005\n",
      "Training step:  847\n",
      "Loss: 0.008093821549394656\n",
      "Training step:  848\n",
      "Loss: 0.008092043809403324\n",
      "Training step:  849\n",
      "Loss: 0.008093477789534061\n",
      "Training step:  850\n",
      "Loss: 0.00809196167877901\n",
      "Training step:  851\n",
      "Loss: 0.0080933950254328\n",
      "Training step:  852\n",
      "Loss: 0.00809188150411956\n",
      "Training step:  853\n",
      "Loss: 0.008093312500852422\n",
      "Training step:  854\n",
      "Loss: 0.008091801058109825\n",
      "Training step:  855\n",
      "Loss: 0.008093230207711551\n",
      "Training step:  856\n",
      "Loss: 0.008091720947218481\n",
      "Training step:  857\n",
      "Loss: 0.008093148147530775\n",
      "Training step:  858\n",
      "Loss: 0.008091641332454\n",
      "Training step:  859\n",
      "Loss: 0.008093066317039908\n",
      "Training step:  860\n",
      "Loss: 0.008091561674416381\n",
      "Training step:  861\n",
      "Loss: 0.008092984710391622\n",
      "Training step:  862\n",
      "Loss: 0.008091481969204166\n",
      "Training step:  863\n",
      "Loss: 0.00809290329381187\n",
      "Training step:  864\n",
      "Loss: 0.008091403387186273\n",
      "Training step:  865\n",
      "Loss: 0.008092822111565846\n",
      "Training step:  866\n",
      "Loss: 0.008091324366994062\n",
      "Training step:  867\n",
      "Loss: 0.008092741114990504\n",
      "Training step:  868\n",
      "Loss: 0.008091245877250556\n",
      "Training step:  869\n",
      "Loss: 0.008092660285879762\n",
      "Training step:  870\n",
      "Loss: 0.00809116756647878\n",
      "Training step:  871\n",
      "Loss: 0.008092579555921716\n",
      "Training step:  872\n",
      "Loss: 0.008091089168090027\n",
      "Training step:  873\n",
      "Loss: 0.008092498700947599\n",
      "Training step:  874\n",
      "Loss: 0.00809101120956258\n",
      "Training step:  875\n",
      "Loss: 0.008092415290738083\n",
      "Training step:  876\n",
      "Loss: 0.008090933146928598\n",
      "Training step:  877\n",
      "Loss: 0.008092085845915045\n",
      "Training step:  878\n",
      "Loss: 0.008090077022265184\n",
      "Training step:  879\n",
      "Loss: 0.008092008628184771\n",
      "Training step:  880\n",
      "Loss: 0.008089999631294744\n",
      "Training step:  881\n",
      "Loss: 0.008091928976951775\n",
      "Training step:  882\n",
      "Loss: 0.008089918860162432\n",
      "Training step:  883\n",
      "Loss: 0.008091849526607494\n",
      "Training step:  884\n",
      "Loss: 0.008088194613154766\n",
      "Training step:  885\n",
      "Loss: 0.008091856644330351\n",
      "Training step:  886\n",
      "Loss: 0.008088119877713825\n",
      "Training step:  887\n",
      "Loss: 0.00809177650780032\n",
      "Training step:  888\n",
      "Loss: 0.008088045055580249\n",
      "Training step:  889\n",
      "Loss: 0.008091696601409277\n",
      "Training step:  890\n",
      "Loss: 0.008087970550906928\n",
      "Training step:  891\n",
      "Loss: 0.008091616924146986\n",
      "Training step:  892\n",
      "Loss: 0.008087895971314405\n",
      "Training step:  893\n",
      "Loss: 0.008091537411057599\n",
      "Training step:  894\n",
      "Loss: 0.008087822184549617\n",
      "Training step:  895\n",
      "Loss: 0.008091458183864836\n",
      "Training step:  896\n",
      "Loss: 0.008087726784468025\n",
      "Training step:  897\n",
      "Loss: 0.008091379172673819\n",
      "Training step:  898\n",
      "Loss: 0.008086900838165193\n",
      "Training step:  899\n",
      "Loss: 0.008091060296826968\n",
      "Training step:  900\n",
      "Loss: 0.008086828911602714\n",
      "Training step:  901\n",
      "Loss: 0.008090981381111358\n",
      "Training step:  902\n",
      "Loss: 0.008086756160644942\n",
      "Training step:  903\n",
      "Loss: 0.008090902691033217\n",
      "Training step:  904\n",
      "Loss: 0.008086683723905669\n",
      "Training step:  905\n",
      "Loss: 0.008090824227152646\n",
      "Training step:  906\n",
      "Loss: 0.008086611305741006\n",
      "Training step:  907\n",
      "Loss: 0.008090745959299464\n",
      "Training step:  908\n",
      "Loss: 0.008086539871188254\n",
      "Training step:  909\n",
      "Loss: 0.008090667943492134\n",
      "Training step:  910\n",
      "Loss: 0.008086467939652361\n",
      "Training step:  911\n",
      "Loss: 0.008090590148420174\n",
      "Training step:  912\n",
      "Loss: 0.008086396631642593\n",
      "Training step:  913\n",
      "Loss: 0.008090512576300985\n",
      "Training step:  914\n",
      "Loss: 0.008086325136736712\n",
      "Training step:  915\n",
      "Loss: 0.008090435223062834\n",
      "Training step:  916\n",
      "Loss: 0.008086253906169407\n",
      "Training step:  917\n",
      "Loss: 0.008090358086309087\n",
      "Training step:  918\n",
      "Loss: 0.008086183307748494\n",
      "Training step:  919\n",
      "Loss: 0.008090281168010763\n",
      "Training step:  920\n",
      "Loss: 0.008086112547312816\n",
      "Training step:  921\n",
      "Loss: 0.008090204464122234\n",
      "Training step:  922\n",
      "Loss: 0.008086041783161366\n",
      "Training step:  923\n",
      "Loss: 0.008090127962229176\n",
      "Training step:  924\n",
      "Loss: 0.008085972062663772\n",
      "Training step:  925\n",
      "Loss: 0.00809005168020982\n",
      "Training step:  926\n",
      "Loss: 0.008085901844645308\n",
      "Training step:  927\n",
      "Loss: 0.008089975604123622\n",
      "Training step:  928\n",
      "Loss: 0.008085831568345228\n",
      "Training step:  929\n",
      "Loss: 0.008089899724244159\n",
      "Training step:  930\n",
      "Loss: 0.008085761724831943\n",
      "Training step:  931\n",
      "Loss: 0.008089824041356667\n",
      "Training step:  932\n",
      "Loss: 0.008084975373356352\n",
      "Training step:  933\n",
      "Loss: 0.008089519095983575\n",
      "Training step:  934\n",
      "Loss: 0.008084905490194846\n",
      "Training step:  935\n",
      "Loss: 0.008089443517400739\n",
      "Training step:  936\n",
      "Loss: 0.008084836774225274\n",
      "Training step:  937\n",
      "Loss: 0.008089368122986437\n",
      "Training step:  938\n",
      "Loss: 0.008084768143465754\n",
      "Training step:  939\n",
      "Loss: 0.008089292877261641\n",
      "Training step:  940\n",
      "Loss: 0.008084700360295616\n",
      "Training step:  941\n",
      "Loss: 0.00808921774284116\n",
      "Training step:  942\n",
      "Loss: 0.008084632261062262\n",
      "Training step:  943\n",
      "Loss: 0.00808914236479848\n",
      "Training step:  944\n",
      "Loss: 0.00808456439283554\n",
      "Training step:  945\n",
      "Loss: 0.008087191916276796\n",
      "Training step:  946\n",
      "Loss: 0.008084609457020425\n",
      "Training step:  947\n",
      "Loss: 0.008086886018996235\n",
      "Training step:  948\n",
      "Loss: 0.008084536895984437\n",
      "Training step:  949\n",
      "Loss: 0.008086588117455613\n",
      "Training step:  950\n",
      "Loss: 0.008083768947927061\n",
      "Training step:  951\n",
      "Loss: 0.008086520119153123\n",
      "Training step:  952\n",
      "Loss: 0.008083700743415674\n",
      "Training step:  953\n",
      "Loss: 0.008086447759240802\n",
      "Training step:  954\n",
      "Loss: 0.00808363235801577\n",
      "Training step:  955\n",
      "Loss: 0.008086375559976993\n",
      "Training step:  956\n",
      "Loss: 0.008083564624252209\n",
      "Training step:  957\n",
      "Loss: 0.0080863034918453\n",
      "Training step:  958\n",
      "Loss: 0.008083496535261258\n",
      "Training step:  959\n",
      "Loss: 0.008086231461605855\n",
      "Training step:  960\n",
      "Loss: 0.008083429015145931\n",
      "Training step:  961\n",
      "Loss: 0.008086159189126514\n",
      "Training step:  962\n",
      "Loss: 0.008083360282507545\n",
      "Training step:  963\n",
      "Loss: 0.008086073613903047\n",
      "Training step:  964\n",
      "Loss: 0.0080796729942725\n",
      "Training step:  965\n",
      "Loss: 0.008084435851279487\n",
      "Training step:  966\n",
      "Loss: 0.008078910075262114\n",
      "Training step:  967\n",
      "Loss: 0.008084142385297147\n",
      "Training step:  968\n",
      "Loss: 0.008078846112283041\n",
      "Training step:  969\n",
      "Loss: 0.008084069989076037\n",
      "Training step:  970\n",
      "Loss: 0.008078781562367911\n",
      "Training step:  971\n",
      "Loss: 0.008083997797326098\n",
      "Training step:  972\n",
      "Loss: 0.008078716859528138\n",
      "Training step:  973\n",
      "Loss: 0.008083925811546929\n",
      "Training step:  974\n",
      "Loss: 0.008078652393733768\n",
      "Training step:  975\n",
      "Loss: 0.00808385403251805\n",
      "Training step:  976\n",
      "Loss: 0.008077922491744443\n",
      "Training step:  977\n",
      "Loss: 0.008083571160683974\n",
      "Training step:  978\n",
      "Loss: 0.008077861448341578\n",
      "Training step:  979\n",
      "Loss: 0.008083499466610322\n",
      "Training step:  980\n",
      "Loss: 0.008077798220614702\n",
      "Training step:  981\n",
      "Loss: 0.008083427977986559\n",
      "Training step:  982\n",
      "Loss: 0.008077735154421724\n",
      "Training step:  983\n",
      "Loss: 0.00808335669429672\n",
      "Training step:  984\n",
      "Loss: 0.00807767234699088\n",
      "Training step:  985\n",
      "Loss: 0.008083285614745266\n",
      "Training step:  986\n",
      "Loss: 0.008077609591493978\n",
      "Training step:  987\n",
      "Loss: 0.008083214738096093\n",
      "Training step:  988\n",
      "Loss: 0.00807754737580946\n",
      "Training step:  989\n",
      "Loss: 0.008083144065287678\n",
      "Training step:  990\n",
      "Loss: 0.008077484980670584\n",
      "Training step:  991\n",
      "Loss: 0.008083073594349408\n",
      "Training step:  992\n",
      "Loss: 0.008077422866451078\n",
      "Training step:  993\n",
      "Loss: 0.008083003324869366\n",
      "Training step:  994\n",
      "Loss: 0.008077360824076873\n",
      "Training step:  995\n",
      "Loss: 0.008082933255808167\n",
      "Training step:  996\n",
      "Loss: 0.008077299192212688\n",
      "Training step:  997\n",
      "Loss: 0.008082863386902802\n",
      "Training step:  998\n",
      "Loss: 0.008077237476482653\n",
      "Training step:  999\n",
      "Loss: 0.008082793715336623\n",
      "Training step:  1000\n",
      "Loss: 0.008077176305024658\n",
      "Training step:  1001\n",
      "Loss: 0.008082724243962544\n",
      "Training step:  1002\n",
      "Loss: 0.008077114970392487\n",
      "Training step:  1003\n",
      "Loss: 0.008082654969423744\n",
      "Training step:  1004\n",
      "Loss: 0.008077054061568206\n",
      "Training step:  1005\n",
      "Loss: 0.008082585892392755\n",
      "Training step:  1006\n",
      "Loss: 0.008076992949037102\n",
      "Training step:  1007\n",
      "Loss: 0.008082517011072576\n",
      "Training step:  1008\n",
      "Loss: 0.008076931611114519\n",
      "Training step:  1009\n",
      "Loss: 0.008082448321715952\n",
      "Training step:  1010\n",
      "Loss: 0.0080762314913538\n",
      "Training step:  1011\n",
      "Loss: 0.008082177779516498\n",
      "Training step:  1012\n",
      "Loss: 0.00807617208072088\n",
      "Training step:  1013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.008082109176333018\n",
      "Training step:  1014\n",
      "Loss: 0.008076112194599961\n",
      "Training step:  1015\n",
      "Loss: 0.008082040764390869\n",
      "Training step:  1016\n",
      "Loss: 0.008076052937970498\n",
      "Training step:  1017\n",
      "Loss: 0.008081972550401361\n",
      "Training step:  1018\n",
      "Loss: 0.008075993532077991\n",
      "Training step:  1019\n",
      "Loss: 0.008081904526459594\n",
      "Training step:  1020\n",
      "Loss: 0.008075934594367012\n",
      "Training step:  1021\n",
      "Loss: 0.008081836698364991\n",
      "Training step:  1022\n",
      "Loss: 0.008075875626595385\n",
      "Training step:  1023\n",
      "Loss: 0.00808176905574273\n",
      "Training step:  1024\n",
      "Loss: 0.008075817032878482\n",
      "Training step:  1025\n",
      "Loss: 0.008081701610702157\n",
      "Training step:  1026\n",
      "Loss: 0.008075758210033469\n",
      "Training step:  1027\n",
      "Loss: 0.008081634345152758\n",
      "Training step:  1028\n",
      "Loss: 0.008075700103337958\n",
      "Training step:  1029\n",
      "Loss: 0.008081567278883572\n",
      "Training step:  1030\n",
      "Loss: 0.008075641711309868\n",
      "Training step:  1031\n",
      "Loss: 0.008081500400141474\n",
      "Training step:  1032\n",
      "Loss: 0.008075583578880198\n",
      "Training step:  1033\n",
      "Loss: 0.008081433706437985\n",
      "Training step:  1034\n",
      "Loss: 0.008075525611400283\n",
      "Training step:  1035\n",
      "Loss: 0.00808136719854228\n",
      "Training step:  1036\n",
      "Loss: 0.008075467894076364\n",
      "Training step:  1037\n",
      "Loss: 0.008081300873449722\n",
      "Training step:  1038\n",
      "Loss: 0.008075410068738156\n",
      "Training step:  1039\n",
      "Loss: 0.008081234728579354\n",
      "Training step:  1040\n",
      "Loss: 0.008075352455028328\n",
      "Training step:  1041\n",
      "Loss: 0.008081168760913878\n",
      "Training step:  1042\n",
      "Loss: 0.00807529455716664\n",
      "Training step:  1043\n",
      "Loss: 0.008081102961310154\n",
      "Training step:  1044\n",
      "Loss: 0.0080746292517802\n",
      "Training step:  1045\n",
      "Loss: 0.008080844213854903\n",
      "Training step:  1046\n",
      "Loss: 0.008074572392612497\n",
      "Training step:  1047\n",
      "Loss: 0.008080778540383471\n",
      "Training step:  1048\n",
      "Loss: 0.008074515984453474\n",
      "Training step:  1049\n",
      "Loss: 0.008080713048843202\n",
      "Training step:  1050\n",
      "Loss: 0.008074459878759111\n",
      "Training step:  1051\n",
      "Loss: 0.008080647738564546\n",
      "Training step:  1052\n",
      "Loss: 0.008074403677916538\n",
      "Training step:  1053\n",
      "Loss: 0.0080805825984335\n",
      "Training step:  1054\n",
      "Loss: 0.008074348007591985\n",
      "Training step:  1055\n",
      "Loss: 0.008080517643030381\n",
      "Training step:  1056\n",
      "Loss: 0.008074292289037124\n",
      "Training step:  1057\n",
      "Loss: 0.008080452861159782\n",
      "Training step:  1058\n",
      "Loss: 0.00807423677720534\n",
      "Training step:  1059\n",
      "Loss: 0.008080388249459492\n",
      "Training step:  1060\n",
      "Loss: 0.008074181480968463\n",
      "Training step:  1061\n",
      "Loss: 0.008080323803785299\n",
      "Training step:  1062\n",
      "Loss: 0.008074126148156491\n",
      "Training step:  1063\n",
      "Loss: 0.008080259512759426\n",
      "Training step:  1064\n",
      "Loss: 0.008074071509371259\n",
      "Training step:  1065\n",
      "Loss: 0.008080195372278762\n",
      "Training step:  1066\n",
      "Loss: 0.008074016521543968\n",
      "Training step:  1067\n",
      "Loss: 0.008080131356402611\n",
      "Training step:  1068\n",
      "Loss: 0.008073961890074245\n",
      "Training step:  1069\n",
      "Loss: 0.008080067425067016\n",
      "Training step:  1070\n",
      "Loss: 0.008073907297026372\n",
      "Training step:  1071\n",
      "Loss: 0.008080003456405048\n",
      "Training step:  1072\n",
      "Loss: 0.0080738527346904\n",
      "Training step:  1073\n",
      "Loss: 0.00807993876230788\n",
      "Training step:  1074\n",
      "Loss: 0.008073798644739739\n",
      "Training step:  1075\n",
      "Loss: 0.008079691208125095\n",
      "Training step:  1076\n",
      "Loss: 0.008073159826539321\n",
      "Training step:  1077\n",
      "Loss: 0.008079629878992014\n",
      "Training step:  1078\n",
      "Loss: 0.008073106576897863\n",
      "Training step:  1079\n",
      "Loss: 0.008079566692726256\n",
      "Training step:  1080\n",
      "Loss: 0.008073053104628476\n",
      "Training step:  1081\n",
      "Loss: 0.008079503625107252\n",
      "Training step:  1082\n",
      "Loss: 0.00807300019131135\n",
      "Training step:  1083\n",
      "Loss: 0.008079440655298198\n",
      "Training step:  1084\n",
      "Loss: 0.008072947169045424\n",
      "Training step:  1085\n",
      "Loss: 0.008079377703793423\n",
      "Training step:  1086\n",
      "Loss: 0.008072894294717197\n",
      "Training step:  1087\n",
      "Loss: 0.008079314543465834\n",
      "Training step:  1088\n",
      "Loss: 0.008072841895986792\n",
      "Training step:  1089\n",
      "Loss: 0.008079249436668844\n",
      "Training step:  1090\n",
      "Loss: 0.008072789424482677\n",
      "Training step:  1091\n",
      "Loss: 0.008077491455584063\n",
      "Training step:  1092\n",
      "Loss: 0.008068730768297006\n",
      "Training step:  1093\n",
      "Loss: 0.008076254277542511\n",
      "Training step:  1094\n",
      "Loss: 0.008068019964680248\n",
      "Training step:  1095\n",
      "Loss: 0.008076003761260934\n",
      "Training step:  1096\n",
      "Loss: 0.008067385567756085\n",
      "Training step:  1097\n",
      "Loss: 0.008075941192474463\n",
      "Training step:  1098\n",
      "Loss: 0.008067320699606202\n",
      "Training step:  1099\n",
      "Loss: 0.008075877685263761\n",
      "Training step:  1100\n",
      "Loss: 0.00806725662961042\n",
      "Training step:  1101\n",
      "Loss: 0.008075637999665318\n",
      "Training step:  1102\n",
      "Loss: 0.008067207155194617\n",
      "Training step:  1103\n",
      "Loss: 0.008075575623314684\n",
      "Training step:  1104\n",
      "Loss: 0.008067156458843703\n",
      "Training step:  1105\n",
      "Loss: 0.008075513407155701\n",
      "Training step:  1106\n",
      "Loss: 0.008067102885226359\n",
      "Training step:  1107\n",
      "Loss: 0.008075451376579043\n",
      "Training step:  1108\n",
      "Loss: 0.008067052900119859\n",
      "Training step:  1109\n",
      "Loss: 0.008075389514153606\n",
      "Training step:  1110\n",
      "Loss: 0.008067002072813934\n",
      "Training step:  1111\n",
      "Loss: 0.00807532781868423\n",
      "Training step:  1112\n",
      "Loss: 0.008066399028962338\n",
      "Training step:  1113\n",
      "Loss: 0.00807527042830766\n",
      "Training step:  1114\n",
      "Loss: 0.00806635036723744\n",
      "Training step:  1115\n",
      "Loss: 0.008075202643301247\n",
      "Training step:  1116\n",
      "Loss: 0.008066301719668304\n",
      "Training step:  1117\n",
      "Loss: 0.008075139275779207\n",
      "Training step:  1118\n",
      "Loss: 0.0080662537052898\n",
      "Training step:  1119\n",
      "Loss: 0.008074905542938155\n",
      "Training step:  1120\n",
      "Loss: 0.008066207592886987\n",
      "Training step:  1121\n",
      "Loss: 0.0080748443818502\n",
      "Training step:  1122\n",
      "Loss: 0.008066159538166516\n",
      "Training step:  1123\n",
      "Loss: 0.008074783368122092\n",
      "Training step:  1124\n",
      "Loss: 0.008066111354021278\n",
      "Training step:  1125\n",
      "Loss: 0.00807472247974496\n",
      "Training step:  1126\n",
      "Loss: 0.008066063372032396\n",
      "Training step:  1127\n",
      "Loss: 0.008074661655937346\n",
      "Training step:  1128\n",
      "Loss: 0.008066015539264247\n",
      "Training step:  1129\n",
      "Loss: 0.008074600567590379\n",
      "Training step:  1130\n",
      "Loss: 0.008065967753411767\n",
      "Training step:  1131\n",
      "Loss: 0.008073119104805727\n",
      "Training step:  1132\n",
      "Loss: 0.00806600563276293\n",
      "Training step:  1133\n",
      "Loss: 0.008072887781760638\n",
      "Training step:  1134\n",
      "Loss: 0.008065957503730774\n",
      "Training step:  1135\n",
      "Loss: 0.008072829137844921\n",
      "Training step:  1136\n",
      "Loss: 0.00806590882714723\n",
      "Training step:  1137\n",
      "Loss: 0.008072770654876762\n",
      "Training step:  1138\n",
      "Loss: 0.008065860693592613\n",
      "Training step:  1139\n",
      "Loss: 0.00807271233761571\n",
      "Training step:  1140\n",
      "Loss: 0.008065802034337634\n",
      "Training step:  1141\n",
      "Loss: 0.008072654178731351\n",
      "Training step:  1142\n",
      "Loss: 0.008065225624160437\n",
      "Training step:  1143\n",
      "Loss: 0.00807243142632355\n",
      "Training step:  1144\n",
      "Loss: 0.008065178910182907\n",
      "Training step:  1145\n",
      "Loss: 0.008072373335063648\n",
      "Training step:  1146\n",
      "Loss: 0.008065131547574588\n",
      "Training step:  1147\n",
      "Loss: 0.008072315407264006\n",
      "Training step:  1148\n",
      "Loss: 0.008065084285228712\n",
      "Training step:  1149\n",
      "Loss: 0.008072257641324557\n",
      "Training step:  1150\n",
      "Loss: 0.00806503715848841\n",
      "Training step:  1151\n",
      "Loss: 0.00807220003599497\n",
      "Training step:  1152\n",
      "Loss: 0.008064990420784329\n",
      "Training step:  1153\n",
      "Loss: 0.008072142593804761\n",
      "Training step:  1154\n",
      "Loss: 0.008064943571791074\n",
      "Training step:  1155\n",
      "Loss: 0.008072085311670476\n",
      "Training step:  1156\n",
      "Loss: 0.008064896908701524\n",
      "Training step:  1157\n",
      "Loss: 0.008072028189430341\n",
      "Training step:  1158\n",
      "Loss: 0.00806485032806633\n",
      "Training step:  1159\n",
      "Loss: 0.008071971225700759\n",
      "Training step:  1160\n",
      "Loss: 0.008064803952196017\n",
      "Training step:  1161\n",
      "Loss: 0.008071914407938321\n",
      "Training step:  1162\n",
      "Loss: 0.008064758164761028\n",
      "Training step:  1163\n",
      "Loss: 0.008071857761154454\n",
      "Training step:  1164\n",
      "Loss: 0.008064712059412229\n",
      "Training step:  1165\n",
      "Loss: 0.008071801258337659\n",
      "Training step:  1166\n",
      "Loss: 0.0080646662321681\n",
      "Training step:  1167\n",
      "Loss: 0.00807174492432788\n",
      "Training step:  1168\n",
      "Loss: 0.008064620345530389\n",
      "Training step:  1169\n",
      "Loss: 0.008071688740132983\n",
      "Training step:  1170\n",
      "Loss: 0.008064574903361713\n",
      "Training step:  1171\n",
      "Loss: 0.008071632712382959\n",
      "Training step:  1172\n",
      "Loss: 0.00806452927965676\n",
      "Training step:  1173\n",
      "Loss: 0.008071576836456883\n",
      "Training step:  1174\n",
      "Loss: 0.008064483558442997\n",
      "Training step:  1175\n",
      "Loss: 0.00807152110897126\n",
      "Training step:  1176\n",
      "Loss: 0.008063936580809701\n",
      "Training step:  1177\n",
      "Loss: 0.008071308021592925\n",
      "Training step:  1178\n",
      "Loss: 0.008063891903319076\n",
      "Training step:  1179\n",
      "Loss: 0.008071252386680718\n",
      "Training step:  1180\n",
      "Loss: 0.008063847363977295\n",
      "Training step:  1181\n",
      "Loss: 0.00807119690594717\n",
      "Training step:  1182\n",
      "Loss: 0.008063802806293159\n",
      "Training step:  1183\n",
      "Loss: 0.008071141576978337\n",
      "Training step:  1184\n",
      "Loss: 0.008063758569770556\n",
      "Training step:  1185\n",
      "Loss: 0.008071086400374804\n",
      "Training step:  1186\n",
      "Loss: 0.008063714271243777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1187\n",
      "Loss: 0.008071031373531901\n",
      "Training step:  1188\n",
      "Loss: 0.008063670225911281\n",
      "Training step:  1189\n",
      "Loss: 0.008070976495872103\n",
      "Training step:  1190\n",
      "Loss: 0.008063626124114407\n",
      "Training step:  1191\n",
      "Loss: 0.00807092176032832\n",
      "Training step:  1192\n",
      "Loss: 0.008063582457194442\n",
      "Training step:  1193\n",
      "Loss: 0.008070867172850776\n",
      "Training step:  1194\n",
      "Loss: 0.008063539009524768\n",
      "Training step:  1195\n",
      "Loss: 0.008070812729700352\n",
      "Training step:  1196\n",
      "Loss: 0.008063495412852046\n",
      "Training step:  1197\n",
      "Loss: 0.008070758424195005\n",
      "Training step:  1198\n",
      "Loss: 0.008063452017567108\n",
      "Training step:  1199\n",
      "Loss: 0.008070704251379481\n",
      "Training step:  1200\n",
      "Loss: 0.0080634086052882\n",
      "Training step:  1201\n",
      "Loss: 0.008070650200514123\n",
      "Training step:  1202\n",
      "Loss: 0.008063365674953409\n",
      "Training step:  1203\n",
      "Loss: 0.008070596259917217\n",
      "Training step:  1204\n",
      "Loss: 0.008063322509391128\n",
      "Training step:  1205\n",
      "Loss: 0.00807054239595201\n",
      "Training step:  1206\n",
      "Loss: 0.008063279390097886\n",
      "Training step:  1207\n",
      "Loss: 0.008070488525878126\n",
      "Training step:  1208\n",
      "Loss: 0.008063236247010743\n",
      "Training step:  1209\n",
      "Loss: 0.008070434283051108\n",
      "Training step:  1210\n",
      "Loss: 0.00806271710457143\n",
      "Training step:  1211\n",
      "Loss: 0.00807023048973479\n",
      "Training step:  1212\n",
      "Loss: 0.008062673595566384\n",
      "Training step:  1213\n",
      "Loss: 0.008070177149603933\n",
      "Training step:  1214\n",
      "Loss: 0.008062631675417173\n",
      "Training step:  1215\n",
      "Loss: 0.00807012394710255\n",
      "Training step:  1216\n",
      "Loss: 0.008062589816887237\n",
      "Training step:  1217\n",
      "Loss: 0.008070070868444386\n",
      "Training step:  1218\n",
      "Loss: 0.008062548060588629\n",
      "Training step:  1219\n",
      "Loss: 0.008070017900608316\n",
      "Training step:  1220\n",
      "Loss: 0.00806250623973678\n",
      "Training step:  1221\n",
      "Loss: 0.008069965013989691\n",
      "Training step:  1222\n",
      "Loss: 0.00806246474390762\n",
      "Training step:  1223\n",
      "Loss: 0.008069912151329748\n",
      "Training step:  1224\n",
      "Loss: 0.008062423538726243\n",
      "Training step:  1225\n",
      "Loss: 0.008069859100246242\n",
      "Training step:  1226\n",
      "Loss: 0.008062382297493169\n",
      "Training step:  1227\n",
      "Loss: 0.008069800454712341\n",
      "Training step:  1228\n",
      "Loss: 0.008062341083286488\n",
      "Training step:  1229\n",
      "Loss: 0.008069747490624184\n",
      "Training step:  1230\n",
      "Loss: 0.008062299904715062\n",
      "Training step:  1231\n",
      "Loss: 0.008069552188895799\n",
      "Training step:  1232\n",
      "Loss: 0.00806179495100699\n",
      "Training step:  1233\n",
      "Loss: 0.008069503413322804\n",
      "Training step:  1234\n",
      "Loss: 0.00806175442150876\n",
      "Training step:  1235\n",
      "Loss: 0.008069451416392974\n",
      "Training step:  1236\n",
      "Loss: 0.008061714058934681\n",
      "Training step:  1237\n",
      "Loss: 0.008069399520092032\n",
      "Training step:  1238\n",
      "Loss: 0.008061673654998778\n",
      "Training step:  1239\n",
      "Loss: 0.008069347686983613\n",
      "Training step:  1240\n",
      "Loss: 0.008061633772790231\n",
      "Training step:  1241\n",
      "Loss: 0.008069295848378868\n",
      "Training step:  1242\n",
      "Loss: 0.008061593830344537\n",
      "Training step:  1243\n",
      "Loss: 0.008069243643033002\n",
      "Training step:  1244\n",
      "Loss: 0.008061553935696013\n",
      "Training step:  1245\n",
      "Loss: 0.008069052084765662\n",
      "Training step:  1246\n",
      "Loss: 0.008061515787172293\n",
      "Training step:  1247\n",
      "Loss: 0.008069001205161486\n",
      "Training step:  1248\n",
      "Loss: 0.008061475913176434\n",
      "Training step:  1249\n",
      "Loss: 0.00806895046753982\n",
      "Training step:  1250\n",
      "Loss: 0.008061436288139318\n",
      "Training step:  1251\n",
      "Loss: 0.008068899871533697\n",
      "Training step:  1252\n",
      "Loss: 0.008061396620841595\n",
      "Training step:  1253\n",
      "Loss: 0.008068849416412333\n",
      "Training step:  1254\n",
      "Loss: 0.00806135714427492\n",
      "Training step:  1255\n",
      "Loss: 0.008068799102029128\n",
      "Training step:  1256\n",
      "Loss: 0.008061317591757357\n",
      "Training step:  1257\n",
      "Loss: 0.008068748927004736\n",
      "Training step:  1258\n",
      "Loss: 0.008061277862552875\n",
      "Training step:  1259\n",
      "Loss: 0.008068698890399881\n",
      "Training step:  1260\n",
      "Loss: 0.008060794435086652\n",
      "Training step:  1261\n",
      "Loss: 0.008068512962054478\n",
      "Training step:  1262\n",
      "Loss: 0.00805842769850589\n",
      "Training step:  1263\n",
      "Loss: 0.008067397293858736\n",
      "Training step:  1264\n",
      "Loss: 0.008057870507664945\n",
      "Training step:  1265\n",
      "Loss: 0.008067346759000355\n",
      "Training step:  1266\n",
      "Loss: 0.008057822682899415\n",
      "Training step:  1267\n",
      "Loss: 0.008067295457784462\n",
      "Training step:  1268\n",
      "Loss: 0.008057775279584583\n",
      "Training step:  1269\n",
      "Loss: 0.00806724435093069\n",
      "Training step:  1270\n",
      "Loss: 0.008057728198737546\n",
      "Training step:  1271\n",
      "Loss: 0.008067193433666705\n",
      "Training step:  1272\n",
      "Loss: 0.008057681534681865\n",
      "Training step:  1273\n",
      "Loss: 0.008067142701022744\n",
      "Training step:  1274\n",
      "Loss: 0.008057635320548078\n",
      "Training step:  1275\n",
      "Loss: 0.00806709214659457\n",
      "Training step:  1276\n",
      "Loss: 0.008057598996544601\n",
      "Training step:  1277\n",
      "Loss: 0.008067041719558467\n",
      "Training step:  1278\n",
      "Loss: 0.008057562552944767\n",
      "Training step:  1279\n",
      "Loss: 0.008066991417018625\n",
      "Training step:  1280\n",
      "Loss: 0.008057526414237787\n",
      "Training step:  1281\n",
      "Loss: 0.008066941247125016\n",
      "Training step:  1282\n",
      "Loss: 0.008057490143627452\n",
      "Training step:  1283\n",
      "Loss: 0.008066891204476541\n",
      "Training step:  1284\n",
      "Loss: 0.00805745383458053\n",
      "Training step:  1285\n",
      "Loss: 0.008066841284617689\n",
      "Training step:  1286\n",
      "Loss: 0.008057415119684214\n",
      "Training step:  1287\n",
      "Loss: 0.008066791478459404\n",
      "Training step:  1288\n",
      "Loss: 0.008057379371142984\n",
      "Training step:  1289\n",
      "Loss: 0.008066741779164586\n",
      "Training step:  1290\n",
      "Loss: 0.008057343176819724\n",
      "Training step:  1291\n",
      "Loss: 0.008066692164311785\n",
      "Training step:  1292\n",
      "Loss: 0.008057305527186183\n",
      "Training step:  1293\n",
      "Loss: 0.008066642597105426\n",
      "Training step:  1294\n",
      "Loss: 0.008057269754767843\n",
      "Training step:  1295\n",
      "Loss: 0.008066592845512312\n",
      "Training step:  1296\n",
      "Loss: 0.008057233625946686\n",
      "Training step:  1297\n",
      "Loss: 0.008065434853804215\n",
      "Training step:  1298\n",
      "Loss: 0.008057265134752566\n",
      "Training step:  1299\n",
      "Loss: 0.00806525014467041\n",
      "Training step:  1300\n",
      "Loss: 0.008056806691102656\n",
      "Training step:  1301\n",
      "Loss: 0.008065070245601881\n",
      "Training step:  1302\n",
      "Loss: 0.008056769434366513\n",
      "Training step:  1303\n",
      "Loss: 0.008065022009964298\n",
      "Training step:  1304\n",
      "Loss: 0.008056733718775558\n",
      "Training step:  1305\n",
      "Loss: 0.008064973401186332\n",
      "Training step:  1306\n",
      "Loss: 0.008056698637488102\n",
      "Training step:  1307\n",
      "Loss: 0.008064798217850406\n",
      "Training step:  1308\n",
      "Loss: 0.008056664677532943\n",
      "Training step:  1309\n",
      "Loss: 0.00806475088158508\n",
      "Training step:  1310\n",
      "Loss: 0.008056629212752625\n",
      "Training step:  1311\n",
      "Loss: 0.008064703667204567\n",
      "Training step:  1312\n",
      "Loss: 0.008056593740456131\n",
      "Training step:  1313\n",
      "Loss: 0.008064656592281281\n",
      "Training step:  1314\n",
      "Loss: 0.008056148356480088\n",
      "Training step:  1315\n",
      "Loss: 0.008064613095502373\n",
      "Training step:  1316\n",
      "Loss: 0.008056113672452993\n",
      "Training step:  1317\n",
      "Loss: 0.008064565593330799\n",
      "Training step:  1318\n",
      "Loss: 0.008056078903400798\n",
      "Training step:  1319\n",
      "Loss: 0.008064517797854163\n",
      "Training step:  1320\n",
      "Loss: 0.008056044150831252\n",
      "Training step:  1321\n",
      "Loss: 0.0080643484019961\n",
      "Training step:  1322\n",
      "Loss: 0.008056011485830428\n",
      "Training step:  1323\n",
      "Loss: 0.008064301765017694\n",
      "Training step:  1324\n",
      "Loss: 0.00805597680830291\n",
      "Training step:  1325\n",
      "Loss: 0.008064255247525373\n",
      "Training step:  1326\n",
      "Loss: 0.008055942807062877\n",
      "Training step:  1327\n",
      "Loss: 0.008064208867007918\n",
      "Training step:  1328\n",
      "Loss: 0.008055907925764648\n",
      "Training step:  1329\n",
      "Loss: 0.008064162609723279\n",
      "Training step:  1330\n",
      "Loss: 0.008053772284282605\n",
      "Training step:  1331\n",
      "Loss: 0.008063198341837295\n",
      "Training step:  1332\n",
      "Loss: 0.008053308704518463\n",
      "Training step:  1333\n",
      "Loss: 0.008063149934283574\n",
      "Training step:  1334\n",
      "Loss: 0.008053267765406399\n",
      "Training step:  1335\n",
      "Loss: 0.008063102738408346\n",
      "Training step:  1336\n",
      "Loss: 0.008053227246844704\n",
      "Training step:  1337\n",
      "Loss: 0.008063055705716485\n",
      "Training step:  1338\n",
      "Loss: 0.008053186876543283\n",
      "Training step:  1339\n",
      "Loss: 0.008063008830081984\n",
      "Training step:  1340\n",
      "Loss: 0.008053151754604656\n",
      "Training step:  1341\n",
      "Loss: 0.008062962094799732\n",
      "Training step:  1342\n",
      "Loss: 0.008053119383244574\n",
      "Training step:  1343\n",
      "Loss: 0.008062915479427836\n",
      "Training step:  1344\n",
      "Loss: 0.008053087055510177\n",
      "Training step:  1345\n",
      "Loss: 0.008062868986727837\n",
      "Training step:  1346\n",
      "Loss: 0.00805305404185556\n",
      "Training step:  1347\n",
      "Loss: 0.008062822614008718\n",
      "Training step:  1348\n",
      "Loss: 0.008053021201586831\n",
      "Training step:  1349\n",
      "Loss: 0.008062776359476992\n",
      "Training step:  1350\n",
      "Loss: 0.008052988260554452\n",
      "Training step:  1351\n",
      "Loss: 0.008062730218625833\n",
      "Training step:  1352\n",
      "Loss: 0.008052955745947119\n",
      "Training step:  1353\n",
      "Loss: 0.008062684191680011\n",
      "Training step:  1354\n",
      "Loss: 0.00805292236402894\n",
      "Training step:  1355\n",
      "Loss: 0.008062638271855835\n",
      "Training step:  1356\n",
      "Loss: 0.008052504431767565\n",
      "Training step:  1357\n",
      "Loss: 0.008062472382561525\n",
      "Training step:  1358\n",
      "Loss: 0.008052472709451915\n",
      "Training step:  1359\n",
      "Loss: 0.008062426568581658\n",
      "Training step:  1360\n",
      "Loss: 0.008052441744882479\n",
      "Training step:  1361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.008062380873250119\n",
      "Training step:  1362\n",
      "Loss: 0.008052410835814532\n",
      "Training step:  1363\n",
      "Loss: 0.008062335295529514\n",
      "Training step:  1364\n",
      "Loss: 0.008052380104406665\n",
      "Training step:  1365\n",
      "Loss: 0.008062289833566359\n",
      "Training step:  1366\n",
      "Loss: 0.0080523493110517\n",
      "Training step:  1367\n",
      "Loss: 0.00806224448296678\n",
      "Training step:  1368\n",
      "Loss: 0.008052318943102828\n",
      "Training step:  1369\n",
      "Loss: 0.008062199243875245\n",
      "Training step:  1370\n",
      "Loss: 0.008052288342299648\n",
      "Training step:  1371\n",
      "Loss: 0.008062154107668683\n",
      "Training step:  1372\n",
      "Loss: 0.008052257831811384\n",
      "Training step:  1373\n",
      "Loss: 0.00806210906427489\n",
      "Training step:  1374\n",
      "Loss: 0.008052227548453065\n",
      "Training step:  1375\n",
      "Loss: 0.008062064098667436\n",
      "Training step:  1376\n",
      "Loss: 0.008052197243233335\n",
      "Training step:  1377\n",
      "Loss: 0.008062019187271447\n",
      "Training step:  1378\n",
      "Loss: 0.008052167111537846\n",
      "Training step:  1379\n",
      "Loss: 0.008061974244633485\n",
      "Training step:  1380\n",
      "Loss: 0.008052135373598633\n",
      "Training step:  1381\n",
      "Loss: 0.00806192870365043\n",
      "Training step:  1382\n",
      "Loss: 0.00805210496634835\n",
      "Training step:  1383\n",
      "Loss: 0.008061769477447031\n",
      "Training step:  1384\n",
      "Loss: 0.00805169672971976\n",
      "Training step:  1385\n",
      "Loss: 0.008061727017070334\n",
      "Training step:  1386\n",
      "Loss: 0.008051667520374858\n",
      "Training step:  1387\n",
      "Loss: 0.008061682620052198\n",
      "Training step:  1388\n",
      "Loss: 0.008051638182998522\n",
      "Training step:  1389\n",
      "Loss: 0.008061638299520566\n",
      "Training step:  1390\n",
      "Loss: 0.008051608914062815\n",
      "Training step:  1391\n",
      "Loss: 0.008061594018473858\n",
      "Training step:  1392\n",
      "Loss: 0.00805157978305889\n",
      "Training step:  1393\n",
      "Loss: 0.008061549676138566\n",
      "Training step:  1394\n",
      "Loss: 0.00805155085463701\n",
      "Training step:  1395\n",
      "Loss: 0.008061504708342318\n",
      "Training step:  1396\n",
      "Loss: 0.008051521794227046\n",
      "Training step:  1397\n",
      "Loss: 0.008061348711849348\n",
      "Training step:  1398\n",
      "Loss: 0.008051494187003827\n",
      "Training step:  1399\n",
      "Loss: 0.00806130525220868\n",
      "Training step:  1400\n",
      "Loss: 0.008051465158667788\n",
      "Training step:  1401\n",
      "Loss: 0.008061261906970965\n",
      "Training step:  1402\n",
      "Loss: 0.008051436079422781\n",
      "Training step:  1403\n",
      "Loss: 0.008061218678445777\n",
      "Training step:  1404\n",
      "Loss: 0.008051407039952984\n",
      "Training step:  1405\n",
      "Loss: 0.008061175568197874\n",
      "Training step:  1406\n",
      "Loss: 0.008051376449434077\n",
      "Training step:  1407\n",
      "Loss: 0.008061132572476516\n",
      "Training step:  1408\n",
      "Loss: 0.008050989867885947\n",
      "Training step:  1409\n",
      "Loss: 0.008061091835220273\n",
      "Training step:  1410\n",
      "Loss: 0.00805096199528971\n",
      "Training step:  1411\n",
      "Loss: 0.008060939040909258\n",
      "Training step:  1412\n",
      "Loss: 0.00805093526360135\n",
      "Training step:  1413\n",
      "Loss: 0.008060896203292929\n",
      "Training step:  1414\n",
      "Loss: 0.008050907353132483\n",
      "Training step:  1415\n",
      "Loss: 0.00806085348067611\n",
      "Training step:  1416\n",
      "Loss: 0.008050879507223035\n",
      "Training step:  1417\n",
      "Loss: 0.00806081087204141\n",
      "Training step:  1418\n",
      "Loss: 0.008050851556473497\n",
      "Training step:  1419\n",
      "Loss: 0.008060768370242935\n",
      "Training step:  1420\n",
      "Loss: 0.008050823822505404\n",
      "Training step:  1421\n",
      "Loss: 0.00806072597860144\n",
      "Training step:  1422\n",
      "Loss: 0.00805079634421355\n",
      "Training step:  1423\n",
      "Loss: 0.008060683704968612\n",
      "Training step:  1424\n",
      "Loss: 0.008050768646244568\n",
      "Training step:  1425\n",
      "Loss: 0.008060641525449986\n",
      "Training step:  1426\n",
      "Loss: 0.008050741189806594\n",
      "Training step:  1427\n",
      "Loss: 0.008060599468844345\n",
      "Training step:  1428\n",
      "Loss: 0.008050713715073753\n",
      "Training step:  1429\n",
      "Loss: 0.008060557519178916\n",
      "Training step:  1430\n",
      "Loss: 0.008050686055753424\n",
      "Training step:  1431\n",
      "Loss: 0.008060515672085858\n",
      "Training step:  1432\n",
      "Loss: 0.008050657944593866\n",
      "Training step:  1433\n",
      "Loss: 0.008060473924292912\n",
      "Training step:  1434\n",
      "Loss: 0.008050630049903933\n",
      "Training step:  1435\n",
      "Loss: 0.008060432271251083\n",
      "Training step:  1436\n",
      "Loss: 0.008050601972815454\n",
      "Training step:  1437\n",
      "Loss: 0.008060390681231766\n",
      "Training step:  1438\n",
      "Loss: 0.00805057416525357\n",
      "Training step:  1439\n",
      "Loss: 0.008060349159659561\n",
      "Training step:  1440\n",
      "Loss: 0.008050546468588028\n",
      "Training step:  1441\n",
      "Loss: 0.008060307568987745\n",
      "Training step:  1442\n",
      "Loss: 0.0080505180263011\n",
      "Training step:  1443\n",
      "Loss: 0.008060259422117995\n",
      "Training step:  1444\n",
      "Loss: 0.008050152250272545\n",
      "Training step:  1445\n",
      "Loss: 0.008060114284951181\n",
      "Training step:  1446\n",
      "Loss: 0.008050126405645638\n",
      "Training step:  1447\n",
      "Loss: 0.00805918301102712\n",
      "Training step:  1448\n",
      "Loss: 0.008048349598607\n",
      "Training step:  1449\n",
      "Loss: 0.008058353000778768\n",
      "Training step:  1450\n",
      "Loss: 0.008047983585153755\n",
      "Training step:  1451\n",
      "Loss: 0.008058206335217316\n",
      "Training step:  1452\n",
      "Loss: 0.008047950937615083\n",
      "Training step:  1453\n",
      "Loss: 0.008058165174773554\n",
      "Training step:  1454\n",
      "Loss: 0.008047919472812488\n",
      "Training step:  1455\n",
      "Loss: 0.008058124028795487\n",
      "Training step:  1456\n",
      "Loss: 0.008047893357996843\n",
      "Training step:  1457\n",
      "Loss: 0.008058082758814302\n",
      "Training step:  1458\n",
      "Loss: 0.00804786639947389\n",
      "Training step:  1459\n",
      "Loss: 0.008058037528142834\n",
      "Training step:  1460\n",
      "Loss: 0.00804784036713016\n",
      "Training step:  1461\n",
      "Loss: 0.00805799624537072\n",
      "Training step:  1462\n",
      "Loss: 0.008047812702551128\n",
      "Training step:  1463\n",
      "Loss: 0.008057854151933627\n",
      "Training step:  1464\n",
      "Loss: 0.008047452357379876\n",
      "Training step:  1465\n",
      "Loss: 0.00805781633417152\n",
      "Training step:  1466\n",
      "Loss: 0.008047427426770217\n",
      "Training step:  1467\n",
      "Loss: 0.008057775822327463\n",
      "Training step:  1468\n",
      "Loss: 0.008047402350087236\n",
      "Training step:  1469\n",
      "Loss: 0.008057735373157293\n",
      "Training step:  1470\n",
      "Loss: 0.008047377502651491\n",
      "Training step:  1471\n",
      "Loss: 0.008057694951653534\n",
      "Training step:  1472\n",
      "Loss: 0.008047352617263134\n",
      "Training step:  1473\n",
      "Loss: 0.008057654444998542\n",
      "Training step:  1474\n",
      "Loss: 0.00804732801167037\n",
      "Training step:  1475\n",
      "Loss: 0.00805761312418527\n",
      "Training step:  1476\n",
      "Loss: 0.008047303424729582\n",
      "Training step:  1477\n",
      "Loss: 0.008057474102492397\n",
      "Training step:  1478\n",
      "Loss: 0.008047279977015017\n",
      "Training step:  1479\n",
      "Loss: 0.008057434444984945\n",
      "Training step:  1480\n",
      "Loss: 0.008047255460076293\n",
      "Training step:  1481\n",
      "Loss: 0.008057394894796465\n",
      "Training step:  1482\n",
      "Loss: 0.008047230832017993\n",
      "Training step:  1483\n",
      "Loss: 0.008057355450288831\n",
      "Training step:  1484\n",
      "Loss: 0.00804720614627143\n",
      "Training step:  1485\n",
      "Loss: 0.008057316109907382\n",
      "Training step:  1486\n",
      "Loss: 0.008047181278621814\n",
      "Training step:  1487\n",
      "Loss: 0.008057276874682233\n",
      "Training step:  1488\n",
      "Loss: 0.0080471554874374\n",
      "Training step:  1489\n",
      "Loss: 0.008057237743433752\n",
      "Training step:  1490\n",
      "Loss: 0.00804713087693481\n",
      "Training step:  1491\n",
      "Loss: 0.008057198702815667\n",
      "Training step:  1492\n",
      "Loss: 0.008047105896354559\n",
      "Training step:  1493\n",
      "Loss: 0.008057159776975444\n",
      "Training step:  1494\n",
      "Loss: 0.008047080820983587\n",
      "Training step:  1495\n",
      "Loss: 0.008057120954651156\n",
      "Training step:  1496\n",
      "Loss: 0.00804674191633712\n",
      "Training step:  1497\n",
      "Loss: 0.008056986817218018\n",
      "Training step:  1498\n",
      "Loss: 0.008046719372133334\n",
      "Training step:  1499\n",
      "Loss: 0.008056948042069259\n",
      "Training step:  1500\n",
      "Loss: 0.008046695791406508\n",
      "Training step:  1501\n",
      "Loss: 0.008056909370166484\n",
      "Training step:  1502\n",
      "Loss: 0.0080466722376266\n",
      "Training step:  1503\n",
      "Loss: 0.00805687079706651\n",
      "Training step:  1504\n",
      "Loss: 0.008046648958805743\n",
      "Training step:  1505\n",
      "Loss: 0.008056832321384145\n",
      "Training step:  1506\n",
      "Loss: 0.008046625754587615\n",
      "Training step:  1507\n",
      "Loss: 0.008056793956388085\n",
      "Training step:  1508\n",
      "Loss: 0.008046602475357793\n",
      "Training step:  1509\n",
      "Loss: 0.008056755692985938\n",
      "Training step:  1510\n",
      "Loss: 0.008046579314085001\n",
      "Training step:  1511\n",
      "Loss: 0.008056717530827508\n",
      "Training step:  1512\n",
      "Loss: 0.00804655617670966\n",
      "Training step:  1513\n",
      "Loss: 0.00805667946954207\n",
      "Training step:  1514\n",
      "Loss: 0.008046533084044372\n",
      "Training step:  1515\n",
      "Loss: 0.008056641508996161\n",
      "Training step:  1516\n",
      "Loss: 0.008046510023629971\n",
      "Training step:  1517\n",
      "Loss: 0.008056603647020703\n",
      "Training step:  1518\n",
      "Loss: 0.008046486980745515\n",
      "Training step:  1519\n",
      "Loss: 0.00805656588626918\n",
      "Training step:  1520\n",
      "Loss: 0.008046463688696158\n",
      "Training step:  1521\n",
      "Loss: 0.008056528224698378\n",
      "Training step:  1522\n",
      "Loss: 0.008046439646689491\n",
      "Training step:  1523\n",
      "Loss: 0.008056490662094766\n",
      "Training step:  1524\n",
      "Loss: 0.00804641658777868\n",
      "Training step:  1525\n",
      "Loss: 0.008056453194611625\n",
      "Training step:  1526\n",
      "Loss: 0.008046392985163455\n",
      "Training step:  1527\n",
      "Loss: 0.00805641582637476\n",
      "Training step:  1528\n",
      "Loss: 0.008046369952237538\n",
      "Training step:  1529\n",
      "Loss: 0.0080563785557747\n",
      "Training step:  1530\n",
      "Loss: 0.00804634578188625\n",
      "Training step:  1531\n",
      "Loss: 0.008056341381367795\n",
      "Training step:  1532\n",
      "Loss: 0.008046025141143378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1533\n",
      "Loss: 0.008056213050833979\n",
      "Training step:  1534\n",
      "Loss: 0.008046003320945587\n",
      "Training step:  1535\n",
      "Loss: 0.008056175926935515\n",
      "Training step:  1536\n",
      "Loss: 0.008045981342512717\n",
      "Training step:  1537\n",
      "Loss: 0.008056138900291152\n",
      "Training step:  1538\n",
      "Loss: 0.008045959342062018\n",
      "Training step:  1539\n",
      "Loss: 0.008056101966332354\n",
      "Training step:  1540\n",
      "Loss: 0.008045937629921486\n",
      "Training step:  1541\n",
      "Loss: 0.008056065132803695\n",
      "Training step:  1542\n",
      "Loss: 0.008045915805894142\n",
      "Training step:  1543\n",
      "Loss: 0.008056028394034803\n",
      "Training step:  1544\n",
      "Loss: 0.008045894231493282\n",
      "Training step:  1545\n",
      "Loss: 0.00805599175192588\n",
      "Training step:  1546\n",
      "Loss: 0.008045872551514165\n",
      "Training step:  1547\n",
      "Loss: 0.00805595520461073\n",
      "Training step:  1548\n",
      "Loss: 0.00804585085519912\n",
      "Training step:  1549\n",
      "Loss: 0.00805591874254456\n",
      "Training step:  1550\n",
      "Loss: 0.00804582956193513\n",
      "Training step:  1551\n",
      "Loss: 0.008055882382978274\n",
      "Training step:  1552\n",
      "Loss: 0.008045807997490653\n",
      "Training step:  1553\n",
      "Loss: 0.008055846115714733\n",
      "Training step:  1554\n",
      "Loss: 0.008045786407165975\n",
      "Training step:  1555\n",
      "Loss: 0.008055809940340825\n",
      "Training step:  1556\n",
      "Loss: 0.008045764463264606\n",
      "Training step:  1557\n",
      "Loss: 0.00805577385477511\n",
      "Training step:  1558\n",
      "Loss: 0.008045742323394982\n",
      "Training step:  1559\n",
      "Loss: 0.008055737858114786\n",
      "Training step:  1560\n",
      "Loss: 0.008045720653332228\n",
      "Training step:  1561\n",
      "Loss: 0.008055701945137713\n",
      "Training step:  1562\n",
      "Loss: 0.008045698408814798\n",
      "Training step:  1563\n",
      "Loss: 0.0080556661196501\n",
      "Training step:  1564\n",
      "Loss: 0.008045676923228913\n",
      "Training step:  1565\n",
      "Loss: 0.008055630374397969\n",
      "Training step:  1566\n",
      "Loss: 0.008045654581561463\n",
      "Training step:  1567\n",
      "Loss: 0.008055594703851207\n",
      "Training step:  1568\n",
      "Loss: 0.00804535048717857\n",
      "Training step:  1569\n",
      "Loss: 0.008055471995920785\n",
      "Training step:  1570\n",
      "Loss: 0.008045329389898425\n",
      "Training step:  1571\n",
      "Loss: 0.008055436415938269\n",
      "Training step:  1572\n",
      "Loss: 0.008045308847910972\n",
      "Training step:  1573\n",
      "Loss: 0.00805540092227452\n",
      "Training step:  1574\n",
      "Loss: 0.008045288368713936\n",
      "Training step:  1575\n",
      "Loss: 0.008055365512684645\n",
      "Training step:  1576\n",
      "Loss: 0.008045268038052295\n",
      "Training step:  1577\n",
      "Loss: 0.00805533018551241\n",
      "Training step:  1578\n",
      "Loss: 0.008045247694633616\n",
      "Training step:  1579\n",
      "Loss: 0.008055294936471067\n",
      "Training step:  1580\n",
      "Loss: 0.00804522740317442\n",
      "Training step:  1581\n",
      "Loss: 0.008055259761079576\n",
      "Training step:  1582\n",
      "Loss: 0.008045207235904581\n",
      "Training step:  1583\n",
      "Loss: 0.008055224651037033\n",
      "Training step:  1584\n",
      "Loss: 0.00804518703006673\n",
      "Training step:  1585\n",
      "Loss: 0.008055189591030467\n",
      "Training step:  1586\n",
      "Loss: 0.00804516694239865\n",
      "Training step:  1587\n",
      "Loss: 0.00805515455462521\n",
      "Training step:  1588\n",
      "Loss: 0.008045146807929414\n",
      "Training step:  1589\n",
      "Loss: 0.00805511946558171\n",
      "Training step:  1590\n",
      "Loss: 0.008045126648950554\n",
      "Training step:  1591\n",
      "Loss: 0.008055083975559048\n",
      "Training step:  1592\n",
      "Loss: 0.008045105898500379\n",
      "Training step:  1593\n",
      "Loss: 0.008054966016803264\n",
      "Training step:  1594\n",
      "Loss: 0.008044809051744416\n",
      "Training step:  1595\n",
      "Loss: 0.008054220848930078\n",
      "Training step:  1596\n",
      "Loss: 0.008041496626308977\n",
      "Training step:  1597\n",
      "Loss: 0.008053677801806648\n",
      "Training step:  1598\n",
      "Loss: 0.008041259415353693\n",
      "Training step:  1599\n",
      "Loss: 0.008052975944994885\n",
      "Training step:  1600\n",
      "Loss: 0.008041206852648006\n",
      "Training step:  1601\n",
      "Loss: 0.008052854048958181\n",
      "Training step:  1602\n",
      "Loss: 0.008041186104751222\n",
      "Training step:  1603\n",
      "Loss: 0.008052733457610782\n",
      "Training step:  1604\n",
      "Loss: 0.008040899686626204\n",
      "Training step:  1605\n",
      "Loss: 0.008052616128457287\n",
      "Training step:  1606\n",
      "Loss: 0.008040881743444472\n",
      "Training step:  1607\n",
      "Loss: 0.00805258085183544\n",
      "Training step:  1608\n",
      "Loss: 0.008040863980002843\n",
      "Training step:  1609\n",
      "Loss: 0.008052545664076228\n",
      "Training step:  1610\n",
      "Loss: 0.008040846217404257\n",
      "Training step:  1611\n",
      "Loss: 0.008052510565709436\n",
      "Training step:  1612\n",
      "Loss: 0.008040828625995072\n",
      "Training step:  1613\n",
      "Loss: 0.00805247555560641\n",
      "Training step:  1614\n",
      "Loss: 0.008040810935336493\n",
      "Training step:  1615\n",
      "Loss: 0.008052440629556077\n",
      "Training step:  1616\n",
      "Loss: 0.008040793398139377\n",
      "Training step:  1617\n",
      "Loss: 0.00805240578560177\n",
      "Training step:  1618\n",
      "Loss: 0.00804077616258612\n",
      "Training step:  1619\n",
      "Loss: 0.008052371035733516\n",
      "Training step:  1620\n",
      "Loss: 0.0080407586940699\n",
      "Training step:  1621\n",
      "Loss: 0.008052336369003356\n",
      "Training step:  1622\n",
      "Loss: 0.008040741399520449\n",
      "Training step:  1623\n",
      "Loss: 0.008052301786108263\n",
      "Training step:  1624\n",
      "Loss: 0.008040724027138393\n",
      "Training step:  1625\n",
      "Loss: 0.008052267279109546\n",
      "Training step:  1626\n",
      "Loss: 0.008040706791043531\n",
      "Training step:  1627\n",
      "Loss: 0.008052232853810072\n",
      "Training step:  1628\n",
      "Loss: 0.00804068969357651\n",
      "Training step:  1629\n",
      "Loss: 0.008052198502558923\n",
      "Training step:  1630\n",
      "Loss: 0.008040672482420103\n",
      "Training step:  1631\n",
      "Loss: 0.008052164216775104\n",
      "Training step:  1632\n",
      "Loss: 0.008040655350587816\n",
      "Training step:  1633\n",
      "Loss: 0.008052129976240698\n",
      "Training step:  1634\n",
      "Loss: 0.008040638477777739\n",
      "Training step:  1635\n",
      "Loss: 0.008052095775985379\n",
      "Training step:  1636\n",
      "Loss: 0.008040621317243575\n",
      "Training step:  1637\n",
      "Loss: 0.008052061537299336\n",
      "Training step:  1638\n",
      "Loss: 0.008040603264520474\n",
      "Training step:  1639\n",
      "Loss: 0.008052026762447621\n",
      "Training step:  1640\n",
      "Loss: 0.0080403315212087\n",
      "Training step:  1641\n",
      "Loss: 0.008051914536047899\n",
      "Training step:  1642\n",
      "Loss: 0.00804031419712003\n",
      "Training step:  1643\n",
      "Loss: 0.008051880676763015\n",
      "Training step:  1644\n",
      "Loss: 0.008040297723773958\n",
      "Training step:  1645\n",
      "Loss: 0.00805184688757753\n",
      "Training step:  1646\n",
      "Loss: 0.008040281191507763\n",
      "Training step:  1647\n",
      "Loss: 0.00805181315865774\n",
      "Training step:  1648\n",
      "Loss: 0.008040264755600978\n",
      "Training step:  1649\n",
      "Loss: 0.0080517794739818\n",
      "Training step:  1650\n",
      "Loss: 0.008040248427393175\n",
      "Training step:  1651\n",
      "Loss: 0.008051745797294724\n",
      "Training step:  1652\n",
      "Loss: 0.008040232180954576\n",
      "Training step:  1653\n",
      "Loss: 0.008051712022057116\n",
      "Training step:  1654\n",
      "Loss: 0.008040215951502928\n",
      "Training step:  1655\n",
      "Loss: 0.008051677244440525\n",
      "Training step:  1656\n",
      "Loss: 0.008040199775227682\n",
      "Training step:  1657\n",
      "Loss: 0.008051571293572266\n",
      "Training step:  1658\n",
      "Loss: 0.00803993601392372\n",
      "Training step:  1659\n",
      "Loss: 0.008051540210302542\n",
      "Training step:  1660\n",
      "Loss: 0.008039920131156378\n",
      "Training step:  1661\n",
      "Loss: 0.008051506906754857\n",
      "Training step:  1662\n",
      "Loss: 0.008039904242007092\n",
      "Training step:  1663\n",
      "Loss: 0.00805147360698484\n",
      "Training step:  1664\n",
      "Loss: 0.008039888547841907\n",
      "Training step:  1665\n",
      "Loss: 0.008051440195178993\n",
      "Training step:  1666\n",
      "Loss: 0.008039872803602098\n",
      "Training step:  1667\n",
      "Loss: 0.008051405543620275\n",
      "Training step:  1668\n",
      "Loss: 0.008039857120100994\n",
      "Training step:  1669\n",
      "Loss: 0.00805136521520456\n",
      "Training step:  1670\n",
      "Loss: 0.008039841490941424\n",
      "Training step:  1671\n",
      "Loss: 0.008051332332954391\n",
      "Training step:  1672\n",
      "Loss: 0.008039825966932696\n",
      "Training step:  1673\n",
      "Loss: 0.008051299447323622\n",
      "Training step:  1674\n",
      "Loss: 0.008039810520372925\n",
      "Training step:  1675\n",
      "Loss: 0.008051266416146952\n",
      "Training step:  1676\n",
      "Loss: 0.008039795036395465\n",
      "Training step:  1677\n",
      "Loss: 0.00805123089629049\n",
      "Training step:  1678\n",
      "Loss: 0.008039779705447269\n",
      "Training step:  1679\n",
      "Loss: 0.008051197838978962\n",
      "Training step:  1680\n",
      "Loss: 0.008039764370721528\n",
      "Training step:  1681\n",
      "Loss: 0.008051094447120615\n",
      "Training step:  1682\n",
      "Loss: 0.008039749909024261\n",
      "Training step:  1683\n",
      "Loss: 0.008051062290707716\n",
      "Training step:  1684\n",
      "Loss: 0.008039734496201696\n",
      "Training step:  1685\n",
      "Loss: 0.008051030211721408\n",
      "Training step:  1686\n",
      "Loss: 0.008039719091101358\n",
      "Training step:  1687\n",
      "Loss: 0.008050998214592774\n",
      "Training step:  1688\n",
      "Loss: 0.008039702564447925\n",
      "Training step:  1689\n",
      "Loss: 0.008050966298263542\n",
      "Training step:  1690\n",
      "Loss: 0.008039450576428585\n",
      "Training step:  1691\n",
      "Loss: 0.008050932030800295\n",
      "Training step:  1692\n",
      "Loss: 0.008039435774819418\n",
      "Training step:  1693\n",
      "Loss: 0.008050899766108434\n",
      "Training step:  1694\n",
      "Loss: 0.008039421015784224\n",
      "Training step:  1695\n",
      "Loss: 0.008050867105574106\n",
      "Training step:  1696\n",
      "Loss: 0.008039406258762831\n",
      "Training step:  1697\n",
      "Loss: 0.008050765064985806\n",
      "Training step:  1698\n",
      "Loss: 0.008039392394741803\n",
      "Training step:  1699\n",
      "Loss: 0.008050733386672063\n",
      "Training step:  1700\n",
      "Loss: 0.00803937762064996\n",
      "Training step:  1701\n",
      "Loss: 0.008050701749463185\n",
      "Training step:  1702\n",
      "Loss: 0.008039363137908165\n",
      "Training step:  1703\n",
      "Loss: 0.008050670145862244\n",
      "Training step:  1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.008039348533050073\n",
      "Training step:  1705\n",
      "Loss: 0.008050638402334852\n",
      "Training step:  1706\n",
      "Loss: 0.008039333979909576\n",
      "Training step:  1707\n",
      "Loss: 0.008050005395877646\n",
      "Training step:  1708\n",
      "Loss: 0.008039355545882353\n",
      "Training step:  1709\n",
      "Loss: 0.008049902708443768\n",
      "Training step:  1710\n",
      "Loss: 0.008039340710589805\n",
      "Training step:  1711\n",
      "Loss: 0.008049872105274088\n",
      "Training step:  1712\n",
      "Loss: 0.008039325798552802\n",
      "Training step:  1713\n",
      "Loss: 0.008049841580007593\n",
      "Training step:  1714\n",
      "Loss: 0.00803931085199398\n",
      "Training step:  1715\n",
      "Loss: 0.008049811133004738\n",
      "Training step:  1716\n",
      "Loss: 0.008039295828386866\n",
      "Training step:  1717\n",
      "Loss: 0.008049780760456546\n",
      "Training step:  1718\n",
      "Loss: 0.008039280576401167\n",
      "Training step:  1719\n",
      "Loss: 0.008049750466412946\n",
      "Training step:  1720\n",
      "Loss: 0.00803903940000823\n",
      "Training step:  1721\n",
      "Loss: 0.008049651667531495\n",
      "Training step:  1722\n",
      "Loss: 0.008039025057618223\n",
      "Training step:  1723\n",
      "Loss: 0.008049621416089975\n",
      "Training step:  1724\n",
      "Loss: 0.008039010524858205\n",
      "Training step:  1725\n",
      "Loss: 0.008049591239783688\n",
      "Training step:  1726\n",
      "Loss: 0.008038996088021944\n",
      "Training step:  1727\n",
      "Loss: 0.008049561139396333\n",
      "Training step:  1728\n",
      "Loss: 0.008038981612271612\n",
      "Training step:  1729\n",
      "Loss: 0.00804953111483638\n",
      "Training step:  1730\n",
      "Loss: 0.008038966966881046\n",
      "Training step:  1731\n",
      "Loss: 0.008049501167172016\n",
      "Training step:  1732\n",
      "Loss: 0.008037796688286702\n",
      "Training step:  1733\n",
      "Loss: 0.008048971981231603\n",
      "Training step:  1734\n",
      "Loss: 0.00803755139201718\n",
      "Training step:  1735\n",
      "Loss: 0.008048941165537768\n",
      "Training step:  1736\n",
      "Loss: 0.008037537877324247\n",
      "Training step:  1737\n",
      "Loss: 0.008048910688468903\n",
      "Training step:  1738\n",
      "Loss: 0.008037524405516586\n",
      "Training step:  1739\n",
      "Loss: 0.008048880255355738\n",
      "Training step:  1740\n",
      "Loss: 0.008037510951636578\n",
      "Training step:  1741\n",
      "Loss: 0.008048849837244616\n",
      "Training step:  1742\n",
      "Loss: 0.008037497679279092\n",
      "Training step:  1743\n",
      "Loss: 0.008048819376265804\n",
      "Training step:  1744\n",
      "Loss: 0.008037484291443877\n",
      "Training step:  1745\n",
      "Loss: 0.008048788534419258\n",
      "Training step:  1746\n",
      "Loss: 0.00803747089332306\n",
      "Training step:  1747\n",
      "Loss: 0.008048693350227785\n",
      "Training step:  1748\n",
      "Loss: 0.008037237189039018\n",
      "Training step:  1749\n",
      "Loss: 0.008048664748727856\n",
      "Training step:  1750\n",
      "Loss: 0.008037224221949668\n",
      "Training step:  1751\n",
      "Loss: 0.008048634654488632\n",
      "Training step:  1752\n",
      "Loss: 0.008037211318441317\n",
      "Training step:  1753\n",
      "Loss: 0.008048604581047912\n",
      "Training step:  1754\n",
      "Loss: 0.008037198410288294\n",
      "Training step:  1755\n",
      "Loss: 0.008048574465813231\n",
      "Training step:  1756\n",
      "Loss: 0.008037185597305103\n",
      "Training step:  1757\n",
      "Loss: 0.008048544027426123\n",
      "Training step:  1758\n",
      "Loss: 0.008037172826813961\n",
      "Training step:  1759\n",
      "Loss: 0.008048451074528673\n",
      "Training step:  1760\n",
      "Loss: 0.008037160781245643\n",
      "Training step:  1761\n",
      "Loss: 0.00804842154421583\n",
      "Training step:  1762\n",
      "Loss: 0.008037147904695367\n",
      "Training step:  1763\n",
      "Loss: 0.008048392083882711\n",
      "Training step:  1764\n",
      "Loss: 0.008037135121725165\n",
      "Training step:  1765\n",
      "Loss: 0.00804836270079727\n",
      "Training step:  1766\n",
      "Loss: 0.00803712219826627\n",
      "Training step:  1767\n",
      "Loss: 0.008048333391103142\n",
      "Training step:  1768\n",
      "Loss: 0.008037108897793245\n",
      "Training step:  1769\n",
      "Loss: 0.008048304151829479\n",
      "Training step:  1770\n",
      "Loss: 0.008037095922194626\n",
      "Training step:  1771\n",
      "Loss: 0.008048274986015036\n",
      "Training step:  1772\n",
      "Loss: 0.008037082672206541\n",
      "Training step:  1773\n",
      "Loss: 0.008048245892294165\n",
      "Training step:  1774\n",
      "Loss: 0.008037069654524668\n",
      "Training step:  1775\n",
      "Loss: 0.008048216872248095\n",
      "Training step:  1776\n",
      "Loss: 0.008037055666656679\n",
      "Training step:  1777\n",
      "Loss: 0.008048187922952503\n",
      "Training step:  1778\n",
      "Loss: 0.008036834995041585\n",
      "Training step:  1779\n",
      "Loss: 0.008048096666572939\n",
      "Training step:  1780\n",
      "Loss: 0.008036823420627039\n",
      "Training step:  1781\n",
      "Loss: 0.00804806775069202\n",
      "Training step:  1782\n",
      "Loss: 0.008036811262094181\n",
      "Training step:  1783\n",
      "Loss: 0.008048038905999387\n",
      "Training step:  1784\n",
      "Loss: 0.008036799197072416\n",
      "Training step:  1785\n",
      "Loss: 0.008048010133265454\n",
      "Training step:  1786\n",
      "Loss: 0.008036787149874701\n",
      "Training step:  1787\n",
      "Loss: 0.008047981431585095\n",
      "Training step:  1788\n",
      "Loss: 0.00803677511562657\n",
      "Training step:  1789\n",
      "Loss: 0.00804795280007549\n",
      "Training step:  1790\n",
      "Loss: 0.008036763112157163\n",
      "Training step:  1791\n",
      "Loss: 0.00804792423646062\n",
      "Training step:  1792\n",
      "Loss: 0.008036751270042695\n",
      "Training step:  1793\n",
      "Loss: 0.008047895745510552\n",
      "Training step:  1794\n",
      "Loss: 0.008036739343710247\n",
      "Training step:  1795\n",
      "Loss: 0.008047867323843149\n",
      "Training step:  1796\n",
      "Loss: 0.008036727517665022\n",
      "Training step:  1797\n",
      "Loss: 0.008047838971748149\n",
      "Training step:  1798\n",
      "Loss: 0.008036715640929936\n",
      "Training step:  1799\n",
      "Loss: 0.008047810689061238\n",
      "Training step:  1800\n",
      "Loss: 0.008036703721925076\n",
      "Training step:  1801\n",
      "Loss: 0.008047782473947935\n",
      "Training step:  1802\n",
      "Loss: 0.008036691714881547\n",
      "Training step:  1803\n",
      "Loss: 0.008047754324607484\n",
      "Training step:  1804\n",
      "Loss: 0.00803667946675486\n",
      "Training step:  1805\n",
      "Loss: 0.008047726244773233\n",
      "Training step:  1806\n",
      "Loss: 0.008036667478696056\n",
      "Training step:  1807\n",
      "Loss: 0.008047698232101257\n",
      "Training step:  1808\n",
      "Loss: 0.008036655169432826\n",
      "Training step:  1809\n",
      "Loss: 0.008047670285033968\n",
      "Training step:  1810\n",
      "Loss: 0.008036643202158102\n",
      "Training step:  1811\n",
      "Loss: 0.00804764240348596\n",
      "Training step:  1812\n",
      "Loss: 0.008036630633361184\n",
      "Training step:  1813\n",
      "Loss: 0.008047614584843535\n",
      "Training step:  1814\n",
      "Loss: 0.008036421868040483\n",
      "Training step:  1815\n",
      "Loss: 0.008047351197637949\n",
      "Training step:  1816\n",
      "Loss: 0.008036212894742443\n",
      "Training step:  1817\n",
      "Loss: 0.008047324121439223\n",
      "Training step:  1818\n",
      "Loss: 0.008036201785787815\n",
      "Training step:  1819\n",
      "Loss: 0.008047296394672512\n",
      "Training step:  1820\n",
      "Loss: 0.008036190701287376\n",
      "Training step:  1821\n",
      "Loss: 0.008047268733164352\n",
      "Training step:  1822\n",
      "Loss: 0.0080361796077892\n",
      "Training step:  1823\n",
      "Loss: 0.008047241135841566\n",
      "Training step:  1824\n",
      "Loss: 0.008036168530573125\n",
      "Training step:  1825\n",
      "Loss: 0.00804721359955859\n",
      "Training step:  1826\n",
      "Loss: 0.00803615756015014\n",
      "Training step:  1827\n",
      "Loss: 0.008047186125885609\n",
      "Training step:  1828\n",
      "Loss: 0.008036146650047371\n",
      "Training step:  1829\n",
      "Loss: 0.00804715871307249\n",
      "Training step:  1830\n",
      "Loss: 0.008036135745970818\n",
      "Training step:  1831\n",
      "Loss: 0.008047131356694395\n",
      "Training step:  1832\n",
      "Loss: 0.008036124958447206\n",
      "Training step:  1833\n",
      "Loss: 0.008047104062472301\n",
      "Training step:  1834\n",
      "Loss: 0.008036114083599126\n",
      "Training step:  1835\n",
      "Loss: 0.008047076822812483\n",
      "Training step:  1836\n",
      "Loss: 0.008036103348920246\n",
      "Training step:  1837\n",
      "Loss: 0.008047049636530081\n",
      "Training step:  1838\n",
      "Loss: 0.008036092530050193\n",
      "Training step:  1839\n",
      "Loss: 0.008047022494580504\n",
      "Training step:  1840\n",
      "Loss: 0.008036081872975331\n",
      "Training step:  1841\n",
      "Loss: 0.008046995395276455\n",
      "Training step:  1842\n",
      "Loss: 0.008036071133323504\n",
      "Training step:  1843\n",
      "Loss: 0.008046968323283424\n",
      "Training step:  1844\n",
      "Loss: 0.008036060365208883\n",
      "Training step:  1845\n",
      "Loss: 0.008046941247276437\n",
      "Training step:  1846\n",
      "Loss: 0.008036049634073242\n",
      "Training step:  1847\n",
      "Loss: 0.008046914092664127\n",
      "Training step:  1848\n",
      "Loss: 0.008036038689385742\n",
      "Training step:  1849\n",
      "Loss: 0.008046886092163384\n",
      "Training step:  1850\n",
      "Loss: 0.008036027644708338\n",
      "Training step:  1851\n",
      "Loss: 0.008046215204982821\n",
      "Training step:  1852\n",
      "Loss: 0.00803379198558077\n",
      "Training step:  1853\n",
      "Loss: 0.008043422455601723\n",
      "Training step:  1854\n",
      "Loss: 0.008032583626093773\n",
      "Training step:  1855\n",
      "Loss: 0.008043174449359277\n",
      "Training step:  1856\n",
      "Loss: 0.008032383851316764\n",
      "Training step:  1857\n",
      "Loss: 0.008042985998396096\n",
      "Training step:  1858\n",
      "Loss: 0.008032186334948822\n",
      "Training step:  1859\n",
      "Loss: 0.008042960004607386\n",
      "Training step:  1860\n",
      "Loss: 0.008032173925872032\n",
      "Training step:  1861\n",
      "Loss: 0.008042933474174393\n",
      "Training step:  1862\n",
      "Loss: 0.008032161576453761\n",
      "Training step:  1863\n",
      "Loss: 0.008042906996442856\n",
      "Training step:  1864\n",
      "Loss: 0.008032149326803658\n",
      "Training step:  1865\n",
      "Loss: 0.008042880556314438\n",
      "Training step:  1866\n",
      "Loss: 0.008032137223844786\n",
      "Training step:  1867\n",
      "Loss: 0.008042854103735973\n",
      "Training step:  1868\n",
      "Loss: 0.00803212520079776\n",
      "Training step:  1869\n",
      "Loss: 0.008042826904149099\n",
      "Training step:  1870\n",
      "Loss: 0.008032113295653035\n",
      "Training step:  1871\n",
      "Loss: 0.008042642776306591\n",
      "Training step:  1872\n",
      "Loss: 0.008031920299183171\n",
      "Training step:  1873\n",
      "Loss: 0.008042616802733937\n",
      "Training step:  1874\n",
      "Loss: 0.008031908593606972\n",
      "Training step:  1875\n",
      "Loss: 0.008042590723289294\n",
      "Training step:  1876\n",
      "Loss: 0.008031897013627418\n",
      "Training step:  1877\n",
      "Loss: 0.00804256468667997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:  1878\n",
      "Loss: 0.008031885589663513\n",
      "Training step:  1879\n",
      "Loss: 0.008042538698013833\n",
      "Training step:  1880\n",
      "Loss: 0.00803187420273855\n",
      "Training step:  1881\n",
      "Loss: 0.008042512736866746\n",
      "Training step:  1882\n",
      "Loss: 0.008031862943036799\n",
      "Training step:  1883\n",
      "Loss: 0.008042486778693719\n",
      "Training step:  1884\n",
      "Loss: 0.008031851744404107\n",
      "Training step:  1885\n",
      "Loss: 0.00804246075024588\n",
      "Training step:  1886\n",
      "Loss: 0.008031840689345364\n",
      "Training step:  1887\n",
      "Loss: 0.008042434152613489\n",
      "Training step:  1888\n",
      "Loss: 0.008031829756686508\n",
      "Training step:  1889\n",
      "Loss: 0.00804194927194594\n",
      "Training step:  1890\n",
      "Loss: 0.008031846400750667\n",
      "Training step:  1891\n",
      "Loss: 0.008041710759195393\n",
      "Training step:  1892\n",
      "Loss: 0.008031657273329058\n",
      "Training step:  1893\n",
      "Loss: 0.008041531582645494\n",
      "Training step:  1894\n",
      "Loss: 0.008031469670988802\n",
      "Training step:  1895\n",
      "Loss: 0.008041505887027954\n",
      "Training step:  1896\n",
      "Loss: 0.008031458732178632\n",
      "Training step:  1897\n",
      "Loss: 0.008041481001147365\n",
      "Training step:  1898\n",
      "Loss: 0.008031447930810813\n",
      "Training step:  1899\n",
      "Loss: 0.008041456162961806\n",
      "Training step:  1900\n",
      "Loss: 0.008031437132539862\n",
      "Training step:  1901\n",
      "Loss: 0.008041431356738285\n",
      "Training step:  1902\n",
      "Loss: 0.008031426554647775\n",
      "Training step:  1903\n",
      "Loss: 0.008041406574514586\n",
      "Training step:  1904\n",
      "Loss: 0.008031415938578477\n",
      "Training step:  1905\n",
      "Loss: 0.008041381780411304\n",
      "Training step:  1906\n",
      "Loss: 0.008031405450683158\n",
      "Training step:  1907\n",
      "Loss: 0.008041356862613334\n",
      "Training step:  1908\n",
      "Loss: 0.008031394931667164\n",
      "Training step:  1909\n",
      "Loss: 0.008040746181278332\n",
      "Training step:  1910\n",
      "Loss: 0.008031215242454648\n",
      "Training step:  1911\n",
      "Loss: 0.008040567833580897\n",
      "Training step:  1912\n",
      "Loss: 0.00803103230124286\n",
      "Training step:  1913\n",
      "Loss: 0.0080405429754571\n",
      "Training step:  1914\n",
      "Loss: 0.008031021859069181\n",
      "Training step:  1915\n",
      "Loss: 0.008040371321922455\n",
      "Training step:  1916\n",
      "Loss: 0.008030841349137254\n",
      "Training step:  1917\n",
      "Loss: 0.008040347330393778\n",
      "Training step:  1918\n",
      "Loss: 0.008030831102319948\n",
      "Training step:  1919\n",
      "Loss: 0.008040323435851003\n",
      "Training step:  1920\n",
      "Loss: 0.008030820986149304\n",
      "Training step:  1921\n",
      "Loss: 0.00804029959339828\n",
      "Training step:  1922\n",
      "Loss: 0.008030810925112562\n",
      "Training step:  1923\n",
      "Loss: 0.008040275799662834\n",
      "Training step:  1924\n",
      "Loss: 0.008030800975571078\n",
      "Training step:  1925\n",
      "Loss: 0.008040252052894976\n",
      "Training step:  1926\n",
      "Loss: 0.00803079104648381\n",
      "Training step:  1927\n",
      "Loss: 0.008040228347452393\n",
      "Training step:  1928\n",
      "Loss: 0.008030781230861926\n",
      "Training step:  1929\n",
      "Loss: 0.008040204677487436\n",
      "Training step:  1930\n",
      "Loss: 0.008030771514696323\n",
      "Training step:  1931\n",
      "Loss: 0.008040181032293543\n",
      "Training step:  1932\n",
      "Loss: 0.008030761876863206\n",
      "Training step:  1933\n",
      "Loss: 0.008040157388183481\n",
      "Training step:  1934\n",
      "Loss: 0.008030752241975352\n",
      "Training step:  1935\n",
      "Loss: 0.008040133667170464\n",
      "Training step:  1936\n",
      "Loss: 0.00803074269622347\n",
      "Training step:  1937\n",
      "Loss: 0.008040108028818247\n",
      "Training step:  1938\n",
      "Loss: 0.00803073321262903\n",
      "Training step:  1939\n",
      "Loss: 0.00803994232264317\n",
      "Training step:  1940\n",
      "Loss: 0.008029877895817073\n",
      "Training step:  1941\n",
      "Loss: 0.008037816353391762\n",
      "Training step:  1942\n",
      "Loss: 0.008028025727997934\n",
      "Training step:  1943\n",
      "Loss: 0.008037431839804066\n",
      "Training step:  1944\n",
      "Loss: 0.008028006828582993\n",
      "Training step:  1945\n",
      "Loss: 0.00803726596665302\n",
      "Training step:  1946\n",
      "Loss: 0.00802783520916258\n",
      "Training step:  1947\n",
      "Loss: 0.008037236882267467\n",
      "Training step:  1948\n",
      "Loss: 0.008027826186121434\n",
      "Training step:  1949\n",
      "Loss: 0.00803721359511992\n",
      "Training step:  1950\n",
      "Loss: 0.008027817279657807\n",
      "Training step:  1951\n",
      "Loss: 0.008037188816038687\n",
      "Training step:  1952\n",
      "Loss: 0.008027808317308274\n",
      "Training step:  1953\n",
      "Loss: 0.008037026636963375\n",
      "Training step:  1954\n",
      "Loss: 0.008027639472467351\n",
      "Training step:  1955\n",
      "Loss: 0.008037004668130452\n",
      "Training step:  1956\n",
      "Loss: 0.008027630649334547\n",
      "Training step:  1957\n",
      "Loss: 0.00803698172480638\n",
      "Training step:  1958\n",
      "Loss: 0.0080276218856556\n",
      "Training step:  1959\n",
      "Loss: 0.00803695880897213\n",
      "Training step:  1960\n",
      "Loss: 0.008027613121744995\n",
      "Training step:  1961\n",
      "Loss: 0.008036935901865576\n",
      "Training step:  1962\n",
      "Loss: 0.008027604354716321\n",
      "Training step:  1963\n",
      "Loss: 0.008036912964949433\n",
      "Training step:  1964\n",
      "Loss: 0.008027595699295864\n",
      "Training step:  1965\n",
      "Loss: 0.008036889870882958\n",
      "Training step:  1966\n",
      "Loss: 0.008027587000683012\n",
      "Training step:  1967\n",
      "Loss: 0.008036461846602913\n",
      "Training step:  1968\n",
      "Loss: 0.008027580869164264\n",
      "Training step:  1969\n",
      "Loss: 0.008036439652478052\n",
      "Training step:  1970\n",
      "Loss: 0.008027571809236621\n",
      "Training step:  1971\n",
      "Loss: 0.008036417510008276\n",
      "Training step:  1972\n",
      "Loss: 0.008027561810380385\n",
      "Training step:  1973\n",
      "Loss: 0.008036395413425735\n",
      "Training step:  1974\n",
      "Loss: 0.008027396650699193\n",
      "Training step:  1975\n",
      "Loss: 0.008036234651687192\n",
      "Training step:  1976\n",
      "Loss: 0.008027388118759748\n",
      "Training step:  1977\n",
      "Loss: 0.008036212645139764\n",
      "Training step:  1978\n",
      "Loss: 0.008027224045960584\n",
      "Training step:  1979\n",
      "Loss: 0.00803605733064422\n",
      "Training step:  1980\n",
      "Loss: 0.008027216848679132\n",
      "Training step:  1981\n",
      "Loss: 0.008036035388901455\n",
      "Training step:  1982\n",
      "Loss: 0.008027207646817615\n",
      "Training step:  1983\n",
      "Loss: 0.00803601348380802\n",
      "Training step:  1984\n",
      "Loss: 0.008027044882287976\n",
      "Training step:  1985\n",
      "Loss: 0.00803546603733891\n",
      "Training step:  1986\n",
      "Loss: 0.00802704021495327\n",
      "Training step:  1987\n",
      "Loss: 0.008035444611211702\n",
      "Training step:  1988\n",
      "Loss: 0.008027031382717377\n",
      "Training step:  1989\n",
      "Loss: 0.008035423235510384\n",
      "Training step:  1990\n",
      "Loss: 0.008027022524718375\n",
      "Training step:  1991\n",
      "Loss: 0.0080354019100854\n",
      "Training step:  1992\n",
      "Loss: 0.008027013717750374\n",
      "Training step:  1993\n",
      "Loss: 0.008035380634303244\n",
      "Training step:  1994\n",
      "Loss: 0.00802700487559981\n",
      "Training step:  1995\n",
      "Loss: 0.00803535940532254\n",
      "Training step:  1996\n",
      "Loss: 0.008026996209569256\n",
      "Training step:  1997\n",
      "Loss: 0.008035338226765412\n",
      "Training step:  1998\n",
      "Loss: 0.008026987440029503\n",
      "Training step:  1999\n",
      "Loss: 0.008035317095557713\n",
      "Loss_min: tensor(0.0080, grad_fn=<DivBackward0>)\n",
      "data: [1.2419559147115304, 1.063782581739103, 0.8912775107570564, 0.5466011231698928, 0.4289814357591683, 0.39055420845408706, 0.32361543073249827, 0.30153824099882376, 0.2941807766846997, 0.28072772055533185, 0.28488980452984874, 0.20504864459711408, 0.1792695877705031, 0.18857899745291548, 0.1731382891023198, 0.16922809834934383, 0.14492701585933437, 0.1108561003388775, 0.11689282919540735, 0.11136916223481351, 0.06866820349198244, 0.06804063754902916, 0.06039665149082543, 0.051289219789986185, 0.02825017013095354, 0.025741999802404283, 0.023072842572708887]\n",
      "[0.01267516 0.00779064]\n",
      "{'beta': 0.1679116505316233, 'gamma_2': 0.338044863926277, 'theta': 0.03287506106609283, 'alpha': 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新增治愈： [ 0  0  0  0  0  1  1  1  1  0  5  1  0  0  2  3 10  5 10  4  3  5  4  5\n",
      " 29 33 17 20 20 18 15 14 13]\n",
      "新增确诊： [ 5.  4.  8. 14.  6. 14. 12. 14. 21. 27. 26. 24. 16. 15. 25. 21. 15. 12.\n",
      " 10.  3.  7.  3.  7.  5.  9.  1.  4.  2.  2.  2.  1.  2.  2.]\n",
      "beta: [1.114430758150335, 1.0313983622922342, 0.944074949756139, 0.739324775163049, 0.654966744010082, 0.6249433641971783, 0.568872068863025, 0.5491249775768935, 0.5423843440630451, 0.5298374472942922, 0.5337506951094759, 0.4528229726914416, 0.42340239462065293, 0.43425683351320504, 0.4160988934163606, 0.4113734293185983, 0.3806928103593951, 0.3329505974448424, 0.3418959332829324, 0.33372018553694577, 0.2620461857993404, 0.26084600351362325, 0.24575730200916804, 0.22647123391280002, 0.16807786924801713, 0.16044313572853244, 0.15189747388521274, 0.1818759091922378]\n",
      "gamma_2: [-6.154907585661412e-05, 8.532062659925808e-05, 0.00024475620154740404, 0.019324277881804103, -0.1646117134587971, 0.0698599235599179, 0.19312958560784976, 0.12706076154657903, 0.11504545183605822, 0.009463158955579542, -0.18158178156346833, -0.08437196057749806, -4.099708189427541e-06, 2.759972323428947e-06, 0.10042935691760493, 0.11660612767057377, 0.2048262762566843, 0.14344055494352234, 0.2096364052157816, 0.10979206679810598, 0.126336293206156, 0.14052070604841596, 0.125798086810214, 0.1396169593083409, 0.3318210020416494, 0.37967318306729614, 0.28205059805452365, 0.3319534672824168]\n",
      "theta: [0.00011122637230688684, -0.00010445574743102128, -0.00017517783495887135, 0.0004059257353577316, -0.17395463844338377, -0.0004952889611620209, -0.00010231873846785818, 8.72660402484943e-05, -8.911651371579516e-05, -9.087010919631814e-05, -8.539563251930121e-05, 6.920454985883328e-05, 4.2212954644388044e-05, 1.532213138652334e-05, -1.8986524027387405e-05, -1.946888633287024e-05, -1.8321235894530322e-05, -2.1776110769468023e-05, -1.4277128201815314e-05, 1.6527959596662056e-05, -1.8716151674429464e-05, 9.193313669686655e-07, -1.3490458137170187e-06, 1.2127591420389507e-06, 1.5413068837060262e-06, -2.1631348207266037e-06, 1.097014851955485e-05, -0.0009094468603503727]\n",
      "alpha: [0.9914631227691135, 1.1664226176700114, 1.0571907926423676, 1.195912380478909, 1.012147032443015, 0.9662134354176426, 0.9046633069669759, 0.849847360906351, 0.9332713553801069, 1.0354307670235503, 1.0025912177685516, 0.8324262090280469, 0.6332097179771278, 0.5286709128192837, 0.5847113854792019, 0.5052417854006759, 0.3901707302282459, 0.3186799430009156, 0.28766009106607315, 0.1406937477530603, 0.1997938757979802, 0.1455969086021513, 0.1867663172193331, 0.15454936507881661, 0.19370913239559778, 0.09127373389774714, 0.12180648955977255, 0.0941278214170232]\n",
      "omega: [0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, 0.0, -0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "other_citys=['北京','上海']\n",
    "populatinos=[21540000.,24240000.,30480000.]\n",
    "param_date='0216'  #指定日期则加载指定日期的参数\n",
    "# for i in range(len(other_citys)):\n",
    "i=1\n",
    "city_name=other_citys[i]\n",
    "N=populatinos[i]\n",
    "#第一次训练\n",
    "# train_predict(N,city_name,param_date=param_date,load_param=False,lr_rate=0.01)\n",
    "train_predict(N,city_name,param_date=param_date,load_param=True,eprochs=2000,lr_rate=0.00007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北京\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/beijing/0217\\\\model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-b06d06b16666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_dict_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcity_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcity_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'I'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cured'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dead'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_date_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_dict_report\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dict_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-7b7909471ef0>\u001b[0m in \u001b[0;36mformat_output\u001b[1;34m(model_city_date_path, data, param_pred, city_name, c, features, pred_date_len, data_dict, data_dict_report)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mI_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecover_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdead_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel_pt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_city_date_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_pt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mI_tensor_cur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR_tensor_cur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/beijing/0217\\\\model.pt'"
     ]
    }
   ],
   "source": [
    "time='0217'\n",
    "citys=['北京','上海']\n",
    "paths=['./ncov/data/beijing_截至'+time+'_24时.csv','./ncov/data/shanghai_截至'+time+'_24时.csv']\n",
    "modelpath=['./models/beijing/'+time,'./models/shanghai/'+time]\n",
    "\n",
    "def init_data_dict(citys):\n",
    "    data_dict = dict.fromkeys(['累计','新增'])\n",
    "    for k in data_dict.keys():\n",
    "        data_dict[k] = dict.fromkeys(citys)\n",
    "        for dc in data_dict[k].keys():\n",
    "            data_dict[k][dc]=[]\n",
    "    return data_dict\n",
    "\n",
    "data_dict = init_data_dict(citys)\n",
    "data_dict_report = init_data_dict(citys)\n",
    "for i in range(len(citys)):\n",
    "    city_name=citys[i]\n",
    "    print(city_name)\n",
    "    data=read_data(paths[i])\n",
    "    data_dict,data_dict_report = format_output(modelpath[i], data, param_pred=True, city_name=city_name,features=['I','cured','dead'], pred_date_len=5, data_dict=data_dict,data_dict_report=data_dict_report)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(citys)):\n",
    "    city_name=citys[i]\n",
    "    if city_name=='全国':\n",
    "        continue\n",
    "    data=read_data(paths[i])\n",
    "    if city_name=='深圳':\n",
    "        data_dict = format_output(modelpath[i], data, param_pred=False, city_name=city_name,features=['I','cured','dead'], pred_date_len=5, data_dict=data_dict)\n",
    "    else:\n",
    "        data_dict = format_output(modelpath[i], data, param_pred=True, city_name=city_name,features=['I','cured','dead'], pred_date_len=5, data_dict=data_dict)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
